<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2024-05-03T10:03:58Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:9985210" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:9985210</identifier>
        <datestamp>2023-03-05</datestamp>
        <setSpec>bmcmedu</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" article-type="research-article" dtd-version="1.3">
          <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
            <restricted-by>pmc</restricted-by>
          </processing-meta>
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">BMC Med Educ</journal-id>
              <journal-id journal-id-type="iso-abbrev">BMC Med Educ</journal-id>
              <journal-title-group>
                <journal-title>BMC Medical Education</journal-title>
              </journal-title-group>
              <issn pub-type="epub">1472-6920</issn>
              <publisher>
                <publisher-name>BioMed Central</publisher-name>
                <publisher-loc>London</publisher-loc>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC9985210</article-id>
              <article-id pub-id-type="pmcid">PMC9985210</article-id>
              <article-id pub-id-type="pmc-uid">9985210</article-id>
              <article-id pub-id-type="pmid">36869306</article-id>
              <article-id pub-id-type="pmid">36869306</article-id>
              <article-id pub-id-type="publisher-id">4122</article-id>
              <article-id pub-id-type="doi">10.1186/s12909-023-04122-6</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Research</subject>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>Can mixed reality technologies teach surgical skills better than traditional methods? A prospective randomised feasibility study</article-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author">
                  <name>
                    <surname>Guha</surname>
                    <given-names>Payal</given-names>
                  </name>
                  <xref ref-type="aff" rid="Aff1"/>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Lawson</surname>
                    <given-names>Jason</given-names>
                  </name>
                  <xref ref-type="aff" rid="Aff1"/>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Minty</surname>
                    <given-names>Iona</given-names>
                  </name>
                  <xref ref-type="aff" rid="Aff1"/>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Kinross</surname>
                    <given-names>James</given-names>
                  </name>
                  <xref ref-type="aff" rid="Aff1"/>
                </contrib>
                <contrib contrib-type="author" corresp="yes">
                  <name>
                    <surname>Martin</surname>
                    <given-names>Guy</given-names>
                  </name>
                  <address>
                    <email>guy.martin@imperial.ac.uk</email>
                  </address>
                  <xref ref-type="aff" rid="Aff1"/>
                </contrib>
                <aff id="Aff1"><institution-wrap><institution-id institution-id-type="GRID">grid.7445.2</institution-id><institution-id institution-id-type="ISNI">0000 0001 2113 8111</institution-id><institution>Department of Surgery and Cancer, </institution><institution>Imperial College London, St Mary’s Hospital, </institution></institution-wrap>10th Floor QEQM Building, W2 1NY London, UK </aff>
              </contrib-group>
              <pub-date pub-type="epub">
                <day>3</day>
                <month>3</month>
                <year>2023</year>
              </pub-date>
              <pub-date pub-type="pmc-release">
                <day>3</day>
                <month>3</month>
                <year>2023</year>
              </pub-date>
              <pub-date pub-type="collection">
                <year>2023</year>
              </pub-date>
              <volume>23</volume>
              <elocation-id>144</elocation-id>
              <history>
                <date date-type="received">
                  <day>30</day>
                  <month>11</month>
                  <year>2022</year>
                </date>
                <date date-type="accepted">
                  <day>24</day>
                  <month>2</month>
                  <year>2023</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>© The Author(s) 2023</copyright-statement>
                <license>
                  <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
                  <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
                </license>
              </permissions>
              <abstract id="Abs2">
                <sec>
                  <title>Background</title>
                  <p id="Par1">Basic surgical skills teaching is often delivered with didactic audio-visual content, and new digital technologies may allow more engaging and effective ways of teaching to be developed. The Microsoft HoloLens 2 (HL2) is a multi-functional mixed reality headset. This prospective feasibility study sought to assess the device as a tool for enhancing technical surgical skills training.</p>
                </sec>
                <sec>
                  <title>Methods</title>
                  <p id="Par2">A prospective randomised feasibility study was conducted. 36 novice medical students were trained to perform a basic arteriotomy and closure using a synthetic model. Participants were randomised to receive a structured surgical skills tutorial via a bespoke mixed reality HL2 tutorial (n = 18), or via a standard video-based tutorial (n = 18). Proficiency scores were assessed by blinded examiners using a validated objective scoring system and participant feedback collected.</p>
                </sec>
                <sec>
                  <title>Results</title>
                  <p id="Par3">The HL2 group showed significantly greater improvement in overall technical proficiency compared to the video group (10.1 vs. 6.89, p = 0.0076), and a greater consistency in skill progression with a significantly narrower range of scores (SD 2.48 vs. 4.03, p = 0.026). Participant feedback showed the HL2 technology to be more interactive and engaging with minimal device related problems experienced.</p>
                </sec>
                <sec>
                  <title>Conclusions</title>
                  <p id="Par4">This study has demonstrated that mixed reality technology may provide a higher quality educational experience, improved skill progression and greater consistency in learning when compared to traditional teaching methodologies for basic surgical skills. Further work is required to refine, translate, and evaluate the scalability and applicability of the technology across a broad range of skills-based disciplines.</p>
                </sec>
                <sec>
                  <title>Supplementary Information</title>
                  <p>The online version contains supplementary material available at 10.1186/s12909-023-04122-6.</p>
                </sec>
              </abstract>
              <kwd-group xml:lang="en">
                <title>Keywords</title>
                <kwd>Mixed reality</kwd>
                <kwd>Clinical competence</kwd>
                <kwd>Technology assessment</kwd>
                <kwd>Medical education</kwd>
              </kwd-group>
              <custom-meta-group>
                <custom-meta>
                  <meta-name>issue-copyright-statement</meta-name>
                  <meta-value>© The Author(s) 2023</meta-value>
                </custom-meta>
              </custom-meta-group>
            </article-meta>
          </front>
          <body>
            <sec id="Sec1">
              <title>Background</title>
              <p id="Par5">Current approaches to surgical skills training commonly utilise the support of didactic video tutorials as these have been shown to effectively teach basic skills such as suturing [<xref ref-type="bibr" rid="CR1">1</xref>]. However, these techniques may disadvantage kinaesthetic learners and provide limited scope for the development of novel teaching approaches. Simulation and video-based learning is now a corner stone of surgical education, with data suggesting that virtual reality (VR) skills-based learning creates engaging learning environments that promote deeper understanding and long-term retention of knowledge and skills [<xref ref-type="bibr" rid="CR2">2</xref>], with multi-modal teaching preferred by students [<xref ref-type="bibr" rid="CR3">3</xref>].</p>
              <p id="Par6">Mixed Reality (MR) technology offers an immersive experience in which real and virtual elements of an environment co-exist. Headsets allow multiple users to remotely link and collaboratively interact through bidirectional communication and interaction with spatially recognised 3D holographic content within the real visualised environment. This technology can therefore provide specific 3D imaging, generic dynamic physiological and anatomical models, or procedural animations to improve the learning offer, whilst also allowing remote access to educations that may widen accessibility and lower barriers to educational opportunities. The HoloLens 2 (HL2) (Microsoft Corporation, Redmond, WA, USA) is an untethered MR headset, and is an example of such technology. It has been successfully used across a range of educational settings including teaching ward rounds [<xref ref-type="bibr" rid="CR4">4</xref>], and human anatomy instruction through bespoke 3D interactive models that have been shown to give a better understanding of anatomical structures compared to standard lecture-based teaching [<xref ref-type="bibr" rid="CR5">5</xref>–<xref ref-type="bibr" rid="CR8">8</xref>]. In addition, the technology has been demonstrated to be a potential method to teach basic practical skills such as digital rectal examinations and urinary catheterisation [<xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR10">10</xref>]. The use of augmented (AR) and virtual reality (VR) for surgical training has been widely reported [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR12">12</xref>], but there remains a paucity of evidence for the potential effectiveness of newer MR technology to support the delivery of basic surgical skills training. MR technology has the potential to enhance all aspects of skills training, and specifically self-directed, remote, or large-group teaching where resource constraints do not allow for instructor-led face-to-face tuition and video-based methods are currently the mainstay of delivery. This study therefore sought to examine the impact of MR technology on basic surgical skills training in a novice cohort when compared to traditional video-based methods of teaching.</p>
            </sec>
            <sec id="Sec2">
              <title>Methods</title>
              <sec id="Sec3">
                <title>Participants</title>
                <p id="Par7">36 novice clinical medical student participants were recruited. All had undergone summative assessment in simple suturing competencies as part of their curriculum prior to participation in the study but had not previously undertaken the surgical skill being taught and assessed. Demographic data were collected, and preferred learning style data self-reported by participants using the VARK (visual, auditory, read/write, kinaesthetic) model; a validated inventory that identifies student learning preferences [<xref ref-type="bibr" rid="CR13">13</xref>].</p>
              </sec>
              <sec id="Sec4">
                <title>Study Design</title>
                <p id="Par8">This was a single blind randomised study with 18 participants randomised to each group. Each group received a structured surgical skills tutorial on performing and closing an arteriotomy: a conventional video-based tutorial group, and a MR HL2 group. The allocation ratio for each group was 1:1 via block randomisation prior to participation. The study received institutional educational ethics approval (EERP2021-027a) and informed consent was obtained from all participants.</p>
                <p id="Par9">The study took place in three stages and employed a modified Peyton’s four-step approach to skills teaching for both groups [<xref ref-type="bibr" rid="CR14">14</xref>]. Participants undertook a baseline assessment of surgical proficiency, received a standardised surgical skills tutorial, and then performed a further assessed task to determine skill progression. Participants were trained to perform a simple arteriotomy and closure on a commercial bench top synthetic surgical model (Limbs &amp; Things Ltd, Bristol, UK). They performed a longitudinal arteriotomy that was then closed with interrupted sutures. A description of the scenario can be found in <italic>Appendix A</italic>. In the first stage, all participants were provided with identical basic written instruction on how to undertake an arteriotomy and closure. The task was then performed on a surgical model to provide a baseline assessment of proficiency. In the second stage, the video group received tuition through a pre-recorded structured skills video. Participants were able to independently replay all, or parts of the video at their preferred pace while practising the skill for 20 min. The HL2 group received instruction on how to fit and use the HL2 device and technical support was provided for participants who had difficulties in using the technology. They received the same structured surgical tutorial that was enhanced with the addition of bespoke interactive holographic content and instruction delivered through Microsoft Dynamics 365 Guides (Microsoft Corporation, Redmond, WA, USA), and were again given 20 min to practice the skill whilst utilising the MR content. The MR tutorial provided to the HL2 group is shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>, and provided simultaneous and interactive written instruction, together with embedded video of each procedural step and live instrument identification and use guidance. In the final stage both groups then undertook a further task assessment to provide an objective assessment of skill progression. Once all tasks had been completed, participants were able to experience the alternative teaching modality to ensure no participant was disadvantaged and all had exposure to both interventions. Participant demographics, learning style information, and teaching and device feedback were collected using 5- point Likert style scale responses scored 1–5 with 1 being “strongly disagree” and 5 being “strongly agree.”</p>
                <p id="Par34">
                  <fig id="Fig1">
                    <label>Fig. 1</label>
                    <caption>
                      <p>Screenshot of the HoloLens teaching session content. The instructions are displayed on a screen in front of the participant whilst an embedded video clip of the step is shown to the left of the instructions. Instruments are highlighted with a 3D hologram in turn, and the surgical model is labelled to identify correct clamp placement (1 A). Close up image demonstrating how the technology highlights the correct instrument in order of use for the student (1B)</p>
                    </caption>
                    <graphic xlink:href="12909_2023_4122_Figa_HTML" id="d32e330"/>
                  </fig>
                </p>
                <p id="Par10">Assessment tools such as the Objective Structured Assessment of Technical Skill (OSATS) have been shown to measure surgical skill proficiency accurately and validly [<xref ref-type="bibr" rid="CR15">15</xref>]. In this study proficiency was measured by evaulating correct instrument selection, task stage completion, and suture quality to produce an overall proficiency score. The surgical skill was divided into several stages, and a modified task specific OSATS checklist was developed to assess corresponding instument selection and task stage completion. This was completed by an examiner, blinided to the participants instructional condition, during each assessed task. The time taken to complete the task was also recorded with a cut-off of 15 min allowed. A second blinded expert reviewer then assessed each completed arteriotomy model to assess suture quality and error using a task-specific score. An overall proficiency score, based on a metric-based performance score with evidence for its validity [<xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR17">17</xref>], was then calculated by combing instrument selection and suture quality scores to determine overall skill progression on a per-participant basis. The surgical proficiency scoring system is provided in <italic>Appendix B</italic>.</p>
              </sec>
              <sec id="Sec5">
                <title>Statistical analysis</title>
                <p id="Par11">Standard descriptive statistics were utilised. The distribution of data was checked for normality using the Shapiro-Wilks test. Comparison of scores between groups were analysed by a T-Test for parametric data and a Mann-Whitney U (MWU) test for non-parametric data. Variance was assessed by an F-test. A Chi-squared test was used to test relationships between categorical data. P-values &lt; 0.05 were considered significant. Statistical analysis was carried out using GraphPad Prism for Mac Version 9.0.0. Data is displayed as mean ± standard deviation.</p>
              </sec>
            </sec>
            <sec id="Sec6" sec-type="results">
              <title>Results</title>
              <sec id="Sec7">
                <title>Participant characteristics</title>
                <p id="Par12">There was no difference in age (22.4 years ± 2.45 vs. 22.6 ± 2.52, p = 0.735) or sex (7 vs. 8 male, p = 0.735) between the HL2 and video groups respectively.</p>
              </sec>
              <sec id="Sec8">
                <title>Overall proficiency score</title>
                <p id="Par13">There was no significant difference in total baseline proficiency scores for the HL2 and video groups (9.11 ± 3.36 vs. 10.2 ± 2.66, p = 0.303). The HL2 teaching group showed a significantly greater gain in raw point proficiency scores compared to the video group (10.1 ± 2.48 vs. 6.89 ± 4.03, p = 0.0076) as illustrated in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. The HL2 teaching group also displayed a narrower range of scores, indicating a greater level of consistency in skill progression compared to the video group (SD 2.48 vs. 4.03, F<sub>17,17</sub> = 2.64 p = 0.026).</p>
                <p id="Par35">
                  <fig id="Fig2">
                    <label>Fig. 2</label>
                    <caption>
                      <p>Bar chart depicting the mean proficiency score gain of each group (n = 18/group) on a per participant basis. Those in the HoloLens group showed a significantly greater raw point improvement in proficiency scores (10.1 ± 2.48 vs. 6.89 ± 4.03, p = 0.0076) and greater consistency in skill progression (SD 2.48 vs. 4.03, F<sub>17,17</sub> = 2.64 p = 0.026)</p>
                    </caption>
                    <graphic xlink:href="12909_2023_4122_Figb_HTML" id="d32e383"/>
                  </fig>
                </p>
              </sec>
              <sec id="Sec9">
                <title>Instrument selection</title>
                <p id="Par14">There was no significant difference in baseline scores for instrument selection for the HL2 and video groups (3.06 ± 0.873 vs. 3.61 ± 1.42, p = 0.246). The HL2 teaching group subsequently had a significantly higher mean score for instrument selection choice when compared to the video group (9.67 ± 0.767 vs. 6.67 ± 1.97, p &lt; 0.0001).</p>
              </sec>
              <sec id="Sec10">
                <title>Suture quality</title>
                <p id="Par15">There was no significant difference in baseline scores for suture quality for the HL2 and video groups (7.17 ± 2.83 vs. 7.50 ± 2.28, p = 0.700), and both groups demonstrated equal improvement in performance (2.22 ± 2.13 vs. 1.94 ± 3.21, p = 0.761).</p>
              </sec>
              <sec id="Sec11">
                <title>Participant learning style and performance</title>
                <p id="Par16">The impact of participant learning styles on proficiency are summarised in Fig. <xref rid="Fig3" ref-type="fig">3</xref> Overall, 20 (56%) participants reported a multi-modal learning style, with the remaining 16 (44%) participants reporting a single preferred learning style. Participants who listed ‘kinaesthetic’ (n = 30 - HL2 15, video 15) as one of their learning modalities showed significantly improved scores for instrument selection in the HL2 group (9.60 ± 0.737 vs. 6.87 ± 1.96, p &lt; 0.0001). Improvements in instrument selection scores were also significantly better in the HL2 group for participants who included ‘visual’ (n = 26 - HL2 11, video 15) as one of their preferred learning styles (9.82 ± 0.751 vs. 6.67 ± 2.09, p &lt; 0.0001). However, there was no significant difference in instrument selection scores for participants who listed “auditory” (n = 11 - HL2 4, video 7) as one of their learning modalities (9.50 ± 0.577 vs. 14 ± 2.27, p = 0.112). Multi-modal participants (n = 20 - HL2 8, video 12) who listed more than one modality of learning also showed significantly greater gains in instrument selection scores in the HL2 group compared to the video group (9.75 ± 0.707 vs. 6.92 ± 2.11, p = 0.0009). No difference in suture quality scores between the two study groups across different learning styles was observed.</p>
                <p id="Par36">
                  <fig id="Fig3">
                    <label>Fig. 3</label>
                    <caption>
                      <p>Charts depicting the mean gain in procedural knowledge through instrument selection choice in participants who selected (A) kinaesthetic (n = 30 - HL2 15, video 15), (B) visual (n = 26 - HL2 11, video 15), (C) auditory (n = 11 - HL2 4, video 7) and (D) multiple modalities (n = 20 - HL2 12, video 8) as preferred learning modalities. * = p &lt; 0.05, ** = p &lt; 0.01, *** = p &lt; 0.001, ****=p &lt; 0.0001</p>
                    </caption>
                    <graphic xlink:href="12909_2023_4122_Figc_HTML" id="d32e413"/>
                  </fig>
                </p>
              </sec>
              <sec id="Sec12">
                <title>Participant feedback</title>
                <p id="Par17">Participant feedback is summarised in Table <xref rid="Tab1" ref-type="table">1</xref>. A minority (6/36, 16.7%) of students felt that surgical skills are currently well taught at their institution. All participants were positive about both teaching modalities and found them easy to use. Teaching using MR content via the HL2 was thought to be more effective than traditional video tutorials (4.50 ± 0.618 vs. 3.83 ± 0.924, p = 0.024), and confidence in performing the skill assessed was better, although not significantly in participants in the HL2 group (2.47 ± 0.624 vs. 1.94 ± 0.802, p = 0.0556). Most participants reported no difficulties or problems with either teaching modality (HL2 26/36, 72.2%. Video 24/36, 66.7%). A minority of participants in the HL2 group reported symptoms or difficulties with wearing the device, with headache reported by 11.1% (2/18) and fatigue or difficulty concentrating by 16.7% (3/18). However, similar difficulties were also reported in the video group with 16.7% (3/18) reporting difficulty concentrating or fatigue.</p>
                <p id="Par18">
                  <table-wrap id="Tab1">
                    <label>Table 1</label>
                    <caption>
                      <p>Summary of participant feedback (n = 36) scored on Likert scale responses (1–5, not confident / strongly disagree - most confident / strongly agree) or via yes/no responses</p>
                    </caption>
                    <table frame="hsides" rules="groups">
                      <thead>
                        <tr>
                          <th align="left"/>
                          <th align="left">HoloLens</th>
                          <th align="left">Video</th>
                          <th align="left">p-value</th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td align="left">Procedural confidence</td>
                          <td align="left">2.47 ± 0.624</td>
                          <td align="left">1.94 ± 0.802</td>
                          <td char="." align="char">0.0556</td>
                        </tr>
                        <tr>
                          <td align="left">Effectiveness of programme</td>
                          <td align="left">4.50 ± 0.618</td>
                          <td align="left">3.83 ± 0.924</td>
                          <td char="." align="char">0.0242</td>
                        </tr>
                        <tr>
                          <td align="left">Ease of use</td>
                          <td align="left">4.28 ± 0.669</td>
                          <td align="left">4.17 ± 0.707</td>
                          <td char="." align="char">0.745</td>
                        </tr>
                        <tr>
                          <td align="left">Enjoyment</td>
                          <td align="left">4.56 ± 0.511</td>
                          <td align="left">4.06 ± 0.873</td>
                          <td char="." align="char">0.0821</td>
                        </tr>
                        <tr>
                          <td align="left">No symptoms</td>
                          <td align="left">13</td>
                          <td align="left">12</td>
                          <td char="." align="char">0.718</td>
                        </tr>
                        <tr>
                          <td align="left">Difficulty concentrating</td>
                          <td align="left">0</td>
                          <td align="left">3</td>
                          <td char="." align="char">0.0704</td>
                        </tr>
                        <tr>
                          <td align="left">Headache</td>
                          <td align="left">2</td>
                          <td align="left">0</td>
                          <td char="." align="char">0.146</td>
                        </tr>
                        <tr>
                          <td align="left">General discomfort, fatigue, difficulty concentrating</td>
                          <td align="left">1</td>
                          <td align="left">1</td>
                          <td char="." align="char">&gt; 0.999</td>
                        </tr>
                        <tr>
                          <td align="left">General discomfort, fatigue</td>
                          <td align="left">2</td>
                          <td align="left">1</td>
                          <td char="." align="char">0.547</td>
                        </tr>
                        <tr>
                          <td align="left">Sore eyes</td>
                          <td align="left">0</td>
                          <td align="left">1</td>
                          <td char="." align="char">0.311</td>
                        </tr>
                      </tbody>
                    </table>
                  </table-wrap>
                </p>
              </sec>
            </sec>
            <sec id="Sec13" sec-type="discussion">
              <title>Discussion</title>
              <p id="Par19">This randomised study has shown that students who participate in surgical skills tuition delivered via MR technology demonstrate greater and more consistent skill progression, in addition to reporting a higher quality educational experience when compared to traditional video-based skills tuition.</p>
              <p id="Par20">The HoloLens teaching session gave consistently better results to all learners. Specifically, it led to significant improvements in instrument selection and more consistent improvements in technical performance. These observations could be due to the nature of the HoloLens content that supported a more structured approach to skill practice for the participant. The interactive tutorial provided reinforcement and immediate confirmation of the key procedural steps by producing holographic representations of each surgical instrument in order of use, in addition to highlighting the correct instrument within the surgical field and providing visual guidance for exact instrument placement on the surgical jig, as illustrated in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. In accordance with pedagogical best practices, this material was presented to the student in a guided and segmented fashion, with progression through the tutorial via hands-free control to allow content manipulation whilst simultaneously performing the task. Conversely, the video group was only able to practice and re-watch the video content using a self-directed approach with no temporal relationship between the video and task. In addition, they had to put down their instruments and disengage from performing the task to control the video that was presented on an adjoining computer. The interactive learning and enhanced feedback for the HoloLens group likely account for higher instrument selection scores and greater consistency of learning for this group.</p>
              <p id="Par21">Differing participant learning styles appeared to influence the effectiveness of the intervention. Participants were either multi-modal learners or reported a single preferred learning style, with an equal distribution across each study group. Participants who included auditory learning as one of their preferred learning styles performed similarly across the two study groups as would be expected given that the audio commentary provided for both teaching modalities were identical. Participants who included visual and kinaesthetic learning as one of their preferred learning styles performed significantly better in the HoloLens group. Although both groups received the same video material and practice time, the addition of holographic content and markers, and interactive task guide in the HoloLens group created a more dynamic learning environment that supported a multi-modal approach to learning. It is well documented that more interactive teaching sessions delivered through a diverse range of media lead to increased engagement and better performances [<xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR19">19</xref>].</p>
              <p id="Par22">Suture quality remained consistent across the two interventions. This was a secondary measure of the study, and instructions and tuition on improving suture quality were not delivered with novel MR content. The lack of significant difference between groups may be accounted for by the limited specificity of the suture quality assessment methodology, however, this observation may also reflect the fact that the students did not have the opportunity to reach a performance plateau in their motor skills [<xref ref-type="bibr" rid="CR20">20</xref>], with insufficient repetitive experiential learning to yield significant improvements in technical quality. However, the HoloLens could readily address this short coming and future models could visualise correct knot quality measures, by superimposing an animated hologram over the participant’s hands showing the correct technique, allowing the participant to mirror the movements [<xref ref-type="bibr" rid="CR21">21</xref>]. This would provide a more interactive way to demonstrate and give immediate confirmation of technique for aspects such as correct positioning and tying techniques.</p>
              <p id="Par23">The global need for improved surgical skills teaching is clear [<xref ref-type="bibr" rid="CR22">22</xref>], and this has been exacerbated during the COVID crisis which has placed significant strain on surgical training. These data suggest that MR technology may have a role to play in addressing these challenges, and that this it is acceptable to students. All HoloLens participants reported enjoying the teaching session, but this observation was not found in the video group. Reasons for a lower enjoyment in the video group can be seen in the written feedback where participants said it was not “interactive” enough and re-watching the video while practising was “too difficult” as they were unable to effectively focus on the task at hand whilst simultaneously controlling and engaging with a non-segmented and poorly accessible passive video. This is in keeping with previous studies that suggest interactive and active learning styles perform better than traditional teaching methods [<xref ref-type="bibr" rid="CR23">23</xref>, <xref ref-type="bibr" rid="CR24">24</xref>]. However, this may represent a bias towards the MR technology amongst participants due to its novelty or inclusion in the study. Nonetheless, high student satisfaction is crucial with educational programmes as it encourages improved engagement and better overall performance [<xref ref-type="bibr" rid="CR25">25</xref>–<xref ref-type="bibr" rid="CR27">27</xref>].</p>
              <p id="Par24">Unfamiliarity and the learning curve associated with new technologies often results in slow adoption [<xref ref-type="bibr" rid="CR28">28</xref>], however, it is promising that no HoloLens participant disagreed with the statement that the technology was easy to use. There is however a learning curve to the technology, and some described that it was initially difficult to interact with some components, but this was rapidly over come with the standardised onboarding protocol. Surprisingly, not all video participants selected “strongly agree” for ease of use for watching the videos. The feedback given suggests this was due to the need to scroll through the video in the practice round which may be challenging whilst simultaneously attempting to practice the technique. This problem is mitigated with the HoloLens teaching programme as Microsoft Dynamics 365 Guides uses a cursor controlled by head movement and gaze. Therefore, the participant did not need to remove their hand from any instruments to continue to the next step or repeat the most recent instruction. This is particularly important when it comes to surgical training as the programme doesn’t disrupt the flow of practice and allows muscle memory to form, leading to enhanced performance of the skills [<xref ref-type="bibr" rid="CR29">29</xref>]. An interesting observation would be that both groups had increased confidence after the teaching session, however this was slightly higher in the HoloLens group. This could be due to the immediate confirmation of the selected instrument and guidance for its correct placement on that surgical jig that the HoloLens tutorial provided; functionality that is not provided in video-based tuition. Many of the instruments used had not been seen by this novice group before, and therefore such positive identification, feedback and reinforcement aids in learning and correctly identifying the differences between similar-looking instruments.</p>
              <p id="Par25">Most participants (72.2%, 13/18) who used the HoloLens did not experience any negative symptoms with the device, with the few symptoms that were experienced being mild. Studies have shown that prolonged use of the HoloLens may lead to symptoms such as headaches or fatigue [<xref ref-type="bibr" rid="CR30">30</xref>]. The video group had a similar number of participants with no symptoms, with the most notable symptom reported being difficulty concentrating. This is emphasised by the feedback given that the videos were “long” and “boring”. This was surprising as both groups were provided with the same basic video content, although delivered via very different and contrasting methodologies, but only one participant from the HoloLens group felt like they had difficulty concentrating likely due to the segmented nature of the video content and additional interactive functionality they experienced. These results are encouraging as they show that it is possible to incorporate the interactive nature of MR learning without the major side effects such as “cybersickness” [<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR31">31</xref>].</p>
              <p id="Par26">A key limitation of this study was provided by the technology itself which remains in relative infancy. The battery life of the device and other technical aspects of its operation were principal concerns. When running a Microsoft Dynamics 365 Guide, such as used in this study, it is much shorter than advertised and lasts for only 90 min. Whilst not of direct consequence in this study as each participant used the device for 40 min, it may limit the scalability of the technology across a wider range of subject areas and skills that require a longer instructional period. Further to this, periods of minimal head movement, for example whilst watching a video through the device, can lead it to automatically go to sleep and therefore interrupt the tutorial. Finally, the device is designed to be operated through specific hand gestures such as tapping the inside of the wrist with two fingers to return to the main menu. Whilst through to be unique in other settings, these were sometimes confused with normal movements undertaken in clinical contexts such as putting on gloves which once again may unintentionally disrupt the tutorial; this could be easily resolved through basic software developments that consider the clinical context. This study was conducted in an institution that had the technical resource to develop the bespoke content, and financial resource to purchase the devices which cost of around $3,500 each. Expert technical knowledge is required to effectively create and deliver the MR content, even with a mature software package such as Dynamics 365 Guides that was used in this instance. A multi-step process is required to film and segment the video content, generate bespoke 3D holographic content through a distinct software application, create a task-specific spatially orientated practice environment in which the suturing skill was performed and finally to link these in a single joined-up interactive guide. This resource requirement may act as a barrier to adoption and the potential scalability of the technology, however, over time it is likely the cost of the technology will fall and therefore it will become a more feasible option for widespread use in medical education. In addition, any technology-based trial, particularly involving novel technology, will likely be affected by some degree of technology bias.</p>
              <p id="Par27">Further to the technical limitations, this study looked solely at improvements in proficiency in a tightly defined individual task over a short period of time, potentially limiting the applicability of the findings to generalised surgical proficiency over the longer term. Secondly, whilst insignificant, there was a difference in baseline participant performance between each group that may have partially contributed to the observed findings. Future studies would benefit from retesting participants at longer time interval to determine if MR teaching methods minimise longitudinal skill fade and improve knowledge retention, and from stratifying participants according to baseline proficiency to assess their effectiveness across different performance levels. It is also important to assess the efficacy of the technology across a wider range of topics, skills and contexts.</p>
            </sec>
            <sec id="Sec14" sec-type="conclusion">
              <title>Conclusion</title>
              <p id="Par28">This study has shown that a HoloLens delivered mixed reality teaching programme has the potential to produce greater skill progression, more consistency in learning and a higher quality educational experience compared to traditional video-based methods for surgical skills training. Although in its infancy, further work to refine, translate and evaluate the scalability and applicability of the technology will allow it to be readily adopted across a broad range of skills-based disciplines.</p>
            </sec>
            <sec sec-type="supplementary-material">
              <title>Electronic supplementary material</title>
              <sec id="Sec15">
                <p>Below is the link to the electronic supplementary material.</p>
                <p>
                  <supplementary-material content-type="local-data" id="MOESM1">
                    <media xlink:href="12909_2023_4122_MOESM1_ESM.docx">
                      <caption>
                        <p>Supplementary Material 1</p>
                      </caption>
                    </media>
                  </supplementary-material>
                </p>
                <p>
                  <supplementary-material content-type="local-data" id="MOESM2">
                    <media xlink:href="12909_2023_4122_MOESM2_ESM.docx">
                      <caption>
                        <p>Supplementary Material 2</p>
                      </caption>
                    </media>
                  </supplementary-material>
                </p>
              </sec>
            </sec>
          </body>
          <back>
            <fn-group>
              <fn>
                <p>
                  <bold>Publisher’s note</bold>
                </p>
                <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
              </fn>
            </fn-group>
            <ack>
              <title>Acknowledgements</title>
              <p>The authors would like to acknowledge all participants who undertook the study.</p>
            </ack>
            <notes notes-type="author-contribution">
              <title>Authors’ contributions</title>
              <p>All authors contributed to the design, conduct and analysis of the study. PG, JL, GM and JK designed the study. PG, IM, JL, and GM conducted the study and collected all data. PG, IM, JK, GM and JK undertook data analysis and initial drafting. All authors read and approved the final manuscript.</p>
            </notes>
            <notes notes-type="funding-information">
              <title>Funding/Support</title>
              <p>This project was internally supported by the NIHR Imperial Biomedical Research Centre (BRC). The views expressed are those of the authors and not necessarily those of the NIHR or the Department of Health and Social Care.</p>
            </notes>
            <notes notes-type="data-availability">
              <title>Data availability</title>
              <p>The data generated and/or analysed during the current study are not publicly available as they contain potentially identifiable participant information. They are available from the corresponding author on reasonable request.</p>
            </notes>
            <notes>
              <title>Declarations</title>
              <notes id="FPar1">
                <title>Ethical approval and consent to participate</title>
                <p id="Par37">The study received institutional ethics approval (Imperial College London Educational Ethics Review Process - EERP2021-027a) for educational research and was conducted in accordance with the Declaration of Helsinki. Written informed consent was obtained from all participants.</p>
              </notes>
              <notes id="FPar2">
                <title>Consent for publication</title>
                <p id="Par38">Not applicable.</p>
              </notes>
              <notes id="FPar3" notes-type="COI-statement">
                <title>Competing interests</title>
                <p id="Par39">All authors declare that they have no relevant conflicts of interest to this manuscript.</p>
              </notes>
            </notes>
            <ref-list id="Bib1">
              <title>References</title>
              <ref id="CR1">
                <label>1.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Shippey</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Chen</surname>
                      <given-names>T</given-names>
                    </name>
                    <name>
                      <surname>Chou</surname>
                      <given-names>B</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Teaching subcuticular suturing to medical students: video versus expert instructor feedback</article-title>
                  <source>J Surg Educ</source>
                  <year>2011</year>
                  <volume>68</volume>
                  <fpage>397</fpage>
                  <lpage>402</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.jsurg.2011.04.006</pub-id>
                  <pub-id pub-id-type="pmid">21821220</pub-id>
                </element-citation>
              </ref>
              <ref id="CR2">
                <label>2.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Gan</surname>
                      <given-names>B</given-names>
                    </name>
                    <name>
                      <surname>Menkhoff</surname>
                      <given-names>T</given-names>
                    </name>
                    <name>
                      <surname>Smith</surname>
                      <given-names>R</given-names>
                    </name>
                  </person-group>
                  <article-title>Enhancing students’ learning process through interactive digital media: new opportunities for collaborative learning</article-title>
                  <source>Comput Hum Behav</source>
                  <year>2015</year>
                  <volume>51</volume>
                  <fpage>652</fpage>
                  <lpage>63</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.chb.2014.12.048</pub-id>
                </element-citation>
              </ref>
              <ref id="CR3">
                <label>3.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Lujan</surname>
                      <given-names>H</given-names>
                    </name>
                    <name>
                      <surname>DiCarlo</surname>
                      <given-names>S</given-names>
                    </name>
                  </person-group>
                  <article-title>First-year medical students prefer multiple learning styles</article-title>
                  <source>Adv Physiol Educ</source>
                  <year>2006</year>
                  <volume>30</volume>
                  <fpage>13</fpage>
                  <lpage>6</lpage>
                  <pub-id pub-id-type="doi">10.1152/advan.00045.2005</pub-id>
                  <pub-id pub-id-type="pmid">16481603</pub-id>
                </element-citation>
              </ref>
              <ref id="CR4">
                <label>4.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Bala</surname>
                      <given-names>L</given-names>
                    </name>
                    <name>
                      <surname>Kinross</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Martin</surname>
                      <given-names>G</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>A remote access mixed reality teaching ward round</article-title>
                  <source>Clin Teach</source>
                  <year>2021</year>
                  <volume>18</volume>
                  <fpage>386</fpage>
                  <lpage>90</lpage>
                  <pub-id pub-id-type="doi">10.1111/tct.13338</pub-id>
                  <pub-id pub-id-type="pmid">33786988</pub-id>
                </element-citation>
              </ref>
              <ref id="CR5">
                <label>5.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Kumar</surname>
                      <given-names>N</given-names>
                    </name>
                    <name>
                      <surname>Pandey</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Rahman</surname>
                      <given-names>E</given-names>
                    </name>
                  </person-group>
                  <article-title>A novel three-dimensional interactive virtual face to facilitate facial anatomy teaching using microsoft holoLens</article-title>
                  <source>Aesthetic Plast Surg</source>
                  <year>2021</year>
                  <volume>45</volume>
                  <issue>3</issue>
                  <fpage>1005</fpage>
                  <lpage>11</lpage>
                  <pub-id pub-id-type="doi">10.1007/s00266-020-02110-5</pub-id>
                  <pub-id pub-id-type="pmid">33469701</pub-id>
                </element-citation>
              </ref>
              <ref id="CR6">
                <label>6.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Bogomolova</surname>
                      <given-names>K</given-names>
                    </name>
                    <name>
                      <surname>Sam</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Misky</surname>
                      <given-names>A</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Development of a virtual three-dimensional assessment scenario for anatomical education</article-title>
                  <source>Anat Sci Educ</source>
                  <year>2021</year>
                  <volume>14</volume>
                  <issue>3</issue>
                  <fpage>385</fpage>
                  <lpage>93</lpage>
                  <pub-id pub-id-type="doi">10.1002/ase.2055</pub-id>
                  <pub-id pub-id-type="pmid">33465814</pub-id>
                </element-citation>
              </ref>
              <ref id="CR7">
                <label>7.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Gnanasegaram</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Leung</surname>
                      <given-names>R</given-names>
                    </name>
                    <name>
                      <surname>Beyea</surname>
                      <given-names>J</given-names>
                    </name>
                  </person-group>
                  <article-title>Evaluating the effectiveness of learning ear anatomy using holographic models</article-title>
                  <source>J Otolaryngol Head Neck Surg</source>
                  <year>2020</year>
                  <volume>49</volume>
                  <issue>1</issue>
                  <fpage>63</fpage>
                  <pub-id pub-id-type="doi">10.1186/s40463-020-00458-x</pub-id>
                  <pub-id pub-id-type="pmid">32814593</pub-id>
                </element-citation>
              </ref>
              <ref id="CR8">
                <label>8.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Moro</surname>
                      <given-names>C</given-names>
                    </name>
                    <name>
                      <surname>Štromberga</surname>
                      <given-names>Z</given-names>
                    </name>
                    <name>
                      <surname>Raikos</surname>
                      <given-names>A</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>The effectiveness of virtual and augmented reality in health sciences and medical anatomy</article-title>
                  <source>Anat Sci Educ</source>
                  <year>2017</year>
                  <volume>10</volume>
                  <fpage>549</fpage>
                  <lpage>59</lpage>
                  <pub-id pub-id-type="doi">10.1002/ase.1696</pub-id>
                  <pub-id pub-id-type="pmid">28419750</pub-id>
                </element-citation>
              </ref>
              <ref id="CR9">
                <label>9.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Muangpoon</surname>
                      <given-names>T</given-names>
                    </name>
                    <name>
                      <surname>Osgouei</surname>
                      <given-names>RH</given-names>
                    </name>
                    <name>
                      <surname>Escobar-Castillejos</surname>
                      <given-names>D</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Augmented reality system for digital rectal examination training and assessment: System validation</article-title>
                  <source>J Med Internet Res</source>
                  <year>2020</year>
                  <volume>22</volume>
                  <issue>8</issue>
                  <fpage>e186737</fpage>
                  <pub-id pub-id-type="doi">10.2196/18637</pub-id>
                </element-citation>
              </ref>
              <ref id="CR10">
                <label>10.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Schoeb</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Schwarz</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Hein</surname>
                      <given-names>S</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Mixed reality for teaching catheter placement to medical students: a randomized single-blinded, prospective trial</article-title>
                  <source>BMC Med Educ</source>
                  <year>2020</year>
                  <volume>20</volume>
                  <issue>1</issue>
                  <fpage>510</fpage>
                  <pub-id pub-id-type="doi">10.1186/s12909-020-02450-5</pub-id>
                  <pub-id pub-id-type="pmid">33327963</pub-id>
                </element-citation>
              </ref>
              <ref id="CR11">
                <label>11.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Sheik-Ali</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Edgcombe</surname>
                      <given-names>H</given-names>
                    </name>
                    <name>
                      <surname>Paton</surname>
                      <given-names>C</given-names>
                    </name>
                  </person-group>
                  <article-title>Next-generation virtual and augmented reality in surgical education: a narrative review</article-title>
                  <source>Surg Technol Int</source>
                  <year>2019</year>
                  <volume>35</volume>
                  <fpage>37</fpage>
                  <lpage>35</lpage>
                </element-citation>
              </ref>
              <ref id="CR12">
                <label>12.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Mackenzie</surname>
                      <given-names>C</given-names>
                    </name>
                    <name>
                      <surname>Harris</surname>
                      <given-names>T</given-names>
                    </name>
                    <name>
                      <surname>Shipper</surname>
                      <given-names>A</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Virtual reality and haptic interfaces for civilian and military open trauma surgery training: a systematic review</article-title>
                  <source>Injury</source>
                  <year>2022</year>
                  <volume>53</volume>
                  <issue>11</issue>
                  <fpage>3575</fpage>
                  <lpage>85</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.injury.2022.08.003</pub-id>
                  <pub-id pub-id-type="pmid">36123192</pub-id>
                </element-citation>
              </ref>
              <ref id="CR13">
                <label>13.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Hawk</surname>
                      <given-names>SA</given-names>
                    </name>
                  </person-group>
                  <article-title>Using learning style instruments to enhance student learning</article-title>
                  <source>Decis Sci J Innovative Educ</source>
                  <year>2007</year>
                  <volume>5</volume>
                  <fpage>1</fpage>
                  <lpage>19</lpage>
                  <pub-id pub-id-type="doi">10.1111/j.1540-4609.2007.00125.x</pub-id>
                </element-citation>
              </ref>
              <ref id="CR14">
                <label>14.</label>
                <element-citation publication-type="book">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Peyton</surname>
                      <given-names>J</given-names>
                    </name>
                  </person-group>
                  <source>Teaching &amp; learning in medical practice</source>
                  <year>1998</year>
                  <publisher-loc>UK</publisher-loc>
                  <publisher-name>Manticore Books</publisher-name>
                </element-citation>
              </ref>
              <ref id="CR15">
                <label>15.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Martin</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Regehr</surname>
                      <given-names>G</given-names>
                    </name>
                    <name>
                      <surname>Reznick</surname>
                      <given-names>R</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Objective structured assessment of technical skill (OSATS) for surgical residents</article-title>
                  <source>Br J Surg</source>
                  <year>1997</year>
                  <volume>84</volume>
                  <issue>2</issue>
                  <fpage>273</fpage>
                  <lpage>8</lpage>
                  <pub-id pub-id-type="pmid">9052454</pub-id>
                </element-citation>
              </ref>
              <ref id="CR16">
                <label>16.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Scott</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Goova</surname>
                      <given-names>M</given-names>
                    </name>
                    <name>
                      <surname>Tesfay</surname>
                      <given-names>S</given-names>
                    </name>
                  </person-group>
                  <article-title>A cost-effective proficiency-based knot-tying and suturing curriculum for residency programs</article-title>
                  <source>J Surg Res</source>
                  <year>2007</year>
                  <volume>141</volume>
                  <issue>1</issue>
                  <fpage>7</fpage>
                  <lpage>1</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.jss.2007.02.043</pub-id>
                  <pub-id pub-id-type="pmid">17574034</pub-id>
                </element-citation>
              </ref>
              <ref id="CR17">
                <label>17.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Goova</surname>
                      <given-names>M</given-names>
                    </name>
                    <name>
                      <surname>Hollett</surname>
                      <given-names>L</given-names>
                    </name>
                    <name>
                      <surname>Tesfay</surname>
                      <given-names>S</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Implementation, construct validity, and benefit of a proficiency-based knot-tying and suturing curriculum</article-title>
                  <source>J Surg Educ</source>
                  <year>2008</year>
                  <volume>65</volume>
                  <fpage>309</fpage>
                  <lpage>15</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.jsurg.2008.04.004</pub-id>
                  <pub-id pub-id-type="pmid">18707666</pub-id>
                </element-citation>
              </ref>
              <ref id="CR18">
                <label>18.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Almarabeh</surname>
                      <given-names>H</given-names>
                    </name>
                    <name>
                      <surname>Almara’beh</surname>
                      <given-names>H</given-names>
                    </name>
                    <name>
                      <surname>Amer</surname>
                      <given-names>E</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>The effectiveness of multimedia learning tools in education</article-title>
                  <source>Int J Adv Res Comput Sci Softw Eng</source>
                  <year>2015</year>
                  <volume>5</volume>
                  <issue>12</issue>
                  <fpage>761</fpage>
                  <lpage>4</lpage>
                </element-citation>
              </ref>
              <ref id="CR19">
                <label>19.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Aloraini</surname>
                      <given-names>S</given-names>
                    </name>
                  </person-group>
                  <article-title>The impact of using multimedia on students’ academic achievement in the College of Education at King Saud University</article-title>
                  <source>J King Saud Univ - Lang Translation</source>
                  <year>2012</year>
                  <volume>24</volume>
                  <fpage>75</fpage>
                  <lpage>82</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.jksult.2012.05.002</pub-id>
                </element-citation>
              </ref>
              <ref id="CR20">
                <label>20.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Ericsson</surname>
                      <given-names>K</given-names>
                    </name>
                  </person-group>
                  <article-title>Deliberate practice and the acquisition and maintenance of expert performance in medicine related domains</article-title>
                  <source>Acad Med</source>
                  <year>2004</year>
                  <volume>79</volume>
                  <fpage>71</fpage>
                  <lpage>s80</lpage>
                  <pub-id pub-id-type="doi">10.1097/00001888-200410001-00022</pub-id>
                </element-citation>
              </ref>
              <ref id="CR21">
                <label>21.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Byrne</surname>
                      <given-names>R</given-names>
                    </name>
                    <name>
                      <surname>Russon</surname>
                      <given-names>A</given-names>
                    </name>
                  </person-group>
                  <article-title>Learning by imitation: a hierarchical approach</article-title>
                  <source>Behav Brain Sci</source>
                  <year>1998</year>
                  <volume>21</volume>
                  <fpage>667</fpage>
                  <lpage>721</lpage>
                  <pub-id pub-id-type="doi">10.1017/S0140525X98001745</pub-id>
                  <pub-id pub-id-type="pmid">10097023</pub-id>
                </element-citation>
              </ref>
              <ref id="CR22">
                <label>22.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Lee</surname>
                      <given-names>M</given-names>
                    </name>
                    <name>
                      <surname>Drake</surname>
                      <given-names>T</given-names>
                    </name>
                    <name>
                      <surname>Malik</surname>
                      <given-names>T</given-names>
                    </name>
                  </person-group>
                  <article-title>Has the bachelor of surgery left medical school? A national undergraduate assessment</article-title>
                  <source>J Surg Educ</source>
                  <year>2016</year>
                  <volume>73</volume>
                  <fpage>655</fpage>
                  <lpage>9</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.jsurg.2016.01.005</pub-id>
                  <pub-id pub-id-type="pmid">26908017</pub-id>
                </element-citation>
              </ref>
              <ref id="CR23">
                <label>23.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Freeman</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Eddy</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>McDonough</surname>
                      <given-names>M</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Active learning increases student performance in science, engineering, and mathematics</article-title>
                  <source>Proc Natl Acad Sci USA</source>
                  <year>2014</year>
                  <volume>111</volume>
                  <fpage>8410</fpage>
                  <lpage>5</lpage>
                  <pub-id pub-id-type="doi">10.1073/pnas.1319030111</pub-id>
                  <pub-id pub-id-type="pmid">24821756</pub-id>
                </element-citation>
              </ref>
              <ref id="CR24">
                <label>24.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Faisal</surname>
                      <given-names>R</given-names>
                    </name>
                    <name>
                      <surname>Khalil-Ur-Rehman, Bahadur</surname>
                      <given-names>S</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Problem-based learning in comparison with lecture-based learning among medical students</article-title>
                  <source>J Pak Med Assoc</source>
                  <year>2016</year>
                  <volume>66</volume>
                  <fpage>650</fpage>
                  <lpage>3</lpage>
                  <pub-id pub-id-type="pmid">27339562</pub-id>
                </element-citation>
              </ref>
              <ref id="CR25">
                <label>25.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Grant</surname>
                      <given-names>L</given-names>
                    </name>
                    <name>
                      <surname>Opperman</surname>
                      <given-names>M</given-names>
                    </name>
                    <name>
                      <surname>Schiller</surname>
                      <given-names>B</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Medical student engagement in a virtual learning environment positively correlates with course performance and satisfaction in psychiatry</article-title>
                  <source>Med Sci Educ</source>
                  <year>2021</year>
                  <volume>31</volume>
                  <issue>3</issue>
                  <fpage>1133</fpage>
                  <lpage>40</lpage>
                  <pub-id pub-id-type="doi">10.1007/s40670-021-01287-x</pub-id>
                  <pub-id pub-id-type="pmid">33868773</pub-id>
                </element-citation>
              </ref>
              <ref id="CR26">
                <label>26.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Hernández-Guerra</surname>
                      <given-names>M</given-names>
                    </name>
                    <name>
                      <surname>Quintero</surname>
                      <given-names>E</given-names>
                    </name>
                    <name>
                      <surname>Morales-Arráez</surname>
                      <given-names>D</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Comparison of flipped learning and traditional lecture method for teaching digestive system diseases in undergraduate medicine: a prospective non-randomized controlled trial</article-title>
                  <source>Med Teach</source>
                  <year>2021</year>
                  <volume>43</volume>
                  <issue>4</issue>
                  <fpage>463</fpage>
                  <lpage>71</lpage>
                  <pub-id pub-id-type="doi">10.1080/0142159X.2020.1867312</pub-id>
                  <pub-id pub-id-type="pmid">33502276</pub-id>
                </element-citation>
              </ref>
              <ref id="CR27">
                <label>27.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Moro</surname>
                      <given-names>C</given-names>
                    </name>
                    <name>
                      <surname>Phelps</surname>
                      <given-names>C</given-names>
                    </name>
                    <name>
                      <surname>Redmond</surname>
                      <given-names>P</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>HoloLens and mobile augmented reality in medical and health science education: a randomised controlled trial</article-title>
                  <source>Br J Edu Technol</source>
                  <year>2021</year>
                  <volume>52</volume>
                  <fpage>680</fpage>
                  <lpage>94</lpage>
                  <pub-id pub-id-type="doi">10.1111/bjet.13049</pub-id>
                </element-citation>
              </ref>
              <ref id="CR28">
                <label>28.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Straub</surname>
                      <given-names>E</given-names>
                    </name>
                  </person-group>
                  <article-title>Understanding technology adoption: theory and future directions for informal learning</article-title>
                  <source>Rev Educ Res</source>
                  <year>2009</year>
                  <volume>79</volume>
                  <issue>2</issue>
                  <fpage>625</fpage>
                  <lpage>49</lpage>
                  <pub-id pub-id-type="doi">10.3102/0034654308325896</pub-id>
                </element-citation>
              </ref>
              <ref id="CR29">
                <label>29.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Papanikolaou</surname>
                      <given-names>I</given-names>
                    </name>
                    <name>
                      <surname>Haidopoulos</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Paschopoulos</surname>
                      <given-names>M</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Changing the way we train surgeons in the 21st century: a narrative comparative review focused on box trainers and virtual reality simulators</article-title>
                  <source>Eur J Obstet Gynecol Reproductive Biology</source>
                  <year>2019</year>
                  <volume>235</volume>
                  <fpage>13</fpage>
                  <lpage>8</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.ejogrb.2019.01.016</pub-id>
                </element-citation>
              </ref>
              <ref id="CR30">
                <label>30.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Pettijohn</surname>
                      <given-names>K</given-names>
                    </name>
                    <name>
                      <surname>Peltier</surname>
                      <given-names>C</given-names>
                    </name>
                    <name>
                      <surname>Lukos</surname>
                      <given-names>J</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Virtual and augmented reality in a simulated naval engagement: preliminary comparisons of simulator sickness and human performance</article-title>
                  <source>Appl Ergon</source>
                  <year>2020</year>
                  <volume>89</volume>
                  <fpage>103200</fpage>
                  <pub-id pub-id-type="doi">10.1016/j.apergo.2020.103200</pub-id>
                  <pub-id pub-id-type="pmid">32658772</pub-id>
                </element-citation>
              </ref>
              <ref id="CR31">
                <label>31.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Rebenitsch</surname>
                      <given-names>L</given-names>
                    </name>
                    <name>
                      <surname>Owen</surname>
                      <given-names>C</given-names>
                    </name>
                  </person-group>
                  <article-title>Review on cybersickness in applications and visual displays</article-title>
                  <source>Virtual Reality</source>
                  <year>2016</year>
                  <volume>20</volume>
                  <fpage>101</fpage>
                  <lpage>25</lpage>
                  <pub-id pub-id-type="doi">10.1007/s10055-016-0285-9</pub-id>
                </element-citation>
              </ref>
            </ref-list>
          </back>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
