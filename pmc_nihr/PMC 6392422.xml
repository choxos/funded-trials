<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2024-05-03T11:04:35Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:6392422" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:6392422</identifier>
        <datestamp>2019-03-08</datestamp>
        <setSpec>plosone</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" article-type="research-article">
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
              <journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id>
              <journal-id journal-id-type="publisher-id">plos</journal-id>
              <journal-id journal-id-type="pmc">plosone</journal-id>
              <journal-title-group>
                <journal-title>PLoS ONE</journal-title>
              </journal-title-group>
              <issn pub-type="epub">1932-6203</issn>
              <publisher>
                <publisher-name>Public Library of Science</publisher-name>
                <publisher-loc>San Francisco, CA USA</publisher-loc>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC6392422</article-id>
              <article-id pub-id-type="pmcid">PMC6392422</article-id>
              <article-id pub-id-type="pmc-uid">6392422</article-id>
              <article-id pub-id-type="pmid">30811431</article-id>
              <article-id pub-id-type="doi">10.1371/journal.pone.0212205</article-id>
              <article-id pub-id-type="publisher-id">PONE-D-18-22975</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Research Article</subject>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>People and Places</subject>
                  <subj-group>
                    <subject>Population Groupings</subject>
                    <subj-group>
                      <subject>Age Groups</subject>
                      <subj-group>
                        <subject>Children</subject>
                        <subj-group>
                          <subject>Infants</subject>
                        </subj-group>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>People and Places</subject>
                  <subj-group>
                    <subject>Population Groupings</subject>
                    <subj-group>
                      <subject>Families</subject>
                      <subj-group>
                        <subject>Children</subject>
                        <subj-group>
                          <subject>Infants</subject>
                        </subj-group>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Biology and Life Sciences</subject>
                  <subj-group>
                    <subject>Psychology</subject>
                    <subj-group>
                      <subject>Emotions</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Social Sciences</subject>
                  <subj-group>
                    <subject>Psychology</subject>
                    <subj-group>
                      <subject>Emotions</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Biology and Life Sciences</subject>
                  <subj-group>
                    <subject>Psychology</subject>
                    <subj-group>
                      <subject>Behavior</subject>
                      <subj-group>
                        <subject>Animal Behavior</subject>
                        <subj-group>
                          <subject>Animal Communication</subject>
                          <subj-group>
                            <subject>Vocalization</subject>
                          </subj-group>
                        </subj-group>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Social Sciences</subject>
                  <subj-group>
                    <subject>Psychology</subject>
                    <subj-group>
                      <subject>Behavior</subject>
                      <subj-group>
                        <subject>Animal Behavior</subject>
                        <subj-group>
                          <subject>Animal Communication</subject>
                          <subj-group>
                            <subject>Vocalization</subject>
                          </subj-group>
                        </subj-group>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Biology and Life Sciences</subject>
                  <subj-group>
                    <subject>Zoology</subject>
                    <subj-group>
                      <subject>Animal Behavior</subject>
                      <subj-group>
                        <subject>Animal Communication</subject>
                        <subj-group>
                          <subject>Vocalization</subject>
                        </subj-group>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Biology and Life Sciences</subject>
                  <subj-group>
                    <subject>Psychology</subject>
                    <subj-group>
                      <subject>Behavior</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Social Sciences</subject>
                  <subj-group>
                    <subject>Psychology</subject>
                    <subj-group>
                      <subject>Behavior</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Social Sciences</subject>
                  <subj-group>
                    <subject>Linguistics</subject>
                    <subj-group>
                      <subject>Speech</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Research and Analysis Methods</subject>
                  <subj-group>
                    <subject>Spectrum Analysis Techniques</subject>
                    <subj-group>
                      <subject>Infrared Spectroscopy</subject>
                      <subj-group>
                        <subject>near-Infrared Spectroscopy</subject>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Research and Analysis Methods</subject>
                  <subj-group>
                    <subject>Imaging Techniques</subject>
                    <subj-group>
                      <subject>Neuroimaging</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Biology and Life Sciences</subject>
                  <subj-group>
                    <subject>Neuroscience</subject>
                    <subj-group>
                      <subject>Neuroimaging</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Biology and Life Sciences</subject>
                  <subj-group>
                    <subject>Psychology</subject>
                    <subj-group>
                      <subject>Behavior</subject>
                      <subj-group>
                        <subject>Parenting Behavior</subject>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Social Sciences</subject>
                  <subj-group>
                    <subject>Psychology</subject>
                    <subj-group>
                      <subject>Behavior</subject>
                      <subj-group>
                        <subject>Parenting Behavior</subject>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>Is infant neural sensitivity to vocal emotion associated with mother-infant relational experience?</article-title>
                <alt-title alt-title-type="running-head">Infant neural processing of vocal emotion at six months</alt-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author">
                  <name>
                    <surname>Zhao</surname>
                    <given-names>Chen</given-names>
                  </name>
                  <role content-type="http://credit.casrai.org/">Conceptualization</role>
                  <role content-type="http://credit.casrai.org/">Data curation</role>
                  <role content-type="http://credit.casrai.org/">Formal analysis</role>
                  <role content-type="http://credit.casrai.org/">Investigation</role>
                  <role content-type="http://credit.casrai.org/">Methodology</role>
                  <role content-type="http://credit.casrai.org/">Project administration</role>
                  <role content-type="http://credit.casrai.org/">Resources</role>
                  <role content-type="http://credit.casrai.org/">Software</role>
                  <role content-type="http://credit.casrai.org/">Validation</role>
                  <role content-type="http://credit.casrai.org/">Visualization</role>
                  <role content-type="http://credit.casrai.org/">Writing – original draft</role>
                  <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
                  <xref ref-type="aff" rid="aff001">
                    <sup>1</sup>
                  </xref>
                  <xref ref-type="corresp" rid="cor001">*</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Chronaki</surname>
                    <given-names>Georgia</given-names>
                  </name>
                  <role content-type="http://credit.casrai.org/">Conceptualization</role>
                  <role content-type="http://credit.casrai.org/">Investigation</role>
                  <role content-type="http://credit.casrai.org/">Methodology</role>
                  <role content-type="http://credit.casrai.org/">Project administration</role>
                  <role content-type="http://credit.casrai.org/">Resources</role>
                  <role content-type="http://credit.casrai.org/">Software</role>
                  <role content-type="http://credit.casrai.org/">Supervision</role>
                  <role content-type="http://credit.casrai.org/">Validation</role>
                  <role content-type="http://credit.casrai.org/">Visualization</role>
                  <role content-type="http://credit.casrai.org/">Writing – original draft</role>
                  <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
                  <xref ref-type="aff" rid="aff002">
                    <sup>2</sup>
                  </xref>
                  <xref ref-type="aff" rid="aff003">
                    <sup>3</sup>
                  </xref>
                  <xref ref-type="aff" rid="aff004">
                    <sup>4</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9599-6194</contrib-id>
                  <name>
                    <surname>Schiessl</surname>
                    <given-names>Ingo</given-names>
                  </name>
                  <role content-type="http://credit.casrai.org/">Conceptualization</role>
                  <role content-type="http://credit.casrai.org/">Data curation</role>
                  <role content-type="http://credit.casrai.org/">Formal analysis</role>
                  <role content-type="http://credit.casrai.org/">Methodology</role>
                  <role content-type="http://credit.casrai.org/">Project administration</role>
                  <role content-type="http://credit.casrai.org/">Software</role>
                  <role content-type="http://credit.casrai.org/">Supervision</role>
                  <role content-type="http://credit.casrai.org/">Validation</role>
                  <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
                  <xref ref-type="aff" rid="aff003">
                    <sup>3</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Wan</surname>
                    <given-names>Ming Wai</given-names>
                  </name>
                  <role content-type="http://credit.casrai.org/">Formal analysis</role>
                  <role content-type="http://credit.casrai.org/">Methodology</role>
                  <role content-type="http://credit.casrai.org/">Project administration</role>
                  <role content-type="http://credit.casrai.org/">Supervision</role>
                  <role content-type="http://credit.casrai.org/">Validation</role>
                  <role content-type="http://credit.casrai.org/">Visualization</role>
                  <role content-type="http://credit.casrai.org/">Writing – original draft</role>
                  <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
                  <xref ref-type="aff" rid="aff001">
                    <sup>1</sup>
                  </xref>
                  <xref ref-type="author-notes" rid="econtrib001">
                    <sup>‡</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Abel</surname>
                    <given-names>Kathryn M.</given-names>
                  </name>
                  <role content-type="http://credit.casrai.org/">Conceptualization</role>
                  <role content-type="http://credit.casrai.org/">Funding acquisition</role>
                  <role content-type="http://credit.casrai.org/">Supervision</role>
                  <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
                  <xref ref-type="aff" rid="aff001">
                    <sup>1</sup>
                  </xref>
                  <xref ref-type="aff" rid="aff005">
                    <sup>5</sup>
                  </xref>
                  <xref ref-type="author-notes" rid="econtrib001">
                    <sup>‡</sup>
                  </xref>
                </contrib>
              </contrib-group>
              <aff id="aff001">
                <label>1</label>
                <addr-line>Centre for Women’s Mental Health, Faculty of Biology, Medicine and Health, University of Manchester, Manchester, United Kingdom</addr-line>
              </aff>
              <aff id="aff002">
                <label>2</label>
                <addr-line>Developmental Cognitive Neuroscience (DCN) Laboratory, School of Psychology, University of Central Lancashire, Preston, United Kingdom</addr-line>
              </aff>
              <aff id="aff003">
                <label>3</label>
                <addr-line>Division of Neuroscience &amp; Experimental Psychology, Faculty of Biology, Medicine and Health, University of Manchester, Manchester, United Kingdom</addr-line>
              </aff>
              <aff id="aff004">
                <label>4</label>
                <addr-line>Developmental Brain-Behaviour Laboratory, Psychology, University of Southampton, United Kingdom</addr-line>
              </aff>
              <aff id="aff005">
                <label>5</label>
                <addr-line>Greater Manchester Mental Health NHS Foundation Trust, Manchester, United Kingdom</addr-line>
              </aff>
              <contrib-group>
                <contrib contrib-type="editor">
                  <name>
                    <surname>Eisenbarth</surname>
                    <given-names>Hedwig</given-names>
                  </name>
                  <role>Editor</role>
                  <xref ref-type="aff" rid="edit1"/>
                </contrib>
              </contrib-group>
              <aff id="edit1">
                <addr-line>Victoria University of Wellington, NEW ZEALAND</addr-line>
              </aff>
              <author-notes>
                <fn fn-type="COI-statement" id="coi001">
                  <p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
                </fn>
                <fn fn-type="other" id="econtrib001">
                  <p>‡ These authors are joint senior authors on this work.</p>
                </fn>
                <corresp id="cor001">* E-mail: <email>chenzhao510@gmail.com</email></corresp>
              </author-notes>
              <pub-date pub-type="epub">
                <day>27</day>
                <month>2</month>
                <year>2019</year>
              </pub-date>
              <pub-date pub-type="collection">
                <year>2019</year>
              </pub-date>
              <volume>14</volume>
              <issue>2</issue>
              <elocation-id>e0212205</elocation-id>
              <history>
                <date date-type="received">
                  <day>3</day>
                  <month>8</month>
                  <year>2018</year>
                </date>
                <date date-type="accepted">
                  <day>29</day>
                  <month>1</month>
                  <year>2019</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>© 2019 Zhao et al</copyright-statement>
                <copyright-year>2019</copyright-year>
                <copyright-holder>Zhao et al</copyright-holder>
                <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
                  <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
                </license>
              </permissions>
              <self-uri content-type="pdf" xlink:href="pone.0212205.pdf"/>
              <abstract>
                <p>An early understanding of others’ vocal emotions provides infants with a distinct advantage for eliciting appropriate care from caregivers and for navigating their social world. Consistent with this notion, an emerging literature suggests that a temporal cortical response to the prosody of emotional speech is observable in the first year of life. Furthermore, neural specialisation to vocal emotion in infancy may vary according to early experience. Neural sensitivity to emotional non-speech vocalisations was investigated in 29 six-month-old infants using near-infrared spectroscopy (fNIRS). Both angry and happy vocalisations evoked increased activation in the temporal cortices (relative to neutral and angry vocalisations respectively), and the strength of the angry minus neutral effect was positively associated with the degree of directiveness in the mothers’ play interactions with their infant. This first fNIRS study of infant vocal emotion processing implicates bilateral temporal mechanisms similar to those found in adults and suggests that infants who experience more directive caregiving or social play may more strongly or preferentially process vocal anger by six months of age.</p>
              </abstract>
              <funding-group>
                <award-group id="award001">
                  <funding-source>
                    <institution>European Research Council Consolidator award</institution>
                  </funding-source>
                  <principal-award-recipient>
                    <name>
                      <surname>Abel</surname>
                      <given-names>Kathryn M.</given-names>
                    </name>
                  </principal-award-recipient>
                </award-group>
                <award-group id="award002">
                  <funding-source>
                    <institution-wrap>
                      <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100004543</institution-id>
                      <institution>China Scholarship Council</institution>
                    </institution-wrap>
                  </funding-source>
                  <award-id>201406990026</award-id>
                  <principal-award-recipient>
                    <name>
                      <surname>Zhao</surname>
                      <given-names>Chen</given-names>
                    </name>
                  </principal-award-recipient>
                </award-group>
                <funding-statement>Chen Zhao was supported by the program of China Scholarship Council (201406990026) while carrying out the study. Professor Kathryn Abel is an NIHR senior Investigator and is funded by a European Research Council Consolidator award.</funding-statement>
              </funding-group>
              <counts>
                <fig-count count="4"/>
                <table-count count="2"/>
                <page-count count="17"/>
              </counts>
              <custom-meta-group>
                <custom-meta id="data-availability">
                  <meta-name>Data Availability</meta-name>
                  <meta-value>The data set underpinning the conclusions of this study consists of fNIRS data, maternal interaction ratings, and mother-infant interaction video data. We have included an anonymized version of our fNIRS data set along with the maternal interaction ratings as Supporting Information. As the mother-infant interaction video data are not anonymized, the sharing of these data has been restricted. They are available upon request from the UK National Health Service ethics committee, ref: 15/NW/0684, Confidentiality Advisory Group (CAG) queries: <email>HRA.CAG@nhs.net</email>.</meta-value>
                </custom-meta>
              </custom-meta-group>
            </article-meta>
            <notes>
              <title>Data Availability</title>
              <p>The data set underpinning the conclusions of this study consists of fNIRS data, maternal interaction ratings, and mother-infant interaction video data. We have included an anonymized version of our fNIRS data set along with the maternal interaction ratings as Supporting Information. As the mother-infant interaction video data are not anonymized, the sharing of these data has been restricted. They are available upon request from the UK National Health Service ethics committee, ref: 15/NW/0684, Confidentiality Advisory Group (CAG) queries: <email>HRA.CAG@nhs.net</email>.</p>
            </notes>
          </front>
          <body>
            <sec sec-type="intro" id="sec001">
              <title>Introduction</title>
              <p>Human responsiveness to familiar vocalisations starts prenatally when the heart rate of the fetus increases in response to the mother’s voice compared to that of an unknown female [<xref rid="pone.0212205.ref001" ref-type="bibr">1</xref>]. The ability to discriminate vocal emotion as early as possible in life serves an adaptive evolutionary function [<xref rid="pone.0212205.ref002" ref-type="bibr">2</xref>]. Infants rely heavily on their mothers’ emotional prosody, such as affective warmth or fear, as a basis to elicit care and, ultimately, to maintain safety from threat [<xref rid="pone.0212205.ref003" ref-type="bibr">3</xref>, <xref rid="pone.0212205.ref004" ref-type="bibr">4</xref>]. Positive vocalisations are likely to facilitate infant-mother bonding and secure attachment [<xref rid="pone.0212205.ref003" ref-type="bibr">3</xref>, <xref rid="pone.0212205.ref005" ref-type="bibr">5</xref>, <xref rid="pone.0212205.ref006" ref-type="bibr">6</xref>] and infants will be familiar with their mothers use of infant-directed speech, a style often characterised by exaggerated positive affect [<xref rid="pone.0212205.ref007" ref-type="bibr">7</xref>, <xref rid="pone.0212205.ref008" ref-type="bibr">8</xref>]. On the other hand, negative vocalisations, especially angry ones, act as a direct cue to react to or avoid dangerous situations [<xref rid="pone.0212205.ref009" ref-type="bibr">9</xref>, <xref rid="pone.0212205.ref010" ref-type="bibr">10</xref>]. The auditory processing of vocal emotion is likely to be rudimentary in the early months [<xref rid="pone.0212205.ref011" ref-type="bibr">11</xref>]; then at around 5 months, the ability to discriminate vocal affective expressions generalises to non-caregiver female voices [<xref rid="pone.0212205.ref012" ref-type="bibr">12</xref>–<xref rid="pone.0212205.ref016" ref-type="bibr">16</xref>]. Soon after, infants develop the ability to ‘social reference’ known adults to gain vocal and facial information on how to react to ambiguous, potentially threatening situations [<xref rid="pone.0212205.ref017" ref-type="bibr">17</xref>, <xref rid="pone.0212205.ref018" ref-type="bibr">18</xref>]. Young infants cannot always access others’ facial cues because of their relative immobility, which may partially explain their increased reliance on vocal over facial expression for accurate emotional information [<xref rid="pone.0212205.ref015" ref-type="bibr">15</xref>, <xref rid="pone.0212205.ref018" ref-type="bibr">18</xref>].</p>
              <p>Research on voice processing in the infant brain is relatively new. Evidence from adult neuroimaging implicates a temporo-frontal pathway for the processing of emotional vocalisations: the temporal cortices for the acoustic analysis of vocal stimuli and the frontal regions for more detailed cognitive evaluation (e.g. [<xref rid="pone.0212205.ref019" ref-type="bibr">19</xref>–<xref rid="pone.0212205.ref022" ref-type="bibr">22</xref>]). Informed by adult brain lesion studies, vocal emotion processing was initially thought to be lateralised to the right hemisphere [<xref rid="pone.0212205.ref020" ref-type="bibr">20</xref>–<xref rid="pone.0212205.ref022" ref-type="bibr">22</xref>]. Current evidence supports the crucial role of bilateral superior temporal and inferior frontal regions [<xref rid="pone.0212205.ref023" ref-type="bibr">23</xref>–<xref rid="pone.0212205.ref026" ref-type="bibr">26</xref>], based on paradigms involving varied stimuli (speech and semantic meanings) and task requirements (implicit and explicit tasks).</p>
              <p>Consistent with adult findings, functional imaging studies of infant voice processing suggest that the temporal and/or frontal cortical regions are sensitive to voice between ages of 3 and 7 months [<xref rid="pone.0212205.ref027" ref-type="bibr">27</xref>–<xref rid="pone.0212205.ref031" ref-type="bibr">31</xref>]. Two of these studies further report that emotional prosody elicited a stronger response compared to neutral vocalisations in voice-sensitive regions [<xref rid="pone.0212205.ref027" ref-type="bibr">27</xref>, <xref rid="pone.0212205.ref030" ref-type="bibr">30</xref>]. These findings broadly mirror the timeline suggested by looking-time studies [<xref rid="pone.0212205.ref012" ref-type="bibr">12</xref>–<xref rid="pone.0212205.ref014" ref-type="bibr">14</xref>], and may reveal an early version of the adult temporo-frontal vocal emotion processing pathway [<xref rid="pone.0212205.ref019" ref-type="bibr">19</xref>–<xref rid="pone.0212205.ref022" ref-type="bibr">22</xref>] which prioritises the processing of emotional [<xref rid="pone.0212205.ref026" ref-type="bibr">26</xref>, <xref rid="pone.0212205.ref032" ref-type="bibr">32</xref>] (especially negative [<xref rid="pone.0212205.ref023" ref-type="bibr">23</xref>, <xref rid="pone.0212205.ref032" ref-type="bibr">32</xref>, <xref rid="pone.0212205.ref033" ref-type="bibr">33</xref>]) prosody. In adults, the relatively stronger neural response to vocal negativity likely reflects an attentional bias for negative stimuli [<xref rid="pone.0212205.ref034" ref-type="bibr">34</xref>]. Furthermore, children show this negativity bias in a range of socio-communicative domains, such as social referencing and language acquisition [<xref rid="pone.0212205.ref002" ref-type="bibr">2</xref>, <xref rid="pone.0212205.ref035" ref-type="bibr">35</xref>]. Studies of infant processing of emotional speech found an increased temporal activation in response to angry and happy speech compared to neutral speech in 7- to 8-month infants [<xref rid="pone.0212205.ref027" ref-type="bibr">27</xref>, <xref rid="pone.0212205.ref036" ref-type="bibr">36</xref>]. Two functional magnetic resonance imaging (fMRI) studies of non-speech prosody processing in 3- to 7-month sleeping infants reported stronger neural responses to sad than neutral vocalisations [<xref rid="pone.0212205.ref029" ref-type="bibr">29</xref>, <xref rid="pone.0212205.ref030" ref-type="bibr">30</xref>], this may suggest that infants are able to detect or discriminate emotion within non-speech vocalisations earlier than in speech.</p>
              <p>Near Infrared Spectroscopy (NIRS) is a neuroimaging technique that offers distinct advantages for studying infant brain functioning in response to vocal stimuli. Compared with fMRI and elecotroencephalogram (EEG), the equipment is portable, silent (thus ideal for using auditory stimuli), and less intrusive (e.g. the infant can sit on the mother’s lap during measurement); all of which makes fNIRS potentially more suitable for infant studies. However, neither of the infant fNIRS studies on vocal emotion processing to date employed non-speech vocalisations at a time when infants are pre-verbal. One study in sleeping neonates found differentiated neural responses in the temporal cortex to fearful, angry, happy speech compared to neutral speech [<xref rid="pone.0212205.ref037" ref-type="bibr">37</xref>]. A study of 7-month-old awake infants similarly suggest that angry and happy speech evoked stronger frontal and temporal activations compared to neutral speech [<xref rid="pone.0212205.ref027" ref-type="bibr">27</xref>]. The present study sought to extend our current understanding of the emergence of vocal emotion sensitivity by using non-speech stimuli with 6-month-old preverbal infants.</p>
              <p>Furthermore, almost no neuroimaging studies have examined whether environmental factors may be associated with individual differences in infant vocal emotion processing. Behavioural studies suggest that both language and relational development are shaped by maternal behaviour toward the infant. For example, qualities of maternal behaviour, such as the degree of behavioural sensitive responding [<xref rid="pone.0212205.ref006" ref-type="bibr">6</xref>, <xref rid="pone.0212205.ref038" ref-type="bibr">38</xref>, <xref rid="pone.0212205.ref039" ref-type="bibr">39</xref>], play a significant role in the child’s language development. The precise significance and meaning that infants attach to different vocal emotions may also differ according the qualities of the mother-infant attachment relationship given that infants are highly dependent on maternal communication to maintain safety from threat. From the earliest months of life, infants begin to regulate their own behaviour and emotions according to the quality of care they receive [<xref rid="pone.0212205.ref011" ref-type="bibr">11</xref>]. The emerging ability to process and differentiate vocal emotions may play an important role in communicative and social-emotional development and may be influenced by the affective tendencies of the mother that accompany her caregiving or interactive style. Evidence from EEG studies suggest that maternal caregiving behaviour may relate to longitudinal changes in infants’ frontal resting EEG power, which serves attentional processes [<xref rid="pone.0212205.ref040" ref-type="bibr">40</xref>, <xref rid="pone.0212205.ref041" ref-type="bibr">41</xref>]. While maternal sensitivity is typically characterised by positive vocal cues from high emotional warmth [<xref rid="pone.0212205.ref003" ref-type="bibr">3</xref>, <xref rid="pone.0212205.ref042" ref-type="bibr">42</xref>], infants with sensitively responsive mothers may prioritise attention to all strong emotional information as they have learned through experience that others’ vocalisations (and their own) are meaningful and relevant for understanding and navigating their interpersonal relationships and environment.</p>
              <p>Another type of caregiving behaviour is described as maternal directiveness, which refers to the amount and severity of vocal or behavioural demands, intrusions or critical utterances used by the mother. Maternal directiveness may be expressed in vocally negative forms and conveys a degree of <italic>expectation</italic> (explicitly or implicitly) that the infant attends to or complies, or prohibits such action [<xref rid="pone.0212205.ref043" ref-type="bibr">43</xref>]. Therefore, exposure to high directiveness over time may plausibly give rise to a bias towards attending to negative prosody that may be observed at a neural level. One study to date has attempted to link maternal behaviour (intrusiveness) with 3- to 7-month-old infant neural vocal response—in infants at high and low risk of autism, and found no significant linear relationship in this specific group [<xref rid="pone.0212205.ref030" ref-type="bibr">30</xref>].</p>
              <p>The current study investigated 6-month-old infant hemodynamic response to emotional prosody in non-speech vocalisations. The key objective was to test whether there was increased neural activation in the temporal region in response to emotional (angry, happy) compared to neutral vocalisations, as found in adult studies. Secondly, we explored whether individual variation in neural response to emotional prosody would correlate with infants’ real-life maternal interactions, as measured from independently video-recorded observations of mother-infant play interactions. Specifically, we examined whether the degree of maternal sensitivity and directiveness toward infant was associated with infant neural activation in response to emotional prosody.</p>
            </sec>
            <sec sec-type="materials|methods" id="sec002">
              <title>Materials and methods</title>
              <sec id="sec003">
                <title>Participants</title>
                <p>Forty white, fluent English-speaking mothers over 18 years of age were recruited from three community health centres in Manchester, UK. Eligible mothers had no current mental disorder and had given birth to healthy infants. Forty infants (20 boys, and 20 girls) of recruited mothers participated in the current study at 6 months of age. The final sample consisted of 29 infants (see <xref rid="pone.0212205.t001" ref-type="table">Table 1</xref> for demographics), as 11 infants did not meet the minimum 4 out of 8 trials per experimental condition as a result of motion artefacts. This attrition rate is within the standard range for infant NIRS studies [<xref rid="pone.0212205.ref044" ref-type="bibr">44</xref>]. A power analysis using the G*power program [<xref rid="pone.0212205.ref045" ref-type="bibr">45</xref>] indicated that a sample size of N = 29 would give 92% power to achieve an effect size of 0.59 (which equals to eta-squared of 0.26). All infants were born full term (37–42 weeks gestation) except n = 1 born at 36 weeks gestation (corrected age used), at normal birth weight (&gt;2500g), and had no hearing difficulties according to parent report. The UK National Health Service ethics committee approved the study (ref: 15/NW/0684), and mothers provided consent for their infant’s involvement.</p>
                <table-wrap id="pone.0212205.t001" orientation="portrait" position="float">
                  <object-id pub-id-type="doi">10.1371/journal.pone.0212205.t001</object-id>
                  <label>Table 1</label>
                  <caption>
                    <title>Sample demographic information (N = 29).</title>
                  </caption>
                  <alternatives>
                    <graphic id="pone.0212205.t001g" xlink:href="pone.0212205.t001"/>
                    <table frame="hsides" rules="groups">
                      <colgroup span="1">
                        <col align="left" valign="middle" span="1"/>
                        <col align="left" valign="middle" span="1"/>
                        <col align="left" valign="middle" span="1"/>
                      </colgroup>
                      <thead>
                        <tr>
                          <th align="left" rowspan="1" colspan="1"/>
                          <th align="center" rowspan="1" colspan="1">Mean ± SD</th>
                          <th align="center" rowspan="1" colspan="1">Range</th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">Maternal age (years)</td>
                          <td align="center" rowspan="1" colspan="1">34.79 ± 3.67</td>
                          <td align="center" rowspan="1" colspan="1">23–40</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">Infant age (days)</td>
                          <td align="center" rowspan="1" colspan="1">189 ± 9.66</td>
                          <td align="center" rowspan="1" colspan="1">175–214</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1"/>
                          <td align="center" rowspan="1" colspan="1">Demographic category</td>
                          <td align="center" rowspan="1" colspan="1">Count (%)</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">Infant sex</td>
                          <td align="center" rowspan="1" colspan="1">Female</td>
                          <td align="center" rowspan="1" colspan="1">15 (51.7)</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1"/>
                          <td align="center" rowspan="1" colspan="1">Male</td>
                          <td align="center" rowspan="1" colspan="1">14 (48.3)</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1"/>
                          <td align="center" rowspan="1" colspan="1">Category</td>
                          <td align="center" rowspan="1" colspan="1">Frequency</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">Current maternal work status<xref ref-type="table-fn" rid="t001fn001">*</xref></td>
                          <td align="center" rowspan="1" colspan="1">Full-time work</td>
                          <td align="center" rowspan="1" colspan="1">7 (24.14)</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1"/>
                          <td align="center" rowspan="1" colspan="1">Part-time work</td>
                          <td align="center" rowspan="1" colspan="1">3 (10.34)</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1"/>
                          <td align="center" rowspan="1" colspan="1">Looking after family or home</td>
                          <td align="center" rowspan="1" colspan="1">1 (3.45)</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1"/>
                          <td align="center" rowspan="1" colspan="1">Maternity leave</td>
                          <td align="center" rowspan="1" colspan="1">17 (58.62)</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">Mother’s highest qualification<xref ref-type="table-fn" rid="t001fn001">*</xref></td>
                          <td align="center" rowspan="1" colspan="1">University degree or above</td>
                          <td align="center" rowspan="1" colspan="1">24 (82.76)</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1"/>
                          <td align="center" rowspan="1" colspan="1">A-levels or equivalent</td>
                          <td align="center" rowspan="1" colspan="1">1 (3.45)</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1"/>
                          <td align="center" rowspan="1" colspan="1">GCSE or equivalent</td>
                          <td align="center" rowspan="1" colspan="1">3 (10.34)</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">Household Income (GBP)<xref ref-type="table-fn" rid="t001fn001">*</xref></td>
                          <td align="center" rowspan="1" colspan="1">20,000–55,000</td>
                          <td align="center" rowspan="1" colspan="1">6 (20.69)</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1"/>
                          <td align="center" rowspan="1" colspan="1">55,001–80,000</td>
                          <td align="center" rowspan="1" colspan="1">12 (41.38)</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1"/>
                          <td align="center" rowspan="1" colspan="1">80,001 upwards</td>
                          <td align="center" rowspan="1" colspan="1">10 (34.48)</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">Marital status<xref ref-type="table-fn" rid="t001fn001">*</xref></td>
                          <td align="center" rowspan="1" colspan="1">Married or cohabiting</td>
                          <td align="center" rowspan="1" colspan="1">28 (96.6)</td>
                        </tr>
                      </tbody>
                    </table>
                  </alternatives>
                  <table-wrap-foot>
                    <fn id="t001fn001">
                      <p>*Missing data = 1 (3.4%)</p>
                    </fn>
                  </table-wrap-foot>
                </table-wrap>
              </sec>
              <sec id="sec004">
                <title>Experimental paradigm and procedure</title>
                <p>During the fNIRS experimental procedure (<xref ref-type="fig" rid="pone.0212205.g001">Fig 1</xref>), infants sat on their mother’s lap facing a laptop and wearing the NIRS headband. The task started with a 20-sec rest period, followed by a 5-sec trial presented through loudspeakers (SPL = 70 dB). A 5-sec silent cartoon video was shown during each trial to attract infant attention and reduce motion artefact, as consistent with previous research [<xref rid="pone.0212205.ref027" ref-type="bibr">27</xref>]. After each trial, a 10-sec silent blurred cartoon baseline was presented. The task was presented with PsychoPy software [<xref rid="pone.0212205.ref046" ref-type="bibr">46</xref>]. Each condition (angry, happy and neutral) was presented 8 times amounting to a total number of 24 trials. The same emotional expression did not occur consecutively. The testing session lasted 6 minutes and 20 seconds.</p>
                <fig id="pone.0212205.g001" orientation="portrait" position="float">
                  <object-id pub-id-type="doi">10.1371/journal.pone.0212205.g001</object-id>
                  <label>Fig 1</label>
                  <caption>
                    <title>Experiment design.</title>
                    <p>The streamline demonstrates the timeline of the experimental task stimulus presentation and baseline. The task started with a 20-sec rest period, followed by a 5-sec stimulation presented. A 5-sec silent cartoon video was shown during each stimulation presentation trial to attract infant attention and reduce motion artefact. After each stimulation trial, a 10-sec silent blurred, cartoon baseline was presented. The silent cartoon was the same for all the stimulation conditions (angry, neutral and happy).</p>
                  </caption>
                  <graphic xlink:href="pone.0212205.g001"/>
                </fig>
              </sec>
              <sec id="sec005">
                <title>Vocal stimuli</title>
                <p>The stimulus material consisted of 15 adult female, non-speech vocalisations of angry, happy and neutral prosody (interjection ‘ah’) from a well-validated battery of vocal emotional expressions [<xref rid="pone.0212205.ref047" ref-type="bibr">47</xref>]. This battery has high internal consistency for each emotion set as well as high levels of specificity (independence between the ratings in the different emotion sets [<xref rid="pone.0212205.ref047" ref-type="bibr">47</xref>]. These stimuli have been validated in previous research in UK children and adults [<xref rid="pone.0212205.ref048" ref-type="bibr">48</xref>] and have been applied in neuroscience studies in typically developing children and children with developmental disorders [<xref rid="pone.0212205.ref035" ref-type="bibr">35</xref>, <xref rid="pone.0212205.ref049" ref-type="bibr">49</xref>]. Five normalised stimuli, each lasting 1 sec, from the same expression category were selected and combined to form a 5-sec trial. All vocal stimuli were normalised with Praat sound-analysis software [<xref rid="pone.0212205.ref050" ref-type="bibr">50</xref>] to the same duration of 1000 ms and mean intensity of 73 dB.</p>
              </sec>
              <sec id="sec006">
                <title>fNIRS data acquisition</title>
                <p>During functional cerebral activation, the NIRS setting measures the attenuation of light that corresponds to an increase of Oxy-Haemoglobin concentrations and a decrease of Deoxy-Haemoglobin concentrations in the blood flow [<xref rid="pone.0212205.ref044" ref-type="bibr">44</xref>, <xref rid="pone.0212205.ref051" ref-type="bibr">51</xref>, <xref rid="pone.0212205.ref052" ref-type="bibr">52</xref>]. Previous fNIRS studies suggested Oxy-Haemoglobin concentration changes as the most sensitive indicator of changes in cerebral blood flow and has the highest signal-to-noise ratio (see [<xref rid="pone.0212205.ref044" ref-type="bibr">44</xref>, <xref rid="pone.0212205.ref053" ref-type="bibr">53</xref>]). Although we reported both Oxy- and Deoxy-Haemoglobin concentration changes, we focus our analysis and discussion on the Oxy-Haemoglobin concentration changes. In the present study, infants’ cerebral responses were recorded with a multichannel NIRS data collection system. The system was built by Biomedical Optics Research Laboratory (Dept. of Medical Physics and Bioengineering, University College London) and applied with 780nm and 850nm continuous wavelengths and 10Hz sampling rate [<xref rid="pone.0212205.ref054" ref-type="bibr">54</xref>]. Two detectors and 6 sources formed 12 source-detector pairs in each hemisphere and were distributed at temporal regions, which have been shown to be voice sensitive in previous research in infants [<xref rid="pone.0212205.ref027" ref-type="bibr">27</xref>, <xref rid="pone.0212205.ref028" ref-type="bibr">28</xref>, <xref rid="pone.0212205.ref055" ref-type="bibr">55</xref>, <xref rid="pone.0212205.ref056" ref-type="bibr">56</xref>]; and adults [<xref rid="pone.0212205.ref033" ref-type="bibr">33</xref>, <xref rid="pone.0212205.ref057" ref-type="bibr">57</xref>, <xref rid="pone.0212205.ref058" ref-type="bibr">58</xref>]. To achieve the best spatial sensitivity profile for infants [<xref rid="pone.0212205.ref059" ref-type="bibr">59</xref>], the distances between source and detectors were fixed between 1.5 and 2.5 cm. Channels were distributed according to the 10–20 system and attached to a custom-made Velcro headband. The headband was adjusted by calculating the distance between the glabella and the ear, ensuring that T3 and T4 are between the two bottom sources in each hemisphere. The locations of the channels and the channel positions with respect to the 10–20 system are presented in <xref ref-type="fig" rid="pone.0212205.g002">Fig 2</xref>. The source-detector geometry was put into the HOMER2 NIRS analysis toolbox (version 2.1, <ext-link ext-link-type="uri" xlink:href="http://homer-fnirs.org/">http://homer-fnirs.org/</ext-link>, Huppert et al., 2009[<xref rid="pone.0212205.ref060" ref-type="bibr">60</xref>]) as a matrix. The HOMER2 package then modelled the scattering paths according to the provided parameters.</p>
                <fig id="pone.0212205.g002" orientation="portrait" position="float">
                  <object-id pub-id-type="doi">10.1371/journal.pone.0212205.g002</object-id>
                  <label>Fig 2</label>
                  <caption>
                    <title>Source-detector distribution.</title>
                    <p>The head model illustrates the source-detector distribution where red dots represent sources (6 in each hemisphere) and blue dots represent detectors (2 in each hemisphere), and are held by Velcro headband. The channel locations with respect to the 10–20 system are marked in red (upper head models). Sources and detectors form 12 recording channels in each hemisphere, which are marked in blue numbers (bottom head models).</p>
                  </caption>
                  <graphic xlink:href="pone.0212205.g002"/>
                </fig>
              </sec>
              <sec id="sec007">
                <title>fNIRS data analysis</title>
                <p>Video-recorded infant behaviour during the task was viewed to code whether the infant attended to the screen without large motion artefacts. Four out of eight trials per condition was set as the minimum criterion for inclusion of each infant dataset.</p>
                <p>All the datasets analysed were filtered at 0.01 to 0.5Hz with 3rd order Butterworth filter, to eliminate slow drifts, instrument noise and physiological artefacts, such as heartbeats [<xref rid="pone.0212205.ref027" ref-type="bibr">27</xref>, <xref rid="pone.0212205.ref061" ref-type="bibr">61</xref>, <xref rid="pone.0212205.ref062" ref-type="bibr">62</xref>]. The remaining artefacts were identified on a channel by channel basis with the algorithm ‘hmrMotionArtifactByChannel’ implemented in the HOMER2 NIRS toolbox. Within the time interval (tMotion), if the change of the signal amplitude exceeded the threshold (AMPthresh) or the standard deviation changes were greater than a factor (STDEVthresh) multiplied by the original channel standard deviation, the time period (tMask time before and after the motion artefact) was marked as artefact. The time period of motion artefact within the channel was corrected with a cubic spline interpolation algorithm with p set to 0.99 as recommended [<xref rid="pone.0212205.ref062" ref-type="bibr">62</xref>, <xref rid="pone.0212205.ref063" ref-type="bibr">63</xref>]. Since the algorithm works on a channel by channel basis, the actual standard deviation threshold for the motion artefact varies according to the standard deviation of the original channel; the setting of the STDEVthresh is the multiplication factor rather than a fixed threshold (i.e. in the current study the standard deviation threshold is 20*standard deviation of the channel). This means that the standard deviation threshold varies from channel to channel and subject to subject. All the values were set as follows: tMotion = 5s; tMask = 1s; STDEVthresh = 20; AMPthresh = 5.</p>
                <p>After pre-processing, data were converted to Oxy- and Deoxy-Haemoglobin concentration changes (ΔHbO<sup>2</sup> and ΔHbR) in HOMER2 and averaged across trials in the same emotion condition within each dataset, with the time window of 1 sec before and 15s after the stimulation onset. The averaged time course of each channel was corrected by subtracting the mean of the 1 sec before the stimulation. The analysis focused on ΔHbO<sup>2</sup> as the most sensitive indicator of changes in cerebral blood flow. Based on earlier work showing that the haemodynamic response reaches the peak around 2 to 4 sec post stimulus [<xref rid="pone.0212205.ref064" ref-type="bibr">64</xref>], we targeted a time window of 2 sec to 9 sec after stimulus onset. Mean amplitudes of cortical haemodynamic responses (ΔHbO<sup>2</sup> and ΔHbR waveforms) were averaged over the time window of 2 sec to 9 sec after stimulus onset. The averaged haemodynamic responses to the expression conditions (angry, happy and neutral) were evaluated with repeated measures ANOVA and post-hoc pairwise comparisons to find channels sensitive to emotional vocalisations.</p>
                <p>We calculated partial eta-squared [<xref rid="pone.0212205.ref065" ref-type="bibr">65</xref>, <xref rid="pone.0212205.ref066" ref-type="bibr">66</xref>] to estimate the effect sizes for the main effect of emotion as well as for contrasts. Partial eta-squared takes values between 0 and 1. Values of 0.02, 0.13 and 0.26 are indicative of a small, medium, and large effect size, respectively [<xref rid="pone.0212205.ref067" ref-type="bibr">67</xref>].</p>
                <p>A false discovery rate (FDR, Benjamini and Hochberg, 1995 [<xref rid="pone.0212205.ref068" ref-type="bibr">68</xref>, <xref rid="pone.0212205.ref069" ref-type="bibr">69</xref>]) correction was applied to correct multiple comparisons, consistent with other recent infant studies [<xref rid="pone.0212205.ref030" ref-type="bibr">30</xref>, <xref rid="pone.0212205.ref070" ref-type="bibr">70</xref>]. As the detector array covers a large area of the infant’s brain, we do not expect all detectors to cover brain areas that are responding to our stimulation. Therefore, we only include channels that show a response to the stimulus paradigm. Within identified emotional sensitive channels, pairwise contrasts were corrected with the following steps: (i) A number of p values obtained from post-hoc comparisons (LSD) were arranged with ascending order (from the smallest to the largest) with an order number index, (ii) Adjusted α values were calculated with the equation αadjust = (order index/total number of comparisons)*0.05 and (iii) A comparison was deemed to be significant if the pairwise p value is smaller than the adjusted α value (αadjust) [<xref rid="pone.0212205.ref068" ref-type="bibr">68</xref>, <xref rid="pone.0212205.ref069" ref-type="bibr">69</xref>]. The significance level is the same as calculated with R code.</p>
              </sec>
              <sec id="sec008">
                <title>Maternal interaction behaviour</title>
                <p>A 6-min mother-infant free play interaction session was video recorded during the same visit following the fNIRS session. Mothers were asked to sit on a floor mat and play with their infant as they would normally do at home optionally using a small set of (supplied) toys. Recording commenced once mother and infant were settled into play. The videos were later coded using the Manchester Assessment of Caregiver-Infant Interaction (MACI [<xref rid="pone.0212205.ref071" ref-type="bibr">71</xref>, <xref rid="pone.0212205.ref072" ref-type="bibr">72</xref>]), a validated global rating scheme comprising eight 7-point scales suitable for use with normative and at-risk groups [<xref rid="pone.0212205.ref073" ref-type="bibr">73</xref>, <xref rid="pone.0212205.ref074" ref-type="bibr">74</xref>]. The current study focused on the two caregiver scales, which are normally distributed in a non-clinical population: (1) sensitivity: the degree to which the infant’s behaviour and state are met by prompt, appropriate and attuned responses to meet the infant’s immediate and developmental needs, including an attentive attitude, appropriate engagement and the provision of support and structuring in response to infant behaviour and a lack of behaviour (7-point scale indicates, in order: minimal, occasional, scattered, some, fairly consistent, consistent or high sensitivity). (2) directiveness (reversed in this study from the ‘nondirectiveness’ scale for ease of interpretation): the degree of restrictive or controlling behaviour as characterised by demanding, intrusive, critical and/or other controlling behaviours or comments directed at the infant (7-point scale, indicates in order: highly nondirective, nondirective, mainly nondirective, somewhat nondirective, moderately directive, directive, highly directive). Rating was based on detailed operationalisation of the scale and each rating outlined in the MACI coding manual [<xref rid="pone.0212205.ref071" ref-type="bibr">71</xref>]. A trained and statistically reliable rater (blind to family information and study aims) reviewed the 6-minute videos of mother-infant play at least twice and assigned a 1–7 rating, guided by the MACI coding manual [<xref rid="pone.0212205.ref071" ref-type="bibr">71</xref>] (for further coder training details, see [<xref rid="pone.0212205.ref069" ref-type="bibr">69</xref>], and <ext-link ext-link-type="uri" xlink:href="http://research.bmh.manchester.ac.uk/maci/">http://research.bmh.manchester.ac.uk/maci/</ext-link>). Based on the second independent blind coding of 12 (30%) videos, inter-rater agreement was high (intraclass correlation using single measures, absolute agreement definition: sensitivity: r = 0.84; directiveness r = 0.70; both p &lt; 0.001).</p>
              </sec>
            </sec>
            <sec sec-type="results" id="sec009">
              <title>Results</title>
              <sec id="sec010">
                <title>Emotion effect</title>
                <p>Repeated measures ANOVAs with emotion (angry, happy and neutral) as the within-subject factor revealed 3 channels that were sensitive to emotional prosody in ΔHbO<sup>2</sup>: Channel 2 in the left hemisphere (F (2, 56) = 3.38, p = .040, <inline-formula id="pone.0212205.e001"><alternatives><graphic xlink:href="pone.0212205.e001.jpg" id="pone.0212205.e001g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M1"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> = .11); channel 14 in the right hemisphere (F (2, 56) = 3.24, p = .047, <inline-formula id="pone.0212205.e002"><alternatives><graphic xlink:href="pone.0212205.e002.jpg" id="pone.0212205.e002g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M2"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> = .10) and channel 16 in the right hemisphere (F (2, 56) = 4.38, p = .017, <inline-formula id="pone.0212205.e003"><alternatives><graphic xlink:href="pone.0212205.e003.jpg" id="pone.0212205.e003g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M3"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> = .14) (<xref rid="pone.0212205.t002" ref-type="table">Table 2</xref>).</p>
                <table-wrap id="pone.0212205.t002" orientation="portrait" position="float">
                  <object-id pub-id-type="doi">10.1371/journal.pone.0212205.t002</object-id>
                  <label>Table 2</label>
                  <caption>
                    <title>Infant ΔHbO<sup>2</sup> change effects in response to vocal emotion: ANOVA on all contrasts.</title>
                  </caption>
                  <alternatives>
                    <graphic id="pone.0212205.t002g" xlink:href="pone.0212205.t002"/>
                    <table frame="hsides" rules="groups">
                      <colgroup span="1">
                        <col align="left" valign="middle" span="1"/>
                        <col align="left" valign="middle" span="1"/>
                        <col align="left" valign="middle" span="1"/>
                        <col align="left" valign="middle" span="1"/>
                        <col align="left" valign="middle" span="1"/>
                        <col align="left" valign="middle" span="1"/>
                        <col align="left" valign="middle" span="1"/>
                        <col align="left" valign="middle" span="1"/>
                        <col align="left" valign="middle" span="1"/>
                        <col align="left" valign="middle" span="1"/>
                        <col align="left" valign="middle" span="1"/>
                      </colgroup>
                      <thead>
                        <tr>
                          <th align="center" rowspan="1" colspan="1">Channel</th>
                          <th align="center" rowspan="1" colspan="1">Emotion</th>
                          <th align="center" rowspan="1" colspan="1">Mean ± SEM</th>
                          <th align="center" colspan="3" rowspan="1">ANOVA</th>
                          <th align="center" rowspan="1" colspan="1"/>
                          <th align="center" colspan="3" rowspan="1">Pairwise Comparisons</th>
                          <th align="center" rowspan="1" colspan="1">Adjusted α value</th>
                        </tr>
                        <tr>
                          <th align="center" rowspan="1" colspan="1"/>
                          <th align="center" rowspan="1" colspan="1"/>
                          <th align="center" rowspan="1" colspan="1"/>
                          <th align="center" rowspan="1" colspan="1">F</th>
                          <th align="center" rowspan="1" colspan="1">p</th>
                          <th align="center" rowspan="1" colspan="1">Partial Eta-squared</th>
                          <th align="center" rowspan="1" colspan="1">Comparison<xref ref-type="table-fn" rid="t002fn002"><sup>a</sup></xref><break/>(A, H and N)</th>
                          <th align="center" rowspan="1" colspan="1">F</th>
                          <th align="center" rowspan="1" colspan="1">p</th>
                          <th align="center" rowspan="1" colspan="1">Partial Eta-squared</th>
                          <th align="center" rowspan="1" colspan="1">α<sub>adjust</sub></th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td align="center" rowspan="3" colspan="1">2</td>
                          <td align="center" rowspan="1" colspan="1">Angry</td>
                          <td align="center" rowspan="1" colspan="1">2.82±1.6</td>
                          <td align="center" rowspan="3" colspan="1">3.38</td>
                          <td align="center" rowspan="3" colspan="1">0.040</td>
                          <td align="center" rowspan="3" colspan="1">0.11</td>
                          <td align="center" rowspan="1" colspan="1">A &gt; H</td>
                          <td align="center" rowspan="1" colspan="1">0.56</td>
                          <td align="center" rowspan="1" colspan="1">0.462</td>
                          <td align="center" rowspan="1" colspan="1">0.02</td>
                          <td align="center" rowspan="1" colspan="1">0.044</td>
                        </tr>
                        <tr>
                          <td align="center" rowspan="1" colspan="1">Happy</td>
                          <td align="center" rowspan="1" colspan="1">0.97±1.9</td>
                          <td align="center" rowspan="1" colspan="1">A &gt; N</td>
                          <td align="center" rowspan="1" colspan="1">9.76</td>
                          <td align="center" rowspan="1" colspan="1">
                            <bold>0.004</bold>
                            <xref ref-type="table-fn" rid="t002fn001">*</xref>
                          </td>
                          <td align="center" rowspan="1" colspan="1">0.26</td>
                          <td align="center" rowspan="1" colspan="1">0.006</td>
                        </tr>
                        <tr>
                          <td align="center" rowspan="1" colspan="1">Neutral</td>
                          <td align="center" rowspan="1" colspan="1">-2.68±1.5</td>
                          <td align="center" rowspan="1" colspan="1">H &gt; N</td>
                          <td align="center" rowspan="1" colspan="1">2.86</td>
                          <td align="center" rowspan="1" colspan="1">0.102</td>
                          <td align="center" rowspan="1" colspan="1">0.10</td>
                          <td align="center" rowspan="1" colspan="1">0.033</td>
                        </tr>
                        <tr>
                          <td align="center" rowspan="3" colspan="1">14</td>
                          <td align="center" rowspan="1" colspan="1">Angry</td>
                          <td align="center" rowspan="1" colspan="1">0.29±1.34</td>
                          <td align="center" rowspan="3" colspan="1">3.24</td>
                          <td align="center" rowspan="3" colspan="1">0.047</td>
                          <td align="center" rowspan="3" colspan="1">0.10</td>
                          <td align="center" rowspan="1" colspan="1">H &gt; A</td>
                          <td align="center" rowspan="1" colspan="1">4.26</td>
                          <td align="center" rowspan="1" colspan="1">0.048</td>
                          <td align="center" rowspan="1" colspan="1">0.13</td>
                          <td align="center" rowspan="1" colspan="1">0.022</td>
                        </tr>
                        <tr>
                          <td align="center" rowspan="1" colspan="1">Happy</td>
                          <td align="center" rowspan="1" colspan="1">4.02±1.67</td>
                          <td align="center" rowspan="1" colspan="1">A &gt; N</td>
                          <td align="center" rowspan="1" colspan="1">0.11</td>
                          <td align="center" rowspan="1" colspan="1">0.746</td>
                          <td align="center" rowspan="1" colspan="1">0.004</td>
                          <td align="center" rowspan="1" colspan="1">0.050</td>
                        </tr>
                        <tr>
                          <td align="center" rowspan="1" colspan="1">Neutral</td>
                          <td align="center" rowspan="1" colspan="1">-0.33±1.24</td>
                          <td align="center" rowspan="1" colspan="1">H &gt; N</td>
                          <td align="center" rowspan="1" colspan="1">5.62</td>
                          <td align="center" rowspan="1" colspan="1">0.025<break/></td>
                          <td align="center" rowspan="1" colspan="1">0.17</td>
                          <td align="center" rowspan="1" colspan="1">0.017</td>
                        </tr>
                        <tr>
                          <td align="center" rowspan="3" colspan="1">16</td>
                          <td align="center" rowspan="1" colspan="1">Angry</td>
                          <td align="center" rowspan="1" colspan="1">-1.51±1.74</td>
                          <td align="center" rowspan="3" colspan="1">4.38</td>
                          <td align="center" rowspan="3" colspan="1">0.017</td>
                          <td align="center" rowspan="3" colspan="1">0.14</td>
                          <td align="center" rowspan="1" colspan="1">H &gt; A</td>
                          <td align="center" rowspan="1" colspan="1">8.26</td>
                          <td align="center" rowspan="1" colspan="1">
                            <bold>0.008</bold>
                            <xref ref-type="table-fn" rid="t002fn001">*</xref>
                          </td>
                          <td align="center" rowspan="1" colspan="1">0.23</td>
                          <td align="center" rowspan="1" colspan="1">0.011</td>
                        </tr>
                        <tr>
                          <td align="center" rowspan="1" colspan="1">Happy</td>
                          <td align="center" rowspan="1" colspan="1">4.49±1.58</td>
                          <td align="center" rowspan="1" colspan="1">N &gt; A</td>
                          <td align="center" rowspan="1" colspan="1">1.10</td>
                          <td align="center" rowspan="1" colspan="1">0.300</td>
                          <td align="center" rowspan="1" colspan="1">0.04</td>
                          <td align="center" rowspan="1" colspan="1">0.039</td>
                        </tr>
                        <tr>
                          <td align="center" rowspan="1" colspan="1">Neutral</td>
                          <td align="center" rowspan="1" colspan="1">0.73±1.25</td>
                          <td align="center" rowspan="1" colspan="1">H &gt; N</td>
                          <td align="center" rowspan="1" colspan="1">3.80</td>
                          <td align="center" rowspan="1" colspan="1">0.060</td>
                          <td align="center" rowspan="1" colspan="1">0.12</td>
                          <td align="center" rowspan="1" colspan="1">0.028</td>
                        </tr>
                      </tbody>
                    </table>
                  </alternatives>
                  <table-wrap-foot>
                    <fn id="t002fn001">
                      <p>* Comparison survived FDR correction (comparisons for which the p values were smaller than the adjusted α value).</p>
                    </fn>
                    <fn id="t002fn002">
                      <p><sup>a</sup> A = Angry, H = Happy, N = Neutral</p>
                    </fn>
                  </table-wrap-foot>
                </table-wrap>
                <p>Pairwise comparisons showed significant increased ΔHbO<sup>2</sup> on hearing angry compared to neutral voices (channel 2: F (1, 28) = 9.76, p = .004, <inline-formula id="pone.0212205.e004"><alternatives><graphic xlink:href="pone.0212205.e004.jpg" id="pone.0212205.e004g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M4"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> = .26) and happy compared to angry voices (channel 16: F (1, 28) = 8.26, p = .008, <inline-formula id="pone.0212205.e005"><alternatives><graphic xlink:href="pone.0212205.e005.jpg" id="pone.0212205.e005g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M5"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> = .23) which survived FDR correction (<xref ref-type="fig" rid="pone.0212205.g003">Fig 3</xref>). Two further pairwise comparisons did not survive FDR correction (<xref rid="pone.0212205.t002" ref-type="table">Table 2</xref>): happy compared to neutral voices (channel 14: F (1, 28) = 5.62, p = .025, <inline-formula id="pone.0212205.e006"><alternatives><graphic xlink:href="pone.0212205.e006.jpg" id="pone.0212205.e006g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M6"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> = .17) and happy compared to angry voices (Channel 14: F (1, 28) = 4.26, p = .048, <inline-formula id="pone.0212205.e007"><alternatives><graphic xlink:href="pone.0212205.e007.jpg" id="pone.0212205.e007g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M7"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> = .13).</p>
                <fig id="pone.0212205.g003" orientation="portrait" position="float">
                  <object-id pub-id-type="doi">10.1371/journal.pone.0212205.g003</object-id>
                  <label>Fig 3</label>
                  <caption>
                    <title>Averaged time courses of ΔHbO<sup>2</sup> in channel 2 and channel 16.</title>
                    <p>Averaged time courses of ΔHbO<sup>2</sup> across all datasets in channel 2 and channel 16 per vocal emotion (angry in red, happy in green and neutral in blue) in the time period of 15 sec (5 sec stimulus and 10 sec baseline). The channel location is marked in red in the infant head model. The stimulus offset is marked by the dashed line (at 5 sec). The time (in sec) and change in amplitude (μMol) are in the x and y axis, respectively. The mean and SEM value of ΔHbO<sup>2</sup> in each channel per vocal emotion is shown in the bar plot. ‘**’ represents the significant (p &lt; 0.01) pairwise comparisons after FDR correction (all the test statistics are presented in <xref rid="pone.0212205.t002" ref-type="table">Table 2</xref>).</p>
                  </caption>
                  <graphic xlink:href="pone.0212205.g003"/>
                </fig>
                <p>DeoxyHb concentration changes complemented the ΔHbO<sup>2</sup>: 2 channels were sensitive to emotional prosody and survived FDR correction: a significant effect of emotion (left hemisphere: channel 2: F (2, 56) = 4.04, p = .020, <inline-formula id="pone.0212205.e008"><alternatives><graphic xlink:href="pone.0212205.e008.jpg" id="pone.0212205.e008g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M8"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> = .13), particularly in response to angry compared to neutral voice (F (1, 28) = 10.26, p = .003, <inline-formula id="pone.0212205.e009"><alternatives><graphic xlink:href="pone.0212205.e009.jpg" id="pone.0212205.e009g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M9"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> = .27) and a significant effect of emotion in channel 16 in the right hemisphere (F (2, 56) = 3.62, p = .030, <inline-formula id="pone.0212205.e010"><alternatives><graphic xlink:href="pone.0212205.e010.jpg" id="pone.0212205.e010g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M10"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> = .11) in response to happy compared to angry voice (F (1, 28) = 7.45, p = .010, <inline-formula id="pone.0212205.e011"><alternatives><graphic xlink:href="pone.0212205.e011.jpg" id="pone.0212205.e011g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M11"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> = .21).</p>
              </sec>
              <sec id="sec011">
                <title>Maternal interaction behaviour and infant neural responses</title>
                <p>The sample received a broad range of ratings (on a 1–7 scale) for maternal sensitivity (Mean ± SD = 4.17 ± 1.31, range: 2–7) and maternal directiveness (Mean ± SD = 3.93 ± 1.65, range: 1–7). Bivariate correlations tested whether (1) maternal characteristics (current work status, mother’s highest qualification, household Income, and partner cohabitation status) were associated with maternal interaction behaviour ratings; (2) ΔHbO<sup>2</sup> concentration changes (emotion minus neutral ΔHbO<sup>2</sup>) in the two significant vocal emotion-sensitive areas that survived FDR correction (angry minus neutral ΔHbO<sup>2</sup> in left hemisphere channel 2; happy minus angry ΔHbO<sup>2</sup> in right hemisphere channel 16) were associated with maternal interactive behaviour ratings; (3) ΔHbO<sup>2</sup> concentration changes were associated with maternal characteristics.</p>
                <p>Only one significant correlation was found between maternal interaction behaviour ratings and maternal characteristics: maternal sensitivity was positively correlated with maternal highest qualification (r = 0.41, p = 0.028). Although ΔHbO<sup>2</sup> in neither region was associated with maternal sensitive responsiveness, increased activation to angry minus neutral prosody was negatively correlated with maternal directiveness: r = 0.41, p = 0.029 (<xref ref-type="fig" rid="pone.0212205.g004">Fig 4</xref>). ΔHbO<sup>2</sup>was not associated with any of maternal characteristics.</p>
                <fig id="pone.0212205.g004" orientation="portrait" position="float">
                  <object-id pub-id-type="doi">10.1371/journal.pone.0212205.g004</object-id>
                  <label>Fig 4</label>
                  <caption>
                    <title>Association between neural responses to angry minus neutral prosody and maternal directiveness.</title>
                    <p>Infant neural response to angry minus neutral vocalisations (y axis) increases linearly with independent ratings of how directive mothers were towards their infant during play interaction (7 = highly directive; x axis). The black hard line represents the mean HbO<sup>2</sup> change for each rating on the maternal directiveness scale.</p>
                  </caption>
                  <graphic xlink:href="pone.0212205.g004"/>
                </fig>
              </sec>
            </sec>
            <sec sec-type="conclusions" id="sec012">
              <title>Discussion</title>
              <p>This is the first study of infant neural processing of emotional non-speech prosody to demonstrate the heightened recruitment of bilateral temporal cortices at 6 months in response to vocal emotion. It suggests that at least part of the temporo-frontal network recruited in adult vocal emotion processing [<xref rid="pone.0212205.ref019" ref-type="bibr">19</xref>–<xref rid="pone.0212205.ref022" ref-type="bibr">22</xref>] is already functioning by 6 months of age. More broadly, our findings are consistent with previous behavioural and neuroimaging findings that 6-month-old infants can distinguish emotional from neutral sounds and between basic emotions (or emotional valence), irrespective of speech [<xref rid="pone.0212205.ref027" ref-type="bibr">27</xref>, <xref rid="pone.0212205.ref029" ref-type="bibr">29</xref>, <xref rid="pone.0212205.ref030" ref-type="bibr">30</xref>, <xref rid="pone.0212205.ref036" ref-type="bibr">36</xref>]. We also offer preliminary evidence of statistical link between negative (angry) vocal discrimination in the temporal region and early social or caregiving experience. Specifically, hearing angry vocalisations evoked stronger responses in the left anterior superior temporal cortex (STC) compared to neutral prosody and infants with stronger activation in this vocal anger-sensitive region experienced more directive interactions from their mother. Happy prosody evoked increased activation in the right posterior (and possibly anterior) STC compared to angry prosody. However, the strength of this response in the right temporal cortex was not associated with our measures of maternal social interaction.</p>
              <p>Our main findings are consistent with previous infant brain studies that implicate the temporal cortices [<xref rid="pone.0212205.ref027" ref-type="bibr">27</xref>, <xref rid="pone.0212205.ref036" ref-type="bibr">36</xref>, <xref rid="pone.0212205.ref075" ref-type="bibr">75</xref>], broadly supporting the temporo-frontal network. Angry and happy prosody evoked left and right STC activations that seem to show distinct cortical activation to emotional stimuli. Rather than a laterality effect, this activation difference is likely to be an artefact of strictly correcting multiple comparisons; thus, we would suggest that the uncorrected results may reflect a broader bilateral STC activation in response to emotional vocalisations generally. Evidence from adult studies suggests that STC is sensitive to emotional vocalisations and the STC activation is not associated with emotional valence [<xref rid="pone.0212205.ref021" ref-type="bibr">21</xref>, <xref rid="pone.0212205.ref025" ref-type="bibr">25</xref>, <xref rid="pone.0212205.ref026" ref-type="bibr">26</xref>]. While previous studies implicate a frontal asymmetry in infants’ responses to emotional stimuli [<xref rid="pone.0212205.ref076" ref-type="bibr">76</xref>, <xref rid="pone.0212205.ref077" ref-type="bibr">77</xref>], evidence to date on the hemispheric lateralisation of effects in response to emotional sounds, especially in the temporal region, is heterogeneous in infant studies. Infant ERP studies found bilateral frontal, temporal, and central activations in response to emotional speech and emotional non-speech sounds [<xref rid="pone.0212205.ref036" ref-type="bibr">36</xref>, <xref rid="pone.0212205.ref078" ref-type="bibr">78</xref>], and fNIRS studies reported right superior temporal and right inferior frontal activations to emotional speech [<xref rid="pone.0212205.ref027" ref-type="bibr">27</xref>, <xref rid="pone.0212205.ref037" ref-type="bibr">37</xref>]. Neuroimaging evidence in adult studies also support both right hemisphere and bilateral involvement in vocal emotion processing [<xref rid="pone.0212205.ref020" ref-type="bibr">20</xref>–<xref rid="pone.0212205.ref026" ref-type="bibr">26</xref>]. Given the range of previous findings and the lack of infant frontal measurement in the present study, we did not hypothesise any laterality effect. The lack of clear lateralisation effect in our study may reflect the relative immaturity of the temporal cortices at 6 months of age when infant neural sensitivity to vocal emotions may not yet be stable or specialised. The superior temporal cortices are known as part of the social brain that undergo an experience-dependent “fine tuning” process into specialised functions [<xref rid="pone.0212205.ref027" ref-type="bibr">27</xref>]. Furthermore, the current study focused on non-speech prosody, reflecting how mothers commonly express themselves to preverbal infants, while previous infant studies measured neural responses to emotion in speech. Emotional information carried in speech may be confounded by the high variation in how much semantic understanding 6-month-old infants have of the speech content (i.e. receptive language, [<xref rid="pone.0212205.ref079" ref-type="bibr">79</xref>, <xref rid="pone.0212205.ref080" ref-type="bibr">80</xref>]).</p>
              <p>We report that hearing angry vocalisations evoked a response localised to the left anterior STC, which may reflect a general negativity attentional bias that is seen in adults [<xref rid="pone.0212205.ref034" ref-type="bibr">34</xref>, <xref rid="pone.0212205.ref048" ref-type="bibr">48</xref>, <xref rid="pone.0212205.ref081" ref-type="bibr">81</xref>–<xref rid="pone.0212205.ref083" ref-type="bibr">83</xref>]. Neural sensitivity to angry compared to neutral voice has also been reported in other infant studies [<xref rid="pone.0212205.ref027" ref-type="bibr">27</xref>, <xref rid="pone.0212205.ref036" ref-type="bibr">36</xref>, <xref rid="pone.0212205.ref075" ref-type="bibr">75</xref>], raising the question of whether a prioritised neural response to threatening vocal information may be innate, consistent with evolutionary explanations [<xref rid="pone.0212205.ref002" ref-type="bibr">2</xref>]. An imaging study of vocal emotion processing in sleeping neonates suggests that an automatic perception of threat-related emotional voices may be active from birth [<xref rid="pone.0212205.ref081" ref-type="bibr">81</xref>], and our findings may reflect a conscious attentional process present at 6 months of age, as reflected in the recruitment of the left STC. Contrary to expectations, neural responsiveness to happy compared to neutral prosody in the anterior STC (channel 14) did not survive FDR correction, possibly suggesting that this localised happy-specific sensitivity is not (yet) stable developmentally or may only be present in a subgroup. A larger sample may provide us with the statistical power to observe greater neural responses to happy vocalisations compared to neutral. An alternative interpretation may be that channel 14 is responsive to emotional valence from negative (angry) to positive (happy) and therefore found happy vocalisations a stronger contrast with angry than with neutral vocalisations. However, the right posterior STC activation to happy compared with angry prosody is consistent with right lateralised effects found in other infant and adult studies on vocal emotion [<xref rid="pone.0212205.ref020" ref-type="bibr">20</xref>–<xref rid="pone.0212205.ref022" ref-type="bibr">22</xref>, <xref rid="pone.0212205.ref027" ref-type="bibr">27</xref>].</p>
              <p>With respect to the second objective, we found that infant neural sensitivity to prosodic anger was associated with degree of maternal directiveness. Maternal directiveness typically involves vocal and behavioural demands, intrusions and/or critical utterances, which requires the infant’s behavioural responses (such as an adjustment of the attention, and/or a change of the current behaviour). A mother may use directive behaviours to teach, guide, or direct the infant to behave and/or play in a socially acceptable way. Our findings require replication in a larger sample but provide preliminary evidence that may suggest that early social experience in the form of directive caregiver interactions, or stress that may result from such interactions, may promote cortical specialisation in vocal anger perception. Although not all directiveness carries vocal negativity, being the recipient of high caregiver directiveness is likely to involve appraising negative emotion more often as a guide to acceptable behaviour, and, therefore may plausibly heighten the STC processing of negative prosody. Since maternal and infant anger were not directly measured in this study, whether more directive caregivers actually used more anger vocal expressions and/or whether their infants experienced more anger (or irritation) as a result of their social interactions is unknown. In addition, few mothers in this study were rated as particularly high or low in directiveness, and, therefore, the effects may be stronger in a sample recruited specifically to test out associations with maternal behaviour.</p>
              <p>On the other hand, we found no association between maternal sensitivity behaviour and neural response to emotional prosody in our 6-month-old infants, suggesting that infant neural processing of vocal emotions does not vary according to infant experience of maternal sensitivity, at least in the typically developing infants of healthy mothers. While maternal directiveness conceptually overlaps with emotional negativity, high maternal sensitivity does not always entail emotional positivity, but rather affect is attuned (i.e. well-modulated to infant affect) and generally well matched–for example, if the infant is fretful, then warm but not affectively positive interactions would constitute a sensitive response. Statistically, in the current sample, the distribution of ratings was slightly narrower for maternal sensitivity (ratings were mostly centred at the medium), which may have also reduced the likelihood of finding a statistical association. It is possible that significant effects may only be seen in a clinical or at-risk group which may have more variation in maternal sensitivity ratings.</p>
              <p>Several methodological considerations must be taken into account in the interpretation of our findings. First, the present study included a relatively modest overall sample size. Although comparable with other similar imaging studies of infants, it precludes analysis of gender effects to take account of known early gender differences in vocal emotion processing [<xref rid="pone.0212205.ref084" ref-type="bibr">84</xref>, <xref rid="pone.0212205.ref085" ref-type="bibr">85</xref>]. Secondly, the study focused on effects in the temporal cortical regions and did not investigate the involvement of other (e.g. frontal) regions implicated in vocal processing [<xref rid="pone.0212205.ref086" ref-type="bibr">86</xref>]. Thirdly, since we used only angry and happy emotional stimuli, the anger-related effects reported may result from emotional negativity in general, rather than being anger-specific. Fourthly, distinctive neural patterns to emotional categories do not necessarily suggest a conceptual understanding of emotions by infants, although experimental findings indicate that discrete emotions are at least paired with different kinds of infant responses or preferences [<xref rid="pone.0212205.ref012" ref-type="bibr">12</xref>–<xref rid="pone.0212205.ref015" ref-type="bibr">15</xref>], suggesting a level of evaluative appraisal rather than solely an acoustic analysis of pitch characteristics by the infant. A combined fNIRS and experimental approach (such as eye-tracking) would provide supportive infant attentional data, providing further understanding of whether neural responses to vocal emotions correspond to infant behaviours. Finally, we did not test infants’ hearing ability directly but relied on maternal report.</p>
              <p>In conclusion, we report novel evidence that prosodic anger elicited STC activation in 6-month-old infants, has also been implicated in adult vocal emotion perception. This is consistent with an important function for vocal emotion perception in the first year of life in guiding communicative and relational development. Furthermore, we report the first preliminary evidence of an association between infant brain responsivity to vocal anger and maternal directiveness in a healthy sample. Replications in larger samples of infants, and in high risk groups (e.g. mothers with mental illness), as well as further investigation of this association may help us understand better the role of early experience on vocal perception as a building block for communicative and socioemotional development. Future studies should also consider broader and more specific environmental influences on infant vocal emotion processing by linking the fNIRS data with infant exposure to maternal and non-maternal positive and negative affect within naturalistic vocalisations and speech, for example, by collecting day-long samples of audio recordings at home. The current paradigm may be developed to evaluate the effectiveness of parenting interventions on neural sensitivity to vocal emotion in healthy and at-risk groups early in infancy. Such interventions may be designed to target caregiver directiveness to help unravel the directionality of effects. Future research employing longitudinal designs could also be useful to follow the developmental trajectories of neural sensitivity to emotional vocalisations in typical development to assess its potential as a biomarker of atypical neurodevelopment in at-risk children [<xref rid="pone.0212205.ref087" ref-type="bibr">87</xref>].</p>
            </sec>
            <sec sec-type="supplementary-material" id="sec013">
              <title>Supporting information</title>
              <supplementary-material content-type="local-data" id="pone.0212205.s001">
                <label>S1 File</label>
                <caption>
                  <title>Dataset.</title>
                  <p>(ZIP)</p>
                </caption>
                <media xlink:href="pone.0212205.s001.zip">
                  <caption>
                    <p>Click here for additional data file.</p>
                  </caption>
                </media>
              </supplementary-material>
            </sec>
          </body>
          <back>
            <ack>
              <p>The authors wish to thank the families who participated in the study. We would also like to thank Dr Darragh Downey for his tremendous help in setting up the study.</p>
            </ack>
            <ref-list>
              <title>References</title>
              <ref id="pone.0212205.ref001">
                <label>1</label>
                <mixed-citation publication-type="journal"><name><surname>Kisilevsky</surname><given-names>BS</given-names></name>, <name><surname>Hains</surname><given-names>SMJ</given-names></name>, <name><surname>Lee</surname><given-names>K</given-names></name>, <name><surname>Xie</surname><given-names>X</given-names></name>, <name><surname>Huang</surname><given-names>HF</given-names></name>, <name><surname>Ye</surname><given-names>HH</given-names></name>, <etal>et al</etal><article-title>Effects of experience on fetal voice recognition</article-title>. <source>Psychol Sci</source>. <year>2003</year>;<volume>14</volume>(<issue>3</issue>):<fpage>220</fpage>–<lpage>4</lpage>. <pub-id pub-id-type="doi">10.1111/1467-9280.02435</pub-id> ISI:000182526900005. <?supplied-pmid 12741744?><pub-id pub-id-type="pmid">12741744</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref002">
                <label>2</label>
                <mixed-citation publication-type="journal"><name><surname>Vaish</surname><given-names>A</given-names></name>, <name><surname>Grossmann</surname><given-names>T</given-names></name>, <name><surname>Woodward</surname><given-names>A</given-names></name>. <article-title>Not all emotions are created equal: The negativity bias in social-emotional development</article-title>. <source>Psychol Bull</source>. <year>2008</year>;<volume>134</volume>(<issue>3</issue>):<fpage>383</fpage>–<lpage>403</lpage>. <pub-id pub-id-type="doi">10.1037/0033-2909.134.3.383</pub-id> WOS:000255313200003. <?supplied-pmid 18444702?><pub-id pub-id-type="pmid">18444702</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref003">
                <label>3</label>
                <mixed-citation publication-type="journal"><name><surname>Lohaus</surname><given-names>A</given-names></name>, <name><surname>Keller</surname><given-names>H</given-names></name>, <name><surname>Ball</surname><given-names>J</given-names></name>, <name><surname>Elben</surname><given-names>C</given-names></name>, <name><surname>Voelker</surname><given-names>S</given-names></name>. <article-title>Maternal Sensitivity: Components and Relations to Warmth and Contingency</article-title>. <source>Parent-Sci Pract</source>. <year>2001</year>;<volume>1</volume>(<issue>4</issue>):<fpage>267</fpage>–<lpage>84</lpage>. <pub-id pub-id-type="doi">10.1207/S15327922par0104_1</pub-id> WOS:000207607400001.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref004">
                <label>4</label>
                <mixed-citation publication-type="journal"><name><surname>Mumme</surname><given-names>DL</given-names></name>, <name><surname>Fernald</surname><given-names>A</given-names></name>, <name><surname>Herrera</surname><given-names>C</given-names></name>. <article-title>Infants' responses to facial and vocal emotional signals in a social referencing paradigm</article-title>. <source>Child Dev</source>. <year>1996</year>;<volume>67</volume>(<issue>6</issue>):<fpage>3219</fpage>–<lpage>37</lpage>. <pub-id pub-id-type="doi">10.2307/1131775</pub-id> WOS:A1996WN23500034. <?supplied-pmid 9071778?><pub-id pub-id-type="pmid">9071778</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref005">
                <label>5</label>
                <mixed-citation publication-type="journal"><name><surname>Tronick</surname><given-names>E</given-names></name>. <article-title>Emotions and Emotional Communication in Infants</article-title>. <source>Am Psychol</source>. <year>1989</year>;<volume>44</volume>(<issue>2</issue>):<fpage>112</fpage>–<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1037//0003-066x.44.2.112</pub-id> WOS:A1989T279900005. <?supplied-pmid 2653124?><pub-id pub-id-type="pmid">2653124</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref006">
                <label>6</label>
                <mixed-citation publication-type="journal"><name><surname>Leigh</surname><given-names>P</given-names></name>, <name><surname>Nievar</surname><given-names>MA</given-names></name>, <name><surname>Nathans</surname><given-names>L</given-names></name>. <article-title>Maternal Sensitivity and Language in Early Childhood: A Test of the Transactional Model</article-title>. <source>Percept Motor Skill</source>. <year>2011</year>;<volume>113</volume>(<issue>1</issue>):<fpage>281</fpage>–<lpage>99</lpage>. <pub-id pub-id-type="doi">10.2466/10.17.21.28.PMS.113.4.281-299</pub-id> WOS:000295071500023.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref007">
                <label>7</label>
                <mixed-citation publication-type="journal"><name><surname>Saint-Georges</surname><given-names>C</given-names></name>, <name><surname>Chetouani</surname><given-names>M</given-names></name>, <name><surname>Cassel</surname><given-names>R</given-names></name>, <name><surname>Apicella</surname><given-names>F</given-names></name>, <name><surname>Mahdhaoui</surname><given-names>A</given-names></name>, <name><surname>Muratori</surname><given-names>F</given-names></name>, <etal>et al</etal><article-title>Motherese in Interaction: At the Cross-Road of Emotion and Cognition? (A Systematic Review)</article-title>. <source>Plos One</source>. <year>2013</year>;<volume>8</volume>(<issue>10</issue>). <pub-id pub-id-type="doi">10.1371/journal.pone.0078103</pub-id> WOS:000326029300139. <?supplied-pmid 24205112?><pub-id pub-id-type="pmid">24205112</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref008">
                <label>8</label>
                <mixed-citation publication-type="journal"><name><surname>Singh</surname><given-names>L</given-names></name>, <name><surname>Morgan</surname><given-names>JL</given-names></name>, <name><surname>Best</surname><given-names>CT</given-names></name>. <article-title>Infants' Listening Preferences: Baby Talk or Happy Talk?</article-title><source>Infancy</source>. <year>2002</year>;<volume>3</volume>(<issue>3</issue>):<fpage>365</fpage>–<lpage>94</lpage>. <pub-id pub-id-type="doi">10.1207/S15327078in0303_5</pub-id> WOS:000204990300005.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref009">
                <label>9</label>
                <mixed-citation publication-type="book"><name><surname>Bowlby</surname><given-names>J</given-names></name>. <chapter-title>Attachment, Vol. 1 of Attachment and loss</chapter-title><publisher-loc>New York</publisher-loc>: <publisher-name>Basic Books</publisher-name>; <year>1969</year>.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref010">
                <label>10</label>
                <mixed-citation publication-type="journal"><name><surname>Dykas</surname><given-names>MJ</given-names></name>, <name><surname>Cassidy</surname><given-names>J</given-names></name>. <article-title>Attachment and the Processing of Social Information Across the Life Span: Theory and Evidence</article-title>. <source>Psychol Bull</source>. <year>2011</year>;<volume>137</volume>(<issue>1</issue>):<fpage>19</fpage>–<lpage>46</lpage>. <pub-id pub-id-type="doi">10.1037/a0021367</pub-id> WOS:000286285100002. <?supplied-pmid 21219056?><pub-id pub-id-type="pmid">21219056</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref011">
                <label>11</label>
                <mixed-citation publication-type="book"><name><surname>Trevarthen</surname><given-names>C.</given-names></name><chapter-title>The function of emotions in early infant communication and development</chapter-title><source>New perspectives in early communicative development</source>: <publisher-name>Routledge</publisher-name>; <year>2017</year> p. <fpage>48</fpage>–<lpage>81</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref012">
                <label>12</label>
                <mixed-citation publication-type="journal"><name><surname>Fernald</surname><given-names>A</given-names></name>. <article-title>Approval and disapproval: Infant responsiveness to vocal affect in familiar and unfamiliar languages</article-title>. <source>Child Dev</source>. <year>1993</year>;<volume>64</volume>(<issue>3</issue>):<fpage>657</fpage>–<lpage>74</lpage>. <?supplied-pmid 8339687?><pub-id pub-id-type="pmid">8339687</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref013">
                <label>13</label>
                <mixed-citation publication-type="journal"><name><surname>Walker-Andrews</surname><given-names>AS</given-names></name>, <name><surname>Grolnick</surname><given-names>W</given-names></name>. <article-title>Discrimination of Vocal Expressions by Young Infants</article-title>. <source>Infant Behav Dev</source>. <year>1983</year>;<volume>6</volume>(<issue>4</issue>):<fpage>491</fpage>–<lpage>8</lpage>. <pub-id pub-id-type="doi">10.1016/S0163-6383(83)90331-4</pub-id> WOS:A1983SM08600008.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref014">
                <label>14</label>
                <mixed-citation publication-type="journal"><name><surname>Flom</surname><given-names>R</given-names></name>, <name><surname>Bahrick</surname><given-names>LE</given-names></name>. <article-title>The development of infant discrimination of affect in multimodal and unimodal stimulation: The role of intersensory redundancy</article-title>. <source>Dev Psychol</source>. <year>2007</year>;<volume>43</volume>(<issue>1</issue>):<fpage>238</fpage>–<lpage>52</lpage>. <pub-id pub-id-type="doi">10.1037/0012-1649.43.1.238</pub-id> WOS:000243060100019. <?supplied-pmid 17201522?><pub-id pub-id-type="pmid">17201522</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref015">
                <label>15</label>
                <mixed-citation publication-type="journal"><name><surname>Caron</surname><given-names>AJ</given-names></name>, <name><surname>Caron</surname><given-names>RF</given-names></name>, <name><surname>MacLean</surname><given-names>DJ</given-names></name>. <article-title>Infant discrimination of naturalistic emotional expressions: the role of face and voice</article-title>. <source>Child Dev</source>. <year>1988</year>;<volume>59</volume>(<issue>3</issue>):<fpage>604</fpage>–<lpage>16</lpage>. .<?supplied-pmid 3383670?><pub-id pub-id-type="pmid">3383670</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref016">
                <label>16</label>
                <mixed-citation publication-type="journal"><name><surname>Walker-Andrews</surname><given-names>AS</given-names></name>. <article-title>Emotions and social development: Infants' recognition of emotions in others</article-title>. <source>Pediatrics</source>. <year>1998</year>;<volume>102</volume>(<issue>5 Suppl E</issue>):<fpage>1268</fpage>–<lpage>71</lpage>. .<?supplied-pmid 9794967?><pub-id pub-id-type="pmid">9794967</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref017">
                <label>17</label>
                <mixed-citation publication-type="journal"><name><surname>Striano</surname><given-names>T</given-names></name>, <name><surname>Rochat</surname><given-names>P</given-names></name>. <article-title>Emergence of Selective Social Referencing in Infancy</article-title>. <source>Infancy</source>. <year>2000</year>;<volume>1</volume>(<issue>2</issue>):<fpage>253</fpage>–<lpage>64</lpage>. <pub-id pub-id-type="doi">10.1207/S15327078in0102_7</pub-id> WOS:000204988800007.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref018">
                <label>18</label>
                <mixed-citation publication-type="journal"><name><surname>Vaish</surname><given-names>A</given-names></name>, <name><surname>Striano</surname><given-names>T</given-names></name>. <article-title>Is visual reference necessary? Contributions of facial versus vocal cues in 12-months-olds' social referencing behavior</article-title>. <source>Developmental Sci</source>. <year>2004</year>;<volume>7</volume>(<issue>3</issue>):<fpage>261</fpage>–<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-7687.2004.00344.x</pub-id> WOS:000221838600001.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref019">
                <label>19</label>
                <mixed-citation publication-type="journal"><name><surname>Alba-Ferrara</surname><given-names>L</given-names></name>, <name><surname>Hausmann</surname><given-names>M</given-names></name>, <name><surname>Mitchell</surname><given-names>RL</given-names></name>, <name><surname>Weis</surname><given-names>S</given-names></name>. <article-title>The Neural Correlates of Emotional Prosody Comprehension: Disentangling Simple from Complex Emotion</article-title>. <source>Plos One</source>. <year>2011</year>;<volume>6</volume>(<issue>12</issue>). <pub-id pub-id-type="doi">10.1371/journal.pone.0028701</pub-id> WOS:000298366600030. <?supplied-pmid 22174872?><pub-id pub-id-type="pmid">22174872</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref020">
                <label>20</label>
                <mixed-citation publication-type="journal"><name><surname>Alba-Ferrara</surname><given-names>L</given-names></name>, <name><surname>Ellison</surname><given-names>A</given-names></name>, <name><surname>Mitchell</surname><given-names>RLC</given-names></name>. <article-title>Decoding emotional prosody: Resolving differences in functional neuroanatomy from fMRI and lesion studies using TMS</article-title>. <source>Brain Stimul</source>. <year>2012</year>;<volume>5</volume>(<issue>3</issue>):<fpage>347</fpage>–<lpage>53</lpage>. <pub-id pub-id-type="doi">10.1016/j.brs.2011.06.004</pub-id> WOS:000307198700021. <?supplied-pmid 21824835?><pub-id pub-id-type="pmid">21824835</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref021">
                <label>21</label>
                <mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>DD</given-names></name>, <name><surname>Zhou</surname><given-names>Y</given-names></name>, <name><surname>Yuan</surname><given-names>JJ</given-names></name>. <article-title>Speech Prosodies of Different Emotional Categories Activate Different Brain Regions in Adult Cortex: an fNIRS Study</article-title>. <source>Sci Rep-Uk</source>. <year>2018</year>;<volume>8</volume><pub-id pub-id-type="doi">10.1038/s41598-017-18683-2</pub-id> WOS:000419659800053. <?supplied-pmid 29317758?><pub-id pub-id-type="pmid">29317758</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref022">
                <label>22</label>
                <mixed-citation publication-type="journal"><name><surname>Ross</surname><given-names>ED</given-names></name>, <name><surname>Monnot</surname><given-names>M</given-names></name>. <article-title>Affective prosody: What do comprehension errors tell us about hemispheric lateralization of emotions, sex and aging effects, and the role of cognitive appraisal</article-title>. <source>Neuropsychologia</source>. <year>2011</year>;<volume>49</volume>(<issue>5</issue>):<fpage>866</fpage>–<lpage>77</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2010.12.024</pub-id> WOS:000290649200012. <?supplied-pmid 21182850?><pub-id pub-id-type="pmid">21182850</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref023">
                <label>23</label>
                <mixed-citation publication-type="journal"><name><surname>Frühholz</surname><given-names>S</given-names></name>, <name><surname>Grandjean</surname><given-names>D</given-names></name>. <article-title>Processing of emotional vocalizations in bilateral inferior frontal cortex</article-title>. <source>Neuroscience and biobehavioral reviews</source>. <year>2013</year>;<volume>37</volume>(<issue>10</issue>):<fpage>2847</fpage>–<lpage>55</lpage>. <pub-id pub-id-type="doi">10.1016/j.neubiorev.2013.10.007</pub-id> WOS:000330490200034. <?supplied-pmid 24161466?><pub-id pub-id-type="pmid">24161466</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref024">
                <label>24</label>
                <mixed-citation publication-type="journal"><name><surname>Witteman</surname><given-names>J</given-names></name>, <name><surname>Van Heuven</surname><given-names>VJP</given-names></name>, <name><surname>Schiller</surname><given-names>NO</given-names></name>. <article-title>Hearing feelings: A quantitative meta-analysis on the neuroimaging literature of emotional prosody perception</article-title>. <source>Neuropsychologia</source>. <year>2012</year>;<volume>50</volume>(<issue>12</issue>):<fpage>2752</fpage>–<lpage>63</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2012.07.026</pub-id> WOS:000310945900006. <?supplied-pmid 22841991?><pub-id pub-id-type="pmid">22841991</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref025">
                <label>25</label>
                <mixed-citation publication-type="journal"><name><surname>Frühholz</surname><given-names>S</given-names></name>, <name><surname>Ceravolo</surname><given-names>L</given-names></name>, <name><surname>Grandjean</surname><given-names>D</given-names></name>. <article-title>Specific Brain Networks during Explicit and Implicit Decoding of Emotional Prosody</article-title>. <source>Cerebral cortex</source>. <year>2012</year>;<volume>22</volume>(<issue>5</issue>):<fpage>1107</fpage>–<lpage>17</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhr184</pub-id> WOS:000303161400012. <?supplied-pmid 21750247?><pub-id pub-id-type="pmid">21750247</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref026">
                <label>26</label>
                <mixed-citation publication-type="journal"><name><surname>Ethofer</surname><given-names>T</given-names></name>, <name><surname>Bretscher</surname><given-names>J</given-names></name>, <name><surname>Gschwind</surname><given-names>M</given-names></name>, <name><surname>Kreifelts</surname><given-names>B</given-names></name>, <name><surname>Wildgruber</surname><given-names>D</given-names></name>, <name><surname>Vuilleumier</surname><given-names>P</given-names></name>. <article-title>Emotional Voice Areas: Anatomic Location, Functional Properties, and Structural Connections Revealed by Combined fMRI/DTI</article-title>. <source>Cerebral cortex</source>. <year>2012</year>;<volume>22</volume>(<issue>1</issue>):<fpage>191</fpage>–<lpage>200</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhr113</pub-id> WOS:000298190500017. <?supplied-pmid 21625012?><pub-id pub-id-type="pmid">21625012</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref027">
                <label>27</label>
                <mixed-citation publication-type="journal"><name><surname>Grossmann</surname><given-names>T</given-names></name>, <name><surname>Oberecker</surname><given-names>R</given-names></name>, <name><surname>Koch</surname><given-names>SP</given-names></name>, <name><surname>Friederici</surname><given-names>AD</given-names></name>. <article-title>The Developmental Origins of Voice Processing in the Human Brain</article-title>. <source>Neuron</source>. <year>2010</year>;<volume>65</volume>(<issue>6</issue>):<fpage>852</fpage>–<lpage>8</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2010.03.001</pub-id> ISI:000276148900013. <?supplied-pmid 20346760?><pub-id pub-id-type="pmid">20346760</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref028">
                <label>28</label>
                <mixed-citation publication-type="journal"><name><surname>Lloyd-Fox</surname><given-names>S</given-names></name>, <name><surname>Blasi</surname><given-names>A</given-names></name>, <name><surname>Mercure</surname><given-names>E</given-names></name>, <name><surname>Elwell</surname><given-names>CE</given-names></name>, <name><surname>Johnson</surname><given-names>MH</given-names></name>. <article-title>The emergence of cerebral specialization for the human voice over the first months of life</article-title>. <source>Soc Neurosci-Uk</source>. <year>2012</year>;<volume>7</volume>(<issue>3</issue>):<fpage>317</fpage>–<lpage>30</lpage>. <pub-id pub-id-type="doi">10.1080/17470919.2011.614696</pub-id> ISI:000303567300009. <?supplied-pmid 21950945?><pub-id pub-id-type="pmid">21950945</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref029">
                <label>29</label>
                <mixed-citation publication-type="journal"><name><surname>Blasi</surname><given-names>A</given-names></name>, <name><surname>Mercure</surname><given-names>E</given-names></name>, <name><surname>Lloyd-Fox</surname><given-names>S</given-names></name>, <name><surname>Thomson</surname><given-names>A</given-names></name>, <name><surname>Brammer</surname><given-names>M</given-names></name>, <name><surname>Sauter</surname><given-names>D</given-names></name>, <etal>et al</etal><article-title>Early Specialization for Voice and Emotion Processing in the Infant Brain</article-title>. <source>Curr Biol</source>. <year>2011</year>;<volume>21</volume>(<issue>14</issue>):<fpage>1220</fpage>–<lpage>4</lpage>. <pub-id pub-id-type="doi">10.1016/j.cub.2011.06.009</pub-id> ISI:000293320000024. <?supplied-pmid 21723130?><pub-id pub-id-type="pmid">21723130</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref030">
                <label>30</label>
                <mixed-citation publication-type="journal"><name><surname>Blasi</surname><given-names>A</given-names></name>, <name><surname>Lloyd-Fox</surname><given-names>S</given-names></name>, <name><surname>Sethna</surname><given-names>V</given-names></name>, <name><surname>Brammer</surname><given-names>MJ</given-names></name>, <name><surname>Mercure</surname><given-names>E</given-names></name>, <name><surname>Murray</surname><given-names>L</given-names></name>, <etal>et al</etal> Atypical processing of voice sounds in infants at risk for autism spectrum disorder. Cortex. <year>2015</year>;<volume>71</volume>:<fpage>122</fpage>–<lpage>33</lpage>. <pub-id pub-id-type="doi">10.1016/j.cortex.2015.06.015</pub-id> WOS:000362131300012. <?supplied-pmid 26200892?><pub-id pub-id-type="pmid">26200892</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref031">
                <label>31</label>
                <mixed-citation publication-type="journal"><name><surname>Dehaene-Lambertz</surname><given-names>G</given-names></name>, <name><surname>Dehaene</surname><given-names>S</given-names></name>, <name><surname>Hertz-Pannier</surname><given-names>L</given-names></name>. <article-title>Functional neuroimaging of speech perception in infants</article-title>. <source>Science</source>. <year>2002</year>;<volume>298</volume>(<issue>5600</issue>):<fpage>2013</fpage>–<lpage>5</lpage>. <pub-id pub-id-type="doi">10.1126/science.1077066</pub-id> ISI:000179629200052. <?supplied-pmid 12471265?><pub-id pub-id-type="pmid">12471265</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref032">
                <label>32</label>
                <mixed-citation publication-type="journal"><name><surname>Pell</surname><given-names>MD</given-names></name>, <name><surname>Rothermich</surname><given-names>K</given-names></name>, <name><surname>Liu</surname><given-names>P</given-names></name>, <name><surname>Paulmann</surname><given-names>S</given-names></name>, <name><surname>Sethi</surname><given-names>S</given-names></name>, <name><surname>Rigoulot</surname><given-names>S</given-names></name>. <article-title>Preferential decoding of emotion from human non-linguistic vocalizations versus speech prosody</article-title>. <source>Biol Psychol</source>. <year>2015</year>;<volume>111</volume>:<fpage>14</fpage>–<lpage>25</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsycho.2015.08.008</pub-id> WOS:000363488500003. <?supplied-pmid 26307467?><pub-id pub-id-type="pmid">26307467</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref033">
                <label>33</label>
                <mixed-citation publication-type="journal"><name><surname>Grandjean</surname><given-names>D</given-names></name>, <name><surname>Sander</surname><given-names>D</given-names></name>, <name><surname>Pourtois</surname><given-names>G</given-names></name>, <name><surname>Schwartz</surname><given-names>S</given-names></name>, <name><surname>Seghier</surname><given-names>ML</given-names></name>, <name><surname>Scherer</surname><given-names>KR</given-names></name>, <etal>et al</etal><article-title>The voices of wrath: brain responses to angry prosody in meaningless speech</article-title>. <source>Nat Neurosci</source>. <year>2005</year>;<volume>8</volume>(<issue>2</issue>):<fpage>145</fpage>–<lpage>6</lpage>. <pub-id pub-id-type="doi">10.1038/nn1392</pub-id> WOS:000226638200011. <?supplied-pmid 15665880?><pub-id pub-id-type="pmid">15665880</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref034">
                <label>34</label>
                <mixed-citation publication-type="journal"><name><surname>Peeters</surname><given-names>G</given-names></name>, <name><surname>Czapinski</surname><given-names>J</given-names></name>. <article-title>Positive-negative asymmetry in evaluations: The distinction between affective and informational negativity effects</article-title>. <source>European review of social psychology</source>. <year>1990</year>;<volume>1</volume>(<issue>1</issue>):<fpage>33</fpage>–<lpage>60</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref035">
                <label>35</label>
                <mixed-citation publication-type="journal"><name><surname>Chronaki</surname><given-names>G</given-names></name>, <name><surname>Broyd</surname><given-names>S</given-names></name>, <name><surname>Garner</surname><given-names>M</given-names></name>, <name><surname>Hadwin</surname><given-names>JA</given-names></name>, <name><surname>Thompson</surname><given-names>MJJ</given-names></name>, <name><surname>Sonuga-Barke</surname><given-names>EJS</given-names></name>. <article-title>Isolating N400 as neural marker of vocal anger processing in 6-11-year old children</article-title>. <source>Dev Cogn Neuros-Neth</source>. <year>2012</year>;<volume>2</volume>(<issue>2</issue>):<fpage>268</fpage>–<lpage>76</lpage>. <pub-id pub-id-type="doi">10.1016/j.dcn.2011.11.007</pub-id> WOS:000315317600007. <?supplied-pmid 22483076?><pub-id pub-id-type="pmid">22483076</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref036">
                <label>36</label>
                <mixed-citation publication-type="journal"><name><surname>Grossmann</surname><given-names>T</given-names></name>, <name><surname>Striano</surname><given-names>T</given-names></name>, <name><surname>Friederici</surname><given-names>AD</given-names></name>. <article-title>Infants' electric brain responses to emotional prosody</article-title>. <source>Neuroreport</source>. <year>2005</year>;<volume>16</volume>(<issue>16</issue>):<fpage>1825</fpage>–<lpage>8</lpage>. <pub-id pub-id-type="doi">10.1097/01.wnr.0000185964.34336.b1</pub-id> WOS:000233277700020. <?supplied-pmid 16237335?><pub-id pub-id-type="pmid">16237335</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref037">
                <label>37</label>
                <mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>DD</given-names></name>, <name><surname>Zhou</surname><given-names>Y</given-names></name>, <name><surname>Hou</surname><given-names>XL</given-names></name>, <name><surname>Cui</surname><given-names>Y</given-names></name>, <name><surname>Zhou</surname><given-names>CL</given-names></name>. <article-title>Discrimination of emotional prosodies in human neonates: A pilot fNIRS study</article-title>. <source>Neurosci Lett</source>. <year>2017</year>;<volume>658</volume>:<fpage>62</fpage>–<lpage>6</lpage>. <pub-id pub-id-type="doi">10.1016/j.neulet.2017.08.047</pub-id> WOS:000414115200012. <?supplied-pmid 28842278?><pub-id pub-id-type="pmid">28842278</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref038">
                <label>38</label>
                <mixed-citation publication-type="journal"><name><surname>Baumwell</surname><given-names>L</given-names></name>, <name><surname>TamisLeMonda</surname><given-names>CS</given-names></name>, <name><surname>Bornstein</surname><given-names>MH</given-names></name>. <article-title>Maternal verbal sensitivity and child language comprehension</article-title>. <source>Infant Behav Dev</source>. <year>1997</year>;<volume>20</volume>(<issue>2</issue>):<fpage>247</fpage>–<lpage>58</lpage>. <pub-id pub-id-type="doi">10.1016/S0163-6383(97)90026-6</pub-id> ISI:A1997YC99000013.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref039">
                <label>39</label>
                <mixed-citation publication-type="journal"><name><surname>Stein</surname><given-names>A</given-names></name>, <name><surname>Malmberg</surname><given-names>LE</given-names></name>, <name><surname>Sylva</surname><given-names>K</given-names></name>, <name><surname>Barnes</surname><given-names>J</given-names></name>, <name><surname>Leach</surname><given-names>P</given-names></name>, <collab>team** F</collab>. <article-title>The influence of maternal depression, caregiving, and socioeconomic status in the post-natal year on children's language development</article-title>. <source>Child: care, health and development</source>. <year>2008</year>;<volume>34</volume>(<issue>5</issue>):<fpage>603</fpage>–<lpage>12</lpage>. <pub-id pub-id-type="doi">10.1111/j.1365-2214.2008.00837.x</pub-id> .<?supplied-pmid 18549438?><pub-id pub-id-type="pmid">18549438</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref040">
                <label>40</label>
                <mixed-citation publication-type="journal"><name><surname>Bernier</surname><given-names>A</given-names></name>, <name><surname>Calkins</surname><given-names>SD</given-names></name>, <name><surname>Bell</surname><given-names>MA</given-names></name>. <article-title>Longitudinal Associations Between the Quality of Mother-Infant Interactions and Brain Development Across Infancy</article-title>. <source>Child Dev</source>. <year>2016</year>;<volume>87</volume>(<issue>4</issue>):<fpage>1159</fpage>–<lpage>74</lpage>. <pub-id pub-id-type="doi">10.1111/cdev.12518</pub-id> WOS:000379911900017. <?supplied-pmid 27040719?><pub-id pub-id-type="pmid">27040719</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref041">
                <label>41</label>
                <mixed-citation publication-type="journal"><name><surname>Swingler</surname><given-names>MM</given-names></name>, <name><surname>Perry</surname><given-names>NB</given-names></name>, <name><surname>Calkins</surname><given-names>SD</given-names></name>, <name><surname>Bell</surname><given-names>MA</given-names></name>. <article-title>Maternal Behavior Predicts Infant Neurophysiological and Behavioral Attention Processes in the First Year</article-title>. <source>Dev Psychol</source>. <year>2017</year>;<volume>53</volume>(<issue>1</issue>):<fpage>13</fpage>–<lpage>27</lpage>. <pub-id pub-id-type="doi">10.1037/dev0000187</pub-id> WOS:000391700500003. <?supplied-pmid 27505693?><pub-id pub-id-type="pmid">27505693</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref042">
                <label>42</label>
                <mixed-citation publication-type="journal"><name><surname>Lohaus</surname><given-names>A</given-names></name>, <name><surname>Keller</surname><given-names>H</given-names></name>, <name><surname>Ball</surname><given-names>J</given-names></name>, <name><surname>Voelker</surname><given-names>S</given-names></name>, <name><surname>Elben</surname><given-names>C</given-names></name>. <article-title>Maternal sensitivity in interactions with three‐and 12‐month‐old infants: stability, structural composition, and developmental consequences</article-title>. <source>Infant Child Dev</source>. <year>2004</year>;<volume>13</volume>(<issue>3</issue>):<fpage>235</fpage>–<lpage>52</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref043">
                <label>43</label>
                <mixed-citation publication-type="journal"><name><surname>Guzell</surname><given-names>JR</given-names></name>, <name><surname>Vernon‐Feagans</surname><given-names>L</given-names></name>. <article-title>Parental perceived control over caregiving and its relationship to parent–infant interaction</article-title>. <source>Child Dev</source>. <year>2004</year>;<volume>75</volume>(<issue>1</issue>):<fpage>134</fpage>–<lpage>46</lpage>. <?supplied-pmid 15015680?><pub-id pub-id-type="pmid">15015680</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref044">
                <label>44</label>
                <mixed-citation publication-type="journal"><name><surname>Lloyd-Fox</surname><given-names>S</given-names></name>, <name><surname>Blasi</surname><given-names>A</given-names></name>, <name><surname>Elwell</surname><given-names>CE</given-names></name>. <article-title>Illuminating the developing brain: the past, present and future of functional near infrared spectroscopy</article-title>. <source>Neuroscience and biobehavioral reviews</source>. <year>2010</year>;<volume>34</volume>(<issue>3</issue>):<fpage>269</fpage>–<lpage>84</lpage>. Epub 2009/07/28. <pub-id pub-id-type="doi">10.1016/j.neubiorev.2009.07.008</pub-id> .<?supplied-pmid 19632270?><pub-id pub-id-type="pmid">19632270</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref045">
                <label>45</label>
                <mixed-citation publication-type="journal"><name><surname>Faul</surname><given-names>F</given-names></name>, <name><surname>Erdfelder</surname><given-names>E</given-names></name>, <name><surname>Lang</surname><given-names>AG</given-names></name>, <name><surname>Buchner</surname><given-names>A</given-names></name>. <article-title>G*Power 3: a flexible statistical power analysis program for the social, behavioral, and biomedical sciences</article-title>. <source>Behavior research methods</source>. <year>2007</year>;<volume>39</volume>(<issue>2</issue>):<fpage>175</fpage>–<lpage>91</lpage>. .<?supplied-pmid 17695343?><pub-id pub-id-type="pmid">17695343</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref046">
                <label>46</label>
                <mixed-citation publication-type="journal"><name><surname>Peirce</surname><given-names>JW</given-names></name>. <article-title>PsychoPy—Psychophysics software in Python</article-title>. <source>J Neurosci Meth</source>. <year>2007</year>;<volume>162</volume>(<issue>1–2</issue>):<fpage>8</fpage>–<lpage>13</lpage>. <pub-id pub-id-type="doi">10.1016/j.jneumeth.2006.11.017</pub-id> WOS:000246429000002. <?supplied-pmid 17254636?><pub-id pub-id-type="pmid">17254636</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref047">
                <label>47</label>
                <mixed-citation publication-type="journal"><name><surname>Maurage</surname><given-names>P</given-names></name>, <name><surname>Joassin</surname><given-names>F</given-names></name>, <name><surname>Philippot</surname><given-names>P</given-names></name>, <name><surname>Campanella</surname><given-names>S</given-names></name>. <article-title>A validated battery of vocal emotional expressions</article-title>. <source>Neuropsychological Trends</source>. <year>2007</year>;<volume>2</volume>(<issue>1</issue>):<fpage>63</fpage>–<lpage>74</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref048">
                <label>48</label>
                <mixed-citation publication-type="journal"><name><surname>Chronaki</surname><given-names>G</given-names></name>, <name><surname>Hadwin</surname><given-names>JA</given-names></name>, <name><surname>Garner</surname><given-names>M</given-names></name>, <name><surname>Maurage</surname><given-names>P</given-names></name>, <name><surname>Sonuga-Barke</surname><given-names>EJS</given-names></name>. <article-title>The development of emotion recognition from facial expressions and non-linguistic vocalizations during childhood</article-title>. <source>Brit J Dev Psychol</source>. <year>2015</year>;<volume>33</volume>(<issue>2</issue>):<fpage>218</fpage>–<lpage>36</lpage>. <pub-id pub-id-type="doi">10.1111/bjdp.12075</pub-id> WOS:000354261500008. <?supplied-pmid 25492258?><pub-id pub-id-type="pmid">25492258</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref049">
                <label>49</label>
                <mixed-citation publication-type="journal"><name><surname>Chronaki</surname><given-names>G</given-names></name>, <name><surname>Benikos</surname><given-names>N</given-names></name>, <name><surname>Fairchild</surname><given-names>G</given-names></name>, <name><surname>Sonuga-Barke</surname><given-names>EJS</given-names></name>. <article-title>Atypical neural responses to vocal anger in attention-deficit/hyperactivity disorder</article-title>. <source>J Child Psychol Psyc</source>. <year>2015</year>;<volume>56</volume>(<issue>4</issue>):<fpage>477</fpage>–<lpage>87</lpage>. <pub-id pub-id-type="doi">10.1111/jcpp.12312</pub-id> WOS:000351402400010. <?supplied-pmid 25117642?><pub-id pub-id-type="pmid">25117642</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref050">
                <label>50</label>
                <mixed-citation publication-type="journal"><name><surname>Boersma</surname><given-names>P</given-names></name>, <name><surname>van Heuven</surname><given-names>V</given-names></name>. <article-title>Speak and unSpeak with PRAAT</article-title>. <source>Glot International</source>. <year>2001</year>;<volume>5</volume>:<fpage>341</fpage>–<lpage>347</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref051">
                <label>51</label>
                <mixed-citation publication-type="journal"><name><surname>Villringer</surname><given-names>A</given-names></name>, <name><surname>Chance</surname><given-names>B</given-names></name>. <article-title>Non-invasive optical spectroscopy and imaging of human brain function</article-title>. <source>Trends Neurosci</source>. <year>1997</year>;<volume>20</volume>(<issue>10</issue>):<fpage>435</fpage>–<lpage>42</lpage>. <pub-id pub-id-type="doi">10.1016/S0166-2236(97)01132-6</pub-id> ISI:A1997XZ02800003. <?supplied-pmid 9347608?><pub-id pub-id-type="pmid">9347608</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref052">
                <label>52</label>
                <mixed-citation publication-type="journal"><name><surname>Gervain</surname><given-names>J</given-names></name>, <name><surname>Mehler</surname><given-names>J</given-names></name>, <name><surname>Werker</surname><given-names>JF</given-names></name>, <name><surname>Nelson</surname><given-names>CA</given-names></name>, <name><surname>Csibra</surname><given-names>G</given-names></name>, <name><surname>Lloyd-Fox</surname><given-names>S</given-names></name>, <etal>et al</etal><article-title>Near-infrared spectroscopy: A report from the McDonnell infant methodology consortium</article-title>. <source>Dev Cogn Neuros-Neth</source>. <year>2011</year>;<volume>1</volume>(<issue>1</issue>):<fpage>22</fpage>–<lpage>46</lpage>. <pub-id pub-id-type="doi">10.1016/j.dcn.2010.07.004</pub-id> ISI:000208653300004. <?supplied-pmid 22436417?><pub-id pub-id-type="pmid">22436417</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref053">
                <label>53</label>
                <mixed-citation publication-type="journal"><name><surname>Pinti</surname><given-names>P</given-names></name>, <name><surname>Tachtsidis</surname><given-names>I</given-names></name>, <name><surname>Hamilton</surname><given-names>A</given-names></name>, <name><surname>Hirsch</surname><given-names>J</given-names></name>, <name><surname>Aichelburg</surname><given-names>C</given-names></name>, <name><surname>Gilbert</surname><given-names>S</given-names></name>, <etal>et al</etal><article-title>The present and future use of functional near‐infrared spectroscopy (fNIRS) for cognitive neuroscience</article-title>. <source>Annals of the New York Academy of Sciences</source>. <year>2018</year>.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref054">
                <label>54</label>
                <mixed-citation publication-type="journal"><name><surname>Everdell</surname><given-names>NL</given-names></name>, <name><surname>Gibson</surname><given-names>AP</given-names></name>, <name><surname>Tullis</surname><given-names>IDC</given-names></name>, <name><surname>Vaithianathan</surname><given-names>T</given-names></name>, <name><surname>Hebden</surname><given-names>JC</given-names></name>, <name><surname>Delpy</surname><given-names>DT</given-names></name>. <article-title>A frequency multiplexed near-infrared topography system for imaging functional activation in the brain</article-title>. <source>Rev Sci Instrum</source>. <year>2005</year>;<volume>76</volume>(<issue>9</issue>). Artn 093705 <pub-id pub-id-type="doi">10.1063/1.2038087</pub-id> WOS:000232034400034.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref055">
                <label>55</label>
                <mixed-citation publication-type="journal"><name><surname>Pena</surname><given-names>M</given-names></name>, <name><surname>Maki</surname><given-names>A</given-names></name>, <name><surname>Kovacic</surname><given-names>D</given-names></name>, <name><surname>Dehaene-Lambertz</surname><given-names>G</given-names></name>, <name><surname>Koizumi</surname><given-names>H</given-names></name>, <name><surname>Bouquet</surname><given-names>F</given-names></name>, <etal>et al</etal><article-title>Sounds and silence: An optical topography study of language recognition at birth</article-title>. <source>P Natl Acad Sci USA</source>. <year>2003</year>;<volume>100</volume>(<issue>20</issue>):<fpage>11702</fpage>–<lpage>5</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1934290100</pub-id> ISI:000185685700094. <?supplied-pmid 14500906?><pub-id pub-id-type="pmid">14500906</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref056">
                <label>56</label>
                <mixed-citation publication-type="journal"><name><surname>Taga</surname><given-names>G</given-names></name>, <name><surname>Asakawa</surname><given-names>K</given-names></name>. <article-title>Selectivity and localization of cortical response to auditory and visual stimulation in awake infants aged 2 to 4 months</article-title>. <source>Neuroimage</source>. <year>2007</year>;<volume>36</volume>(<issue>4</issue>):<fpage>1246</fpage>–<lpage>52</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.04.037</pub-id> ISI:000248152400018. <?supplied-pmid 17524672?><pub-id pub-id-type="pmid">17524672</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref057">
                <label>57</label>
                <mixed-citation publication-type="journal"><name><surname>Belin</surname><given-names>P</given-names></name>, <name><surname>Zatorre</surname><given-names>RJ</given-names></name>, <name><surname>Lafaille</surname><given-names>P</given-names></name>, <name><surname>Ahad</surname><given-names>P</given-names></name>, <name><surname>Pike</surname><given-names>B</given-names></name>. <article-title>Voice-selective areas in human auditory cortex</article-title>. <source>Nature</source>. <year>2000</year>;<volume>403</volume>(<issue>6767</issue>):<fpage>309</fpage>–<lpage>12</lpage>. <pub-id pub-id-type="doi">10.1038/35002078</pub-id> ISI:000084899700052. <?supplied-pmid 10659849?><pub-id pub-id-type="pmid">10659849</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref058">
                <label>58</label>
                <mixed-citation publication-type="journal"><name><surname>Ethofer</surname><given-names>T</given-names></name>, <name><surname>Anders</surname><given-names>S</given-names></name>, <name><surname>Wiethoff</surname><given-names>S</given-names></name>, <name><surname>Erb</surname><given-names>M</given-names></name>, <name><surname>Herbert</surname><given-names>C</given-names></name>, <name><surname>Saur</surname><given-names>R</given-names></name>, <etal>et al</etal><article-title>Effects of prosodic emotional intensity on activation of associative auditory cortex</article-title>. <source>Neuroreport</source>. <year>2006</year>;<volume>17</volume>(<issue>3</issue>):<fpage>249</fpage>–<lpage>53</lpage>. <pub-id pub-id-type="doi">10.1097/01.wnr.0000199466.32036.5d</pub-id> .<?supplied-pmid 16462592?><pub-id pub-id-type="pmid">16462592</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref059">
                <label>59</label>
                <mixed-citation publication-type="journal"><name><surname>Fukui</surname><given-names>Y</given-names></name>, <name><surname>Ajichi</surname><given-names>Y</given-names></name>, <name><surname>Okada</surname><given-names>E</given-names></name>. <article-title>Monte Carlo prediction of near-infrared light propagation in realistic adult and neonatal head models</article-title>. <source>Appl Optics</source>. <year>2003</year>;<volume>42</volume>(<issue>16</issue>):<fpage>2881</fpage>–<lpage>7</lpage>. <pub-id pub-id-type="doi">10.1364/Ao.42.002881</pub-id> WOS:000183256600003.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref060">
                <label>60</label>
                <mixed-citation publication-type="journal"><name><surname>Huppert</surname><given-names>TJ</given-names></name>, <name><surname>Diamond</surname><given-names>SG</given-names></name>, <name><surname>Franceschini</surname><given-names>MA</given-names></name>, <name><surname>Boas</surname><given-names>DA</given-names></name>. <article-title>HomER: a review of time-series analysis methods for near-infrared spectroscopy of the brain</article-title>. <source>Appl Optics</source>. <year>2009</year>;<volume>48</volume>(<issue>10</issue>):<fpage>D280</fpage>–<lpage>D98</lpage>. ISI:000265443700033.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref061">
                <label>61</label>
                <mixed-citation publication-type="journal"><name><surname>Fox</surname><given-names>SE</given-names></name>, <name><surname>Wagner</surname><given-names>JB</given-names></name>, <name><surname>Shrock</surname><given-names>CL</given-names></name>, <name><surname>Tager-Flusberg</surname><given-names>H</given-names></name>, <name><surname>Nelson</surname><given-names>CA</given-names></name>. <article-title>Neural processing of facial identity and emotion in infants at high-risk for autism spectrum disorders</article-title>. <source>Frontiers in human neuroscience</source>. <year>2013</year>;<volume>7</volume><pub-id pub-id-type="doi">10.3389/Fnhum.2013.00089</pub-id> ISI:000317335500001. <?supplied-pmid 23576966?><pub-id pub-id-type="pmid">23576966</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref062">
                <label>62</label>
                <mixed-citation publication-type="journal"><name><surname>Cooper</surname><given-names>RJ</given-names></name>, <name><surname>Seib</surname><given-names>J</given-names></name>, <name><surname>Gagnon</surname><given-names>L</given-names></name>, <name><surname>Phillip</surname><given-names>D</given-names></name>, <name><surname>Schytz</surname><given-names>HW</given-names></name>, <name><surname>Iversen</surname><given-names>HK</given-names></name>, <etal>et al</etal><article-title>A systematic comparison of motion artifact correction techniques for functional near-infrared spectroscopy</article-title>. <source>Front Neurosci-Switz</source>. <year>2012</year>;<volume>6</volume><pub-id pub-id-type="doi">10.3389/fnins.2012.00147</pub-id> WOS:000209165300153. <?supplied-pmid 23087603?><pub-id pub-id-type="pmid">23087603</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref063">
                <label>63</label>
                <mixed-citation publication-type="journal"><name><surname>Scholkmann</surname><given-names>F</given-names></name>, <name><surname>Spichtig</surname><given-names>S</given-names></name>, <name><surname>Muehlemann</surname><given-names>T</given-names></name>, <name><surname>Wolf</surname><given-names>M</given-names></name>. <article-title>How to detect and reduce movement artifacts in near-infrared imaging using moving standard deviation and spline interpolation</article-title>. <source>Physiol Meas</source>. <year>2010</year>;<volume>31</volume>(<issue>5</issue>):<fpage>649</fpage>–<lpage>62</lpage>. <pub-id pub-id-type="doi">10.1088/0967-3334/31/5/004</pub-id> WOS:000276728000004. <?supplied-pmid 20308772?><pub-id pub-id-type="pmid">20308772</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref064">
                <label>64</label>
                <mixed-citation publication-type="journal"><name><surname>Brigadoi</surname><given-names>S</given-names></name>, <name><surname>Ceccherini</surname><given-names>L</given-names></name>, <name><surname>Cutini</surname><given-names>S</given-names></name>, <name><surname>Scarpa</surname><given-names>F</given-names></name>, <name><surname>Scatturin</surname><given-names>P</given-names></name>, <name><surname>Selb</surname><given-names>J</given-names></name>, <etal>et al</etal><article-title>Motion artifacts in functional near-infrared spectroscopy: A comparison of motion correction techniques applied to real cognitive data</article-title>. <source>Neuroimage</source>. <year>2014</year>;<volume>85</volume>:<fpage>181</fpage>–<lpage>91</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.04.082</pub-id> WOS:000328869700014. <?supplied-pmid 23639260?><pub-id pub-id-type="pmid">23639260</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref065">
                <label>65</label>
                <mixed-citation publication-type="journal"><name><surname>Kennedy</surname><given-names>JJ</given-names></name>. <article-title>The eta coefficient in complex ANOVA designs</article-title>. <source>Educational and Psychological Measurement</source>. <year>1970</year>;<volume>30</volume>(<issue>4</issue>):<fpage>885</fpage>–<lpage>9</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref066">
                <label>66</label>
                <mixed-citation publication-type="journal"><name><surname>Cohen</surname><given-names>J</given-names></name>. <article-title>Eta-squared and partial eta-squared in fixed factor ANOVA designs</article-title>. <source>Educational and psychological measurement</source>. <year>1973</year>;<volume>33</volume>(<issue>1</issue>):<fpage>107</fpage>–<lpage>12</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref067">
                <label>67</label>
                <mixed-citation publication-type="book"><name><surname>Murphy</surname><given-names>KR</given-names></name>, <name><surname>Myors</surname><given-names>B</given-names></name>, <name><surname>Wolach</surname><given-names>A</given-names></name>. <source>Statistical power analysis: A simple and general model for traditional and modern hypothesis tests</source>: <publisher-name>Routledge</publisher-name>; <year>2014</year>.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref068">
                <label>68</label>
                <mixed-citation publication-type="journal"><name><surname>Benjamini</surname><given-names>Y</given-names></name>, <name><surname>Hochberg</surname><given-names>Y</given-names></name>. <article-title>Controlling the False Discovery Rate—a Practical and Powerful Approach to Multiple Testing</article-title>. <source>J Roy Stat Soc B Met</source>. <year>1995</year>;<volume>57</volume>(<issue>1</issue>):<fpage>289</fpage>–<lpage>300</lpage>. WOS:A1995QE45300017.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref069">
                <label>69</label>
                <mixed-citation publication-type="book"><name><surname>Field</surname><given-names>A</given-names></name>, <name><surname>Miles</surname><given-names>J</given-names></name>, <name><surname>Field</surname><given-names>Z</given-names></name>. <source>Discovering statistics using R</source>: <publisher-name>Sage publications</publisher-name>; <year>2012</year>.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref070">
                <label>70</label>
                <mixed-citation publication-type="journal"><name><surname>Lloyd-Fox</surname><given-names>S</given-names></name>, <name><surname>Begus</surname><given-names>K</given-names></name>, <name><surname>Halliday</surname><given-names>D</given-names></name>, <name><surname>Pirazzoli</surname><given-names>L</given-names></name>, <name><surname>Blasi</surname><given-names>A</given-names></name>, <name><surname>Papademetriou</surname><given-names>M</given-names></name>, <etal>et al</etal><article-title>Cortical specialisation to social stimuli from the first days to the second year of life: A rural Gambian cohort</article-title>. <source>Dev Cogn Neuros-Neth</source>. <year>2017</year>.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref071">
                <label>71</label>
                <mixed-citation publication-type="other">Wan MW. Manchester Assessment of Caregiver-Infant Interaction. Coding Manual, Version 2. Manchester: Unpublished manual. 2015.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref072">
                <label>72</label>
                <mixed-citation publication-type="journal"><name><surname>Wan</surname><given-names>MW</given-names></name>, <name><surname>Brooks</surname><given-names>A</given-names></name>, <name><surname>Green</surname><given-names>J</given-names></name>, <name><surname>Abel</surname><given-names>KM</given-names></name>, <name><surname>Elmadih</surname><given-names>A</given-names></name>. <article-title>Psychometrics and validation of a brief rating measure of parent-infant interaction: Manchester assessment of caregiver–infant interaction</article-title>. <source>Int J Behav Dev</source>. <year>2017</year>;<volume>41</volume>(<issue>4</issue>):<fpage>542</fpage>–<lpage>9</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref073">
                <label>73</label>
                <mixed-citation publication-type="journal"><name><surname>Wan</surname><given-names>MW</given-names></name>, <name><surname>Downey</surname><given-names>D</given-names></name>, <name><surname>Strachan</surname><given-names>H</given-names></name>, <name><surname>Elliott</surname><given-names>R</given-names></name>, <name><surname>Williams</surname><given-names>SR</given-names></name>, <name><surname>Abel</surname><given-names>KM</given-names></name>. <article-title>The Neural Basis of Maternal Bonding</article-title>. <source>Plos One</source>. <year>2014</year>;<volume>9</volume>(<issue>3</issue>). ISI:000332475500004.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref074">
                <label>74</label>
                <mixed-citation publication-type="journal"><name><surname>Wan</surname><given-names>MW</given-names></name>, <name><surname>Green</surname><given-names>J</given-names></name>, <name><surname>Elsabbagh</surname><given-names>M</given-names></name>, <name><surname>Johnson</surname><given-names>M</given-names></name>, <name><surname>Charman</surname><given-names>T</given-names></name>, <name><surname>Plummer</surname><given-names>F</given-names></name>, <etal>et al</etal><article-title>Parent-infant interaction in infant siblings at risk of autism</article-title>. <source>Res Dev Disabil</source>. <year>2012</year>;<volume>33</volume>(<issue>3</issue>):<fpage>924</fpage>–<lpage>32</lpage>. <pub-id pub-id-type="doi">10.1016/j.ridd.2011.12.011</pub-id> ISI:000301015700018. <?supplied-pmid 22257674?><pub-id pub-id-type="pmid">22257674</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref075">
                <label>75</label>
                <mixed-citation publication-type="journal"><name><surname>Grossmann</surname><given-names>T</given-names></name>, <name><surname>Vaish</surname><given-names>A</given-names></name>, <name><surname>Franz</surname><given-names>J</given-names></name>, <name><surname>Schroeder</surname><given-names>R</given-names></name>, <name><surname>Stoneking</surname><given-names>M</given-names></name>, <name><surname>Friederici</surname><given-names>AD</given-names></name>. <article-title>Emotional Voice Processing: Investigating the Role of Genetic Variation in the Serotonin Transporter across Development</article-title>. <source>Plos One</source>. <year>2013</year>;<volume>8</volume>(<issue>7</issue>). <pub-id pub-id-type="doi">10.1371/journal.pone.0068377</pub-id> WOS:000321692000026. <?supplied-pmid 23861897?><pub-id pub-id-type="pmid">23861897</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref076">
                <label>76</label>
                <mixed-citation publication-type="journal"><name><surname>Missana</surname><given-names>M</given-names></name>, <name><surname>Grossmann</surname><given-names>T</given-names></name>. <article-title>Infants' emerging sensitivity to emotional body expressions: insights from asymmetrical frontal brain activity</article-title>. <source>Dev Psychol</source>. <year>2015</year>;<volume>51</volume>(<issue>2</issue>):<fpage>151</fpage>–<lpage>60</lpage>. <pub-id pub-id-type="doi">10.1037/a0038469</pub-id> .<?supplied-pmid 25546593?><pub-id pub-id-type="pmid">25546593</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref077">
                <label>77</label>
                <mixed-citation publication-type="journal"><name><surname>Brooker</surname><given-names>RJ</given-names></name>, <name><surname>Canen</surname><given-names>MJ</given-names></name>, <name><surname>Davidson</surname><given-names>RJ</given-names></name>, <name><surname>Hill Goldsmith</surname><given-names>H</given-names></name>. <article-title>Short- and long-term stability of alpha asymmetry in infants: Baseline and affective measures</article-title>. <source>Psychophysiology</source>. <year>2017</year>;<volume>54</volume>(<issue>8</issue>):<fpage>1100</fpage>–<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1111/psyp.12866</pub-id>
<?supplied-pmid 28383124?><pub-id pub-id-type="pmid">28383124</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref078">
                <label>78</label>
                <mixed-citation publication-type="journal"><name><surname>Missana</surname><given-names>M</given-names></name>, <name><surname>Altvater-Mackensen</surname><given-names>N</given-names></name>, <name><surname>Grossmann</surname><given-names>T</given-names></name>. <article-title>Neural correlates of infants' sensitivity to vocal expressions of peers</article-title>. <source>Dev Cogn Neurosci</source>. <year>2017</year>;<volume>26</volume>:<fpage>39</fpage>–<lpage>44</lpage>. <pub-id pub-id-type="doi">10.1016/j.dcn.2017.04.003</pub-id> .<?supplied-pmid 28456088?><pub-id pub-id-type="pmid">28456088</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref079">
                <label>79</label>
                <mixed-citation publication-type="journal"><name><surname>Bergelson</surname><given-names>E</given-names></name>, <name><surname>Swingley</surname><given-names>D</given-names></name>. <article-title>Early Word Comprehension in Infants: Replication and Extension</article-title>. <source>Language learning and development: the official journal of the Society for Language Development</source>. <year>2015</year>;<volume>11</volume>(<issue>4</issue>):<fpage>369</fpage>–<lpage>80</lpage>. <pub-id pub-id-type="doi">10.1080/15475441.2014.979387</pub-id>
<?supplied-pmid 26664329?><pub-id pub-id-type="pmid">26664329</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref080">
                <label>80</label>
                <mixed-citation publication-type="journal"><name><surname>Bergelson</surname><given-names>E</given-names></name>, <name><surname>Swingley</surname><given-names>D</given-names></name>. <article-title>At 6–9 months, human infants know the meanings of many common nouns</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2012</year>;<volume>109</volume>(<issue>9</issue>):<fpage>3253</fpage>–<lpage>8</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1113380109</pub-id>
<?supplied-pmid 22331874?><pub-id pub-id-type="pmid">22331874</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref081">
                <label>81</label>
                <mixed-citation publication-type="journal"><name><surname>Ito</surname><given-names>TA</given-names></name>, <name><surname>Larsen</surname><given-names>JT</given-names></name>, <name><surname>Smith</surname><given-names>NK</given-names></name>, <name><surname>Cacioppo</surname><given-names>JT</given-names></name>. <article-title>Negative information weighs more heavily on the brain: The negativity bias in evaluative categorizations</article-title>. <source>J Pers Soc Psychol</source>. <year>1998</year>;<volume>75</volume>(<issue>4</issue>):<fpage>887</fpage>–<lpage>900</lpage>. <pub-id pub-id-type="doi">10.1037//0022-3514.75.4.887</pub-id> WOS:000076933200004. <?supplied-pmid 9825526?><pub-id pub-id-type="pmid">9825526</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref082">
                <label>82</label>
                <mixed-citation publication-type="journal"><name><surname>Schupp</surname><given-names>HT</given-names></name>, <name><surname>Ohman</surname><given-names>A</given-names></name>, <name><surname>Junghofer</surname><given-names>M</given-names></name>, <name><surname>Weike</surname><given-names>AI</given-names></name>, <name><surname>Stockburger</surname><given-names>J</given-names></name>, <name><surname>Hamm</surname><given-names>AO</given-names></name>. <article-title>The facilitated processing of threatening faces: An ERP analysis</article-title>. <source>Emotion</source>. <year>2004</year>;<volume>4</volume>(<issue>2</issue>):<fpage>189</fpage>–<lpage>200</lpage>. <pub-id pub-id-type="doi">10.1037/1528-3542.4.2.189</pub-id> WOS:000224030500009. <?supplied-pmid 15222855?><pub-id pub-id-type="pmid">15222855</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref083">
                <label>83</label>
                <mixed-citation publication-type="journal"><name><surname>Stifter</surname><given-names>CA</given-names></name>, <name><surname>Fox</surname><given-names>NA</given-names></name>. <article-title>Preschool children's ability to identify and label emotions</article-title>. <source>J Nonverbal Behav</source>. <year>1987</year>;<volume>11</volume>(<issue>1</issue>):<fpage>43</fpage>–<lpage>54</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0212205.ref084">
                <label>84</label>
                <mixed-citation publication-type="journal"><name><surname>McClure</surname><given-names>EB</given-names></name>. <article-title>A meta-analytic review of sex differences in facial expression processing and their development in infants, children, and adolescents</article-title>. <source>Psychol Bull</source>. <year>2000</year>;<volume>126</volume>(<issue>3</issue>):<fpage>424</fpage><?supplied-pmid 10825784?><pub-id pub-id-type="pmid">10825784</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref085">
                <label>85</label>
                <mixed-citation publication-type="journal"><name><surname>Lausen</surname><given-names>A</given-names></name>, <name><surname>Schacht</surname><given-names>A</given-names></name>. <article-title>Gender Differences in the Recognition of Vocal Emotions</article-title>. <source>Front Psychol</source>. <year>2018</year>;<volume>9</volume>:<fpage>882</fpage><pub-id pub-id-type="doi">10.3389/fpsyg.2018.00882</pub-id><?supplied-pmid 29922202?><pub-id pub-id-type="pmid">29922202</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref086">
                <label>86</label>
                <mixed-citation publication-type="journal"><name><surname>Schirmer</surname><given-names>A</given-names></name>, <name><surname>Kotz</surname><given-names>SA</given-names></name>. <article-title>Beyond the right hemisphere: brain mechanisms mediating vocal emotional processing</article-title>. <source>Trends Cogn Sci</source>. <year>2006</year>;<volume>10</volume>(<issue>1</issue>):<fpage>24</fpage>–<lpage>30</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2005.11.009</pub-id> WOS:000234910400008. <?supplied-pmid 16321562?><pub-id pub-id-type="pmid">16321562</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0212205.ref087">
                <label>87</label>
                <mixed-citation publication-type="journal"><name><surname>Elsabbagh</surname><given-names>M</given-names></name>, <name><surname>Johnson</surname><given-names>MH</given-names></name>. <article-title>Infancy and autism: progress, prospects, and challenges</article-title>. <source>From Action to Cognition</source>. <year>2007</year>;<volume>164</volume>:<fpage>355</fpage>–<lpage>83</lpage>. <pub-id pub-id-type="doi">10.1016/S0079-6123(07)64020-5</pub-id> WOS:000252019900020.</mixed-citation>
              </ref>
            </ref-list>
          </back>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
