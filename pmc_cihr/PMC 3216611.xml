<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2024-05-03T08:57:12Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:3216611" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:3216611</identifier>
        <datestamp>2011-12-22</datestamp>
        <setSpec>scirep</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" article-type="research-article">
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">Sci Rep</journal-id>
              <journal-title-group>
                <journal-title>Scientific Reports</journal-title>
              </journal-title-group>
              <issn pub-type="epub">2045-2322</issn>
              <publisher>
                <publisher-name>Nature Publishing Group</publisher-name>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC3216611</article-id>
              <article-id pub-id-type="pmcid">PMC3216611</article-id>
              <article-id pub-id-type="pmc-uid">3216611</article-id>
              <article-id pub-id-type="pmid">22355647</article-id>
              <article-id pub-id-type="pii">srep00130</article-id>
              <article-id pub-id-type="doi">10.1038/srep00130</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Article</subject>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>Bringing the real world into the fMRI scanner: Repetition effects for pictures versus real objects</article-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author">
                  <name>
                    <surname>Snow</surname>
                    <given-names>Jacqueline C.</given-names>
                  </name>
                  <xref ref-type="corresp" rid="c1">a</xref>
                  <xref ref-type="aff" rid="a1">1</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Pettypiece</surname>
                    <given-names>Charles E.</given-names>
                  </name>
                  <xref ref-type="aff" rid="a2">2</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>McAdam</surname>
                    <given-names>Teresa D.</given-names>
                  </name>
                  <xref ref-type="aff" rid="a2">2</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>McLean</surname>
                    <given-names>Adam D.</given-names>
                  </name>
                  <xref ref-type="aff" rid="a1">1</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Stroman</surname>
                    <given-names>Patrick W.</given-names>
                  </name>
                  <xref ref-type="aff" rid="a3">3</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Goodale</surname>
                    <given-names>Melvyn A.</given-names>
                  </name>
                  <xref ref-type="aff" rid="a1">1</xref>
                  <xref ref-type="aff" rid="a2">2</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Culham</surname>
                    <given-names>Jody C.</given-names>
                  </name>
                  <xref ref-type="aff" rid="a1">1</xref>
                  <xref ref-type="aff" rid="a2">2</xref>
                </contrib>
                <aff id="a1"><label>1</label><institution>Department of Psychology, The University of Western Ontario</institution>, London, ON, <country>Canada</country>. N6A 5C2</aff>
                <aff id="a2"><label>2</label><institution>Graduate Program in Neuroscience, The University of Western Ontario</institution>, London, ON, <country>Canada</country>. N6A 5K8</aff>
                <aff id="a3"><label>3</label><institution>Centre for Neuroscience Studies, Queen's University</institution>, 18 Stuart St., Kingston, Ontario, <country>Canada</country>. K7L 3N6</aff>
              </contrib-group>
              <author-notes>
                <corresp id="c1">
                  <label>a</label>
                  <email>jacqueline.c.snow@gmail.com</email>
                </corresp>
              </author-notes>
              <pub-date pub-type="epub">
                <day>26</day>
                <month>10</month>
                <year>2011</year>
              </pub-date>
              <pub-date pub-type="collection">
                <year>2011</year>
              </pub-date>
              <volume>1</volume>
              <elocation-id>130</elocation-id>
              <history>
                <date date-type="received">
                  <day>20</day>
                  <month>05</month>
                  <year>2011</year>
                </date>
                <date date-type="accepted">
                  <day>05</day>
                  <month>10</month>
                  <year>2011</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>Copyright © 2011, Macmillan Publishers Limited. All rights reserved</copyright-statement>
                <copyright-year>2011</copyright-year>
                <copyright-holder>Macmillan Publishers Limited. All rights reserved</copyright-holder>
                <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by-nc-sa/3.0/">
                  <!--author-paid-->
                  <license-p>This work is licensed under a Creative Commons Attribution-NonCommercial-ShareALike 3.0 Unported License. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc-sa/3.0/">http://creativecommons.org/licenses/by-nc-sa/3.0/</ext-link></license-p>
                </license>
              </permissions>
              <abstract>
                <p>Our understanding of the neural underpinnings of perception is largely built upon studies employing 2-dimensional (2D) planar images. Here we used slow event-related functional imaging in humans to examine whether neural populations show a characteristic repetition-related change in haemodynamic response for real-world 3-dimensional (3D) objects, an effect commonly observed using 2D images. As expected, trials involving 2D pictures of objects produced robust repetition effects within classic object-selective cortical regions along the ventral and dorsal visual processing streams. Surprisingly, however, repetition effects were weak, if not absent on trials involving the 3D objects. These results suggest that the neural mechanisms involved in processing real objects may therefore be distinct from those that arise when we encounter a 2D representation of the same items. These preliminary results suggest the need for further research with ecologically valid stimuli in other imaging designs to broaden our understanding of the neural mechanisms underlying human vision.</p>
              </abstract>
            </article-meta>
          </front>
          <body>
            <p>Almost all functional magnetic resonance imaging (fMRI) studies that have examined the human neural substrates of object processing have utilized 2-dimensional (2D) pictures of objects. Although pictures are ubiquitous in everyday life, we interact with real 3-dimensional (3D) objects far more often than 2D representations. Moreover, we have little difficulty in distinguishing between the two. Numerous cortical areas have been identified in the perception of object shape but the neural mechanisms involved in the perception of real 3D objects have received scant investigation with fMRI. In this study we ‘bring the real world into the scanner' to examine whether the large body of evidence pertaining to human neural processing of pictorial stimuli is applicable also to real-world objects.</p>
            <p>The processing of object shape in humans is broadly distributed across a number of cortical areas spanning both the dorsal and ventral visual pathways. Most notably, object-selective neural populations have been identified within the ventral stream along a swathe of inferior temporal cortex known as lateral occipital complex (LOC)<xref ref-type="bibr" rid="b1">1</xref><xref ref-type="bibr" rid="b2">2</xref>. The LOC is dedicated to processing object shape independent of the low-level image features that define the shape. Area LOC produces robust responses to objects depicted in a range of formats including greyscale images, line drawings, silhouettes, shapes defined by motion or textures, or when the percept of form is induced by an illusory contour<xref ref-type="bibr" rid="b3">3</xref>. Additional object-selective regions have also been identified within the ‘dorsal' processing stream particularly along the intraparietal sulcus (IPS)<xref ref-type="bibr" rid="b3">3</xref><xref ref-type="bibr" rid="b4">4</xref><xref ref-type="bibr" rid="b5">5</xref><xref ref-type="bibr" rid="b6">6</xref>.</p>
            <p>Beyond simple fMRI subtraction designs, neural coding within object-selective cortex has been further investigated using comparisons between repeated vs. unrepeated objects<xref ref-type="bibr" rid="b7">7</xref><xref ref-type="bibr" rid="b8">8</xref><xref ref-type="bibr" rid="b9">9</xref><xref ref-type="bibr" rid="b10">10</xref><xref ref-type="bibr" rid="b11">11</xref>. The characteristic reduction in haemodynamic response with stimulus repetition has been variously referred to as ‘fMR adaptation' (fMR-A)<xref ref-type="bibr" rid="b7">7</xref><xref ref-type="bibr" rid="b12">12</xref><xref ref-type="bibr" rid="b13">13</xref>, or ‘repetition suppression'<xref ref-type="bibr" rid="b14">14</xref><xref ref-type="bibr" rid="b15">15</xref>. fMR-A is a robust effect that is a putative analogue of a similar effect seen in nonhuman primates in which neurons within infero-temporal cortex show reduced firing rates as a result of stimulus repetition<xref ref-type="bibr" rid="b16">16</xref><xref ref-type="bibr" rid="b17">17</xref>. Repetition designs have become a popular methodological approach that contrast with standard mapping techniques in their ability to probe neural selectivity in higher-order visual areas at a sub-voxel scale beyond that of traditional fMRI designs<xref ref-type="bibr" rid="b12">12</xref><xref ref-type="bibr" rid="b15">15</xref><xref ref-type="bibr" rid="b18">18</xref>. In the field of object perception, repetition designs have perhaps most commonly been used to determine whether object-selective neural populations are response invariant to image transformations such as changes in viewpoint, size or illumination<xref ref-type="bibr" rid="b4">4</xref><xref ref-type="bibr" rid="b7">7</xref>.</p>
            <p>Repetition effects have been observed in human object-selective cortex with a variety of 2D image types. These include simplified monochrome shapes<xref ref-type="bibr" rid="b4">4</xref>, silhouettes<xref ref-type="bibr" rid="b19">19</xref> and line drawings that convey object structure via contours<xref ref-type="bibr" rid="b5">5</xref><xref ref-type="bibr" rid="b7">7</xref> or integrated elements<xref ref-type="bibr" rid="b20">20</xref><xref ref-type="bibr" rid="b21">21</xref>. Repetition effects have also been demonstrated with ‘richer' stimuli such as greyscale photographs or other detailed images that provide more information about an object's 3D characteristics via shading and texture<xref ref-type="bibr" rid="b4">4</xref><xref ref-type="bibr" rid="b7">7</xref><xref ref-type="bibr" rid="b10">10</xref><xref ref-type="bibr" rid="b22">22</xref><xref ref-type="bibr" rid="b23">23</xref><xref ref-type="bibr" rid="b24">24</xref>, or that induce the percept of depth so that they appear to lie in front of the fixation plane<xref ref-type="bibr" rid="b19">19</xref><xref ref-type="bibr" rid="b25">25</xref>.</p>
            <p>While this approach has been highly fruitful, we wondered how well this large body of results would generalize to realistic 3D objects. The choice of 2D stimuli to study object recognition has been largely one of convenience and experimental control. The presentation of 2D images simply requires projection of the images onto a flat screen viewed through a mirror by the participant who can lie comfortably in the supine position; moreover, the control of image parameters (e.g., size, depth, timing) is straightforward. Many additional challenges arise in the presentation of real world 3D stimuli; however, many of these problems have been solved in fMRI research on grasping and reaching where 3D objects are required to elicit normal object-directed actions<xref ref-type="bibr" rid="b26">26</xref><xref ref-type="bibr" rid="b27">27</xref><xref ref-type="bibr" rid="b28">28</xref>. Such approaches involve tilting of the head and head coil to enable direct viewing of real 3D objects within reachable space (<xref ref-type="fig" rid="f1">Figure 1a</xref>). These configurations offer realistic presentations of objects in which (a) all binocular and monocular depth cues are consistent, (b) retinal size, viewing distance and expected size are consistent, and (c) the location within reachable space means that objects may afford real actions such as manipulation<xref ref-type="bibr" rid="b29">29</xref>. Given these differences, we investigated whether the effects obtained with 2D images would be corroborated in a richer, more realistic context.</p>
            <p>Here we used an fMR repetition paradigm to examine both the overall level of activation and repetition-based effects in the context of real-world 3D objects compared to 2D pictures. We expected clear activation and repetition effects within the ventral and dorsal stream areas identified across prior studies for both stimulus classes. However, the main question was how similar these effects would be for 3D objects. We anticipated that the overall level of activation as well as the strength of repetition effects for the richer, real-world 3D objects would be at least equal to, if not greater than, those for 2D pictures, particularly within the dorsal stream<xref ref-type="bibr" rid="b30">30</xref>. Neurophysiology research has characterized several areas within the macaque dorsal stream with 3D object-selective responses, including the anterior intraparietal area (AIP)<xref ref-type="bibr" rid="b31">31</xref><xref ref-type="bibr" rid="b32">32</xref><xref ref-type="bibr" rid="b33">33</xref><xref ref-type="bibr" rid="b34">34</xref>, lateral intraparietal area (LIP)<xref ref-type="bibr" rid="b35">35</xref>, and caudal intraparietal sulcus (cIPS)<xref ref-type="bibr" rid="b36">36</xref>, areas for which human homologues have been proposed<xref ref-type="bibr" rid="b37">37</xref>. These areas are postulated to be involved in the extraction of 3D shape for visuomotor transformations associated with the control of action<xref ref-type="bibr" rid="b38">38</xref>. Given that human dorsal stream areas show fMR-A with repeated 2D object images<xref ref-type="bibr" rid="b4">4</xref><xref ref-type="bibr" rid="b5">5</xref>, and respond strongly to 3D objects<xref ref-type="bibr" rid="b39">39</xref>, such areas may be expected to show larger responses and stronger repetition effects in the context of real-world objects.</p>
            <sec disp-level="1">
              <title>Results</title>
              <p>We investigated neural object representations associated with 2D pictures and real 3D stimuli within known object selective areas of human cortex. Previous fMR-A paradigms have reported robust repetition effects within the LOC when comparing repeated versus different 2D object images. Here we asked whether real 3D objects elicit a similar pattern. A slow event-related fMR-adaptation design (<xref ref-type="fig" rid="f1">Figure 1c</xref>) was employed in which two objects appeared sequentially on each trial. Blood-oxygen-level dependent (BOLD) responses were compared across trials in which paired objects had the same identity (‘Repeat' condition) versus trials where they were not the same (‘Different' condition). Repetition effects were measured across two classes of stimuli: real-world 3D objects and 2D colour photographs of the same objects (<xref ref-type="fig" rid="f1">Figure 1a,b</xref>) that were matched in all possible respects for size, distance, viewpoint, and illumination. We examined repetition effects across the whole brain, and within independently defined sub-regions of object-selective LOC.</p>
              <sec disp-level="2">
                <title>Region of interest (ROI) analyses</title>
                <p>Because of the wealth of past studies showing object selectivity and fMR repetition effects for object images in LOC, our initial analyses utilized a region of interest (ROI) approach to identify LOC within individuals based on an independent localizer run and then extract its pattern of activation from separate experimental runs. LOC was localized by contrasting epochs containing pictures of objects and shapes with those of their scrambled counterparts (see <bold>Methods</bold>). In accordance with early studies that reported fMR-A effects using 2D stimuli<xref ref-type="bibr" rid="b7">7</xref><xref ref-type="bibr" rid="b19">19</xref>, we searched within two sub-divisions of LOC: an anterior-ventral portion in the posterior fusiform sulcus (pFS), and a posterior-dorsal portion of LOC (LO). Based on previous findings we anticipated that on Different trials where object identity changes BOLD responses should be maximal, whereas on Repeat trials, where paired objects shared the same identity, the BOLD response should be comparatively attenuated. Importantly, we anticipated that the pattern of repetition effects would be similar for 2D and 3D stimuli (if not greater in magnitude for real 3D objects).</p>
                <p>To validate our design and procedure, fMRI signals were first compared on event-related trials involving 2D pictures. Time courses of fMRI signals on Different versus Repeat trials involving pictures are displayed in <xref ref-type="fig" rid="f2">Figure 2</xref>, for LO and pFS (left upper and lower panels, respectively). To quantify repetition effects and compare them across the different stimulus types, we used an adaptation index (AI) which estimates response difference between Repeat and Different conditions relative to the overall fMRI response to a given stimulus<xref ref-type="bibr" rid="b4">4</xref>. Positive index values reflect higher responses on Different than Repeat trials; negative values indicate the reverse pattern and values around zero indicate a lack of repetition effects. AIs were calculated using mean activation (β coefficients) in the Different versus Repeat conditions for each stimulus type, and the magnitude of repetition effects contrasted using a one-sample t-test against zero and paired-samples t-tests.</p>
                <p><xref ref-type="fig" rid="f3">Figure 3</xref> plots the AIs for 2D pictures and 3D objects in LO and pFS. To provide meaningful data interpretation in a within-subjects design<xref ref-type="bibr" rid="b40">40</xref><xref ref-type="bibr" rid="b41">41</xref> error bars in <xref ref-type="fig" rid="f3">Figure 3</xref> represent 95% confidence interval (CI) of the difference from zero. Robust repetition effects for 2D pictures was observed within both LO (t(12)  =  3.68, p = 0.003) and pFS (t(12)  = 5.38, p &lt;0.0001) sub-regions of LOC. These findings replicate those of previous studies<xref ref-type="bibr" rid="b4">4</xref><xref ref-type="bibr" rid="b5">5</xref><xref ref-type="bibr" rid="b7">7</xref><xref ref-type="bibr" rid="b10">10</xref><xref ref-type="bibr" rid="b12">12</xref> and confirm that our design and stimuli were sufficiently sensitive to demonstrate repetition effects.</p>
                <p>Next we examined whether similar effects would be observed on 3D object trials that were randomly intermixed with 2D picture trials. Time courses of fMRI signals for 3D objects on Different versus Repeat trials within LO and pFS are displayed in <xref ref-type="fig" rid="f2">Figure 2</xref> (right upper and lower panels, respectively). Although a qualitatively small change in BOLD signal was evident in the time courses of the Repeat condition relative to the Different condition, the magnitude of this effect was qualitatively attenuated compared to that observed for 2D pictures. Planned comparisons confirmed that for 3D objects, repetition effects did not reach statistical significance in LO (t(12)  =  0.88, p  =  0.392). In pFS, repetition effects also did not reach statistical significance (t(12)  =  1.99, p  =  0.057), although there was a clear trend in this direction in this more anterior sub-portion of the LO complex. Finally, a paired-samples t-test contrasting the AIs for 2D versus 3D stimuli in each ROI revealed a trend toward significance between the AIs for 2D versus 3D stimuli in LO (t(12)  =  2.04, p  =  0.06), but no significant differences between AIs in pFS (t(12)  =  0.05, p  =  0.29).</p>
                <p>As an index of between-subject consistency the proportion of observers who showed greater fMRI BOLD response on Different versus Repeat trials was calculated for each stimulus type and ROI. The observed direction of β coefficients (e.g., a binary score reflecting Different &gt; Repeat, or Repeat &gt; Different) across all participants was compared to the distribution of scores to be expected by chance alone (e.g., a test of the null hypotheses that Different &gt; Repeat in 50% of subjects) using Pearson's chi-square test. For 2D picture trials, 12/13 subjects showed effects in the expected direction (i.e., Different &gt; Repeat) within LO (χ<sup>2</sup>  =  9.31, <italic>p</italic>&lt;0.005), and <italic>all</italic> subjects showed this pattern within pFS, indicating that the frequency of the pattern was not attributable to chance alone. Conversely, for 3D object trials fewer subjects showed effects in the expected direction. The observed proportions were not significantly above chance levels in LO (8/13 subjects; χ<sup>2</sup>  =  0.69, <italic>p</italic>&gt;0.40), or pFS (10/13 within pFS; χ<sup>2</sup>  =  3.77, <italic>p</italic>&gt;0.05), although there was a trend toward significance in pFS.</p>
                <p>In summary, we found robust repetition effects for repeated 2D pictures within both LO and pFS sub-regions of LOC, and this pattern was highly consistent across individuals. Surprisingly, however, repetition effects were attenuated for trials involving real 3D objects; we did not observe significant repetition effects within LO or pFS sub-regions of object-selective cortex. Furthermore, the direction of effects in Different versus Repeat conditions varied across subjects in both ROIs suggesting that changes in 3D object identity did not have a reliable influence on the BOLD response.</p>
              </sec>
              <sec disp-level="2">
                <title>Voxel-wise group analyses</title>
                <p>Group-based voxel-wise GLM analyses were subsequently performed to explore repetition effects at the whole-brain level, and specifically to determine whether there was evidence for repetition-based BOLD changes on 3D object trials outside of LOC. We first ran the contrast [+2D Different −2D Repeat] to identify regions showing significant repetition effects for 2D pictures (using a threshold of <italic>p</italic>&lt;0.005, cluster size threshold corrected). <xref ref-type="fig" rid="f4">Figure 4</xref> illustrates the group results displayed on the cortical surface of a representative participant. As expected, significant areas of activation were observed within established regions of object-selective cortex. Large bilateral clusters were observed along lateral and ventral occipito-temporal cortex, including fusiform, lingual, lateral occipital and inferior temporal regions. Similar activation was also evident within ‘dorsal stream object areas', extending from the expected location of anterior V3, dorsally into the intraparietal sulcus (IPS) anterior to the expected location of IPS-0<xref ref-type="bibr" rid="b42">42</xref>. In sharp contrast, an analogous comparison for 3D stimuli (using the contrast [+3D Different −3D Repeat] at the same <italic>p-</italic>value threshold) revealed no significant areas of positive activation, either cortically or sub-cortically (<xref ref-type="table" rid="t1">Table 1</xref>). In fact, the reverse contrast [+3D Repeat −3D Different] revealed several clusters of significant activation consistent with a pattern of ‘repetition enhancement' (i.e., greater BOLD response on Repeat than Different trials).</p>
                <p>We then searched for areas in which activation was significantly different for 2D than 3D stimuli (collapsed across Repeat and Different trials) using the contrasts [+2D−3D], and [+3D−2D] (<xref ref-type="table" rid="t1">Table 1</xref>). The comparison [+2D−3D] revealed two small clusters of positive activation: one cluster centered at the occipital pole (V1) of the RH calcarine sulcus, and another in the inferior temporal gyrus of the RH. The comparison [+3D−2D] revealed no positive activation. The representation of our 2D pictures and real-world 3D instances of the same objects therefore shared the same anatomical loci. Finally, any interaction between Stimulus Type and Repetition was examined using the contrasts (a): +3D Different −3D Repeat +2D Different +2D Repeat (i.e., greater repetition effects for 3D than 2D stimuli), and (b): +2D Different −2D Repeat −3D Different +3D Repeat (i.e., greater repetition effects for 2D than 3D stimuli). Brain areas showing greater repetition effects for 2D than 3D stimuli again included largely bilateral swathes of activation around the lingual and fusiform gyri and superior temporal sulci, as well as clusters in the left parieto-occipital fissure and middle frontal gyrus of the RH. The reverse interaction contrast (i.e., greater repetition effects for 3D than 2D stimuli) revealed no positive activation clusters.</p>
              </sec>
              <sec disp-level="2">
                <title>Comparisons with Foci from Prior Studies</title>
                <p>Finally, we sampled group activation within a number of additional ROIs that correspond to areas previously implicated in 3D form processing<xref ref-type="bibr" rid="b4">4</xref><xref ref-type="bibr" rid="b39">39</xref><xref ref-type="bibr" rid="b43">43</xref> (see <xref ref-type="fig" rid="f5">Figure 5</xref>). Across a total of 14 ROIs spanning early visual, temporal, and parietal cortex, we found significant 3D repetition effects in just two areas; one roughly corresponding to V3A, and another within left-sided ‘LOtv' – a putative visuo-tactile ‘multimodal' sub-component of the LO complex situated along the ventro-lateral bank of the temporal lobe<xref ref-type="bibr" rid="b43">43</xref>. In contrast, significant (or close to significant) 2D repetition effects were found in almost all of the additional ROIs (see <bold><xref ref-type="supplementary-material" rid="s1">Supplementary Table 1</xref></bold>).</p>
              </sec>
            </sec>
            <sec disp-level="1">
              <title>Discussion</title>
              <p>Here we used slow event-related fMRI to contrast repetition-related changes in fMRI responses to 2D pictures of objects with real-world 3D exemplars. Whereas presentation of 2D pictures elicited strong repetition-related changes in the BOLD response, the same effect was surprisingly weak, if not absent, in the context of real-world 3D objects. We searched for repetition effects within discrete regions of object-selective cortex and across the whole brain. Contrary to our expectations, manipulating 3D object identity (using Repeated versus Different objects) did not produce a significant change in BOLD response within LOC. Further, within this area there was marked variability across participants in the relative magnitude of the BOLD response in Repeat versus Different 3D object conditions. Indeed, within area LO individual participants were just as likely to show a stronger BOLD response on Repeat object-identity trials for 3D objects than on Different trials for 3D objects – a pattern sometimes labeled as ‘repetition enhancement'<xref ref-type="bibr" rid="b2">2</xref><xref ref-type="bibr" rid="b7">7</xref><xref ref-type="bibr" rid="b22">22</xref><xref ref-type="bibr" rid="b24">24</xref><xref ref-type="bibr" rid="b44">44</xref><xref ref-type="bibr" rid="b45">45</xref><xref ref-type="bibr" rid="b46">46</xref><xref ref-type="bibr" rid="b47">47</xref>. In line with these results, an analysis of group effects at the whole brain level also revealed no evidence of fMR-repetition effects on 3D object trials.</p>
              <p>The results for real-world 3D objects contrast sharply with those for 2D object images. In line with previous reports, participants in our study showed robust fMRI repetition-based changes on randomly interleaved trials that involved 2D pictures. In the ROI analyses, significant 2D repetition effects were observed within both LO and pFS sub-regions of LOC, and BOLD response patterns were highly consistent across observers. Accordingly, whole-brain analyses revealed robust repetition effects for 2D objects that spread anteriorly and bilaterally along classical ventral stream object-selective cortex and dorsally along putative object-selective cortex in the vicinity of the IPS. Finally, we found evidence for 2D repetition effects within a number of additional ROIs that correspond to areas previously implicated in 3D form processing<xref ref-type="bibr" rid="b4">4</xref><xref ref-type="bibr" rid="b39">39</xref><xref ref-type="bibr" rid="b43">43</xref>. The same pattern was not observed for 3D stimuli.</p>
              <p>Whole brain analyses confirmed that activation patterns were strikingly similar for our 2D pictures and 3D object trials, confirming that our stimulus sets were matched for low-level properties (including illumination, size, colour and viewpoint). We further quantified repetition effects using an adaptation index to account for possible underlying differences in responsivity across different brain areas to our paired 2D and 3D stimulus events<xref ref-type="bibr" rid="b4">4</xref>. The effect we observed for 2D vs. 3D stimulus classes is unlikely to be attributable to differences in eye movement patterns or shifts of attention. Our tilted-head setup precluded the use of an eye-tracker; however, all participants reported that they were able to easily discriminate all stimuli while maintaining their gaze on the fixation point. Moreover, no activation differences between 2D and 3D objects were found in eye-movement- and attention-related areas, such as the frontal eye fields or parietal cortex<xref ref-type="bibr" rid="b48">48</xref><xref ref-type="bibr" rid="b49">49</xref><xref ref-type="bibr" rid="b50">50</xref>. Further, given that participants merely passively viewed the stimuli, differences in task-related attentional demands were also unlikely. It is possible that observers found the 3D objects “more interesting” than their 2D counterparts. If that were the case, however, then one would have expected to see greater activation in LOC and other object-related areas with 3D as opposed to 2D and amplified repetition effects for 3D compared to 2D stimuli<xref ref-type="bibr" rid="b51">51</xref><xref ref-type="bibr" rid="b52">52</xref>. But we found exactly the opposite.</p>
              <p>Given that explanations based on attention or eye-movements are unlikely, our results may reflect differences in the way real world 3D objects are processed as compared to 2D pictures. Real objects differ from pictures in several important respects: (a) they possess additional shape information from stereoscopic cues such as vergence and disparity, (b) both monocular and binocular cues to object shape are consistent for real objects, and (c) 3D objects are tangible substances that exist in the environment. The possible contribution of each of these differences between pictures and real objects to our observed findings is considered in turn below.</p>
              <p>Given that real objects possess additional shape information from stereoscopic cues compared to pictures, this raises the question of whether or not the same pattern observed for real objects would arise with objects defined by stereopsis alone (i.e. stereograms) where the percept of 3-dimensionality arises entirely from binocular disparity. Neurophysiological studies have identified neurons that are sensitive to shapes defined by binocular disparity within early visual areas<xref ref-type="bibr" rid="b53">53</xref><xref ref-type="bibr" rid="b54">54</xref><xref ref-type="bibr" rid="b55">55</xref><xref ref-type="bibr" rid="b56">56</xref><xref ref-type="bibr" rid="b57">57</xref><xref ref-type="bibr" rid="b58">58</xref><xref ref-type="bibr" rid="b59">59</xref>, dorsal areas such as MT and parietal cortex<xref ref-type="bibr" rid="b60">60</xref><xref ref-type="bibr" rid="b61">61</xref><xref ref-type="bibr" rid="b62">62</xref><xref ref-type="bibr" rid="b63">63</xref><xref ref-type="bibr" rid="b64">64</xref><xref ref-type="bibr" rid="b65">65</xref>, and in the inferior temporal cortex<xref ref-type="bibr" rid="b66">66</xref><xref ref-type="bibr" rid="b67">67</xref><xref ref-type="bibr" rid="b68">68</xref><xref ref-type="bibr" rid="b69">69</xref><xref ref-type="bibr" rid="b70">70</xref><xref ref-type="bibr" rid="b71">71</xref><xref ref-type="bibr" rid="b72">72</xref><xref ref-type="bibr" rid="b73">73</xref>. To our knowledge, no human fMRI studies to date have directly compared repetition effects for stereo versus real-world 3D objects, or stereo displays involving objects with 3D structure. Kourtzi and Kanwisher<xref ref-type="bibr" rid="b25">25</xref>, used stereo displays involving planar shapes to show that responses within LOC were identical despite changes in the stereoscopic depth of the shape. Similarly, Kourtzi et al.,<xref ref-type="bibr" rid="b19">19</xref> found equivalent BOLD responses on trials depicting identical silhouette shapes and trials where a 2D silhouette was followed by a stereo silhouette image (so that the shape appeared to lie in front of the fixation plane). These findings imply that object shape is processed similarly within LOC, whether the shape is depicted in a purely 2D format or with additional stereo cues. Importantly, however, the stimulus objects in these studies had no 3D structure; the stimuli simply defined figure from ground and provided information about the outer contours of the shape (i.e., first-order stereo). Unlike real objects, they contained no information about intrinsic curvature or shape (i.e., second-order stereo). Therefore, it remains an open question as to whether the effects observed here for real world objects would also emerge with stereo displays with objects that possess different second-order shape cues.</p>
              <p>Another important difference between pictures and real objects is that the binocular and monocular cues to object shape are completely consistent for 3D objects but are in conflict for 2D pictures. Looking at a picture, binocular cues indicate that it is completely flat whereas monocular cues such as shading, texture gradients, occlusion, specular highlights, and other pictorial cues signify a 3D representation. It is possible that classical repetition and release effects typically observed in picture viewing may be attributable to processes associated with resolving such depth cue conflict. For example, the additional processing required to decipher object identity from 2D pictures as a result of cue conflict could result in a higher fMR response (release from adaptation) on ‘Different' 2D trials. Further, the similarity in stereo information conveyed by pictures may result in stereo cues being discounted in the analysis of object shape, and other pictorial cues weighted more highly. Given that some pictorial cues can be more effective than others in conveying object shape for particular objects, these differences in the cues that are used across trials would result in greater release from adaptation on ‘different' trials, because different sets of neurons, each tuned to particular pictorial cues, would be engaged in each case. In contrast, because binocular cues like stereo are such powerful indicators of object shape in the case of 3D objects (which may therefore be weighted more highly in the analysis of object shape), the same set of stereo-sensitive neurons that analysis object shape would be engaged – even for different objects.</p>
              <p>Finally, our preliminary fMRI results raise the provocative suggestion that the presence of real-world objects (i.e., as indicated initially via stereoscopic cues) invokes qualitatively different computations to those elicited by 2D images. Researchers in the field of behavioral psychophysics have expressed long-standing concern about the extent to which pictures of objects capture the properties of their real-world counterparts (i.e., their ecological validity), with reservations as to their appropriateness as stimuli with which to examine the nature of human object perception<xref ref-type="bibr" rid="b74">74</xref><xref ref-type="bibr" rid="b75">75</xref>. Indeed, there are clear differences between pictures and objects that suggest some degree of caution in assuming equal neuronal response patterns between the two stimulus classes. Whereas images consist merely of patterns of light arising from a 2D projection surface, real objects are tangible substances that exist in 3D space with a definite texture, reflectance, colour and shape. Real objects, unlike pictures, have an unambiguous size, distance, and location relative to the observer – factors that are known to alter single unit responses in macaque inferior temporal cortex<xref ref-type="bibr" rid="b76">76</xref>. Moreover, as discussed earlier all the cues to depth structure, both binocular and monocular, are congruent for 3D objects. Finally, real objects have properties that relate specifically to the motives and needs of the observer – that is, they provide affordances<xref ref-type="bibr" rid="b74">74</xref>. An object placed within arm's length affords reaching, grasping, and manipulation. Indeed, fMRI studies demonstrate that information about 3D form is critical for the visual control of grasping and manipulation<xref ref-type="bibr" rid="b26">26</xref><xref ref-type="bibr" rid="b29">29</xref>.</p>
              <p>Although comparatively few research studies have been carried out with real-world objects than with 2D images in humans, numerous findings point to the possibility that real objects are cognitively distinct from their 2D counterparts. For example, patients with visual agnosia often show a ‘real object advantage' in which identification of objects depicted as line-drawings or silhouettes is impaired while recognition performance for real objects remains intact<xref ref-type="bibr" rid="b77">77</xref><xref ref-type="bibr" rid="b78">78</xref><xref ref-type="bibr" rid="b79">79</xref><xref ref-type="bibr" rid="b80">80</xref><xref ref-type="bibr" rid="b81">81</xref>. Similarly, in healthy observers, the value applied to objects is affected by the format in which they are viewed. For example, Bushong et al.,<xref ref-type="bibr" rid="b82">82</xref> gave university students a small monetary endowment that could be used to purchase a range of test objects (i.e., food or trinkets). The test items were depicted in one of three formats: text displays, high-resolution images, or actual real-world objects. Surprisingly, students were willing to pay between 40–61% more for objects they viewed as real-world exemplars over the same items depicted in text format or image displays. Moreover, this effect went away when the objects were placed behind a transparent barrier, suggesting that the effect was driven by the potential for interaction with the objects.</p>
              <p>In summary, relative to previous research using 2D pictures<xref ref-type="bibr" rid="b5">5</xref><xref ref-type="bibr" rid="b25">25</xref><xref ref-type="bibr" rid="b83">83</xref>, our findings indicate that the neural analysis of 3D objects may not fit within the classically defined pattern, and that adaptation and corresponding release effects may not be an obligatory consequence of object repetition manipulations<xref ref-type="bibr" rid="b13">13</xref>. Our results further suggest that the analysis and/or representation of object structure does not proceed independently of the cues that define the object – in this case, when the term ‘object' is extended to include actual real-world exemplars. The neural mechanisms involved in the perception of real-world 3D objects may therefore be distinct from those that arise when we encounter a 2D planar representation of the very same items. Furthermore, such processes may also change with environmental context – such as whether an object is located within reachable space<xref ref-type="bibr" rid="b29">29</xref>. We have highlighted a number of possible routes for future investigation to further elucidate the cognitive and neural mechanisms responsible for the pattern of repetition effects reported here for 2D versus 3D objects. As we have argued, many of the simpler explanations seem unlikely (eye movements, attention), leaving the possibility of inherent differences in the processing of real objects vs. photographs. Whether the invariant neural response we observed for real-world 3D objects is attributable to the additional depth cues provided by binocular vision or the physical presence of the objects, the important finding here is that the underlying response pattern is different from that observed in the context of 2D planar images. Although many fMRI studies have used repetition designs to probe neural sensitivity to different types of stimuli, the computational mechanisms that underlie this effect are not fully understood<xref ref-type="bibr" rid="b84">84</xref><xref ref-type="bibr" rid="b85">85</xref><xref ref-type="bibr" rid="b86">86</xref><xref ref-type="bibr" rid="b87">87</xref><xref ref-type="bibr" rid="b88">88</xref><xref ref-type="bibr" rid="b89">89</xref>. Regardless of which particular mechanisms account for repetition effects, however, there is no doubt that differential adaptation effects for 2D pictures and 3D objects reflect differences in neuronal processing and interactions.</p>
              <p>Due to the technical challenges associated with presenting real world objects within the scanner, we used a slow event-related design. It is possible that the different pattern of repetition effects reported here for 2D versus 3D stimuli are specific to the temporal dynamics of our stimulus presentation. Similarly, the paired adaptation paradigm used in the present study may have a small dynamic range and in the presence of noise, small but nevertheless significant repetition effects may be missed. An important question for future investigation therefore is whether or not the patterns observed here also emerge in the context of different stimulus durations or alternative fMRI designs, such as blocked or rapid event-related designs with more repetitions that yield stronger repetition effects. In any case, if the statistical power of the present design were to be increased, then it is likely that the differences that we have already observed between 2D and 3D stimuli would be amplified rather than reduced.</p>
              <p>Our ability to perceive real 3D objects from patterns of light that project on the retina remains one of the most remarkable and yet perplexing aspects of human vision. Yet our understanding of the neural substrate of perception is largely based upon studies that have utilized 2D images. The conventional use of 2D images in fMRI research, in particular, may pose underestimated limits to our understanding of the neural underpinnings of human vision. The human visual system has largely evolved to perceive and interact with a 3-dimensional environment, rather than pictures. Surprisingly, however, there is a paucity of controlled published studies involving real objects, and fewer still that directly contrast behavioral or fMR measures across objects and images. We argue here that pictures might represent a limited class of stimuli with which to characterize the neural computations associated with human object recognition<xref ref-type="bibr" rid="b74">74</xref>. Our findings for real 3D objects suggest some caution in extrapolating experimental results based upon the presentation of abstract or simplified stimuli, or findings drawn from within artificial or constrained environments. Notwithstanding, these results provide an important first step in understanding how real-world stimuli are coded by the human brain and complement a growing body of research<xref ref-type="bibr" rid="b90">90</xref><xref ref-type="bibr" rid="b91">91</xref> emphasizing the importance of studying behavior in ecologically valid contexts.</p>
            </sec>
            <sec disp-level="1" sec-type="methods">
              <title>Methods</title>
              <sec disp-level="2">
                <title>Subjects</title>
                <p>Sixteen healthy observers with normal or corrected-to-normal vision participated in two scanning sessions, one for the fMR-A experiment, and one session for localizing LOC. The data from two subjects was removed due to excessive head movement (between 2 to &gt; 4mm translation or 2 to &gt;4 degrees of rotation). Data from an additional participant was eliminated due to technical problems with the LED illuminators. Informed consent was obtained in accordance with procedures approved by the University of Western Ontario's Health Sciences Review Ethics Board and of the Queen's University Human Research Ethics Board. All participants were naive with respect to the experimental hypothesis.</p>
              </sec>
              <sec disp-level="2">
                <title>Visual stimuli</title>
                <p>Stimuli for the fMR-A experiment comprised of a set of 30 easily recognizable real 3D objects and a corresponding set of 30 2D coloured photographs of the same objects (see <xref ref-type="fig" rid="f1">Figure 1(b)</xref>). Although it was not our intention to directly compare 2D-to-3D stimulus presentations within a given trial, the 2D photographs were nonetheless closely matched to the 3D objects in aspects of luminance, shading, position and orientation. Stimulus position and orientation were controlled using mountings beneath each stimulus that attached to the viewing platform. The rear side of each stimulus was fitted with a wooden pedestal block. The pedestal blocks fit into a concave holder attached to the viewing platform. On each trial stimuli were mounted on a black turntable placed over the participant's waist and fixed to the scanner bed (see <xref ref-type="fig" rid="f1">Figure 1(a)</xref>). The turntable had a central divider, yielding two semicircular platforms for stimulus presentation. The pedestal holders, one fixed to the midline of each semicircular platform, held the stimuli firmly in place and ensured identical viewing conditions within and between trials. The 2D stimuli were constructed by photographing each 3D object with a Sony Alpha DSLR-A100 camera (with flash) held on a tripod. Each object was photographed mounted on the viewing platform, with the platform fixed at a comparable angle and viewing distance to that used in the scanner. High resolution 2D colour images of each object were printed on matte paper and mounted upon card backing that was cut to match the outline of turntable divider. The paradigm and all object stimuli were pilot-tested in the scanner with an inert phantom to ensure that they did not produce any artifacts (i.e., from turntable movement or object transition).</p>
              </sec>
              <sec disp-level="2">
                <title>Procedure and design</title>
                <p>The main fMR-A experiment had a 2 × 2 design with the factors of Repetition (Repeat versus Different objects) and Stimulus Type (2D pictures versus 3D objects). In the 2D-Repeat condition, both pictures within the trial depicted the same object, while in the 2D-Different condition the two pictures depicted different object identities. In the 3D-Repeat condition both stimuli within the trial were the same real 3D object, while in the 3D-Different condition the objects presented within a trial had different identities. Each scan consisted of 20 trials, 5 trials for each of the four conditions. The order of conditions was counterbalanced so that trials from a given condition were preceded equally often by trials from each of the other conditions. The 60 stimuli were divided into 6 sets of 10 items, one set per scan (five 3D objects plus five matching 2D pictures). Each stimulus object exemplar appeared equally often in each of the four conditions, ensuring that activation differences were due to the relationship between the paired stimuli and not differences in the stimulus objects used in each condition. A new set of stimuli was used for each scan to prevent long-term adaptation. Participants each completed 5–6 scans (depending on time constraints) and the order of scans (object sets) was counterbalanced across subjects.</p>
                <p>The setup (<bold>see </bold><xref ref-type="fig" rid="f1">Figure 1(a)</xref>) enabled participants to directly view the stimuli without the need for a mirror. The experiment was conducted in complete darkness, except for a small red LED fixation light positioned in-front of the stimulus plane. The fixation point remained on throughout the entire scan but was too dim to illuminate the scene. Each trial lasted for 24 s. Picture or object stimuli were presented for 500 ms with a 3 s inter-stimulus interval (<xref ref-type="fig" rid="f1">Figure 1c</xref>). Stimulus duration was controlled by the onset of a white LED ‘illuminator light' positioned just above and in front of the turntable. A 20 s inter-trial interval (fixation only) followed each stimulus pair and served as the baseline against which to compare trial-related neural activity. An additional 10 s of fixation baseline were collected at the start of each scan, and 20 s at the end. Timing of stimulus illumination, fixation, and auditory events were controlled using E-Prime software.</p>
                <p>On each trial, stimuli were manually positioned in the turntable by the experimenter. The experimenter received an auditory cue via headphones as to which objects or pictures to mount on the turntable on upcoming trials. Small glow-in-the-dark shapes attached to the base of each pedestal block enabled the experimenter to locate the relevant stimulus items. An infra-red MR-compatible bore camera (MRC Systems GmbH) positioned just behind the participant's head was used to record the accuracy of the experimenter's stimulus presentations. Participants were instructed to observe and identify the objects presented on each trial, while maintaining their gaze at fixation throughout the entire experiment, including the stimulus events.</p>
                <p>All participants completed a separate LOC localizer scan (2 runs) in which visual stimuli were presented using a video projector connected to a personal computer laptop. Stimuli for the LOC localizer consisted of 300 × 300 pixel greyscale images and line drawings of familiar and novel objects, and scrambled versions of each set, each with overlapping grid-lines, as described in numerous previous studies<xref ref-type="bibr" rid="b5">5</xref><xref ref-type="bibr" rid="b19">19</xref><xref ref-type="bibr" rid="b25">25</xref>. The images were back-projected onto a screen which was viewed via a mirror attached to the top of the head coil. The LOC localizer had a blocked design with sixteen stimulus epochs and interleaved fixation periods of 16 s each. Twenty images were presented within each epoch. Images were presented for 250 ms with a blank interval of 550 ms between stimuli. Participants were instructed to passively view the images while fixating.</p>
              </sec>
              <sec disp-level="2">
                <title>MRI acquisition</title>
                <p>Scanning was carried out on a 3 Tesla Siemens Magnetom Tim Trio imaging system. From the participants whose data were used in the analysis, ten participants were scanned at Queen's University (Kingston, Ontario, Canada), and three participants were scanned on an identical machine at the Robarts Research Institute at The University of Western Ontario (London, Ontario, Canada), each using identical scanning parameters. For all participants in the fMR-A experiment, the functional data were acquired with a T2*-weighted single-shot gradient-echo echo-planar imaging sequence with interleaved slice acquisition. Rather than using a standard head coil configuration, we positioned subjects within the tilted the posterior half (6 channels) of a 12-channel (Siemens) receive-only head coil to enable direct viewing of the stimuli. Participants scanned in London also had an additional 4-channel flex coil suspended over the front of the head to enhance signal-to-noise ratio in anterior regions. Foam padding was used to reduce head motion.</p>
                <p>For the main experiment the parameters for obtaining functional data were: field of view (FOV)  =  211 mm × 211 mm; in-plane resolution  =  3.3 mm × 3.3 mm; slice thickness  =  3.3 mm; 32 axial slices; echo time (TE)  =  30 ms; repetition time (TR)  =  2000 ms; flip angle (FA)  =  78°. For the LOC localizer, subjects were scanned using a 12-channel Siemens head coil (un-tilted). Scanning parameters for the localizer were identical to that of the main experiment except for number of slices (33). Functional data were aligned to high-resolution anatomical images obtained using a 3D T1-weighted MPRAGE sequence (TE  =  2.98 ms; TR  =  2300 ms; TI (inversion time) =  900 ms; FA  =  9°; 192 contiguous slices of 1 mm thickness; FOV  =  240 mm × 250 mm<sup>2</sup>).</p>
              </sec>
              <sec disp-level="2">
                <title>Data Preprocessing and Analysis</title>
                <p>Data were preprocessed and analyzed using Brain Voyager QX (Version 1.10.2, Brain Innovation, Maastricht, Netherlands). Functional data were assessed for head motion and/or magnet artifacts by viewing cine-loop animation and examining motion detection parameter plots following 3D motion correction algorithms on the untransformed two-dimensional data, aligned to the functional volume closest in time to the anatomical scan. Any runs where head motion exceeded 1 mm of translation and/or 1 degrees of rotation were excluded from the analyses (5 runs in total across all 13 subjects). Functional data were preprocessed with high-pass temporal filtering to remove frequencies below 3 cycles/run. Functional volumes were then superimposed on anatomical brain images transformed into Talairach space<xref ref-type="bibr" rid="b92">92</xref>.</p>
              </sec>
              <sec disp-level="2">
                <title>Region of interest (ROI) analyses</title>
                <p>We first performed ROI analyses to determine whether neural populations within the LOC respond similarly to repetitions of 2D and to 3D objects. As in previous object fMR-A studies<xref ref-type="bibr" rid="b7">7</xref><xref ref-type="bibr" rid="b19">19</xref>, two subregions of the LOC were identified: LO (lateral occipital) located at the posterior end of the inferior temporal sulcus, and pFS (posterior fusiform sulcus). For each individual, ROIs were identified by selecting voxels within these anatomically defined regions of ventral occipitotemporal cortex that were activated more strongly by intact than scrambled images of objects presented in the localizer scans. ROIs were isolated by first locating the peak voxel of activation within each region. ROI size was constrained by setting the threshold to a desired minimum (<italic>t</italic>&gt;3.0) before selecting a volume of interest up to 10 mm<sup>3</sup> around the peak voxel. All single-subject analyses were performed on unsmoothed data. fMRI signal time-courses and β weights were extracted for each scan and hemisphere. The data were averaged to produce means for each condition in the two ROIs. These data were then averaged across subjects to yield group results. Repetition effects were quantified using an adaptation index (AI). The AI is defined based on responses elicited in the Different versus Repeat conditions using the following formula: AI  =  (R<sub>different</sub> − R<sub>repeat</sub>)/(R<sub>different</sub> + R<sub>repeat</sub>), where R<sub>repeat</sub> is the mean fMRI signal obtained on Repeat trials and R<sub>different</sub> is the mean fMRI signal obtained on Different trials<xref ref-type="bibr" rid="b4">4</xref><xref ref-type="bibr" rid="b93">93</xref>. β weights were positive for all subjects in both ROIs; consequently, no negative values were entered into the denominator term of the AI. Statistical significance was assessed using single-sample <italic>t</italic>-tests against zero, and paired samples <italic>t</italic>-tests.</p>
              </sec>
              <sec disp-level="2">
                <title>Voxel-wise group analyses</title>
                <p>We subsequently performed a whole-volume voxel-wise analysis of the group data to determine the extent to which repetition-based effects occurred for 2D and 3D objects at the whole-brain level. Data for each subject were spatially smoothed (6 mm full-width at half-maximum Gaussian kernel), and separate predictor functions generated for the four experimental conditions. Predictor functions were generated for the four conditions by convolving a rectangular wave function with a standard haemodynamic response function. Group data were then analyzed using a random effects (RFX) general linear model (GLM). The data were processed using a percentage signal change transformation.</p>
                <p>Repetition effects were examined separately for each stimulus category (2D, 3D). Activation in Different trials was contrasted with that on Repeat stimulus trials (e.g., +Different -Repeat). For each contrast, the resultant group activation maps were set to a minimum statistical threshold (<italic>p</italic>&lt;0.005) and minimum cluster size threshold of 5 functional voxels of 3 mm<sup>3</sup> each, totaling 135 mm<sup>3</sup> or greater (based on Brain Voyager's cluster threshold estimation plug-in). In addition, we examined whether there was a main effect of Stimulus Type by searching for areas in which activation was significantly different for 2D than 3D stimuli (and vice versa) using the contrast (+2D −3D). Finally, the interaction between Stimulus Type and Repetition was examined using the contrasts (a): +3D Different −3D Repeat −2D Different +2D Repeat (i.e., greater adaptation for 3D than 2D stimuli), and (b): +2D Different −2D Repeat −3D Different +3D Repeat (i.e., greater adaptation for 2D than 3D stimuli).</p>
              </sec>
              <sec disp-level="2">
                <title>Comparisons with Foci from Prior Studies</title>
                <p>Further to conducting the ROI analyses for individual subjects, we then compared BOLD responses for our 2D and 3D conditions across the group as a whole within brain areas identified in previous fMRI studies of ‘3D object perception'<xref ref-type="bibr" rid="b4">4</xref><xref ref-type="bibr" rid="b39">39</xref><xref ref-type="bibr" rid="b43">43</xref> (see <xref ref-type="fig" rid="f5">Figure 5</xref> &amp; <bold><xref ref-type="supplementary-material" rid="s1">Supplementary Table 1</xref></bold>). Group activation for all 4 conditions of the main experiment were contrasted with Fixation (i.e., +2D Different +2D Repeat +3D Different +3D Repeat). The resultant activation map was set to a minimum statistical threshold (t&gt;3.0) and displayed on the anatomical surface of a representative observer. ROI size was constrained by setting the activation threshold to a minimum (<italic>t</italic>&gt;3.0) before selecting a volume up to 10 mm<sup>3</sup> around the selected voxel (except for IPS points 1–4 in which, due to the proximity of neighboring regions, a 5 mm<sup>3</sup> cluster size was applied to prevent ROI overlap). MNI co-ordinates of the nine regions involved in processing 3D depth structure from stereo identified by Georgieva et al.,<xref ref-type="bibr" rid="b39">39</xref> were converted to TAL points using the MNI to Talairach Coordinate Converter (http://www.bioimagesuite.org/Mni2Tal/index.html).</p>
              </sec>
            </sec>
            <sec disp-level="1">
              <title>Author Contributions</title>
              <p>J.C.S., J.C.C. and M.A.G. designed the experiment; J.C.S., C.E.P. T.D.McA., A.D.McL. and P.W.S. acquired the data, J.C.S. analyzed the data; J.C.S., M.A.G. and J.C.C. wrote the manuscript.</p>
            </sec>
            <sec sec-type="supplementary-material" id="s1">
              <title>Supplementary Material</title>
              <supplementary-material id="d31e24" content-type="local-data">
                <caption>
                  <title>Supplementary Information</title>
                  <p>Supplementary Table 1</p>
                </caption>
                <media xlink:href="srep00130-s1.doc" mimetype="application" mime-subtype="msword"/>
              </supplementary-material>
            </sec>
          </body>
          <back>
            <ack>
              <p>This work was supported by grants from the Natural Sciences and Engineering Research Council of Canada to JC (Discovery Grant #249877-2006 RGPIN and E. W. R. Steacie Memorial Fellowship), grants from the Canadian Institutes of Health Research to the Group on Action and Perception (Group Grant # MGC 36036) and to MG (MOP-67006) and a CIHR Vision Health Research Training Grant to JCS (STN-118624). We thank Sharon David and Chase Figley for assistance with fMRI at Queen's University and Chad Marsolek for interesting discussion on possible links with his research.</p>
            </ack>
            <ref-list>
              <ref id="b1">
                <mixed-citation publication-type="journal"><name><surname>Kanwisher</surname><given-names>N. G.</given-names></name>, <name><surname>Chun</surname><given-names>M. M.</given-names></name>, <name><surname>McDermott</surname><given-names>J.</given-names></name> &amp; <name><surname>Ledden</surname><given-names>P. J.</given-names></name> <article-title>Functional imaging of human visual recognition</article-title>. <source>Cogn. Brain Res.</source> <volume>5</volume>, <fpage>55</fpage>–<lpage>67</lpage> (<year>1996</year>).</mixed-citation>
              </ref>
              <ref id="b2">
                <mixed-citation publication-type="journal"><name><surname>Malach</surname><given-names>R.</given-names></name>, <italic>et al.</italic>. <article-title>Object-related activity revealed by functional magnetic resonance imaging in human occipital cortex</article-title>. <source>Proc. Natl. Acad. Sci. USA</source><volume>92</volume>, <fpage>8135</fpage>–<lpage>8139</lpage> (<year>1995</year>).<pub-id pub-id-type="pmid">7667258</pub-id></mixed-citation>
              </ref>
              <ref id="b3">
                <mixed-citation publication-type="journal"><name><surname>Grill-Spector</surname><given-names>K.</given-names></name><article-title>The neural basis of object perception</article-title>. <source>Curr. Opin. Neurobiol.</source><volume>13</volume>, <fpage>159</fpage>–<lpage>166</lpage> (<year>2003</year>).<pub-id pub-id-type="pmid">12744968</pub-id></mixed-citation>
              </ref>
              <ref id="b4">
                <mixed-citation publication-type="journal"><name><surname>Konen</surname><given-names>C. S.</given-names></name> &amp; <name><surname>Kastner</surname><given-names>S.</given-names></name> <article-title>Two hierarchically organized neural systems for object information in human visual cortex</article-title>. <source>Nat. Neurosci.</source> <volume>11</volume>, <fpage>224</fpage>–<lpage>231</lpage> (<year>2008</year>).<pub-id pub-id-type="pmid">18193041</pub-id></mixed-citation>
              </ref>
              <ref id="b5">
                <mixed-citation publication-type="journal"><name><surname>Kourtzi</surname><given-names>Z.</given-names></name> &amp; <name><surname>Kanwisher</surname><given-names>N.</given-names></name> <article-title>Cortical regions involved in perceiving object shape</article-title>. <source>J. Neurosci.</source> <volume>20</volume>, <fpage>3310</fpage>–<lpage>3318</lpage> (<year>2000</year>).<pub-id pub-id-type="pmid">10777794</pub-id></mixed-citation>
              </ref>
              <ref id="b6">
                <mixed-citation publication-type="journal"><name><surname>Grill-Spector</surname><given-names>K.</given-names></name> &amp; <name><surname>Malach</surname><given-names>R.</given-names></name> <article-title>The human visual cortex</article-title>. <source>Annu. Rev. Neurosci.</source> <volume>27</volume>, <fpage>649</fpage>–<lpage>677</lpage> (<year>2004</year>).<pub-id pub-id-type="pmid">15217346</pub-id></mixed-citation>
              </ref>
              <ref id="b7">
                <mixed-citation publication-type="journal"><name><surname>Grill-Spector</surname><given-names>K.</given-names></name>, <italic>et al.</italic>. <article-title>Differential processing of objects under various viewing conditions in the human lateral occipital complex</article-title>. <source>Neuron</source><volume>24</volume>, <fpage>187</fpage>–<lpage>203</lpage> (<year>1999</year>).<pub-id pub-id-type="pmid">10677037</pub-id></mixed-citation>
              </ref>
              <ref id="b8">
                <mixed-citation publication-type="journal"><name><surname>Squire</surname><given-names>L. R.</given-names></name>, <italic>et al.</italic>. <article-title>Activation of the hippocampus in normal humans: a functional anatomical study of memory</article-title>. <source>Proc. Natl. Acad. Sci. USA</source><volume>89</volume>, <fpage>1837</fpage>–<lpage>1841</lpage> (<year>1992</year>).<pub-id pub-id-type="pmid">1542680</pub-id></mixed-citation>
              </ref>
              <ref id="b9">
                <mixed-citation publication-type="journal"><name><surname>Stern</surname><given-names>C. E.</given-names></name>, <italic>et al.</italic>. <article-title>The hippocampal formation participates in novel picture encoding: evidence from functional magnetic resonance imaging</article-title>. <source>Proc. Natl. Acad. Sci. USA</source><volume>93</volume>, <fpage>8660</fpage>–<lpage>8665</lpage> (<year>1996</year>).<pub-id pub-id-type="pmid">8710927</pub-id></mixed-citation>
              </ref>
              <ref id="b10">
                <mixed-citation publication-type="journal"><name><surname>Buckner</surname><given-names>R. L.</given-names></name>, <italic>et al.</italic>. <article-title>Functional-anatomic correlates of object priming in humans revealed by rapid presentation event-related fMRI</article-title>. <source>Neuron</source><volume>20</volume>, <fpage>285</fpage>–<lpage>296</lpage> (<year>1998</year>).<pub-id pub-id-type="pmid">9491989</pub-id></mixed-citation>
              </ref>
              <ref id="b11">
                <mixed-citation publication-type="journal"><name><surname>Wiggs</surname><given-names>C. L.</given-names></name> &amp; <name><surname>Martin</surname><given-names>A.</given-names></name> <article-title>Properties and mechanisms of perceptual priming</article-title>. <source>Curr. Opin. Neurobiol.</source> <volume>8</volume>, <fpage>227</fpage>–<lpage>233</lpage> (<year>1998</year>).<pub-id pub-id-type="pmid">9635206</pub-id></mixed-citation>
              </ref>
              <ref id="b12">
                <mixed-citation publication-type="journal"><name><surname>Grill-Spector</surname><given-names>K.</given-names></name> &amp; <name><surname>Malach</surname><given-names>R.</given-names></name> <article-title>fMR-adaptation: a tool for studying the functional properties of human cortical neurons</article-title>. <source>Acta Psychol. (Amst).</source> <volume>107</volume>, <fpage>293</fpage>–<lpage>321</lpage> (<year>2001</year>).<pub-id pub-id-type="pmid">11388140</pub-id></mixed-citation>
              </ref>
              <ref id="b13">
                <mixed-citation publication-type="journal"><name><surname>Henson</surname><given-names>R. N.</given-names></name><article-title>Neuroimaging studies of priming</article-title>. <source>Prog. Neurobiol.</source><volume>70</volume>, <fpage>53</fpage>–<lpage>81</lpage> (<year>2003</year>).<pub-id pub-id-type="pmid">12927334</pub-id></mixed-citation>
              </ref>
              <ref id="b14">
                <mixed-citation publication-type="journal"><name><surname>Desimone</surname><given-names>R.</given-names></name><article-title>Neural mechanisms for visual memory and their role in attention</article-title>. <source>Proc. Natl. Acad. Sci. USA</source><volume>93</volume>, <fpage>13494</fpage>–<lpage>13499</lpage> (<year>1996</year>).<pub-id pub-id-type="pmid">8942962</pub-id></mixed-citation>
              </ref>
              <ref id="b15">
                <mixed-citation publication-type="journal"><name><surname>Grill-Spector</surname><given-names>K.</given-names></name>, <name><surname>Henson</surname><given-names>R.</given-names></name> &amp; <name><surname>Martin</surname><given-names>A.</given-names></name> <article-title>Repetition and the brain: neural models of stimulus-specific effects</article-title>. <source>Trends Cogn. Sci.</source> <volume>10</volume>, <fpage>14</fpage>–<lpage>23</lpage> (<year>2006</year>).<pub-id pub-id-type="pmid">16321563</pub-id></mixed-citation>
              </ref>
              <ref id="b16">
                <mixed-citation publication-type="journal"><name><surname>Miller</surname><given-names>E. K.</given-names></name>, <name><surname>Li</surname><given-names>L.</given-names></name> &amp; <name><surname>Desimone</surname><given-names>R.</given-names></name> <article-title>A neural mechanism for working and recognition memory in inferior temporal cortex</article-title>. <source>Science</source> <volume>254</volume>, <fpage>1377</fpage>–<lpage>1379</lpage> (<year>1991</year>).<pub-id pub-id-type="pmid">1962197</pub-id></mixed-citation>
              </ref>
              <ref id="b17">
                <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>L.</given-names></name>, <name><surname>Miller</surname><given-names>E. K.</given-names></name> &amp; <name><surname>Desimone</surname><given-names>R.</given-names></name> <article-title>The representation of stimulus familiarity in anterior inferior temporal cortex</article-title>. <source>J. Neurophysiol.</source> <volume>69</volume>, <fpage>1918</fpage>–<lpage>1929</lpage> (<year>1993</year>).<pub-id pub-id-type="pmid">8350131</pub-id></mixed-citation>
              </ref>
              <ref id="b18">
                <mixed-citation publication-type="journal"><name><surname>Krekelberg</surname><given-names>B.</given-names></name>, <name><surname>Boynton</surname><given-names>G. M.</given-names></name> &amp; <name><surname>van Wezel</surname><given-names>R. J. A.</given-names></name> <article-title>Adaptation: from single cells to BOLD signals</article-title>. <source>Trends Neurosci.</source> <volume>29</volume>, <fpage>250</fpage>–<lpage>256</lpage> (<year>2006</year>).<pub-id pub-id-type="pmid">16529826</pub-id></mixed-citation>
              </ref>
              <ref id="b19">
                <mixed-citation publication-type="journal"><name><surname>Kourtzi</surname><given-names>Z.</given-names></name>, <name><surname>Erb</surname><given-names>M.</given-names></name>, <name><surname>Grodd</surname><given-names>W.</given-names></name> &amp; <name><surname>Bulthoff</surname><given-names>H. H.</given-names></name> <article-title>Representation of the perceived 3-D object shape in the human lateral occipital complex</article-title>. <source>Cereb. Cortex</source> <volume>13</volume>, <fpage>911</fpage>–<lpage>920</lpage> (<year>2003</year>).<pub-id pub-id-type="pmid">12902390</pub-id></mixed-citation>
              </ref>
              <ref id="b20">
                <mixed-citation publication-type="journal"><name><surname>Kourtzi</surname><given-names>Z.</given-names></name> &amp; <name><surname>Huberle</surname><given-names>E.</given-names></name> <article-title>Spatiotemporal characteristics of form analysis in the human visual cortex revealed by rapid event-related fMRI adaptation</article-title>. <source>Neuroimage</source> <volume>28</volume>, <fpage>440</fpage>–<lpage>452</lpage> (<year>2005</year>).<pub-id pub-id-type="pmid">16046147</pub-id></mixed-citation>
              </ref>
              <ref id="b21">
                <mixed-citation publication-type="journal"><name><surname>Kourtzi</surname><given-names>Z.</given-names></name>, <name><surname>Tolias</surname><given-names>A. S.</given-names></name>, <name><surname>Altmann</surname><given-names>C. F.</given-names></name>, <name><surname>Augath</surname><given-names>M.</given-names></name> &amp; <name><surname>Logothetis</surname><given-names>N. K.</given-names></name> <article-title>Integration of local features into global shapes: monkey and human FMRI studies</article-title>. <source>Neuron</source> <volume>37</volume>, <fpage>333</fpage>–<lpage>346</lpage> (<year>2003</year>).<pub-id pub-id-type="pmid">12546827</pub-id></mixed-citation>
              </ref>
              <ref id="b22">
                <mixed-citation publication-type="journal"><name><surname>James</surname><given-names>T. W.</given-names></name>, <italic>et al.</italic>. <article-title>Haptic study of three-dimensional objects activates extrastriate visual areas</article-title>. <source>Neuropsychologia</source><volume>40</volume>, <fpage>1706</fpage>–<lpage>1714</lpage> (<year>2002</year>).<pub-id pub-id-type="pmid">11992658</pub-id></mixed-citation>
              </ref>
              <ref id="b23">
                <mixed-citation publication-type="journal"><name><surname>Koutstaal</surname><given-names>W.</given-names></name>, <italic>et al.</italic>. <article-title>Perceptual specificity in visual object priming: functional magnetic resonance imaging evidence for a laterality difference in fusiform cortex</article-title>. <source>Neuropsychologia</source><volume>39</volume>, <fpage>184</fpage>–<lpage>199</lpage> (<year>2001</year>).<pub-id pub-id-type="pmid">11163375</pub-id></mixed-citation>
              </ref>
              <ref id="b24">
                <mixed-citation publication-type="journal"><name><surname>Vuilleumier</surname><given-names>P.</given-names></name>, <name><surname>Henson</surname><given-names>R. N.</given-names></name>, <name><surname>Driver</surname><given-names>J.</given-names></name> &amp; <name><surname>Dolan</surname><given-names>R. J.</given-names></name> <article-title>Multiple levels of visual object constancy revealed by event-related fMRI of repetition priming</article-title>. <source>Nat. Neurosci.</source> <volume>5</volume>, <fpage>491</fpage>–<lpage>499</lpage> (<year>2002</year>).<pub-id pub-id-type="pmid">11967545</pub-id></mixed-citation>
              </ref>
              <ref id="b25">
                <mixed-citation publication-type="journal"><name><surname>Kourtzi</surname><given-names>Z.</given-names></name> &amp; <name><surname>Kanwisher</surname><given-names>N.</given-names></name> <article-title>Representation of perceived object shape by the human lateral occipital complex</article-title>. <source>Science</source> <volume>293</volume>, <fpage>1506</fpage>–<lpage>1509</lpage> (<year>2001</year>).<pub-id pub-id-type="pmid">11520991</pub-id></mixed-citation>
              </ref>
              <ref id="b26">
                <mixed-citation publication-type="journal"><name><surname>Culham</surname><given-names>J. C.</given-names></name>, <italic>et al.</italic>. <article-title>Visually guided grasping produces fMRI activation in dorsal but not ventral stream brain areas</article-title>. <source>Exp. Brain Res.</source><volume>153</volume>, <fpage>180</fpage>–<lpage>189</lpage> (<year>2003</year>).<pub-id pub-id-type="pmid">12961051</pub-id></mixed-citation>
              </ref>
              <ref id="b27">
                <mixed-citation publication-type="journal"><name><surname>Cavina-Pratesi</surname><given-names>C.</given-names></name>, <italic>et al.</italic>. <article-title>Functional magnetic resonance imaging reveals the neural substrates of arm transport and grip formation in reach-to-grasp actions in humans</article-title>. <source>J. Neurosci.</source><volume>30</volume>, <fpage>10306</fpage>–<lpage>10323</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">20685975</pub-id></mixed-citation>
              </ref>
              <ref id="b28">
                <mixed-citation publication-type="journal"><name><surname>Verhagen</surname><given-names>L.</given-names></name>, <name><surname>Dijkerman</surname><given-names>H. C.</given-names></name>, <name><surname>Grol</surname><given-names>M. J.</given-names></name> &amp; <name><surname>Toni</surname><given-names>I.</given-names></name> <article-title>Perceptuo-motor interactions during prehension movements</article-title>. <source>J. Neurosci.</source> <volume>28</volume>, <fpage>4726</fpage>–<lpage>4735</lpage> (<year>2008</year>).<pub-id pub-id-type="pmid">18448649</pub-id></mixed-citation>
              </ref>
              <ref id="b29">
                <mixed-citation publication-type="journal"><name><surname>Gallivan</surname><given-names>J. P.</given-names></name>, <name><surname>Cavina-Pratesi</surname><given-names>C.</given-names></name> &amp; <name><surname>Culham</surname><given-names>J. C.</given-names></name> <article-title>Is that within reach? fMRI reveals that the human superior parieto-occipital cortex encodes objects reachable by the hand</article-title>. <source>J. Neurosci.</source> <volume>29</volume>, <fpage>4381</fpage>–<lpage>4391</lpage> (<year>2009</year>).<pub-id pub-id-type="pmid">19357266</pub-id></mixed-citation>
              </ref>
              <ref id="b30">
                <mixed-citation publication-type="journal"><name><surname>Ishai</surname><given-names>A.</given-names></name>, <name><surname>Ungerleider</surname><given-names>L. G.</given-names></name>, <name><surname>Martin</surname><given-names>A.</given-names></name>, <name><surname>Schouten</surname><given-names>J. L.</given-names></name> &amp; <name><surname>Haxby</surname><given-names>J. V.</given-names></name> <article-title>Distributed representation of objects in the human ventral visual pathway</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source> <volume>96</volume>, <fpage>9379</fpage>–<lpage>9384</lpage> (<year>1999</year>).<pub-id pub-id-type="pmid">10430951</pub-id></mixed-citation>
              </ref>
              <ref id="b31">
                <mixed-citation publication-type="journal"><name><surname>Sakata</surname><given-names>H.</given-names></name>, <name><surname>Taira</surname><given-names>M.</given-names></name>, <name><surname>Murata</surname><given-names>A.</given-names></name> &amp; <name><surname>Mine</surname><given-names>S.</given-names></name> <article-title>Neural mechanisms of visual guidance of hand action in the parietal cortex of the monkey</article-title>. <source>Cereb. Cortex</source> <volume>5</volume>, <fpage>429</fpage>–<lpage>438</lpage> (<year>1995</year>).<pub-id pub-id-type="pmid">8547789</pub-id></mixed-citation>
              </ref>
              <ref id="b32">
                <mixed-citation publication-type="journal"><name><surname>Murata</surname><given-names>A.</given-names></name>, <name><surname>Gallese</surname><given-names>V.</given-names></name>, <name><surname>Luppino</surname><given-names>G.</given-names></name>, <name><surname>Kaseda</surname><given-names>M.</given-names></name> &amp; <name><surname>Sakata</surname><given-names>H.</given-names></name> <article-title>Selectivity for the shape, size, and orientation of objects for grasping in neurons of monkey parietal area AIP</article-title>. <source>J. Neurophysiol.</source> <volume>83</volume>, <fpage>2580</fpage>–<lpage>2601</lpage> (<year>2000</year>).<pub-id pub-id-type="pmid">10805659</pub-id></mixed-citation>
              </ref>
              <ref id="b33">
                <mixed-citation publication-type="journal"><name><surname>Verhoef</surname><given-names>B. E.</given-names></name>, <name><surname>Vogels</surname><given-names>R.</given-names></name> &amp; <name><surname>Janssen</surname><given-names>P.</given-names></name> <article-title>Contribution of inferior temporal and posterior parietal activity to three-dimensional shape perception</article-title>. <source>Curr. Biol.</source> <volume>20</volume>, <fpage>909</fpage>–<lpage>913</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">20434342</pub-id></mixed-citation>
              </ref>
              <ref id="b34">
                <mixed-citation publication-type="journal"><name><surname>Srivastava</surname><given-names>S.</given-names></name>, <name><surname>Orban</surname><given-names>G. A.</given-names></name>, <name><surname>De Maziere</surname><given-names>P. A.</given-names></name> &amp; <name><surname>Janssen</surname><given-names>P.</given-names></name> <article-title>A distinct representation of three-dimensional shape in macaque anterior intraparietal area: fast, metric, and coarse</article-title>. <source>J. Neurosci.</source> <volume>29</volume>, <fpage>10613</fpage>–<lpage>11026</lpage> (<year>2009</year>).<pub-id pub-id-type="pmid">19710314</pub-id></mixed-citation>
              </ref>
              <ref id="b35">
                <mixed-citation publication-type="journal"><name><surname>Janssen</surname><given-names>P.</given-names></name>, <name><surname>Srivastava</surname><given-names>S.</given-names></name>, <name><surname>Ombelet</surname><given-names>S.</given-names></name> &amp; <name><surname>Orban</surname><given-names>G. A.</given-names></name> <article-title>Coding of shape and position in macaque lateral intraparietal area</article-title>. <source>J Neurosci</source> <volume>28</volume>, <fpage>6679</fpage>–<lpage>6690</lpage> (<year>2008</year>).<pub-id pub-id-type="pmid">18579742</pub-id></mixed-citation>
              </ref>
              <ref id="b36">
                <mixed-citation publication-type="journal"><name><surname>Sakata</surname><given-names>H.</given-names></name>, <italic>et al.</italic>. <article-title>Neural representation of three-dimensional features of manipulation objects with stereopsis</article-title>. <source>Exp. Brain Res.</source><volume>128</volume>, <fpage>160</fpage>–<lpage>169</lpage> (<year>1999</year>).<pub-id pub-id-type="pmid">10473754</pub-id></mixed-citation>
              </ref>
              <ref id="b37">
                <mixed-citation publication-type="journal"><name><surname>Culham</surname><given-names>J. C.</given-names></name> &amp; <name><surname>Valyear</surname><given-names>K. F.</given-names></name> <article-title>Human parietal cortex in action</article-title>. <source>Curr. Opin. Neurobiol.</source> <volume>16</volume>, <fpage>205</fpage>–<lpage>212</lpage> (<year>2006</year>).<pub-id pub-id-type="pmid">16563735</pub-id></mixed-citation>
              </ref>
              <ref id="b38">
                <mixed-citation publication-type="journal"><name><surname>Goodale</surname><given-names>M. A.</given-names></name> &amp; <name><surname>Milner</surname><given-names>A. D.</given-names></name> <article-title>Separate visual pathways for perception and action</article-title>. <source>Trends Neurosci.</source> <volume>15</volume>, <fpage>20</fpage>–<lpage>25</lpage> (<year>1992</year>).<pub-id pub-id-type="pmid">1374953</pub-id></mixed-citation>
              </ref>
              <ref id="b39">
                <mixed-citation publication-type="journal"><name><surname>Georgieva</surname><given-names>S.</given-names></name>, <name><surname>Peeters</surname><given-names>R.</given-names></name>, <name><surname>Kolster</surname><given-names>H.</given-names></name>, <name><surname>Todd</surname><given-names>J. T.</given-names></name> &amp; <name><surname>Orban</surname><given-names>G. A.</given-names></name> <article-title>The processing of three-dimensional shape from disparity in the human brain</article-title>. <source>J. Neurosci.</source> <volume>29</volume>, <fpage>727</fpage>–<lpage>742</lpage> (<year>2009</year>).<pub-id pub-id-type="pmid">19158299</pub-id></mixed-citation>
              </ref>
              <ref id="b40">
                <mixed-citation publication-type="journal"><name><surname>Loftus</surname><given-names>G. R.</given-names></name> &amp; <name><surname>Masson</surname><given-names>M. E. J.</given-names></name> <article-title>Using confidence intervals in within-subject designs</article-title>. <source>Psychon. Bull. Rev.</source> <volume>1</volume>, <fpage>476</fpage>–<lpage>490</lpage> (<year>1994</year>).</mixed-citation>
              </ref>
              <ref id="b41">
                <mixed-citation publication-type="journal"><name><surname>Belia</surname><given-names>S.</given-names></name>, <name><surname>Fidler</surname><given-names>F.</given-names></name>, <name><surname>Williams</surname><given-names>J.</given-names></name> &amp; <name><surname>Cumming</surname><given-names>G.</given-names></name> <article-title>Researchers misunderstand confidence intervals and standard error bars</article-title>. <source>Psychol. Methods</source> <volume>10</volume>, <fpage>389</fpage>–<lpage>396</lpage> (<year>2005</year>).<pub-id pub-id-type="pmid">16392994</pub-id></mixed-citation>
              </ref>
              <ref id="b42">
                <mixed-citation publication-type="journal"><name><surname>Wandell</surname><given-names>B. A.</given-names></name>, <name><surname>Dumoulin</surname><given-names>S. O.</given-names></name> &amp; <name><surname>Brewer</surname><given-names>A. A.</given-names></name> <article-title>Visual field maps in human cortex</article-title>. <source>Neuron</source> <volume>56</volume>, <fpage>366</fpage>–<lpage>383</lpage> (<year>2007</year>).<pub-id pub-id-type="pmid">17964252</pub-id></mixed-citation>
              </ref>
              <ref id="b43">
                <mixed-citation publication-type="journal"><name><surname>Amedi</surname><given-names>A.</given-names></name>, <name><surname>Jacobson</surname><given-names>G.</given-names></name>, <name><surname>Hendler</surname><given-names>T.</given-names></name>, <name><surname>Malach</surname><given-names>R.</given-names></name> &amp; <name><surname>Zohary</surname><given-names>E.</given-names></name> <article-title>Convergence of visual and tactile shape processing in the human lateral occipital complex</article-title>. <source>Cereb. Cortex</source> <volume>12</volume>, <fpage>1202</fpage>–<lpage>1212</lpage> (<year>2002</year>).<pub-id pub-id-type="pmid">12379608</pub-id></mixed-citation>
              </ref>
              <ref id="b44">
                <mixed-citation publication-type="journal"><name><surname>Schacter</surname><given-names>D. L.</given-names></name>, <italic>et al.</italic>. <article-title>Brain regions associated with retrieval of structurally coherent visual information</article-title>. <source>Nature</source><volume>376</volume>, <fpage>587</fpage>–<lpage>590</lpage> (<year>1995</year>).<pub-id pub-id-type="pmid">7637806</pub-id></mixed-citation>
              </ref>
              <ref id="b45">
                <mixed-citation publication-type="journal"><name><surname>Henson</surname><given-names>R.</given-names></name>, <name><surname>Shallice</surname><given-names>T.</given-names></name> &amp; <name><surname>Dolan</surname><given-names>R.</given-names></name> <article-title>Neuroimaging evidence for dissociable forms of repetition priming</article-title>. <source>Science</source> <volume>287</volume>, <fpage>1269</fpage>–<lpage>1272</lpage> (<year>2000</year>).<pub-id pub-id-type="pmid">10678834</pub-id></mixed-citation>
              </ref>
              <ref id="b46">
                <mixed-citation publication-type="journal"><name><surname>Dolan</surname><given-names>R. J.</given-names></name>, <italic>et al.</italic>. <article-title>How the brain learns to see objects and faces in an impoverished context</article-title>. <source>Nature</source><volume>389</volume>, <fpage>596</fpage>–<lpage>599</lpage> (<year>1997</year>).<pub-id pub-id-type="pmid">9335498</pub-id></mixed-citation>
              </ref>
              <ref id="b47">
                <mixed-citation publication-type="journal"><name><surname>James</surname><given-names>T. W.</given-names></name> &amp; <name><surname>Gauthier</surname><given-names>I.</given-names></name> <article-title>Repetition-induced changes in BOLD response reflect accumulation of neural activity</article-title>. <source>Hum. Brain Mapp.</source> <volume>27</volume>, <fpage>37</fpage>–<lpage>46</lpage> (<year>2006</year>).<pub-id pub-id-type="pmid">15954142</pub-id></mixed-citation>
              </ref>
              <ref id="b48">
                <mixed-citation publication-type="journal"><name><surname>Hopfinger</surname><given-names>J. B.</given-names></name>, <name><surname>Buonocore</surname><given-names>M. H.</given-names></name> &amp; <name><surname>Mangun</surname><given-names>G. R.</given-names></name> <article-title>The neural mechanisms of top-down attentional control</article-title>. <source>Nat. Neurosci.</source> <volume>3</volume>, <fpage>284</fpage>–<lpage>291</lpage> (<year>2000</year>).<pub-id pub-id-type="pmid">10700262</pub-id></mixed-citation>
              </ref>
              <ref id="b49">
                <mixed-citation publication-type="journal"><name><surname>Silver</surname><given-names>M. A.</given-names></name>, <name><surname>Ress</surname><given-names>D.</given-names></name> &amp; <name><surname>Heeger</surname><given-names>D. J.</given-names></name> <article-title>Topographic maps of visual spatial attention in human parietal cortex</article-title>. <source>J. Neurophysiol.</source> <volume>94</volume>, <fpage>1358</fpage>–<lpage>1371</lpage> (<year>2005</year>).<pub-id pub-id-type="pmid">15817643</pub-id></mixed-citation>
              </ref>
              <ref id="b50">
                <mixed-citation publication-type="journal"><name><surname>Corbetta</surname><given-names>M.</given-names></name>, <italic>et al.</italic>. <article-title>A common network of functional areas for attention and eye movements</article-title>. <source>Neuron</source><volume>21</volume>, <fpage>761</fpage>–<lpage>773</lpage> (<year>1998</year>).<pub-id pub-id-type="pmid">9808463</pub-id></mixed-citation>
              </ref>
              <ref id="b51">
                <mixed-citation publication-type="journal"><name><surname>Yi</surname><given-names>D. J.</given-names></name> &amp; <name><surname>Chun</surname><given-names>M. M.</given-names></name> <article-title>Attentional modulation of learning-related repetition attenuation effects in human parahippocampal cortex</article-title>. <source>J. Neurosci.</source> <volume>25</volume>, <fpage>3593</fpage>–<lpage>3600</lpage> (<year>2005</year>).<pub-id pub-id-type="pmid">15814790</pub-id></mixed-citation>
              </ref>
              <ref id="b52">
                <mixed-citation publication-type="journal"><name><surname>Murray</surname><given-names>S. O.</given-names></name> &amp; <name><surname>Wojciulik</surname><given-names>E.</given-names></name> <article-title>Attention increases neural selectivity in the human lateral occipital complex</article-title>. <source>Nat Neurosci.</source> <volume>7</volume>, <fpage>70</fpage>–<lpage>74</lpage> (<year>2004</year>).<pub-id pub-id-type="pmid">14647291</pub-id></mixed-citation>
              </ref>
              <ref id="b53">
                <mixed-citation publication-type="journal"><name><surname>Bakin</surname><given-names>J. S.</given-names></name>, <name><surname>Nakayama</surname><given-names>K.</given-names></name> &amp; <name><surname>Gilbert</surname><given-names>C. D.</given-names></name> <article-title>Visual responses in monkey areas V1 and V2 to three-dimensional surface configurations</article-title>. <source>J. Neurosci.</source> <volume>20</volume>, <fpage>8188</fpage>–<lpage>8198</lpage> (<year>2000</year>).<pub-id pub-id-type="pmid">11050142</pub-id></mixed-citation>
              </ref>
              <ref id="b54">
                <mixed-citation publication-type="journal"><name><surname>Cumming</surname><given-names>B. G.</given-names></name> &amp; <name><surname>Parker</surname><given-names>A. J.</given-names></name> <article-title>Responses of primary visual cortical neurons to binocular disparity without depth perception</article-title>. <source>Nature</source> <volume>389</volume>, <fpage>280</fpage>–<lpage>283</lpage> (<year>1997</year>).<pub-id pub-id-type="pmid">9305841</pub-id></mixed-citation>
              </ref>
              <ref id="b55">
                <mixed-citation publication-type="journal"><name><surname>Cumming</surname><given-names>B. G.</given-names></name> &amp; <name><surname>Parker</surname><given-names>A. J.</given-names></name> <article-title>Local disparity not perceived depth is signaled by binocular neurons in cortical area V1 of the Macaque</article-title>. <source>J. Neurosci.</source> <volume>20</volume>, <fpage>4758</fpage>–<lpage>4767</lpage> (<year>2000</year>).<pub-id pub-id-type="pmid">10844045</pub-id></mixed-citation>
              </ref>
              <ref id="b56">
                <mixed-citation publication-type="journal"><name><surname>Poggio</surname><given-names>G. F.</given-names></name> &amp; <name><surname>Fischer</surname><given-names>B.</given-names></name> <article-title>Binocular interaction and depth sensitivity in striate and prestriate cortex of behaving rhesus monkey</article-title>. <source>J. Neurophysiol.</source> <volume>40</volume>, <fpage>1392</fpage>–<lpage>1405</lpage> (<year>1977</year>).<pub-id pub-id-type="pmid">411898</pub-id></mixed-citation>
              </ref>
              <ref id="b57">
                <mixed-citation publication-type="journal"><name><surname>Poggio</surname><given-names>G. F.</given-names></name>, <name><surname>Gonzalez</surname><given-names>F.</given-names></name> &amp; <name><surname>Krause</surname><given-names>F.</given-names></name> <article-title>Stereoscopic mechanisms in monkey visual cortex: binocular correlation and disparity selectivity</article-title>. <source>J. Neurosci.</source> <volume>8</volume>, <fpage>4531</fpage>–<lpage>4550</lpage> (<year>1988</year>).<pub-id pub-id-type="pmid">3199191</pub-id></mixed-citation>
              </ref>
              <ref id="b58">
                <mixed-citation publication-type="journal"><name><surname>Thomas</surname><given-names>O. M.</given-names></name>, <name><surname>Cumming</surname><given-names>B. G.</given-names></name> &amp; <name><surname>Parker</surname><given-names>A. J.</given-names></name> <article-title>A specialization for relative disparity in V2</article-title>. <source>Nat. Neurosci.</source> <volume>5</volume>, <fpage>472</fpage>–<lpage>478</lpage> (<year>2002</year>).<pub-id pub-id-type="pmid">11967544</pub-id></mixed-citation>
              </ref>
              <ref id="b59">
                <mixed-citation publication-type="journal"><name><surname>von der Heydt</surname><given-names>R.</given-names></name>, <name><surname>Zhou</surname><given-names>H.</given-names></name> &amp; <name><surname>Friedman</surname><given-names>H. S.</given-names></name> <article-title>Representation of stereoscopic edges in monkey visual cortex</article-title>. <source>Vision Res.</source> <volume>40</volume>, <fpage>1955</fpage>–<lpage>1967</lpage> (<year>2000</year>).<pub-id pub-id-type="pmid">10828464</pub-id></mixed-citation>
              </ref>
              <ref id="b60">
                <mixed-citation publication-type="journal"><name><surname>DeAngelis</surname><given-names>G. C.</given-names></name>, <name><surname>Cumming</surname><given-names>B. G.</given-names></name> &amp; <name><surname>Newsome</surname><given-names>W. T.</given-names></name> <article-title>Cortical area MT and the perception of stereoscopic depth</article-title>. <source>Nature</source> <volume>394</volume>, <fpage>677</fpage>–<lpage>680</lpage> (<year>1998</year>).<pub-id pub-id-type="pmid">9716130</pub-id></mixed-citation>
              </ref>
              <ref id="b61">
                <mixed-citation publication-type="journal"><name><surname>DeAngelis</surname><given-names>G. C.</given-names></name> &amp; <name><surname>Newsome</surname><given-names>W. T.</given-names></name> <article-title>Organization of disparity-selective neurons in macaque area MT</article-title>. <source>J. Neurosci.</source> <volume>19</volume>, <fpage>1398</fpage>–<lpage>1415</lpage> (<year>1999</year>).<pub-id pub-id-type="pmid">9952417</pub-id></mixed-citation>
              </ref>
              <ref id="b62">
                <mixed-citation publication-type="journal"><name><surname>Maunsell</surname><given-names>J. H.</given-names></name> &amp; <name><surname>Van Essen</surname><given-names>D. C.</given-names></name> <article-title>Functional properties of neurons in middle temporal visual area of the macaque monkey. II. Binocular interactions and sensitivity to binocular disparity</article-title>. <source>J. Neurophysiol.</source> <volume>49</volume>, <fpage>1148</fpage>–<lpage>1167</lpage> (<year>1983</year>).<pub-id pub-id-type="pmid">6864243</pub-id></mixed-citation>
              </ref>
              <ref id="b63">
                <mixed-citation publication-type="journal"><name><surname>Roy</surname><given-names>J. P.</given-names></name>, <name><surname>Komatsu</surname><given-names>H.</given-names></name> &amp; <name><surname>Wurtz</surname><given-names>R. H.</given-names></name> <article-title>Disparity sensitivity of neurons in monkey extrastriate area MST</article-title>. <source>J. Neurosci.</source> <volume>12</volume>, <fpage>2478</fpage>–<lpage>2492</lpage> (<year>1992</year>).<pub-id pub-id-type="pmid">1613542</pub-id></mixed-citation>
              </ref>
              <ref id="b64">
                <mixed-citation publication-type="journal"><name><surname>Shikata</surname><given-names>E.</given-names></name>, <name><surname>Tanaka</surname><given-names>Y.</given-names></name>, <name><surname>Nakamura</surname><given-names>H.</given-names></name>, <name><surname>Taira</surname><given-names>M.</given-names></name> &amp; <name><surname>Sakata</surname><given-names>H.</given-names></name> <article-title>Selectivity of the parietal visual neurones in 3D orientation of surface of stereoscopic stimuli</article-title>. <source>Neuroreport</source> <volume>7</volume>, <fpage>2389</fpage>–<lpage>2394</lpage> (<year>1996</year>).<pub-id pub-id-type="pmid">8951858</pub-id></mixed-citation>
              </ref>
              <ref id="b65">
                <mixed-citation publication-type="journal"><name><surname>Taira</surname><given-names>M.</given-names></name>, <name><surname>Tsutsui</surname><given-names>K. I.</given-names></name>, <name><surname>Jiang</surname><given-names>M.</given-names></name>, <name><surname>Yara</surname><given-names>K.</given-names></name> &amp; <name><surname>Sakata</surname><given-names>H.</given-names></name> <article-title>Parietal neurons represent surface orientation from the gradient of binocular disparity</article-title>. <source>J. Neurophysiol.</source> <volume>83</volume>, <fpage>3140</fpage>–<lpage>3146</lpage> (<year>2000</year>).<pub-id pub-id-type="pmid">10805708</pub-id></mixed-citation>
              </ref>
              <ref id="b66">
                <mixed-citation publication-type="journal"><name><surname>Janssen</surname><given-names>P.</given-names></name>, <name><surname>Vogels</surname><given-names>R.</given-names></name> &amp; <name><surname>Orban</surname><given-names>G. A.</given-names></name> <article-title>Macaque inferior temporal neurons are selective for disparity-defined three-dimensional shapes</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>96</volume>, <fpage>8217</fpage>–<lpage>8222</lpage> (<year>1999</year>).<pub-id pub-id-type="pmid">10393975</pub-id></mixed-citation>
              </ref>
              <ref id="b67">
                <mixed-citation publication-type="journal"><name><surname>Janssen</surname><given-names>P.</given-names></name>, <name><surname>Vogels</surname><given-names>R.</given-names></name>, <name><surname>Liu</surname><given-names>Y.</given-names></name> &amp; <name><surname>Orban</surname><given-names>G. A.</given-names></name> <article-title>Macaque inferior temporal neurons are selective for three-dimensional boundaries and surfaces</article-title>. <source>J. Neurosci</source> <volume>21</volume>, <fpage>9419</fpage>–<lpage>9429</lpage> (<year>2001</year>).<pub-id pub-id-type="pmid">11717375</pub-id></mixed-citation>
              </ref>
              <ref id="b68">
                <mixed-citation publication-type="other"><name><surname>Janssen</surname><given-names>P.</given-names></name>, <name><surname>Vogels</surname><given-names>R.</given-names></name> &amp; <name><surname>Orban</surname><given-names>G. A.</given-names></name> <article-title>Three-dimensional shape coding in inferior temporal cortex</article-title>. <volume>27</volume>, <fpage>385</fpage>–<lpage>397</lpage> (<year>2000</year>).</mixed-citation>
              </ref>
              <ref id="b69">
                <mixed-citation publication-type="other"><name><surname>Janssen</surname><given-names>P.</given-names></name>, <name><surname>Vogels</surname><given-names>R.</given-names></name> &amp; <name><surname>Orban</surname><given-names>G. A.</given-names></name> <article-title>Selectivity for 3D shape that reveals distinct areas within macaque inferior temporal cortex</article-title>. <volume>288</volume>, <fpage>2054</fpage>–<lpage>2056</lpage> (<year>2000</year>).</mixed-citation>
              </ref>
              <ref id="b70">
                <mixed-citation publication-type="journal"><name><surname>Hinkle</surname><given-names>D. A.</given-names></name> &amp; <name><surname>Connor</surname><given-names>C. E.</given-names></name> <article-title>Three-dimensional orientation tuning in macaque area V4</article-title>. <source>Nat. Neurosci.</source> <volume>5</volume>, <fpage>665</fpage>–<lpage>670</lpage> (<year>2002</year>).<pub-id pub-id-type="pmid">12068303</pub-id></mixed-citation>
              </ref>
              <ref id="b71">
                <mixed-citation publication-type="journal"><name><surname>Tanaka</surname><given-names>H.</given-names></name>, <name><surname>Uka</surname><given-names>T.</given-names></name>, <name><surname>Yoshiyama</surname><given-names>K.</given-names></name>, <name><surname>Kato</surname><given-names>M.</given-names></name> &amp; <name><surname>Fujita</surname><given-names>I.</given-names></name> <article-title>Processing of shape defined by disparity in monkey inferior temporal cortex</article-title>. <source>J. Neurophysiol.</source> <volume>85</volume>, <fpage>735</fpage>–<lpage>744</lpage> (<year>2001</year>).<pub-id pub-id-type="pmid">11160508</pub-id></mixed-citation>
              </ref>
              <ref id="b72">
                <mixed-citation publication-type="journal"><name><surname>Uka</surname><given-names>T.</given-names></name>, <name><surname>Tanaka</surname><given-names>H.</given-names></name>, <name><surname>Yoshiyama</surname><given-names>K.</given-names></name>, <name><surname>Kato</surname><given-names>M.</given-names></name> &amp; <name><surname>Fujita</surname><given-names>I.</given-names></name> <article-title>Disparity selectivity of neurons in monkey inferior temporal cortex</article-title>. <source>J. Neurophysiol.</source> <volume>84</volume>, <fpage>120</fpage>–<lpage>132</lpage> (<year>2000</year>).<pub-id pub-id-type="pmid">10899190</pub-id></mixed-citation>
              </ref>
              <ref id="b73">
                <mixed-citation publication-type="journal"><name><surname>Watanabe</surname><given-names>M.</given-names></name>, <name><surname>Tanaka</surname><given-names>H.</given-names></name>, <name><surname>Uka</surname><given-names>T.</given-names></name> &amp; <name><surname>Fujita</surname><given-names>I.</given-names></name> <article-title>Disparity-selective neurons in area V4 of macaque monkeys</article-title>. <source>J. Neurophysiol.</source> <volume>87</volume>, <fpage>1960</fpage>–<lpage>1973</lpage> (<year>2002</year>).<pub-id pub-id-type="pmid">11929915</pub-id></mixed-citation>
              </ref>
              <ref id="b74">
                <mixed-citation publication-type="book"><name><surname>Gibson</surname><given-names>J. J.</given-names></name><source>The Ecological Approach to Visual Perception</source> (Houghton Mifflin, Boston, <year>1979</year>).</mixed-citation>
              </ref>
              <ref id="b75">
                <mixed-citation publication-type="book"><name><surname>Marr</surname><given-names>D.</given-names></name><source>Vision</source> (Freeman, San Francisco, <year>1982</year>).</mixed-citation>
              </ref>
              <ref id="b76">
                <mixed-citation publication-type="journal"><name><surname>Ashbridge</surname><given-names>E.</given-names></name>, <name><surname>Perrett</surname><given-names>D. I.</given-names></name>, <name><surname>Oram</surname><given-names>M. W.</given-names></name> &amp; <name><surname>Jellema</surname><given-names>T.</given-names></name> <article-title>Effect of image orientation and size on object recognition: responses of single units in the macaque monkey temporal cortex</article-title>. <source>Cogn. Neuropsychol.</source> <volume>17</volume>, <fpage>13</fpage>–<lpage>34</lpage> (<year>2000</year>).<pub-id pub-id-type="pmid">20945169</pub-id></mixed-citation>
              </ref>
              <ref id="b77">
                <mixed-citation publication-type="journal"><name><surname>Chainay</surname><given-names>H.</given-names></name> &amp; <name><surname>Humphreys</surname><given-names>G. W.</given-names></name> <article-title>The real-object advantage in agnosia: Evidence for a role of surface and depth information in object recognition</article-title>. <source>Cogn. Neuropsychol.</source> <volume>18</volume>, <fpage>175</fpage>–<lpage>191</lpage> (<year>2001</year>).<pub-id pub-id-type="pmid">20945210</pub-id></mixed-citation>
              </ref>
              <ref id="b78">
                <mixed-citation publication-type="journal"><name><surname>Hiraoka</surname><given-names>K.</given-names></name>, <name><surname>Suzuki</surname><given-names>K.</given-names></name>, <name><surname>Hirayama</surname><given-names>K.</given-names></name> &amp; <name><surname>Mori</surname><given-names>E.</given-names></name> <article-title>Visual agnosia for line drawings and silhouettes without apparent impairment of real-object recognition: a case report</article-title>. <source>Behav. Neurol.</source> <volume>21</volume>, <fpage>187</fpage>–<lpage>192</lpage> (<year>2009</year>).<pub-id pub-id-type="pmid">19996516</pub-id></mixed-citation>
              </ref>
              <ref id="b79">
                <mixed-citation publication-type="journal"><name><surname>Servos</surname><given-names>P.</given-names></name>, <name><surname>Goodale</surname><given-names>M. A.</given-names></name> &amp; <name><surname>Humphrey</surname><given-names>G. K.</given-names></name> <article-title>The drawing of objects by a visual form agnosic: contribution of surface properties and memorial representations</article-title>. <source>Neuropsychologia</source> <volume>31</volume>, <fpage>251</fpage>–<lpage>259</lpage> (<year>1993</year>).<pub-id pub-id-type="pmid">8492878</pub-id></mixed-citation>
              </ref>
              <ref id="b80">
                <mixed-citation publication-type="journal"><name><surname>Humphrey</surname><given-names>G. K.</given-names></name>, <name><surname>Goodale</surname><given-names>M. A.</given-names></name>, <name><surname>Jakobson</surname><given-names>L. S.</given-names></name> &amp; <name><surname>Servos</surname><given-names>P.</given-names></name> <article-title>The role of surface information in object recognition: studies of a visual form agnosic and normal subjects</article-title>. <source>Perception</source> <volume>23</volume>, <fpage>1457</fpage>–<lpage>1481</lpage> (<year>1994</year>).<pub-id pub-id-type="pmid">7792135</pub-id></mixed-citation>
              </ref>
              <ref id="b81">
                <mixed-citation publication-type="journal"><name><surname>Turnbull</surname><given-names>O. H.</given-names></name>, <name><surname>Driver</surname><given-names>J.</given-names></name> &amp; <name><surname>McCarthy</surname><given-names>R. A.</given-names></name> <article-title>2D but not 3D: pictorial-depth deficits in a case of visual agnosia</article-title>. <source>Cortex</source> <volume>40</volume>, <fpage>723</fpage>–<lpage>738</lpage> (<year>2004</year>).<pub-id pub-id-type="pmid">15505981</pub-id></mixed-citation>
              </ref>
              <ref id="b82">
                <mixed-citation publication-type="journal"><name><surname>Bushong</surname><given-names>B.</given-names></name>, <name><surname>King</surname><given-names>L. M.</given-names></name>, <name><surname>Camerer</surname><given-names>C. F.</given-names></name> &amp; <name><surname>Rangel</surname><given-names>A.</given-names></name> <article-title>Pavlovian Processes in Consumer Choice: The Physical Presence of a Good Increases Willingness-to-Pay</article-title>. <source>Am. Econ. Rev.</source> <volume>100</volume>, <fpage>1556</fpage>–<lpage>1571</lpage> (<year>2010</year>).</mixed-citation>
              </ref>
              <ref id="b83">
                <mixed-citation publication-type="journal"><name><surname>Vinberg</surname><given-names>J.</given-names></name> &amp; <name><surname>Grill-Spector</surname><given-names>K.</given-names></name> <article-title>Representation of shapes, edges, and surfaces across multiple cues in the human visual cortex</article-title>. <source>J. Neurophysiol.</source> <volume>99</volume>, <fpage>1380</fpage>–<lpage>1393</lpage> (<year>2008</year>).<pub-id pub-id-type="pmid">18171705</pub-id></mixed-citation>
              </ref>
              <ref id="b84">
                <mixed-citation publication-type="journal"><name><surname>De Baene</surname><given-names>W.</given-names></name> &amp; <name><surname>Vogels</surname><given-names>R.</given-names></name> <article-title>Effects of adaptation on the stimulus selectivity of macaque inferior temporal spiking activity and local field potentials</article-title>. <source>Cereb. Cortex</source> <volume>20</volume>, <fpage>2145</fpage>–<lpage>2165</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">20038542</pub-id></mixed-citation>
              </ref>
              <ref id="b85">
                <mixed-citation publication-type="journal"><name><surname>Mur</surname><given-names>M.</given-names></name>, <name><surname>Ruff</surname><given-names>D. A.</given-names></name>, <name><surname>Bodurka</surname><given-names>J.</given-names></name>, <name><surname>Bandettini</surname><given-names>P. A.</given-names></name> &amp; <name><surname>Kriegeskorte</surname><given-names>N.</given-names></name> <article-title>Face-identity change activation outside the face system: "release from adaptation" may not always indicate neuronal selectivity</article-title>. <source>Cereb. Cortex</source> <volume>20</volume>, <fpage>2027</fpage>–<lpage>2042</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">20051364</pub-id></mixed-citation>
              </ref>
              <ref id="b86">
                <mixed-citation publication-type="journal"><name><surname>Tolias</surname><given-names>A. S.</given-names></name>, <name><surname>Keliris</surname><given-names>G. A.</given-names></name>, <name><surname>Smirnakis</surname><given-names>S. M.</given-names></name> &amp; <name><surname>Logothetis</surname><given-names>N. K.</given-names></name> <article-title>Neurons in macaque area V4 acquire directional tuning after adaptation to motion stimuli</article-title>. <source>Nat. Neurosci.</source> <volume>8</volume>, <fpage>591</fpage>–<lpage>593</lpage> (<year>2005</year>).<pub-id pub-id-type="pmid">15834417</pub-id></mixed-citation>
              </ref>
              <ref id="b87">
                <mixed-citation publication-type="journal"><name><surname>Sawamura</surname><given-names>H.</given-names></name>, <name><surname>Orban</surname><given-names>G. A.</given-names></name> &amp; <name><surname>Vogels</surname><given-names>R.</given-names></name> <article-title>Selectivity of neuronal adaptation does not match response selectivity: a single-cell study of the FMRI adaptation paradigm</article-title>. <source>Neuron</source> <volume>49</volume>, <fpage>307</fpage>–<lpage>318</lpage> (<year>2006</year>).<pub-id pub-id-type="pmid">16423703</pub-id></mixed-citation>
              </ref>
              <ref id="b88">
                <mixed-citation publication-type="journal"><name><surname>Marsolek</surname><given-names>C. J.</given-names></name><article-title>What antipriming reveals about priming</article-title>. <source>Trends Cogn. Sci.</source><volume>12</volume>, <fpage>176</fpage>–<lpage>181</lpage> (<year>2008</year>).<pub-id pub-id-type="pmid">18403251</pub-id></mixed-citation>
              </ref>
              <ref id="b89">
                <mixed-citation publication-type="journal"><name><surname>Marsolek</surname><given-names>C. J.</given-names></name><italic>, </italic><italic>et al.</italic>. <article-title>Identifying objects impairs knowledge of other objects: a relearning explanation for the neural repetition effect</article-title>. <source>Neuroimage</source><volume>49</volume>, <fpage>1919</fpage>–<lpage>1932</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">19744565</pub-id></mixed-citation>
              </ref>
              <ref id="b90">
                <mixed-citation publication-type="book"><name><surname>Proffitt</surname><given-names>D. R.</given-names></name><article-title>An Action Specific Approach to Spatial Perception</article-title>. in <source>Embodiment, Ego-Space, and Action</source> (ed. Klatzky R. L., , MacWhinney B.,  &amp; Behrmann M., eds. ) <fpage>177</fpage>–<lpage>201</lpage> (Psychology Press, New York, <year>2008</year>).</mixed-citation>
              </ref>
              <ref id="b91">
                <mixed-citation publication-type="journal"><name><surname>Proffitt</surname><given-names>D. R.</given-names></name>, <name><surname>Creem</surname><given-names>S. H.</given-names></name> &amp; <name><surname>Zosh</surname><given-names>W. D.</given-names></name> <article-title>Seeing mountains in mole hills: geographical-slant perception</article-title>. <source>Psychol. Sci.</source> <volume>12</volume>, <fpage>418</fpage>–<lpage>423</lpage> (<year>2001</year>).<pub-id pub-id-type="pmid">11554677</pub-id></mixed-citation>
              </ref>
              <ref id="b92">
                <mixed-citation publication-type="book"><name><surname>Talairach</surname><given-names>J.</given-names></name> &amp; <name><surname>Tournoux</surname><given-names>P.</given-names></name> <source>Co-Planar Stereotaxic Atlas of the Human brain</source> (Thieme Medical Publishers, New York, <year>1988</year>).</mixed-citation>
              </ref>
              <ref id="b93">
                <mixed-citation publication-type="journal"><name><surname>Konen</surname><given-names>C. S.</given-names></name>, <name><surname>Behrmann</surname><given-names>M.</given-names></name>, <name><surname>Nishimura</surname><given-names>M.</given-names></name> &amp; <name><surname>Kastner</surname><given-names>S.</given-names></name> <article-title>The functional neuroanatomy of object agnosia: a case study</article-title>. <source>Neuron</source> <volume>71</volume>, <fpage>49</fpage>–<lpage>60</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">21745637</pub-id></mixed-citation>
              </ref>
            </ref-list>
          </back>
          <floats-group>
            <fig id="f1">
              <label>Figure 1</label>
              <caption>
                <title>Experimental setup, stimulus items and fMRI trial sequence.</title>
                <p>(a) Participants lay supine in the MR scanner with the head supported within the lower portion (6 elements) of an inclined 12-channel head coil. A 4-channel flex coil was positioned over the front of the head. The head coil was tilted forward by ∼30<sup>o</sup> to enable direct viewing of stimuli. 2D pictures and 3D object stimuli (illustrated above) were mounted by the experimenter on a turntable positioned over the waist. The experiment was conducted in complete darkness and all trials recorded using an infra-red camera. Stimulus presentation duration was controlled by an LED (illuminator). Participants were asked to identify the objects presented on each trial while maintaining fixation on a single red LED positioned just above the stimulus plane. (b) Six sets of 5 stimulus exemplar objects were used in the fMRI-A experiment (30 in total). A different set of stimulus items was used in each run to prevent cross-adaptation. 3D stimuli from ‘Set 1' are depicted in (a) and (c). (c) Example trial sequence. Each stimulus item was presented for 500ms within a 3 sec inter-stimulus interval. Stimuli for each upcoming trial were positioned on the turntable during the 20 sec inter-trial interval.</p>
              </caption>
              <graphic xlink:href="srep00130-f1"/>
            </fig>
            <fig id="f2">
              <label>Figure 2</label>
              <caption>
                <title>Timecourse of fMRI signals within LO and pFS for 2D-pictures and 3D-objects.</title>
                <p>Data are group results (n = 13). (a–b) Upper panels show responses within LO for Different versus Repeat 2D-pictures (left) or real 3D-objects (right). (c–d) Lower panels show responses within pFS for Different versus Repeat 2D-pictures (left) or real 3D-objects (right). (—) Trials in which a different stimulus appeared on each trial (Different condition). (---) Trials in which identical stimuli appeared (Repeat condition).</p>
              </caption>
              <graphic xlink:href="srep00130-f2"/>
            </fig>
            <fig id="f3">
              <label>Figure 3</label>
              <caption>
                <title>Repetition effects for 2D pictures and 3D objects within LO and pFS.</title>
                <p>The magnitude of repetition effects for each stimulus type within each region was quantified using an Adaptation Index (AI)<xref ref-type="bibr" rid="b4">4</xref><xref ref-type="bibr" rid="b93">93</xref>. The AI represents differences in responses between Repeat and Different conditions relative to the overall fMRI response, thereby providing a measure of repetition effects scaled according to activation levels for each stimulus in each ROI. Positive index values reflect higher responses on Different than Repeat trials; negative values indicate the reverse pattern and values around zero indicate a lack of repetition effects. To provide meaningful data interpretation in a within-subjects design, error bars for the difference scores are based on the 95% confidence intervals, which indicate whether or not the average difference was significantly greater than zero (with probabilities equal to those from the t-test).</p>
              </caption>
              <graphic xlink:href="srep00130-f3"/>
            </fig>
            <fig id="f4">
              <label>Figure 4</label>
              <caption>
                <title>Group functional activation for the contrast [2D-Different &gt; 2D-Repeat] in the whole-brain voxel-wise analysis.</title>
                <p>Activation is overlaid on the inflated cortical surface of a representative observer. Widespread repetition-based changes in activation for pictures of objects were observed across temporal and parietal cortex. Conversely, no such activation changes were identified for real 3D objects [i.e., using the contrast 3D-Different &gt; 3D-Repeat] at the same threshold. Dorsal surface (far left), Right Hemisphere (top middle), Left Hemisphere (lower middle) and Ventral Surface (far right). Sulci are represented in dark grey and gyri in light grey.</p>
              </caption>
              <graphic xlink:href="srep00130-f4"/>
            </fig>
            <fig id="f5">
              <label>Figure 5</label>
              <caption>
                <title>Loci of additional group-based region of interest (ROI) analyses displayed on the inflated cortex of a representative subject.</title>
                <p>The cortex is illustrated from a posterior-ventral viewpoint. Group-based region of interest analyses were conducted at the marked loci in each hemisphere (see <xref ref-type="supplementary-material" rid="s1">Supplementary Table</xref> 1). (A–I): Sites within occipital cortex, intraparietal sulcus, inferior temporal gyrus and premotor cortex in which second-order disparity-selective neurons are thought to extract and process 3D depth structure from stereo<xref ref-type="bibr" rid="b39">39</xref>. Points (H–I) lie anterior to the central sulcus and are not visible from the above viewpoint. (J–M): Topographically organized areas within the intraparietal sulcus (IPS) areas 1–4, as reported by Konen &amp; Kastner<xref ref-type="bibr" rid="b4">4</xref>. Using a variety of 2D greyscale picture stimuli these authors report significant adaptation effects within IPS1 and IPS2, but not more dorsally within IPS 3 and IPS4. (K) Loci correspond to LOtv, located along the ventro-lateral bank of the temporal lobe<xref ref-type="bibr" rid="b43">43</xref>. Area LOtv is selective for both visual and haptic object properties and is argued to support abstract 3D shape representations. (A) V3A complex (1); (B) V3A complex 2; (C) ITG; (D) VIPS/V7; (E) POIPS; (F) DIPSM; (G) DIPSA; (H) dPrCS; (I) vPrCS; (J) IPS1; (K) IPS2; (L) IPS3; (M) IPS4; (N) LO<sub>TV</sub>. (See also Table S1.)</p>
              </caption>
              <graphic xlink:href="srep00130-f5"/>
            </fig>
            <table-wrap position="float" id="t1">
              <label>Table 1</label>
              <caption>
                <title>Voxelwise Group Results. Talairach coordinates and cluster size for identified regions.</title>
              </caption>
              <table frame="hsides" rules="groups" border="1">
                <colgroup>
                  <col align="left"/>
                  <col align="center"/>
                  <col align="center"/>
                  <col align="center"/>
                  <col align="center"/>
                </colgroup>
                <thead valign="bottom">
                  <tr>
                    <th align="left" valign="top" charoff="50"> </th>
                    <th colspan="3" align="center" valign="top" charoff="50">Talairach Coordinates</th>
                    <th align="center" valign="top" charoff="50">Cluster Size</th>
                  </tr>
                  <tr>
                    <th align="left" valign="top" charoff="50">Contrast Region</th>
                    <th align="center" valign="top" charoff="50">
                      <italic>x</italic>
                    </th>
                    <th align="center" valign="top" charoff="50">
                      <italic>y</italic>
                    </th>
                    <th align="center" valign="top" charoff="50">
                      <italic>z</italic>
                    </th>
                    <th align="center" valign="top" charoff="50">Volume (mm3)</th>
                  </tr>
                </thead>
                <tbody valign="top">
                  <tr>
                    <td align="left" valign="top" charoff="50">
                      <bold>Different &gt; Repeat</bold>
                    </td>
                    <td align="left" valign="top" charoff="50"> </td>
                    <td align="left" valign="top" charoff="50"> </td>
                    <td align="left" valign="top" charoff="50"> </td>
                    <td align="left" valign="top" charoff="50"> </td>
                  </tr>
                  <tr>
                    <td colspan="5" align="justify" valign="top" charoff="50">
                      <bold>2D Pictures: [2D Different &gt; 2D Repeat]</bold>
                    </td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">(*<italic>See </italic><xref ref-type="fig" rid="f4">Figure 4</xref>)</td>
                    <td align="left" valign="top" charoff="50"> </td>
                    <td align="left" valign="top" charoff="50"> </td>
                    <td align="left" valign="top" charoff="50"> </td>
                    <td align="left" valign="top" charoff="50"> </td>
                  </tr>
                  <tr>
                    <td colspan="5" align="justify" valign="top" charoff="50">
                      <bold>3D Objects: [3D Different &gt; 3D Repeat]</bold>
                    </td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">-</td>
                    <td align="center" valign="top" charoff="50">-</td>
                    <td align="center" valign="top" charoff="50">-</td>
                    <td align="center" valign="top" charoff="50">-</td>
                    <td align="center" valign="top" charoff="50">-</td>
                  </tr>
                  <tr>
                    <td colspan="5" align="left" valign="top" charoff="50">
                      <bold>Repeat &gt; Different</bold>
                    </td>
                  </tr>
                  <tr>
                    <td colspan="5" align="justify" valign="top" charoff="50">
                      <bold>2D Pictures: [2D Repeat &gt; 2D Different]</bold>
                    </td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">-</td>
                    <td align="center" valign="top" charoff="50">-</td>
                    <td align="center" valign="top" charoff="50">-</td>
                    <td align="center" valign="top" charoff="50">-</td>
                    <td align="center" valign="top" charoff="50">-</td>
                  </tr>
                  <tr>
                    <td colspan="5" align="left" valign="top" charoff="50">
                      <bold>3D Objects: [3D Repeat &gt; 3D Different]</bold>
                    </td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">Right superior temporal sulcus</td>
                    <td align="center" valign="top" charoff="50">47</td>
                    <td align="center" valign="top" charoff="50">−35</td>
                    <td align="center" valign="top" charoff="50">3</td>
                    <td align="center" valign="top" charoff="50">433</td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">Right insula</td>
                    <td align="center" valign="top" charoff="50">39</td>
                    <td align="center" valign="top" charoff="50">10</td>
                    <td align="center" valign="top" charoff="50">−1</td>
                    <td align="center" valign="top" charoff="50">204</td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">Right inferior frontal gyrus</td>
                    <td align="center" valign="top" charoff="50">49</td>
                    <td align="center" valign="top" charoff="50">15</td>
                    <td align="center" valign="top" charoff="50">17</td>
                    <td align="center" valign="top" charoff="50">542</td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">Right cingulate sulcus / superior frontal gyrus</td>
                    <td align="center" valign="top" charoff="50">12</td>
                    <td align="center" valign="top" charoff="50">38</td>
                    <td align="center" valign="top" charoff="50">28</td>
                    <td align="center" valign="top" charoff="50">238</td>
                  </tr>
                  <tr>
                    <td colspan="5" align="justify" valign="top" charoff="50">
                      <bold>MAIN EFFECTS</bold>
                    </td>
                  </tr>
                  <tr>
                    <td colspan="5" align="justify" valign="top" charoff="50">
                      <bold>Main Effect Stimulus Type [2D &gt; 3D]</bold>
                    </td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">Right V1 (posterior calcarine)</td>
                    <td align="center" valign="top" charoff="50">9</td>
                    <td align="center" valign="top" charoff="50">−96</td>
                    <td align="center" valign="top" charoff="50">−2</td>
                    <td align="center" valign="top" charoff="50">318</td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">Right Inferior temporal gyrus</td>
                    <td align="center" valign="top" charoff="50">52</td>
                    <td align="center" valign="top" charoff="50">−18</td>
                    <td align="center" valign="top" charoff="50">−14</td>
                    <td align="center" valign="top" charoff="50">149</td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">
                      <bold>Main Effect Stimulus Type [3D &gt; 2D]</bold>
                    </td>
                    <td align="left" valign="top" charoff="50"> </td>
                    <td align="left" valign="top" charoff="50"> </td>
                    <td align="left" valign="top" charoff="50"> </td>
                    <td align="left" valign="top" charoff="50"> </td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">-</td>
                    <td align="center" valign="top" charoff="50">-</td>
                    <td align="center" valign="top" charoff="50">-</td>
                    <td align="center" valign="top" charoff="50">-</td>
                    <td align="center" valign="top" charoff="50">-</td>
                  </tr>
                  <tr>
                    <td colspan="5" align="justify" valign="top" charoff="50">
                      <bold>INTERACTION EFFECTS</bold>
                    </td>
                  </tr>
                  <tr>
                    <td colspan="5" align="left" valign="top" charoff="50">
                      <bold>Interaction Effect: 2D-Repetition Effects &gt; 3D-Repetition Effects [2D Different + 3D Repeat &gt; 2D Repeat + 3D Different]</bold>
                    </td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">Left lingual gyrus</td>
                    <td align="center" valign="top" charoff="50">−17</td>
                    <td align="center" valign="top" charoff="50">−39</td>
                    <td align="center" valign="top" charoff="50">−6</td>
                    <td align="center" valign="top" charoff="50">55</td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">Left fusiform gyrus</td>
                    <td align="center" valign="top" charoff="50">−20</td>
                    <td align="center" valign="top" charoff="50">−48</td>
                    <td align="center" valign="top" charoff="50">−3</td>
                    <td align="center" valign="top" charoff="50">647</td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">Right fusiform gyrus</td>
                    <td align="center" valign="top" charoff="50">38</td>
                    <td align="center" valign="top" charoff="50">−53</td>
                    <td align="center" valign="top" charoff="50">−3</td>
                    <td align="center" valign="top" charoff="50">284</td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">Left parieto-occipital fissure</td>
                    <td align="center" valign="top" charoff="50">−14</td>
                    <td align="center" valign="top" charoff="50">−60</td>
                    <td align="center" valign="top" charoff="50">8</td>
                    <td align="center" valign="top" charoff="50">916</td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">Left superior temporal sulcus</td>
                    <td align="center" valign="top" charoff="50">−50</td>
                    <td align="center" valign="top" charoff="50">−47</td>
                    <td align="center" valign="top" charoff="50">10</td>
                    <td align="center" valign="top" charoff="50">557</td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">Right superior temporal sulcus − anterior</td>
                    <td align="center" valign="top" charoff="50">59</td>
                    <td align="center" valign="top" charoff="50">−36</td>
                    <td align="center" valign="top" charoff="50">9</td>
                    <td align="center" valign="top" charoff="50">401</td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">Right superior temporal sulcus − posterior</td>
                    <td align="center" valign="top" charoff="50">49</td>
                    <td align="center" valign="top" charoff="50">−48</td>
                    <td align="center" valign="top" charoff="50">17</td>
                    <td align="center" valign="top" charoff="50">322</td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">Right thalamus</td>
                    <td align="center" valign="top" charoff="50">13</td>
                    <td align="center" valign="top" charoff="50">−24</td>
                    <td align="center" valign="top" charoff="50">8</td>
                    <td align="center" valign="top" charoff="50">208</td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">Right precuneus</td>
                    <td align="center" valign="top" charoff="50">10</td>
                    <td align="center" valign="top" charoff="50">−48</td>
                    <td align="center" valign="top" charoff="50">29</td>
                    <td align="center" valign="top" charoff="50">210</td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">Right middle frontal gyrus</td>
                    <td align="center" valign="top" charoff="50">47</td>
                    <td align="center" valign="top" charoff="50">22</td>
                    <td align="center" valign="top" charoff="50">39</td>
                    <td align="center" valign="top" charoff="50">195</td>
                  </tr>
                  <tr>
                    <td colspan="5" align="left" valign="top" charoff="50">
                      <bold>Interaction Effect: 3D-Repetition Effects &gt; 2D-Repetition Effects [3D Different + 2D Repeat &gt; 3D Repeat + 2D Different]</bold>
                    </td>
                  </tr>
                  <tr>
                    <td align="left" valign="top" charoff="50">-</td>
                    <td align="center" valign="top" charoff="50">-</td>
                    <td align="center" valign="top" charoff="50">-</td>
                    <td align="center" valign="top" charoff="50">-</td>
                    <td align="center" valign="top" charoff="50">-</td>
                  </tr>
                </tbody>
              </table>
              <table-wrap-foot>
                <fn id="t1-fn1">
                  <p>Regions for each contrast were identified using p&lt;0.005 in a random-effects voxelwise analysis, and cluster size threshold of 5 functional voxels of 3 mm<sup>3</sup> each. “-“ signifies that no activation was observed that met threshold. Activated areas for the contrast [2D Different &gt; 2D Repeat] (i.e., 2D-repetition effects) was extensive and is therefore displayed in <xref ref-type="fig" rid="f4">Figure 4</xref>.</p>
                </fn>
              </table-wrap-foot>
            </table-wrap>
          </floats-group>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
