<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2024-05-03T05:03:51Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:7027056" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:7027056</identifier>
        <datestamp>2020-02-24</datestamp>
        <setSpec>jneurorehab</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" article-type="research-article">
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">J Neuroeng Rehabil</journal-id>
              <journal-id journal-id-type="iso-abbrev">J Neuroeng Rehabil</journal-id>
              <journal-title-group>
                <journal-title>Journal of NeuroEngineering and Rehabilitation</journal-title>
              </journal-title-group>
              <issn pub-type="epub">1743-0003</issn>
              <publisher>
                <publisher-name>BioMed Central</publisher-name>
                <publisher-loc>London</publisher-loc>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC7027056</article-id>
              <article-id pub-id-type="pmcid">PMC7027056</article-id>
              <article-id pub-id-type="pmc-uid">7027056</article-id>
              <article-id pub-id-type="pmid">32066467</article-id>
              <article-id pub-id-type="publisher-id">642</article-id>
              <article-id pub-id-type="doi">10.1186/s12984-020-0642-5</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Research</subject>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>Exercising with Baxter: preliminary support for assistive social-physical human-robot interaction</article-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author" corresp="yes">
                  <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6759-5948</contrib-id>
                  <name>
                    <surname>Fitter</surname>
                    <given-names>Naomi T.</given-names>
                  </name>
                  <address>
                    <email>naomi.fitter@oregonstate.edu</email>
                  </address>
                  <xref ref-type="aff" rid="Aff1">1</xref>
                  <xref ref-type="aff" rid="Aff2">2</xref>
                </contrib>
                <contrib contrib-type="author">
                  <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-0732-4476</contrib-id>
                  <name>
                    <surname>Mohan</surname>
                    <given-names>Mayumi</given-names>
                  </name>
                  <address>
                    <email>maymohan@is.mpg.de</email>
                  </address>
                  <xref ref-type="aff" rid="Aff3">3</xref>
                  <xref ref-type="aff" rid="Aff4">4</xref>
                </contrib>
                <contrib contrib-type="author">
                  <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5004-0313</contrib-id>
                  <name>
                    <surname>Kuchenbecker</surname>
                    <given-names>Katherine J.</given-names>
                  </name>
                  <address>
                    <email>kjk@is.mpg.de</email>
                  </address>
                  <xref ref-type="aff" rid="Aff2">2</xref>
                  <xref ref-type="aff" rid="Aff3">3</xref>
                </contrib>
                <contrib contrib-type="author">
                  <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7964-0304</contrib-id>
                  <name>
                    <surname>Johnson</surname>
                    <given-names>Michelle J.</given-names>
                  </name>
                  <address>
                    <email>Michelle.Johnson2@uphs.upenn.edu</email>
                  </address>
                  <xref ref-type="aff" rid="Aff2">2</xref>
                  <xref ref-type="aff" rid="Aff4">4</xref>
                </contrib>
                <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.4391.f</institution-id><institution-id institution-id-type="ISNI">0000 0001 2112 1969</institution-id><institution>Collaborative Robotics and Intelligent Systems Institute, Oregon State University, </institution></institution-wrap>Corvallis, OR USA </aff>
                <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.25879.31</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8972</institution-id><institution>Department of Mechanical Engineering and Applied Mechanics, University of Pennsylvania, </institution></institution-wrap>Philadelphia, PA USA </aff>
                <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.419534.e</institution-id><institution-id institution-id-type="ISNI">0000 0001 1015 6533</institution-id><institution>Haptic Intelligence Department, Max Planck Institute for Intelligent Systems, </institution></institution-wrap>Stuttgart, Germany </aff>
                <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.25879.31</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8972</institution-id><institution>Department of Physical Medicine and Rehabilitation, University of Pennsylvania, </institution></institution-wrap>Philadelphia, PA USA </aff>
              </contrib-group>
              <pub-date pub-type="epub">
                <day>17</day>
                <month>2</month>
                <year>2020</year>
              </pub-date>
              <pub-date pub-type="pmc-release">
                <day>17</day>
                <month>2</month>
                <year>2020</year>
              </pub-date>
              <pub-date pub-type="collection">
                <year>2020</year>
              </pub-date>
              <volume>17</volume>
              <elocation-id>19</elocation-id>
              <history>
                <date date-type="received">
                  <day>15</day>
                  <month>6</month>
                  <year>2019</year>
                </date>
                <date date-type="accepted">
                  <day>13</day>
                  <month>1</month>
                  <year>2020</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>© The Author(s) 2020</copyright-statement>
                <license license-type="OpenAccess">
                  <license-p><bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License(<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
                </license>
              </permissions>
              <abstract id="Abs1">
                <sec>
                  <title>Background</title>
                  <p id="Par1">The worldwide population of older adults will soon exceed the capacity of assisted living facilities. Accordingly, we aim to understand whether appropriately designed robots could help older adults stay active at home.</p>
                </sec>
                <sec>
                  <title>Methods</title>
                  <p id="Par2">Building on related literature as well as guidance from experts in game design, rehabilitation, and physical and occupational therapy, we developed eight human-robot exercise games for the Baxter Research Robot, six of which involve physical human-robot contact. After extensive iteration, these games were tested in an exploratory user study including 20 younger adult and 20 older adult users.</p>
                </sec>
                <sec>
                  <title>Results</title>
                  <p id="Par3">Only socially and physically interactive games fell in the highest ranges for pleasantness, enjoyment, engagement, cognitive challenge, and energy level. Our games successfully spanned three different physical, cognitive, and temporal challenge levels. User trust and confidence in Baxter increased significantly between pre- and post-study assessments. Older adults experienced higher exercise, energy, and engagement levels than younger adults, and women rated the robot more highly than men on several survey questions.</p>
                </sec>
                <sec>
                  <title>Conclusions</title>
                  <p id="Par4">The results indicate that social-physical exercise with a robot is more pleasant, enjoyable, engaging, cognitively challenging, and energetic than similar interactions that lack physical touch. In addition to this main finding, researchers working in similar areas can build on our design practices, our open-source resources, and the age-group and gender differences that we found.</p>
                </sec>
              </abstract>
              <kwd-group xml:lang="en">
                <title>Keywords</title>
                <kwd>Socially assistive robotics</kwd>
                <kwd>Physical human-robot interaction</kwd>
                <kwd>Exercise games</kwd>
                <kwd>Personal robots</kwd>
              </kwd-group>
              <funding-group>
                <award-group>
                  <funding-source>
                    <institution-wrap>
                      <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id>
                      <institution>National Science Foundation</institution>
                    </institution-wrap>
                  </funding-source>
                  <award-id>DGE-0822</award-id>
                </award-group>
              </funding-group>
              <funding-group>
                <award-group>
                  <funding-source>
                    <institution-wrap>
                      <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id>
                      <institution>National Science Foundation</institution>
                    </institution-wrap>
                  </funding-source>
                  <award-id>0966142</award-id>
                </award-group>
              </funding-group>
              <custom-meta-group>
                <custom-meta>
                  <meta-name>issue-copyright-statement</meta-name>
                  <meta-value>© The Author(s) 2020</meta-value>
                </custom-meta>
              </custom-meta-group>
            </article-meta>
          </front>
          <body>
            <sec id="Sec1">
              <title>Background</title>
              <p>Increases in life expectancy foreshadow the need for more accessible healthcare solutions in the United States and beyond [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. Society will soon encounter limits not only on the capacity of assisted living facilities, but also on medical services at large. Thus, solutions that bolster the health of older adults while allowing them to live independently will become more important. One strategy to enhance our society’s ability to keep older adults <bold>healthy and active</bold> in their homes is the introduction of assistive robots in everyday environments.</p>
              <p>A key contribution of this work is understanding how robots with <bold>social interaction skills</bold><italic>and</italic><bold>dynamic physical interaction skills</bold> can <italic>encourage exercise</italic>. Generally, low-impact exercises are recommended to keep older individuals cognitively and physically well [<xref ref-type="bibr" rid="CR3">3</xref>–<xref ref-type="bibr" rid="CR5">5</xref>]. Researchers have already found that robotic exoskeletons can promote upper-limb exercise by physically interacting with human users [<xref ref-type="bibr" rid="CR6">6</xref>]. Other investigations have indicated that robots can motivate older adults to stay active via social exercise encouragement [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>]. As pictured in Fig. <xref rid="Fig1" ref-type="fig">1</xref>, the exercise games we designed fit at the <bold>new intersection</bold> of physical human-robot interaction and socially assistive robotics. <italic>Our central goal is to determine whether and how a robot can encourage enjoyable light exercise via social-physical exercise games.</italic><fig id="Fig1"><label>Fig. 1</label><caption><p>Example human-robot exercise game interaction. Our customization of this robot’s facial expressions and end-effectors help Baxter serve as a gameplay partner</p></caption><graphic xlink:href="12984_2020_642_Fig1_HTML" id="MO1"/></fig></p>
              <p>This research builds on our previous investigations of playful hand-clapping robots [<xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR10">10</xref>] by applying similar hardware, robot motion, and hand-contact detection strategies to accomplish a wider variety of physical human-robot interactions. Our work explores the use of the Rethink Robotics Baxter Research Robot to promote exercise via eight games, six of which involve dynamic physical human-robot interaction (pHRI). These activities were further designed for personalization to the physical and cognitive abilities of the user. Initial prototypes of these six pHRI games were described in [<xref ref-type="bibr" rid="CR11">11</xref>] and demonstrated at the 2017 ACM/IEEE International Conference on Human-Robot Interaction [<xref ref-type="bibr" rid="CR12">12</xref>].</p>
              <p>After we review the related work in the next subsection, the Human-Robot Exercise Game Design Section of this paper outlines our game design iteration steps. The Exploratory User Study Methods Section describes the proof-of-concept study that helped us judge the viability of using these games to engage older adults and promote exercise. The Results Section demonstrates that both younger and older people are willing to interact with the robot in playful exercise games and that only physically interactive games fell in the highest ranges for pleasantness, enjoyment, engagement, cognitive challenge, and energy level. The Discussion Section reviews the key points and future directions related to this work.</p>
              <sec id="Sec2">
                <title>Related work</title>
                <p>One of the key contributions of our present work is the investigation of exercise games that are both <bold>socially interactive</bold> and <bold>dynamically physically interactive</bold>. <italic>Although each characteristic has been explored in isolation, almost no socially assistive robots make physical contact with people, especially not in a dynamic and high-energy way.</italic> Touch is an essential pathway for human connection and emotion [<xref ref-type="bibr" rid="CR13">13</xref>], and we thus expect the incorporation of direct physical interaction into social robotic systems to lead to increased engagement and enjoyment. Physical interaction with the hands is of particular interest because it greatly aids human understanding and serves as a channel for complex sensation and expression [<xref ref-type="bibr" rid="CR14">14</xref>]. A few past projects began to combine social and physical human-robot interaction. The Haptic Creature Project, for example, explores an expressively actuated furry robotic companion that people treat in pet-like ways [<xref ref-type="bibr" rid="CR15">15</xref>]. The Paro [<xref ref-type="bibr" rid="CR16">16</xref>], Huggable [<xref ref-type="bibr" rid="CR17">17</xref>], and HuggieBot [<xref ref-type="bibr" rid="CR18">18</xref>] robots leverage physical interaction with people to comfort and support them. Our work explores a <bold>new and highly dynamic application of social touch</bold> with the potential to benefit the lives of older adults.</p>
                <p>While designing our dynamic social-physical human-robot exercise games, we considered past physical rehabilitation and exercise interventions involving hand contact and the use of assistive robots. Boxing is one hand-to-hand exercise strategy that has been used to help treat cerebral palsy and Parkinson’s Disease [<xref ref-type="bibr" rid="CR19">19</xref>, <xref ref-type="bibr" rid="CR20">20</xref>]. Low-impact exercises are generally recommended to keep people cognitively and physically well [<xref ref-type="bibr" rid="CR3">3</xref>]. A range of approaches can help facilitate this activity, such as robot exoskeletons [<xref ref-type="bibr" rid="CR21">21</xref>, <xref ref-type="bibr" rid="CR22">22</xref>] and robot end-effectors [<xref ref-type="bibr" rid="CR23">23</xref>] that promote upper-limb exercise by physically interacting with human users, robots that use social interaction to motivate a user to exercise [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>], and systems that encourage gamified arm motion by people with stroke [<xref ref-type="bibr" rid="CR24">24</xref>]. Music creation has additionally been used as a motivating factor in rehabilitation robotics [<xref ref-type="bibr" rid="CR25">25</xref>], and a past need-finding study with older adults found that the ability to play games, present music, and promote physical activity are among key design criteria for a robot in an assisted living community [<xref ref-type="bibr" rid="CR26">26</xref>]. Accordingly, investigations of robot play activities like dancing [<xref ref-type="bibr" rid="CR27">27</xref>], hugging [<xref ref-type="bibr" rid="CR28">28</xref>], and performing magic [<xref ref-type="bibr" rid="CR29">29</xref>] inform our interaction design and evaluation. The related work overall demonstrates that assistive robots using various combinations of social abilities, physical interaction abilities, and playful interaction premises can have distinct benefits for diverse groups of people, from offering enjoyable exercise to individuals with cerebral palsy to improving the well-being of older adults. We intend to <bold>better understand and leverage the unique advantages at the intersection of physical human-robot interaction and socially assistive robotics</bold> for human-robot exercise interactions.</p>
                <p>Our efforts were further influenced by past research on robotic assistants for older adult care. A survey of robots that support the independent living of older adults found that there has been a rapid evolution of technology in this area, and that most studies to date have been conducted in laboratories and hospital settings [<xref ref-type="bibr" rid="CR30">30</xref>]. Another review paper found evidence that socially assistive robots can enhance the well-being of older adults while reducing the workload for caregivers [<xref ref-type="bibr" rid="CR31">31</xref>], and other work suggests that older adults can adopt new technologies to support better diet and physical activity practices given proper training and guidance [<xref ref-type="bibr" rid="CR32">32</xref>]. Past ethnographic research provides best practices for introducing a robot into an assisted living facility while also presenting evidence that older adults accepted the robot into the community [<xref ref-type="bibr" rid="CR33">33</xref>]. Older adults on the whole are not more accepting of robots than younger adults, and some of the negative perceptions held by this age group are similar to those of the younger community [<xref ref-type="bibr" rid="CR34">34</xref>]. At the same time, past work has found younger and older adult users to uniformly prefer exercise games with a physical robot, compared to an onscreen image of a robot [<xref ref-type="bibr" rid="CR35">35</xref>, <xref ref-type="bibr" rid="CR36">36</xref>]. Older adults and stakeholders in older adult care also value designing robots to center on autonomy and resilience, not just potential challenges associated with aging [<xref ref-type="bibr" rid="CR37">37</xref>]. Thus, it is important to take care when designing robots for older adults and validate proposed interactions before introducing them in broader communities.</p>
              </sec>
            </sec>
            <sec id="Sec3">
              <title>Human-robot exercise game design</title>
              <p>To begin prototyping social-physical human-robot interactions for assistive applications, we needed to identify robotic hardware that is safe for physical interaction, consult with experts, and create a set of games that attempt to motivate different kinds of exercise.</p>
              <sec id="Sec4">
                <title>Hardware for exercise interactions</title>
                <p>Based on our past work identifying the Rethink Robotics Baxter Research Robot as a capable platform for social-physical interaction with people [<xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR10">10</xref>], we selected Baxter for the present investigation. This robot offers advantages for pHRI and exercise interactions because it is human-sized, anthropomorphic, and safe for physically interactive tasks. Baxter’s mechanical safety features include series elastic actuators, fully backdrivable joints, and impact-absorbing shells. The humanoid anatomy of this robot allows for an intuitive mapping of game motions to the human body, and it was available at the time at a relatively low price (∼$32,000).</p>
                <p>Baxter’s commercially available end-effectors proved unsuitable for our envisioned human-robot interactions. Instead, we used Everlast brand boxing pads that were easily placed over the standard parallel-jaw grippers as end-effectors. These lightweight pads allow users to interact quite forcefully with Baxter without pain or discomfort.</p>
                <p>External computer speakers were also incorporated into the system to add music and other sounds to game interactions. We used the Mingus synthesizer (a wrapper for the FluidSynth MIDI sound synthesizer) to compose, load, and play musical effects in the exercise games. FluidSynth requires a sound font file; we selected the OmegaGMGS2 sound font, which suited our purposes for playing different notes in various instrument modes.</p>
              </sec>
              <sec id="Sec5">
                <title>Gameplay design</title>
                <p>We designed eight games for users to play with Baxter: the Mimic, Stretch, Teach, Agility, Strength, Handclap, Roboga, and Flamenco Games shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. Our intention was to create safe and entertaining interactions that promote upper-limb movement while inducing a moderate level of physical and cognitive exercise. To promote social engagement, the games were augmented by a suite of facial expressions [<xref ref-type="bibr" rid="CR38">38</xref>] and nonverbal behaviors (blinking, changes in emotion, head movements, etc.) implemented using Baxter’s LCD screen and head joints. Music and audiovisual feedback were incorporated into many of the games in an effort to enhance motivation. Concise descriptions of each game follow:
<list list-type="bullet"><list-item><p>The <bold>Mimic Game</bold> is a “Simon Says”-style game during which the user teaches Baxter a pattern of left-, right-, and both-handed claps.
<fig id="Fig2"><label>Fig. 2</label><caption><p>Illustrative frames from the eight developed exercise games</p></caption><graphic xlink:href="12984_2020_642_Fig2_HTML" id="MO2"/></fig></p></list-item><list-item><p>In the <bold>Stretch Game</bold>, Baxter strikes a series of poses, and the user must mimic its pose and hit its end-effectors in each new pose.</p></list-item><list-item><p>In the <bold>Teach Game</bold>, the user can move Baxter’s arms to different positions to play and record musical chords mapped to its workspace.</p></list-item><list-item><p>The <bold>Agility Game</bold> challenges users to wake a “sleeping” Baxter by making rapid contact with its end-effectors.</p></list-item><list-item><p>The <bold>Strength Game</bold> is a boxing training-like interaction during which Baxter strikes a series of poses and prompts the user to contact its end-effectors.</p></list-item><list-item><p>In the <bold>Handclap Game</bold>, Baxter teaches the user a sequence of hand-clapping game motions and the user plays the game with the robot.</p></list-item><list-item><p>The <bold>Roboga Game</bold> (an abbreviated spelling of “Robot Yoga”) requires the user to match and hold stretching poses demonstrated by Baxter.</p></list-item><list-item><p>In the <bold>Flamenco Game</bold>, Baxter teaches the user a sequence of dance moves to music and the user replicates the dance along with the same music clip.</p></list-item></list></p>
                <p>Games varied across active, passive, or zero physical contact, as well as constant, intermittent, and zero sound. We list the corresponding overall expected sensory level of each game in Fig. <xref rid="Fig3" ref-type="fig">3</xref>. We further intended the designs to vary between lower or higher cognitive demand, lower or higher physical demand, lower or higher temporal demand, and competitive or cooperative premises, as summarized in Fig. <xref rid="Fig3" ref-type="fig">3</xref> and described in more detail in Appendix <xref rid="Sec23" ref-type="sec">Appendix A: Exercise Game Descriptions</xref> and the supplementary materials (Additional files <xref rid="MOESM1" ref-type="media">1</xref>, <xref rid="MOESM2" ref-type="media">2</xref>, <xref rid="MOESM3" ref-type="media">3</xref>, <xref rid="MOESM4" ref-type="media">4</xref>, <xref rid="MOESM5" ref-type="media">5</xref>, <xref rid="MOESM6" ref-type="media">6</xref>, <xref rid="MOESM7" ref-type="media">7</xref>, <xref rid="MOESM8" ref-type="media">8</xref>, <xref rid="MOESM9" ref-type="media">9</xref>, <xref rid="MOESM10" ref-type="media">10</xref>, <xref rid="MOESM11" ref-type="media">11</xref>, <xref rid="MOESM12" ref-type="media">12</xref>, <xref rid="MOESM13" ref-type="media">13</xref>, <xref rid="MOESM14" ref-type="media">14</xref>, <xref rid="MOESM15" ref-type="media">15</xref>, <xref rid="MOESM16" ref-type="media">16</xref>, and <xref rid="MOESM17" ref-type="media">17</xref>). This diversity of game characteristics allows us to consider how these factors affect user interaction experience.
<fig id="Fig3"><label>Fig. 3</label><caption><p>Intended game characteristics of each human-robot exercise game. Upward-facing arrows indicate more emergence of that row’s attribute, downward-facing arrows indicate less emergence, and dashes represent areas where we expected the game to be neutral on the given axis</p></caption><graphic xlink:href="12984_2020_642_Fig3_HTML" id="MO3"/></fig></p>
                <p>
                  <media xlink:href="12984_2020_642_MOESM2_ESM.mov" id="MOESM2">
                    <caption>
                      <p>Additional file 2: Video demonstration of the Mimic Game.</p>
                    </caption>
                  </media>
                </p>
                <p>
                  <media xlink:href="12984_2020_642_MOESM4_ESM.mov" id="MOESM4">
                    <caption>
                      <p>Additional file 4: Video demonstration of the Stretch Game.</p>
                    </caption>
                  </media>
                </p>
                <p>
                  <media xlink:href="12984_2020_642_MOESM6_ESM.mov" id="MOESM6">
                    <caption>
                      <p>Additional file 6: Video demonstration of the Teach Game.</p>
                    </caption>
                  </media>
                </p>
                <p>
                  <media xlink:href="12984_2020_642_MOESM8_ESM.mov" id="MOESM8">
                    <caption>
                      <p>Additional file 8: Video demonstration of the Agility Game.</p>
                    </caption>
                  </media>
                </p>
                <p>
                  <media xlink:href="12984_2020_642_MOESM10_ESM.mov" id="MOESM10">
                    <label>Additional file 10</label>
                    <caption>
                      <p>Video demonstration of the Strength Game.</p>
                    </caption>
                  </media>
                </p>
                <p>
                  <media xlink:href="12984_2020_642_MOESM12_ESM.mov" id="MOESM12">
                    <label>Additional file 12</label>
                    <caption>
                      <p>Video demonstration of the Handclap Game.</p>
                    </caption>
                  </media>
                </p>
                <p>
                  <media xlink:href="12984_2020_642_MOESM14_ESM.mov" id="MOESM14">
                    <label>Additional file 14</label>
                    <caption>
                      <p>Video demonstration of the Roboga Game.</p>
                    </caption>
                  </media>
                </p>
                <p>
                  <media xlink:href="12984_2020_642_MOESM16_ESM.mov" id="MOESM16">
                    <label>Additional file 16</label>
                    <caption>
                      <p>Video demonstration of the Flamenco Game.</p>
                    </caption>
                  </media>
                </p>
                <p>
                  <media xlink:href="12984_2020_642_MOESM17_ESM.mp4" id="MOESM17">
                    <label>Additional file 17</label>
                    <caption>
                      <p>Video demonstration and instructions for the eight exercise games.</p>
                    </caption>
                  </media>
                </p>
                <p>This work was informed by expert guidance from a game designer, a physical therapist, and an occupational therapist. Feedback throughout iterative design steps with these experts helped us to instill the games with clear social cues by Baxter, adaptive cognitive and physical difficulty levels, and fitting musical premises. These ideas are well supported by past work on designing effective exercise games for therapeutic interactions [<xref ref-type="bibr" rid="CR39">39</xref>–<xref ref-type="bibr" rid="CR41">41</xref>]. Throughout the games, the maximum hand-to-hand span of the robot was limited to the user’s height. For games with action speed requirements, we incrementally lowered the speed threshold for users with limited arm motion speed. Games with memory requirements were adjusted based on cognitive ability levels.</p>
              </sec>
            </sec>
            <sec id="Sec6">
              <title>Exploratory user study methods</title>
              <p>We conducted an exploratory user study to evaluate how people respond to prompts to play exercise games with Baxter and how such games may fit into assistive applications. Eligible participants played a sample segment of each game, immediately reported their perceptions of that game, and selected their favorite game to try again in a longer free-play interaction. The University of Pennsylvania (Penn) IRB approved all study procedures under protocol 826370.</p>
              <sec id="Sec7">
                <title>Study factors and covariates</title>
                <p>This experiment employed a within-subjects design that enabled all participants to experience all eight exercise games pictured in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. The experimenter read scripted instructions to each participant to prepare them for each semi-randomly ordered game interaction. When referring to each game, the experimenter used only a letter label (A-H), rather than the game name, to avoid influencing participants’ interaction styles. The between-subjects factor in this study was age; one younger adult and one older adult group of participants completed the study. We sought gender balance in each group to better perform later analyses with gender as a covariate.</p>
              </sec>
              <sec id="Sec8">
                <title>Participants</title>
                <p>We recruited participants using flyers in the Philadelphia area and emails to university listservs. Thirty-nine participants (20 male and 19 female) enrolled, gave informed consent, and successfully completed the study. One additional male participant enrolled in the study but broke one of Baxter’s parts and thus did not complete the full study. His partial survey data were excluded from analysis. Participants were divided into two groups: a younger group from 18 to 36 years old (10 male, 10 female, aged 23.6 ± 4.1 years) and an older group from 54 to 70 years old (11 male, 9 female, aged 59.6 ± 3.9 years), where our notation represents the mean ± the standard deviation. All younger adult participants and eight older adults were affiliated with Penn. According to the demographic survey responses, the younger group was made up of seventeen technically trained (for example, working or studying in science, mathematics, engineering, or technology fields) and three non-technical individuals, while the older adult group comprised four technical and fifteen non-technical individuals. On a scale of 0 (least experience) to 100 (most experience), younger participants reported moderate experience levels with robots on average (55.2 ± 25.5) and low experience with Baxter (26.4 ± 19.2). Older adults reported very low experience with robots on average (12.2 ± 14.9) and similarly low experience with Baxter (15.7 ± 19.8). All participants possessed full function in their arms and hands and had normal or corrected-to-normal vision and hearing.</p>
              </sec>
              <sec id="Sec9">
                <title>Pre-study assessment data</title>
                <p>To gain some understanding of participant physical and cognitive abilities, we measured each person’s dexterous manipulation abilities with the Box and Blocks manual dexterity assessment (BnB) [<xref ref-type="bibr" rid="CR42">42</xref>], depression levels with Beck’s Depression Inventory (BDI) [<xref ref-type="bibr" rid="CR43">43</xref>], and (for older adults) cognitive abilities with the Montreal Cognitive Assessment (MoCA) [<xref ref-type="bibr" rid="CR44">44</xref>]. We also recorded user height to ensure that the study activities stayed within the physical armspan of the user.</p>
                <p>The BnB activity let us confirm that participants had full function in their arms and hands, and it also gave us an idea of their motion speed capabilities. Small adjustments to exercise game timeout periods were made based on the BnB scores (60.21 ± 8.27 blocks moved in one minute), our proxy for participant motion speed. A t-test on BnB score across age group revealed that younger adults (63.3 ± 7.4) moved significantly more blocks than older adults (56.7 ± 8.0) (<italic>p</italic> &lt; 0.001).</p>
                <p>Since depression has been shown to influence the activity motivation of depressed individuals, BDI scores (4.02 ± 5.29) were recorded. Two younger adults were in the mild clinical disturbance range (scoring 11 and 13), one younger adult had borderline clinical depression (scoring 17), and one older adult had moderate depression (scoring 25). All other scores were below 11, a range not indicative of any depression or mood disturbance. Younger (4.5 ± 4.6) and older (3.7 ± 6.1) adult BDI scores were not significantly different.</p>
                <p>We assumed that younger adult participants were cognitively well, but we administered the MoCA to older adult participants to quantify their cognitive function. The MoCA scores (26.20 ± 2.59) were used to set the Mimic Game sequence length. Six older adult participants scored in the MoCA range indicative of mild cognitive impairment.</p>
              </sec>
              <sec id="Sec10">
                <title>Measurement</title>
                <p>Our study software recorded the accelerometer data from Baxter’s onboard wrist accelerometers, the key sensors used to accomplish the logical flow of most of our exercise games. The study was additionally videotaped for later annotation. We asked participants to complete four types of surveys:
<list list-type="bullet"><list-item><p><bold>Survey 1</bold>: a robot evaluation after hearing introductory information about Baxter</p></list-item><list-item><p><bold>Survey 2</bold>: an exercise game survey after each gameplay experience</p></list-item><list-item><p><bold>Survey 3</bold>: a concluding survey after the free play interaction</p></list-item><list-item><p><bold>Survey 4</bold>: a basic demographic survey after the concluding survey</p></list-item></list></p>
                <p>Table <xref rid="Tab1" ref-type="table">1</xref> summarizes the overall types of collected data. More information about what measures each survey entailed appears below and in the supplementary materials (Additional files <xref rid="MOESM18" ref-type="media">18</xref>, <xref rid="MOESM19" ref-type="media">19</xref>, <xref rid="MOESM20" ref-type="media">20</xref>, and <xref rid="MOESM21" ref-type="media">21</xref>).
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Self-reported, annotated, and sensor metrics that helped us understand participant experiences during the exercise games</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Source of data</th><th align="left">All games</th><th align="left">Subset of games</th></tr></thead><tbody><tr><td align="justify">Self-Reports</td><td align="justify">Exercise level</td><td align="justify"/></tr><tr><td align="justify"/><td align="justify">Pleasure</td><td align="justify"/></tr><tr><td align="justify"/><td align="justify">Energy level</td><td align="justify"/></tr><tr><td align="justify"/><td align="justify">Dominance</td><td align="justify"/></tr><tr><td align="justify"/><td align="justify">Pain</td><td align="justify"/></tr><tr><td align="justify"/><td align="justify">Safety</td><td align="justify"/></tr><tr><td align="justify"/><td align="justify">Enjoyment</td><td align="justify"/></tr><tr><td align="justify"/><td align="justify">Engagement</td><td align="justify"/></tr><tr><td align="justify"/><td align="justify">Human performance</td><td align="justify"/></tr><tr><td align="justify"/><td align="justify">Robot performance</td><td align="justify"/></tr><tr><td align="justify"/><td align="justify">Rushedness</td><td align="justify"/></tr><tr><td align="justify"/><td align="justify">Calmness</td><td align="justify"/></tr><tr><td align="justify">Video Annotations</td><td align="justify">Number of tries</td><td align="justify"/></tr><tr><td align="justify"/><td align="justify">Task clarifications</td><td align="justify"/></tr><tr><td align="justify">Sensor Recordings</td><td align="justify"/><td align="justify">Contact acceleration (Mimic, Stretch, Agility, Strength, Handclap)</td></tr><tr><td align="justify"/><td align="justify"/><td align="justify">Arc length traveled (Teach)</td></tr></tbody></table></table-wrap></p>
                <p>Surveys 1 and 3 included questions adapted from the Unified Theory of Acceptance and Use of Technology (UTAUT) and other metrics employed in [<xref ref-type="bibr" rid="CR45">45</xref>] and [<xref ref-type="bibr" rid="CR46">46</xref>]. The question topic groupings on this survey included:
<list list-type="bullet"><list-item><p>attitude toward technology (ATECH, 3 questions)</p></list-item><list-item><p>cultural context (CC, 3 questions)</p></list-item><list-item><p>effort expectancy (EE, 2 questions)</p></list-item><list-item><p>forms of grouping (GR, 3 questions)</p></list-item><list-item><p>performance expectancy (PE, 3 questions)</p></list-item><list-item><p>reciprocity (REC, 2 questions)</p></list-item><list-item><p>self-efficacy from UTAUT model (SE, 4 questions)</p></list-item><list-item><p>attachment (ATT, 2 questions)</p></list-item></list></p>
                <p>Survey 2 used questions adapted from a variety of relevant sources, as detailed in the list below. Participants responded to each question on a slider scale from 0 to 100.
<list list-type="bullet"><list-item><p>Pleasure, energy, and dominance levels: derived from Self-Assessment Manikin (SAM) [<xref ref-type="bibr" rid="CR47">47</xref>] scales with the standard visual aids representing pleasure, energy, and dominance levels, 3 questions.</p></list-item><list-item><p>Performance and temporal demand levels: derived from the NASA Task Load Index (TLX) [<xref ref-type="bibr" rid="CR48">48</xref>] ratings of human performance, robot performance, rushedness (inverse scale), and calmness levels, 4 questions.</p></list-item><list-item><p>Enjoyability and engagement levels: derived from interaction enjoyment and engagement survey questions used in [<xref ref-type="bibr" rid="CR49">49</xref>], 2 questions.</p></list-item><list-item><p>Exercise level: derived from the Borg perceived exertion scale [<xref ref-type="bibr" rid="CR50">50</xref>], 1 question.</p></list-item><list-item><p>Pain level: gathered as another perspective on exercise level/muscle burn, derived from the Wong-Baker FACES pain rating scale [<xref ref-type="bibr" rid="CR51">51</xref>], 1 question.</p></list-item><list-item><p>Safety level: derived from a scale used in our past work to track user feelings of safety [<xref ref-type="bibr" rid="CR10">10</xref>], 1 question.</p></list-item></list></p>
                <p>Surveys 2 and 3 also included free response questions to help elicit additional experiential data from users about the following items: enjoyable aspects of the interaction, challenging aspects of the interaction, what stood out overall, and other activities they would like to do with the robot. Survey 4 gathered information about participant age, gender, handedness, profession, technical or non-technical background, experience level with robots, experience level with Baxter, and hometown.</p>
              </sec>
              <sec id="Sec11">
                <title>Study procedure</title>
                <p>Each person came to the lab for a single 90-minute session. Before the study interactions began, the participant completed the screening activities mentioned previously: the BnB, BDI, and MoCA. Baxter then waved hello to the user, and the research assistant read a script to relay relevant background information on Baxter. This information was followed by an opening survey about user perception of Baxter (survey 1). Next, the participant stood facing Baxter and played 90-second-long samples of the eight different exercise games in a unique pre-determined order that was balanced across participants. After each exercise game, the user completed a survey about that game (survey 2). The relayed instructions for each game and general gameplay concept for each game are further explained in a video available at [<xref ref-type="bibr" rid="CR52">52</xref>], and the source code for these exercise games is available at [<xref ref-type="bibr" rid="CR53">53</xref>]. After the eight games, the user refreshed their memory of the game options by watching video snippets of all the games (in the same order as they experienced the games), selected their favorite game, and entered a free play mode during which they could play that game for up to ten minutes. Lastly, participants completed a closing survey (survey 3) and a brief demographic survey (survey 4). Participants received $20 for completing the study and up to $10 for transportation.</p>
              </sec>
              <sec id="Sec12">
                <title>Hypotheses</title>
                <p>This experiment sought to test several hypotheses, as detailed below:
<list list-type="bullet"><list-item><p><bold>H1</bold>: Users will perceive games to have distinct attributes (as designed), and they will express a breadth of game preferences. As detailed in the Gameplay Design Section and Fig. <xref rid="Fig3" ref-type="fig">3</xref>, we designed each activity to have varying sensory levels, cognitive challenge, physical challenge, temporal challenge, and cooperative/competitive characteristics. Distinct game premises inspired by discussions with our game design expert are likely to satisfy users with different interests and preferences.</p></list-item><list-item><p><bold>H2</bold>: User perceptions of Baxter, including feelings of trust and opinions of the robot, will improve over the course of the study. Most participants will not have interacted with a robot in this way before, and playful interactions with a robot seem likely to lead to positive or lighthearted perceptions.</p></list-item><list-item><p><bold>H3</bold>: Younger adult participants will feel safer interacting with Baxter, affective effects of different games will vary between the younger and older age groups, and the two age groups will have different preferences in their free play game selection. Our younger participants are expected to have more experience and comfort with technology than the older adult group.</p></list-item><list-item><p><bold>H4</bold>: Gender will influence participant perceptions of Baxter and other self-reported metrics. In past related work, gender has influenced perceptions of robot sociability, positive or negative feelings toward robots, and anxieties about robots [<xref ref-type="bibr" rid="CR54">54</xref>–<xref ref-type="bibr" rid="CR57">57</xref>]. Any emergent differences across gender may be a useful indicator for assessing which population would most benefit from interactions with a physically interactive exercise robot.</p></list-item></list></p>
              </sec>
              <sec id="Sec13">
                <title>Analyses</title>
                <p>Generally, our main statistical analysis tool was an 8 ×2 two-factor mixed design repeated measures analysis of variance (rANOVA) in SPSS with an <italic>α</italic>=0.05 significance level and game identity and age group as factors. Because of past effects of gender on affective perceptions, exercise experiences, and more, these tests also considered gender as a covariate. We calculated the effect size using eta squared, as explained further in [<xref ref-type="bibr" rid="CR58">58</xref>].</p>
                <p>The evaluation of <bold>H1</bold>, <bold>H3</bold>, and <bold>H4</bold> depended partly on rANOVA tests of responses to survey 2. The evaluation of <bold>H2</bold>, <bold>H3</bold>, and <bold>H4</bold> also relied at least in part on rANOVA tests on the survey 1 and 3 responses. We used rANOVA tests on raw Baxter data recordings (such as contact acceleration and motion arc length) to assess differences between subsets of our participant pool. <bold>H2</bold> depends on the game chosen for the final free-play period; we used a Kruskal-Wallis test with an <italic>α</italic>=0.05 significance level to look for differences in these preference distributions. Our analyses also relied on annotations of how many times participants tried each game and how many times users asked clarifying questions from the study video.</p>
              </sec>
            </sec>
            <sec id="Sec14" sec-type="results">
              <title>Results</title>
              <p>Before dividing the gathered data to address each hypothesis, we outline the high-level significance test results for survey responses. We then formulate our results in a way to address each individual hypothesis. When one or both main effects were significant for a particular outcome measure, post-hoc multiple comparison tests in SPSS revealed which pairs of conditions had statistically significant differences. The multiple comparisons test results appear later on, in the results corresponding to each hypothesis.</p>
              <p>At a high level, we wanted to know how game mode and participant age group affected user ratings of game exercise and pain levels in survey 2. Box plots of these raw data with indicators of significance appear in Fig. <xref rid="Fig4" ref-type="fig">4</xref>. Game modes had statistically significant effects on the ratings of users’ exercise level (<italic>F</italic>(7,266) = 10.04, <italic>p</italic> &lt;0.001, <italic>η</italic><sup>2</sup>= 0.190) and pain sensation (<italic>F</italic>(7,266) = 4.34, <italic>p</italic> &lt;0.001, <italic>η</italic><sup>2</sup>= 0.092). Additionally, greater participant age led to higher reported exercise levels (<italic>F</italic>(1,38) = 5.50, <italic>p</italic> =0.020, <italic>η</italic><sup>2</sup>= 0.018; younger 28.64 ± 21.24; older 34.74 ± 25.37) and pain levels (<italic>F</italic>(1,38) = 22.71, <italic>p</italic> &lt;0.001, <italic>η</italic><sup>2</sup>= 0.070; younger 5.32 ± 6.98; older 10.20 ± 11.24).
<fig id="Fig4"><label>Fig. 4</label><caption><p>Survey responses to questions about exercise level and pain over game condition. The center box lines represent the median, and the box edges are the 25th and 75th percentiles. The whiskers show the range up to 1.5 times the interquartile range, and outliers are marked with a “+”. Filled-in box plots indicate games that were significantly differently rated compared to at least one other game. The grid next to each subplot indicates which games were rated as significantly different from others, with black indicating <italic>p</italic> &lt;0.01 and gray indicating <italic>p</italic> = 0.01 through 0.05</p></caption><graphic xlink:href="12984_2020_642_Fig4_HTML" id="MO4"/></fig></p>
              <p>Additional questions in the post-exercise game survey helped us to identify how game mode and participant age group influenced user ratings of their own affect (SAM ratings) and safety feelings during interactions, as captured in survey 2. Data related to these questions appear in Fig. <xref rid="Fig5" ref-type="fig">5</xref>. Game mode had statistically significant effects on the ratings of user pleasantness feelings (<italic>F</italic>(7,266) = 3.47, <italic>p</italic> =0.001, <italic>η</italic><sup>2</sup>= 0.075), energetic feelings (<italic>F</italic>(7,266) = 5.72, <italic>p</italic> &lt;0.001, <italic>η</italic><sup>2</sup>= 0.118), and dominance feelings (<italic>F</italic>(7,266) = 7.87, <italic>p</italic> &lt;0.001, <italic>η</italic><sup>2</sup>= 0.155). Older adults reported a slightly higher energy level than younger adult participants (<italic>F</italic>(1,38) = 4.19, <italic>p</italic> =0.041, <italic>η</italic><sup>2</sup>= 0.014; younger 72.59 ± 22.54; older 77.04 ± 17.52). Game mode did not significantly influence safety ratings, and age group did not significantly influence user pleasantness, dominance, or safety ratings.
<fig id="Fig5"><label>Fig. 5</label><caption><p>Survey responses to questions about pleasure, energy, dominance, and safety over game condition. Filled-in box plots indicate games that were significantly differently rated compared to at least one other game. The grid next to each subplot indicates which games were rated as significantly different from others, with black indicating <italic>p</italic> &lt;0.01 and gray indicating <italic>p</italic> = 0.01 through 0.05</p></caption><graphic xlink:href="12984_2020_642_Fig5_HTML" id="MO5"/></fig></p>
              <p>We also wanted to know how game mode and participant age group influenced the user ratings of enjoyment and engagement on survey 2. Raw data and significance test results related to this topic appear in Fig. <xref rid="Fig6" ref-type="fig">6</xref>. Game mode had statistically significant effects on the ratings of interaction enjoyment (<italic>F</italic>(7,266) = 4.65, <italic>p</italic> &lt;0.001, <italic>η</italic><sup>2</sup>= 0.098) and engagement (<italic>F</italic>(7,266) = 3.16, <italic>p</italic> =0.003, <italic>η</italic><sup>2</sup>= 0.069). Older adult users reported a slightly higher engagement level than younger participants (<italic>F</italic>(1,38) = 3.94, <italic>p</italic> = 0.048, <italic>η</italic><sup>2</sup>= 0.013; younger 81.83 ± 18.22; older 85.28 ± 14.50). Enjoyment ratings did not differ over age group.
<fig id="Fig6"><label>Fig. 6</label><caption><p>Survey responses to questions about enjoyment and engagement over game condition. Filled in box plots indicate games that were significantly differently rated compared to at least one other game. The grid next to each subplot indicates which games were rated as significantly different from others, with black indicating <italic>p</italic> &lt;0.01 and gray indicating <italic>p</italic> = 0.01 through 0.05</p></caption><graphic xlink:href="12984_2020_642_Fig6_HTML" id="MO6"/></fig></p>
              <p>Lastly, we looked to identify how game mode and participant age group influenced user ratings of certain task load aspects of the exercise interactions (performance and demand questions from survey 2). There were several statistically significant trends in the responses to these survey questions, as outlined in Fig. <xref rid="Fig7" ref-type="fig">7</xref>. Game mode had statistically significant effects on the ratings of human performance (<italic>F</italic>(7,266) = 11.94, <italic>p</italic> &lt;0.001, <italic>η</italic><sup>2</sup>= 0.218), robot performance (<italic>F</italic>(7,266) = 4.56, <italic>p</italic> &lt;0.001, <italic>η</italic><sup>2</sup>= 0.096), rushedness during gameplay (<italic>F</italic>(7,266) = 6.46, <italic>p</italic> &lt;0.001, <italic>η</italic><sup>2</sup>= 0.131), and calmness during gameplay (<italic>F</italic>(7,266) = 5.41, <italic>p</italic> &lt;0.001, <italic>η</italic><sup>2</sup>= 0.112). Additionally, age group significantly influenced self-ratings of human performance, with older adults rating themselves lower (<italic>F</italic>(1,38) = 9.15, <italic>p</italic> = 0.003, <italic>η</italic><sup>2</sup>= 0.030; younger 81.04 ± 20.57; older 73.01 ± 26.73). No other performance- or temporal demand-related ratings differed over age group.
<fig id="Fig7"><label>Fig. 7</label><caption><p>Performance- and demand-related survey responses over game condition. Filled in box plots indicate games that were significantly differently rated compared to at least one other game. The grid next to each subplot indicates which games were rated as significantly different from others, with black indicating <italic>p</italic> &lt;0.01 and gray indicating <italic>p</italic> = 0.01 through 0.05</p></caption><graphic xlink:href="12984_2020_642_Fig7_HTML" id="MO7"/></fig></p>
              <sec id="Sec15">
                <title>Game attributes and preferences (H1)</title>
                <p>As outlined previously, we designed the games to have different sensory levels, cognitive challenge, physical challenge, temporal challenge, and competitive/collaborative elements. The proxy measurements delineated in Table <xref rid="Tab2" ref-type="table">2</xref> helped us to evaluate whether or not games fit these intended qualities. Using the results of the above significance tests, we can determine whether the intended attributes matched the ones perceived by participants. For the purposes of this exploratory analysis, we consider games that fell significantly higher than at least one other game to be in the “high” category, games that fell significantly lower than at least one other game to be in the “low” category, and games that were not significantly different from any other game to be in the “neutral” category for each proxy scale. We weigh the overall “high”, “neutral”, and “low” counts for each game to determine the higher-level attributes. Figures <xref rid="Fig8" ref-type="fig">8</xref>, <xref rid="Fig9" ref-type="fig">9</xref>, <xref rid="Fig10" ref-type="fig">10</xref>, <xref rid="Fig11" ref-type="fig">11</xref>, and <xref rid="Fig12" ref-type="fig">12</xref> illustrate a recap of intended attributes along with the rating tendencies for each game across appropriate proxy measurements. Games shaded in green tended to match our expectations for that particular attribute, while we did not see support for the target attribute level for games shaded in orange.
<fig id="Fig8"><label>Fig. 8</label><caption><p>Intended engagement levels and the self-reported proxy measurements of pleasure, enjoyment, and engagement for each game. Cells in green represent games that were generally perceived as intended, while cells in orange highlight games that did not match our intended design</p></caption><graphic xlink:href="12984_2020_642_Fig8_HTML" id="MO8"/></fig><fig id="Fig9"><label>Fig. 9</label><caption><p>Intended cognitive challenge levels and the self-reported proxy measurements of number of task clarifications and number of tries for each game. Cells in green represent games that were generally perceived as intended, while cells in orange highlight games that did not match our intended design</p></caption><graphic xlink:href="12984_2020_642_Fig9_HTML" id="MO9"/></fig><fig id="Fig10"><label>Fig. 10</label><caption><p>Intended physical challenge levels and the self-reported proxy measurements of exercise level, pain level, and energy level for each game. Cells in green represent games that were generally perceived as intended, while cells in orange highlight games that did not match our intended design</p></caption><graphic xlink:href="12984_2020_642_Fig10_HTML" id="MO10"/></fig><fig id="Fig11"><label>Fig. 11</label><caption><p>Intended temporal challenge levels and the self-reported proxy measurements of rushedness and calmness for each game. Cells in green represent games that were generally perceived as intended, while cells in orange highlight games that did not match our intended design</p></caption><graphic xlink:href="12984_2020_642_Fig11_HTML" id="MO11"/></fig><fig id="Fig12"><label>Fig. 12</label><caption><p>Intended competition/cooperation levels and the self-reported proxy measurements of dominance level and lack of robot performance for each game. Cells in green represent games that were generally perceived as intended, while cells in orange highlight games that did not match our intended design</p></caption><graphic xlink:href="12984_2020_642_Fig12_HTML" id="MO12"/></fig><table-wrap id="Tab2"><label>Table 2</label><caption><p>Design parameters of interest and measurements that served as proxies to help us evaluate the games for each of these attributes</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Engaging</th><th align="left">Cognitively Challenging</th><th align="left">Physically Challenging</th><th align="left">Temporally Challenging</th><th align="left">Competitive</th></tr></thead><tbody><tr><td align="left">Pleasure</td><td align="justify">Task clarifications</td><td align="justify">Exercise level</td><td align="justify">Rushedness</td><td align="justify">Dominance</td></tr><tr><td align="left">Enjoyment</td><td align="justify">Number of tries</td><td align="justify">Energy level</td><td align="justify">Calmness</td><td align="justify">Robot performance</td></tr><tr><td align="left">Engagement</td><td align="justify"/><td align="justify">Pain</td><td align="justify"/><td align="justify"/></tr></tbody></table></table-wrap></p>
                <p>Because we expected users to rate immersive games more positively, we used self-reported pleasure, enjoyment, and engagement to assess the sensory level of each exercise game, as highlighted in Fig. <xref rid="Fig8" ref-type="fig">8</xref>. Three of the games trended as expected: the Stretch and Strength Games tended to be rated with higher pleasure/enjoyment/engagement, and the non-contact Roboga Game tended to be rated lower on these scales.</p>
                <p>The metrics that we used to assess the cognitive challenge level of games were the number of task clarifications and number of tries per game. We found significant differences in both of these metrics across game (task clarifications: <italic>F</italic>(7,266) = 22.58, <italic>p</italic> &lt;0.001, <italic>η</italic><sup>2</sup>= 0.347, number of tries: <italic>F</italic>(7,266) = 17.14, <italic>p</italic> &lt;0.001, <italic>η</italic><sup>2</sup>= 0.392). Task clarifications were significantly more common in the Teach Game (1.50 ± 1.24) than in any other game. The Mimic Game (0.56 ± 0.99) also elicited significantly more clarifications than the Stretch, Strength, and Roboga Games (all ≤0.10 ± 0.31). If participants lost the exercise games because of a misunderstanding about the gameplay rules, the research assistant allowed them to try the game again. Participants required significantly more tries to master the Mimic Game (1.72 ± 0.94) than any other game. The Handclap Game (1.32 ± 0.47) led to more tries than any other game except the Mimic and Teach Games (all ≤ 1.02 ± 0.16). All eight participants who required three or more tries on the Mimic Game were in the older adult group, and three of them exhibited signs of mild cognitive impairment on the opening MoCA assessment. Overall, the Mimic, Stretch, Agility, Strength, and Roboga Games trended as expected. The Mimic Game was more cognitively challenging, and the Stretch, Agility, Strength, and Roboga Games were less challenging in this area.</p>
                <p>Self-reported exercise level, pain, and energy level served as proxies for the physical challenge of exercise games, as detailed in Fig. <xref rid="Fig10" ref-type="fig">10</xref>. Our understanding of the games was mixed in this category; four of the games trended as expected, but the others were perceived in a mixed or opposite way. The Agility, Strength, and Roboga Games were generally correctly predicted as higher exercise level/pain level/energy level, and the Flamenco Game was correctly predicted as lower in these categories.</p>
                <p>We used self-reported rushedness and calmness levels as proxies for temporal challenge, as illustrated in Fig. <xref rid="Fig11" ref-type="fig">11</xref>. Six of the games trended as expected: the Agility, Handclap, and Flamenco Games tended to be rated with higher rushedness/lower calmness, and the Mimic, Teach, and Roboga Games tended to be rated lower on these scales.</p>
                <p>We assessed the competitive or collaborative nature of different games with the help of self-reported dominance and the inverse of robot performance ratings, as illustrated in Fig. <xref rid="Fig12" ref-type="fig">12</xref>. Five of the games trended as expected: the Mimic Game tended to be rated as more competitive, the Stretch, Strength, and Handclap Game were rated in a mixed or neutral way, and the Roboga Game was rated as lower/more collaborative.</p>
                <p>Figure <xref rid="Fig13" ref-type="fig">13</xref> summarizes the game characteristics, outlining boxes that were perceived by participants as we expected. Overall, more than half of the game attributes were perceived as intended. The Mimic, Stretch, Agility, Strength, and Roboga Games resulted in perceptions most similar to our expectations (majority of correct attributes), so we view these games as closest to our designed intentions.
<fig id="Fig13"><label>Fig. 13</label><caption><p>Actual perceived game characteristics of each human-robot exercise game. Outlined boxes indicate attributes perceived as expected</p></caption><graphic xlink:href="12984_2020_642_Fig13_HTML" id="MO13"/></fig></p>
                <p>All users were able to identify a favorite game that they wanted to play again, and every participant interacted with Baxter in this free-play game condition for at least as long as the sample game interactions. Several people played many repetitions of their chosen game, and some opted to increase the difficulty level over their free-play game experiences. As illustrated in Fig. <xref rid="Fig14" ref-type="fig">14</xref>, the Strength Game was the most popular choice, but aside from the Flamenco Game, every game was chosen as a favorite by at least two users. A Kruskal-Wallis test revealed no significant difference between the game selections of younger and older adults (<italic>p</italic> = 0.365).
<fig id="Fig14"><label>Fig. 14</label><caption><p>Favorite games of the two participant age groups</p></caption><graphic xlink:href="12984_2020_642_Fig14_HTML" id="MO14"/></fig></p>
              </sec>
              <sec id="Sec16">
                <title>Changing perceptions of Baxter (H2)</title>
                <p>We gathered two sets of robot perception survey responses, one before and one after the experiment; these results are shown in Fig. <xref rid="Fig15" ref-type="fig">15</xref>. Because we gathered these data from two different participant age groups, our main analysis tool for evaluating differences in the robot perception survey was a 2 ×2 two-factor mixed design rANOVA performed in SPSS with an <italic>α</italic>=0.05 significance level. We additionally calculated effect sizes using eta squared. The before/after results are discussed here, and the age-related results of this analysis appear in the following section.
<fig id="Fig15"><label>Fig. 15</label><caption><p>Differences in responses to the UTAUT-inspired robot perception survey. In each plot, the top box plot represents the pre-experiment responses, and the bottom box plot represents the post-experiment responses. Filled in box plots with starred titles indicate significant differences. Clusters of plots with matching colors and letter codings represent survey question groupings</p></caption><graphic xlink:href="12984_2020_642_Fig15_HTML" id="MO15"/></fig></p>
                <p>Based on this analysis, we discovered that over the course of the experiment, users became more positive about the idea of using the robot (<italic>F</italic>(1,38) = 4.38, <italic>p</italic> = 0.045, <italic>η</italic><sup>2</sup>= 0.054) but more afraid to make mistakes while playing with Baxter (<italic>F</italic>(1,38) = 5.40, <italic>p</italic> = 0.023, <italic>η</italic><sup>2</sup>= 0.069). Participants also came to think that the robot was nicer to work with (<italic>F</italic>(1,38) = 5.28, <italic>p</italic> = 0.024, <italic>η</italic><sup>2</sup>= 0.068) and easier to use (<italic>F</italic>(1,38) = 19.81, <italic>p</italic> &lt;0.001, <italic>η</italic><sup>2</sup>= 0.213) after the experiment. Users further reported liking the presence of the robot more (<italic>F</italic>(1,38) = 7.63, <italic>p</italic> = 0.007, <italic>η</italic><sup>2</sup>= 0.095) and being more able to imagine doing activities with the robot (<italic>F</italic>(1,38) = 7.41, <italic>p</italic> = 0.008, <italic>η</italic><sup>2</sup>= 0.092). Ratings of comfort interacting with the robot also increased (<italic>F</italic>(1,38) = 11.75, <italic>p</italic> = 0.001, <italic>η</italic><sup>2</sup>= 0.139). Lastly, respondents were more trusting of Baxter (<italic>F</italic>(1,38) = 16.76, <italic>p</italic> &lt;0.001, <italic>η</italic><sup>2</sup>= 0.187) and more willing to follow Baxter’s example (<italic>F</italic>(1,38) = 11.83, <italic>p</italic> = 0.001, <italic>η</italic><sup>2</sup>= 0.139) after the experiment. It is important to note that these findings were true for both younger and older adults.</p>
              </sec>
              <sec id="Sec17">
                <title>Age differences (H3)</title>
                <p>Certain differences were present in the younger vs. older adult perceptions of Baxter, as shown in Fig. <xref rid="Fig16" ref-type="fig">16</xref>. Younger adults agreed more with the statement that others would be impressed if they had a robot like Baxter (<italic>F</italic>(1,38) = 6.45, <italic>p</italic> = 0.013, <italic>η</italic><sup>2</sup>= 0.081), and the younger group also thought robots are nicer to work with (<italic>F</italic>(1,38) = 4.41, <italic>p</italic> = 0.039, <italic>η</italic><sup>2</sup>= 0.057). The younger group liked the presence of Baxter more (<italic>F</italic>(1,38) = 3.71, <italic>p</italic> = 0.042, <italic>η</italic><sup>2</sup>= 0.056). In contrast, the older adults agreed more strongly that Baxter could help them (<italic>F</italic>(1,38) = 4.36, <italic>p</italic> = 0.040, <italic>η</italic><sup>2</sup>= 0.056). Lastly, younger adults felt more confident about using Baxter without any help (<italic>F</italic>(1,38) = 4.18, <italic>p</italic> = 0.044, <italic>η</italic><sup>2</sup>= 0.054).
<fig id="Fig16"><label>Fig. 16</label><caption><p>Differences in responses to the UTAUT-inspired robot perception survey. In each plot, the top box plot represents the younger adult responses, and the bottom box plot represents the older adult responses. Clusters of plots with matching colors and letter codings represent survey question groupings</p></caption><graphic xlink:href="12984_2020_642_Fig16_HTML" id="MO16"/></fig></p>
                <p>Age-related differences also appeared in post-game surveys and data recordings from younger vs. older adult study participants. As reported previously in the main effects, older adult participants felt like they were exercising harder and felt more pain during the experiment. Older adults also rated themselves as more energetic than younger adult participants, and the older participant group reported being more engaged than younger participants. Additionally, age group significantly influenced self-ratings of human performance; older adults generally rated themselves as performing worse.</p>
                <p>There were no significant differences between the participant-wise mean accelerations at hand impact for younger and older adult participants (lowest <italic>p</italic> = 0.140). Differences did appear in arc length moved during the Teach Game; older adults moved both the right and left robot arms through higher arc length distances during this activity (left: <italic>F</italic>(1,39) = 5.12, <italic>p</italic> = 0.030, <italic>η</italic><sup>2</sup>= 0.122; right: <italic>F</italic>(1,39) = 4.11, <italic>p</italic> = 0.050, <italic>η</italic><sup>2</sup>= 0.100), which may indicate that they were more motivated to explore the space and compose a song during this game in particular.</p>
              </sec>
              <sec id="Sec18">
                <title>Gender effects (H4)</title>
                <p>Throughout many of the tests described above, including gender as a covariate revealed differences between the responses of participating men and women. Certain differences arose in the participants’ overall opinions of Baxter; women agreed significantly more with all of the following statements:
<list list-type="bullet"><list-item><p>I think using the robot is a good idea (<italic>F</italic>(1,38) = 11.66, <italic>p</italic> = 0.001, <italic>η</italic><sup>2</sup>= 0.138)</p></list-item><list-item><p>People would be impressed if I had such a robot (<italic>F</italic>(1,38) = 8.46, <italic>p</italic> = 0.005, <italic>η</italic><sup>2</sup>= 0.104)</p></list-item><list-item><p>Robots are nice to work with (<italic>F</italic>(1,38) = 4.30, <italic>p</italic> = 0.042, <italic>η</italic><sup>2</sup>= 0.056)</p></list-item><list-item><p>I could cooperate with the robot (<italic>F</italic>(1,38) = 5.72, <italic>p</italic> = 0.019, <italic>η</italic><sup>2</sup>= 0.073)</p></list-item><list-item><p>I like the presence of the robot (<italic>F</italic>(1,38) = 7.66, <italic>p</italic> = 0.007, <italic>η</italic><sup>2</sup>= 0.095)</p></list-item><list-item><p>I consider the robot to be a social agent (<italic>F</italic>(1,38) = 4.58, <italic>p</italic> = 0.036, <italic>η</italic><sup>2</sup>= 0.059)</p></list-item><list-item><p>I feel understood by the robot (<italic>F</italic>(1,38) = 8.08, <italic>p</italic> = 0.006, <italic>η</italic><sup>2</sup>= 0.100)</p></list-item><list-item><p>I trust the robot (<italic>F</italic>(1,38) = 14.09, <italic>p</italic> &lt;0.001, <italic>η</italic><sup>2</sup>= 0.162)</p></list-item><list-item><p>I would follow the example of the robot (<italic>F</italic>(1,38) = 24.34, <italic>p</italic> &lt;0.001, <italic>η</italic><sup>2</sup>= 0.250)</p></list-item></list></p>
                <p>Self-reported metrics also differed occasionally between male and female participants. In these survey responses, female participants rated all of the following significantly higher than men:
<list list-type="bullet"><list-item><p>Pain (<italic>F</italic>(7,266) = 8.42, <italic>p</italic> = 0.004, <italic>η</italic><sup>2</sup>= 0.027)</p></list-item><list-item><p>Robot performance (<italic>F</italic>(7,266) = 19.33, <italic>p</italic> &lt;0.001, <italic>η</italic><sup>2</sup>= 0.061)</p></list-item><list-item><p>Lack of rushedness (<italic>F</italic>(7,266) = 12.30, <italic>p</italic> = 0.001, <italic>η</italic><sup>2</sup>= 0.039)</p></list-item><list-item><p>Calmness (<italic>F</italic>(7,266) = 17.04, <italic>p</italic> &lt;0.001, <italic>η</italic><sup>2</sup>= 0.054)</p></list-item></list></p>
                <p>These effects held true for both younger and older participants.</p>
              </sec>
            </sec>
            <sec id="Sec19" sec-type="discussion">
              <title>Discussion</title>
              <p>The study results enable us to evaluate our hypotheses about the human-robot exercise games, reflect on strengths and limitations of this work, and make recommendations about how this exploratory study can inform future work.</p>
              <sec id="Sec20">
                <title>Hypothesis testing</title>
                <p>Five of the eight exercise games mostly matched the expected attributes referenced in <bold>H1</bold>: the Mimic, Stretch, Agility, Strength, and Roboga Games. Three games did not fulfill our intentions for how participants would feel during gameplay. The Teach Game fit only one of our expectations, and the Handclap and Flamenco Games met only two. The most popular activity among participants was the Strength Game, perhaps because of its use of energetic and recognizable music. Even so, participant preferences spanned almost all other games. We consider these results as preliminary evidence that we successfully designed an array of games suitable to users with different interests, fitness goals, physical abilities, and cognitive needs.</p>
                <p>The experience of interacting with Baxter influenced user perception of the robot, as anticipated in <bold>H2</bold>. The strongest effects were increases in user trust of the robot and feelings that the robot is easy to use (both <italic>η</italic><sup>2</sup> &gt; 0.18). Perception of using the robot, how the robot is to work with, the presence of the robot, doing activities with the robot, comfort with the robot, and willingness to follow the robot’s example all increased significantly as well. These findings align well with past qualitative observations from [<xref ref-type="bibr" rid="CR59">59</xref>].</p>
                <p>Although there were several differences between younger and older adult participant responses to the games, almost none of the differences postulated in <bold>H3</bold> were upheld. Overall, younger participants did give higher ratings of confidence about using Baxter, being around Baxter, and Baxter’s impressiveness than older participants, but the older adults thought Baxter would be more able to help them. Older adult participants seemed to get more out of the exercise interactions, as intended; they felt more energetic and engaged during exercise, and they also reported higher exercise and pain levels than younger adults. The cause of most reported pain was muscle burn from exercise, but we recommend caregiver supervision to monitor pain levels. Older adults also rated their own performance as worse, which may be beneficial in this work; if we aim to create games that are challenging but possible, this balance may ultimately lead to more satisfaction and feelings of self-efficacy [<xref ref-type="bibr" rid="CR60">60</xref>].</p>
                <p>As anticipated in <bold>H4</bold>, female participants perceived the robot differently than men on several pre- and post-study survey scales. Overall, female users’ opinion of Baxter was higher, and they also experienced more pain (usually muscle burn- or contact comfort-related) during the exercise games. These results, in combination with the positive feedback from older female users of the system, may indicate that women are better target users for this type of exercise system, both in terms of acceptance and potential exercise gains. The all-female composition of our research team might also be partially responsible for these gender differences.</p>
              </sec>
              <sec id="Sec21">
                <title>Major strengths and limitations</title>
                <p>The results of this experiment showed us how younger and older adults respond to exercise games with a robot. Participants felt safe physically interacting with Baxter and playing the exercise games. Most games were perceived approximately as expected, fulfilling a majority of the design attributes that we aimed to deliver in each activity. This result gives us confidence in the ability of researchers to use similar strategies in the future design of more targeted interventions.</p>
                <p>User preferences were split across activities, and each game seemed to possess characteristic advantages as follows:
<list list-type="bullet"><list-item><p><bold>Mimic Game</bold>: Although participants often needed multiple tries to understand this game, it was clearly understood to be a competitive game. Participants’ perceptions of the activity were mostly aligned with our intended design criteria.</p></list-item><list-item><p><bold>Stretch Game</bold>: This game achieved most of our intended design characteristics. It seemed to be one of the most attainable and relaxing games for users.</p></list-item><list-item><p><bold>Teach Game</bold>: This game was not interpreted as we intended, but this activity prompted many questions from participants. Some users were uninterested in the musical premise, but others became determined and thoroughly explored the robot’s workspace during their trial.</p></list-item><list-item><p><bold>Agility Game</bold>: Participants worked harder than expected during this game, leading to high physical and cognitive challenge. A frequent favorite of participants, this game fulfilled most of our design attributes.</p></list-item><list-item><p><bold>Strength Game</bold>: This game achieved most of our intended design characteristics and was the most frequent favorite game choice of participants. Participants were generally very positive about this activity, and the Strength Game led to higher reports of exercise than several other games.</p></list-item><list-item><p><bold>Handclap Game</bold>: Participants experienced some of the highest cognitive challenge levels when playing this game, because of both spatial awareness and memory demands.</p></list-item><list-item><p><bold>Roboga Game</bold>: This activity met most of our design expectations. The game was simple to grasp (no participants needed instruction clarifications or additional chances to try the game).</p></list-item><list-item><p><bold>Flamenco Game</bold>: Although no participants chose this activity for the free play period, this game led to a playful interaction, and many individuals reported enjoying the game in their spoken and written game commentary.</p></list-item></list></p>
                <p>Only <italic>socially and physically interactive</italic> games <bold>fell in the highest ranges for pleasantness, enjoyment, engagement, cognitive challenge, energy level, and competitiveness</bold>.</p>
                <p>Users typically finished or won all the games, which emphasizes the readability and comprehensibility of the activities. This result was ideal because we wanted to verify that people can succeed in the games before testing more challenging or vigorous game modes. Doing this type of activity with a robot before a higher-stakes team interaction may help the pair to build rapport and trust; users’ opinions of and trust in the robot improved over the course of the study.</p>
                <p>Certain limitations arose from the study design. Although the user population was diverse, users were not uniformly representative of the target population for this research. Collecting data from a larger and more diverse sample could increase the strength of our results. Likewise, the lab setting of the experiment and the short duration of each interaction did not perfectly match our intended use case. To ensure broader applicability, it would be ideal to run a similar experiment in an assisted living facility. Additionally, the within-subjects nature of the experiment may have exaggerated differences between game conditions due to demand characteristics.</p>
                <p>Users reported a growing fear of making mistakes when interacting with Baxter. This change is likely a byproduct of the ability to lose the exercise games by making mistakes, but we will monitor for this same concern in future studies and seek to understand why this change occurs. The implementation of the exercise games stands to be improved before future deployments; the operation of the robot was nearly, but not yet fully, autonomous. Another drawback was that one user broke Baxter’s wrist motor coupler (W2 joint). In similar future exercise studies, we recommend developing a protocol to service the robot between study sessions as needed and supplying cautionary feedback if participants hit the robot with excessive force.</p>
              </sec>
            </sec>
            <sec id="Sec22" sec-type="conclusion">
              <title>Conclusions</title>
              <p>Overall, the positive results of this study show that social-physical exercise with a human-sized humanoid robot has the potential to encourage physical and cognitive exercise by older adults. Both younger and older participants felt that the robot was safe and were willing to play the games. Games involving both social and physical interaction were rated as most pleasant, enjoyable, engaging, cognitively challenging, and energetic. The games also successfully achieved different physical, cognitive, and temporal challenge levels. The social aspects of interactions were especially well received by female users. Older users’ higher energy level, exercise, and pain ratings show that these games are more relevant to the exercise of older individuals.</p>
              <p>Researchers working on related topics can learn from the iterative game design approach that we followed, the open-source resources we provide, and the scientific results from our research. Our work with clinicians and other experts during exercise game design helped us to propose safe, entertaining, and beneficial interactions with various built-in song/pattern modes and difficulty levels to preserve interest in the robot over multiple interactions. The code and instructions needed to run the exercise games from our study are publicly available at [<xref ref-type="bibr" rid="CR53">53</xref>]. Our game-specific findings relate most closely to the specific activities investigated in this work, but other results (e.g., experience differences across age group and gender, implications of social-physical interactions generally) can guide assistive robotics work more broadly.</p>
              <p>In our own future steps, we see potential to adjust games or select a subset of games to accomplish specific physical therapy goals; for example, we can emphasize physical, cognitive, or temporal challenge. Our future investigations of social-physical robots as exercise partners will help us understand how to use these agents to support older adults and other individuals with exercise needs.</p>
            </sec>
            <sec id="Sec23">
              <title>Appendix A: Exercise Game Descriptions</title>
              <p>Here, we outline additional information about the games used in our study. We further describe the logical flow of each game in figures and videos included as supplementary material with this article. (Additional files <xref rid="MOESM1" ref-type="media">1</xref>, <xref rid="MOESM2" ref-type="media">2</xref>, <xref rid="MOESM3" ref-type="media">3</xref>, <xref rid="MOESM4" ref-type="media">4</xref>, <xref rid="MOESM5" ref-type="media">5</xref>, <xref rid="MOESM6" ref-type="media">6</xref>, <xref rid="MOESM7" ref-type="media">7</xref>, <xref rid="MOESM8" ref-type="media">8</xref>, <xref rid="MOESM9" ref-type="media">9</xref>, <xref rid="MOESM10" ref-type="media">10</xref>, <xref rid="MOESM11" ref-type="media">11</xref>, <xref rid="MOESM12" ref-type="media">12</xref>, <xref rid="MOESM13" ref-type="media">13</xref>, <xref rid="MOESM14" ref-type="media">14</xref>, <xref rid="MOESM15" ref-type="media">15</xref>, <xref rid="MOESM16" ref-type="media">16</xref>, and <xref rid="MOESM17" ref-type="media">17</xref>)</p>
              <p>The <bold>Mimic Game</bold> was designed to make users hold up their arms and contact Baxter’s end-effectors. In this game, the user gradually teaches Baxter a long pattern of left-, right-, and/or both-handed impacts which Baxter has to repeat during each round of the activity. The participant can win the game by demonstrating a sequence of hand impacts that is long enough to “confuse” the robot. Specifically, based on the participant cognitive wellness level assessed by our opening MoCA evaluation, we set the number of motions needed to win at 3-6. To discourage the case where participants could repeat the same motion again and again to win, we counted motions repeated in direct sequence as only half of a motion. The human user loses if they make a mistake when repeating their own hand impact pattern. This game involves a cognitive dimension that challenges the user to remember a pattern. We believed this game would involve a high sensory level because of the energetic hand contacts in the interaction and intermittent percussive sounds associated with each gameplay move. The Mimic Game was designed to be a cognitively challenging and competitive experience with low physical and temporal demand.</p>
              <p>The <bold>Stretch Game</bold> leverages Baxter’s sizable workspace to encourage the user to make large arm motions. In this interaction, Baxter strikes a series of poses, cuing the user to mimic its pose and simultaneously hit both of its end-effectors within a fixed time after reaching each new pose. At the end of the game, Baxter plays a series of chords for all of the presented poses, with dissonant chords to represent any contacts that the user missed. People engaging with the robot must use their spatial awareness to reposition themselves and their arms as needed throughout the game. We thought this game would involve a high sensory level because of the energetic hand contacts involved in the gameplay and intermittent chords associated with each gameplay pose. The Stretch Game was designed to be a physically demanding, temporally challenging, and part-competitive/part-collaborative experience with low cognitive demand.</p>
              <p>The <bold>Teach Game</bold> challenges users to support Baxter’s arms while moving them around the robot’s workspace to create a musical composition. The user can play notes by twisting just one of Baxter’s wrists; arm locations map to notes. Chords are recorded to the composition when the user twists both of Baxter’s wrists simultaneously. Once the user is done composing, Baxter plays back the recorded sequence of notes with the associated motions. If the user intends to create a particular composition, the game requires cognitive abstraction skills (to understand how the robot’s pose relates to a musical note) and attention (to be able to explore the workspace and select notes before losing track of current and past notes). We thought this activity would involve a moderate sensory level because the participant is more passively contacting Baxter (holding the robot’s arms) and the game involves intermittent chord sounds. The Teach Game was designed to be a cognitively demanding and collaborative experience with low physical and temporal challenge.</p>
              <p>The <bold>Agility Game</bold> was designed to encourage users to hold up their arms and rapidly contact Baxter. In this interaction, the user attempts to “wake” a sleeping Baxter by repeatedly hitting its end-effectors. This activity requires fast, but not necessarily forceful, hand contact. We believed this game would involve a high sensory level because of the energetic hand contacts and the intermittent sound effects involved in the interaction. The Agility Game was designed to be a physically challenging, temporally challenging, and competitive experience with low cognitive demand.</p>
              <p>The <bold>Strength Game</bold> encourages users to hit Baxter somewhat forcefully while going through a boxing training-like interaction set to energetic music. Baxter strikes a sequence of poses and prompts the user to contact its end-effectors with a punch to each boxing pad in every subsequent pose. This game requires attention (to perceive the cues indicating that Baxter is ready for contact). We thought this game would involve a high sensory level because of the energetic hand contacts and music involved in the gameplay. The Strength Game was designed to be a physically challenging, temporally challenging, and part-collaborative/part-competitive experience with low cognitive demand.</p>
              <p>The <bold>Handclap Game</bold> was designed to make users hold up their arms and contact Baxter’s end-effectors. This interaction is similar to a children’s hand-clapping game, such as “Pat-a-Cake” or “Miss Mary Mack.” Baxter demonstrates a series of hand-clapping motions, and the user joins in the clapping game by physically contacting the robot’s hands. The same hand-clapping game repeats with one new appended motion in each repetition. Users are challenged in visuospatial cognition as they interpret and reciprocate robot movements. We believed this game would involve a medium sensory level because although the interaction involves energetic hand contacts, there is no accompanying sound. The Handclap Game was designed to be a cognitively challenging, physically demanding, temporally challenging, and part-competitive/part-collaborative experience.</p>
              <p>The <bold>Roboga Game</bold> is similar to related work in [<xref ref-type="bibr" rid="CR7">7</xref>] and does not involve physical human-robot contact. Users are challenged by the need to hold up their own arms’ weight. Baxter strikes a stretching pose, the user matches the pose, and both parties hold the pose for several seconds. The Roboga Game has a set length, and the game concludes when the robot completes its sequence of movements. There is no feedback or automated user monitoring, although we found that users attempted to mimic the robot in all cases but one (during an inquisitive free-play trial). The poses are concatenated to create stretching routines similar to those found in physical therapy exercises for shoulder and bicep tendon injuries, and potentially beneficial for general strength and flexibility. Because of the lack of physical contact and sound during this activity, we expected this game to have a lower sensory level. Overall, the Roboga Game was designed to be a physically demanding and collaborative experience that is less cognitively and temporally challenging.</p>
              <p>The <bold>Flamenco Game</bold> challenges users to exercise by carrying out different dance moves, none of which involve physical human-robot contact. Baxter demonstrates a sequence of simple dance moves along with music, nods to the participant, and then waits for the human user to try the same dance along with a music replay. The researcher manually started each sequence of robot dance moves after the music replay from the previous sequence concluded. There was no user feedback during this game, but we found that participants always attempted the dance replay. Users are challenged in visuospatial cognition as they interpret and reciprocate robot movements. Since this game involved no physical contact but did involve energetic music, we expected this game to involve a medium sensory level. The Flamenco Game was designed to be a cognitively challenging, temporally challenging, and part-competitive/part-collaborative experience that is less physically demanding.</p>
            </sec>
            <sec sec-type="supplementary-material">
              <title>Supplementary information</title>
              <sec id="Sec24">
                <p>
                  <supplementary-material content-type="local-data" id="MOESM1">
                    <media xlink:href="12984_2020_642_MOESM1_ESM.pdf">
                      <caption>
                        <p><bold>Additional file 1</bold> Gameplay flow of the Mimic Game.</p>
                      </caption>
                    </media>
                  </supplementary-material>
                </p>
                <p>
                  <supplementary-material content-type="local-data" id="MOESM3">
                    <media xlink:href="12984_2020_642_MOESM3_ESM.pdf">
                      <caption>
                        <p><bold>Additional file 3</bold> Gameplay flow of the Stretch Game.</p>
                      </caption>
                    </media>
                  </supplementary-material>
                </p>
                <p>
                  <supplementary-material content-type="local-data" id="MOESM5">
                    <media xlink:href="12984_2020_642_MOESM5_ESM.pdf">
                      <caption>
                        <p><bold>Additional file 5</bold> Gameplay flow of the Teach Game.</p>
                      </caption>
                    </media>
                  </supplementary-material>
                </p>
                <p>
                  <supplementary-material content-type="local-data" id="MOESM7">
                    <media xlink:href="12984_2020_642_MOESM7_ESM.pdf">
                      <caption>
                        <p><bold>Additional file 7</bold> Gameplay flow of the Agility Game.</p>
                      </caption>
                    </media>
                  </supplementary-material>
                </p>
                <p>
                  <supplementary-material content-type="local-data" id="MOESM9">
                    <media xlink:href="12984_2020_642_MOESM9_ESM.pdf">
                      <caption>
                        <p><bold>Additional file 9</bold> Gameplay flow of the Strength Game.</p>
                      </caption>
                    </media>
                  </supplementary-material>
                </p>
                <p>
                  <supplementary-material content-type="local-data" id="MOESM11">
                    <media xlink:href="12984_2020_642_MOESM11_ESM.pdf">
                      <caption>
                        <p><bold>Additional file 11</bold> Gameplay flow of the Handclap Game.</p>
                      </caption>
                    </media>
                  </supplementary-material>
                </p>
                <p>
                  <supplementary-material content-type="local-data" id="MOESM13">
                    <media xlink:href="12984_2020_642_MOESM13_ESM.pdf">
                      <caption>
                        <p><bold>Additional file 13</bold> Gameplay flow of the Roboga Game.</p>
                      </caption>
                    </media>
                  </supplementary-material>
                </p>
                <p>
                  <supplementary-material content-type="local-data" id="MOESM15">
                    <media xlink:href="12984_2020_642_MOESM15_ESM.pdf">
                      <caption>
                        <p><bold>Additional file 15</bold> Gameplay flow of the Flamenco Game.</p>
                      </caption>
                    </media>
                  </supplementary-material>
                </p>
                <p>
                  <supplementary-material content-type="local-data" id="MOESM18">
                    <media xlink:href="12984_2020_642_MOESM18_ESM.pdf">
                      <caption>
                        <p><bold>Additional file 18</bold> Opening survey (survey 1) completed by study participants.</p>
                      </caption>
                    </media>
                  </supplementary-material>
                </p>
                <p>
                  <supplementary-material content-type="local-data" id="MOESM19">
                    <media xlink:href="12984_2020_642_MOESM19_ESM.pdf">
                      <caption>
                        <p><bold>Additional file 19</bold> Post-game survey (survey 2) completed by study participants.</p>
                      </caption>
                    </media>
                  </supplementary-material>
                </p>
                <p>
                  <supplementary-material content-type="local-data" id="MOESM20">
                    <media xlink:href="12984_2020_642_MOESM20_ESM.pdf">
                      <caption>
                        <p><bold>Additional file 20</bold> Closing survey (survey 3) completed by study participants.</p>
                      </caption>
                    </media>
                  </supplementary-material>
                </p>
                <p>
                  <supplementary-material content-type="local-data" id="MOESM21">
                    <media xlink:href="12984_2020_642_MOESM21_ESM.pdf">
                      <caption>
                        <p><bold>Additional file 21</bold> Demographic survey (survey 4) completed by study participants.</p>
                      </caption>
                    </media>
                  </supplementary-material>
                </p>
              </sec>
            </sec>
          </body>
          <back>
            <glossary>
              <title>Abbreviations</title>
              <def-list>
                <def-item>
                  <term>BDI</term>
                  <def>
                    <p>Beck’s depression inventory</p>
                  </def>
                </def-item>
                <def-item>
                  <term>BnB</term>
                  <def>
                    <p>Box and blocks</p>
                  </def>
                </def-item>
                <def-item>
                  <term>MoCA</term>
                  <def>
                    <p>Montreal cognitive assessment</p>
                  </def>
                </def-item>
                <def-item>
                  <term>NSF</term>
                  <def>
                    <p>National science foundation</p>
                  </def>
                </def-item>
                <def-item>
                  <term>Penn</term>
                  <def>
                    <p>University of Pennsylvania</p>
                  </def>
                </def-item>
                <def-item>
                  <term>pHRI</term>
                  <def>
                    <p>physical human-robot interaction</p>
                  </def>
                </def-item>
                <def-item>
                  <term>rANOVA</term>
                  <def>
                    <p>repeated measures analysis of variance</p>
                  </def>
                </def-item>
                <def-item>
                  <term>SAM</term>
                  <def>
                    <p>Self-assessment manikin</p>
                  </def>
                </def-item>
                <def-item>
                  <term>TLX</term>
                  <def>
                    <p>Task load index</p>
                  </def>
                </def-item>
                <def-item>
                  <term>UTAUT</term>
                  <def>
                    <p>Unified theory of acceptance and use of technology</p>
                  </def>
                </def-item>
              </def-list>
            </glossary>
            <fn-group>
              <fn>
                <p>
                  <bold>Publisher’s Note</bold>
                </p>
                <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
              </fn>
            </fn-group>
            <sec>
              <title>Supplementary information</title>
              <p><bold>Supplementary information</bold> accompanies this paper at 10.1186/s12984-020-0642-5.</p>
            </sec>
            <ack>
              <p>The first author was supported by a US National Science Foundation (NSF) Graduate Research Fellowship under Grant No. DGE-0822 and by the Penn NSF Integrative Graduate Education and Research Traineeship under Grant No. 0966142. We thank the Penn Physical Medicine and Rehabilitation Department’s Rehabilitation Robotics Lab and Professor Kostas Daniilidis for allowing us to use their Baxter Research Robots in our work. Thanks also go out to Alex Miller, Laurence Devinney, Rochelle Mendonca, Pamela Z. Cacchione, and Nora Johnson for their advice. We thank Dylan Hawkes for his help with preliminary steps of this research and Elyse D. Z. Chase for her assistance creating the video that demonstrates the different exercise games.</p>
            </ack>
            <notes notes-type="author-contribution">
              <title>Authors’ contributions</title>
              <p>NF was responsible for system engineering, experiment preparation, data acquisition, data processing, and publication writing. MM assisted with data collection, video coding, and data analysis. KK advised throughout system engineering, experiment preparation, data acquisition, and data processing. MJ likewise supplied advice on experiment preparation, data acquisition, and data processing, in addition to providing domain expertise on best practices in rehabilitation robotics. All authors were engaged in the iterative testing of games, and all authors supplied revisions for each publication draft. All authors read and approved the final manuscript.</p>
            </notes>
            <notes notes-type="funding-information">
              <title>Funding</title>
              <p>NF and KK have received research grants from the US National Science Foundation. KK has also received funding from the National Institutes of Health, Intuitive Surgical, Inc., IERION, Inc., Rolls Royce, Inc., the Wallace H. Coulter Foundation, the Defense Advanced Research Projects Agency, the Army Research Laboratory, Willow Garage, and the Pennsylvania Department of Health. MJ has received funding from the National Institutes of Health and the US National Science Foundation.</p>
            </notes>
            <notes notes-type="data-availability">
              <title>Availability of data and materials</title>
              <p>The full datasets generated and analyzed during the current study are not publicly available based on the terms of our IRB protocol, but they are available to individuals upon their addition to the protocol. This modification may be accomplished upon reasonable request with the approval of the Penn IRB. We believe that the exercise games themselves are a key contribution of this work, so we have attempted to provide the information needed for interested parties to reproduce and build on these games. A video explaining each of the exercise games is available here: <ext-link ext-link-type="uri" xlink:href="https://www.youtube.com/watch?v=5zlaqlJJpts&amp;feature=youtu.be">https://www.youtube.com/watch?v=5zlaqlJJpts&amp;feature=youtu.be</ext-link>. Interested parties can download the source code for our games here: <ext-link ext-link-type="uri" xlink:href="https://github.com/shareresearchteam/baxter-exercise-games">https://github.com/shareresearchteam/baxter-exercise-games</ext-link>. In this repository, we include details on how to launch the exercise games in the same way that we did in our study.</p>
            </notes>
            <notes>
              <title>Ethics approval and consent to participate</title>
              <p>The Penn IRB approved all study procedures under protocol 826370. All participants completed an informed consent document before beginning the study.</p>
            </notes>
            <notes>
              <title>Consent for publication</title>
              <p>All individuals depicted in this article have given written consent for their data and images to be used in this way.</p>
            </notes>
            <notes notes-type="COI-statement">
              <title>Competing interests</title>
              <p>NF now works at Oregon State University. KK and MM now work at the Max Planck Institute for Intelligent Systems. KK has also served as the Chief Scientist for Tactai, Inc. MJ is the founder of Recupero Robotics, LLC.</p>
            </notes>
            <ref-list id="Bib1">
              <title>References</title>
              <ref id="CR1">
                <label>1</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Coughlin</surname>
                      <given-names>JF</given-names>
                    </name>
                    <name>
                      <surname>Pope</surname>
                      <given-names>JE</given-names>
                    </name>
                    <name>
                      <surname>Leedle</surname>
                      <given-names>BR</given-names>
                    </name>
                  </person-group>
                  <article-title>Old age, new technology, and future innovations in disease management and home health care</article-title>
                  <source>Home Health Care Manag Pract</source>
                  <year>2006</year>
                  <volume>18</volume>
                  <issue>3</issue>
                  <fpage>196</fpage>
                  <lpage>207</lpage>
                  <pub-id pub-id-type="doi">10.1177/1084822305281955</pub-id>
                </element-citation>
              </ref>
              <ref id="CR2">
                <label>2</label>
                <element-citation publication-type="book">
                  <person-group person-group-type="author">
                    <collab>World Health Organization</collab>
                  </person-group>
                  <source>World Report on Ageing and Health</source>
                  <year>2015</year>
                  <publisher-loc>Geneva</publisher-loc>
                  <publisher-name>World Health Organization</publisher-name>
                </element-citation>
              </ref>
              <ref id="CR3">
                <label>3</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Dawe</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Moore-Orr</surname>
                      <given-names>R</given-names>
                    </name>
                  </person-group>
                  <article-title>Low-intensity, range-of-motion exercise: invaluable nursing care for elderly patients</article-title>
                  <source>J Adv Nurs</source>
                  <year>1995</year>
                  <volume>21</volume>
                  <issue>4</issue>
                  <fpage>675</fpage>
                  <lpage>81</lpage>
                  <pub-id pub-id-type="doi">10.1046/j.1365-2648.1995.21040675.x</pub-id>
                  <pub-id pub-id-type="pmid">7797702</pub-id>
                </element-citation>
              </ref>
              <ref id="CR4">
                <label>4</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Bauman</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Merom</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Bull</surname>
                      <given-names>FC</given-names>
                    </name>
                    <name>
                      <surname>Buchner</surname>
                      <given-names>DM</given-names>
                    </name>
                    <name>
                      <surname>Fiatarone Singh</surname>
                      <given-names>MA</given-names>
                    </name>
                  </person-group>
                  <article-title>Updating the evidence for physical activity: Summative reviews of the epidemiological evidence, prevalence, and interventions to promote “active aging”</article-title>
                  <source>Gerontologist</source>
                  <year>2016</year>
                  <volume>56</volume>
                  <issue>Suppl_2</issue>
                  <fpage>268</fpage>
                  <lpage>80</lpage>
                  <pub-id pub-id-type="doi">10.1093/geront/gnw031</pub-id>
                </element-citation>
              </ref>
              <ref id="CR5">
                <label>5</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>de Souto Barreto</surname>
                      <given-names>P</given-names>
                    </name>
                    <name>
                      <surname>Morley</surname>
                      <given-names>JE</given-names>
                    </name>
                    <name>
                      <surname>Chodzko-Zajko</surname>
                      <given-names>W</given-names>
                    </name>
                    <name>
                      <surname>Pitkala</surname>
                      <given-names>KH</given-names>
                    </name>
                    <name>
                      <surname>Weening-Djiksterhuis</surname>
                      <given-names>E</given-names>
                    </name>
                    <name>
                      <surname>Rodriguez-Manas</surname>
                      <given-names>L</given-names>
                    </name>
                    <name>
                      <surname>Barbagallo</surname>
                      <given-names>M</given-names>
                    </name>
                    <name>
                      <surname>Rosendahl</surname>
                      <given-names>E</given-names>
                    </name>
                    <name>
                      <surname>Sinclair</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Landi</surname>
                      <given-names>F</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Recommendations on physical activity and exercise for older adults living in long-term care facilities: A taskforce report</article-title>
                  <source>J Am Med Dir Assoc</source>
                  <year>2016</year>
                  <volume>17</volume>
                  <issue>5</issue>
                  <fpage>381</fpage>
                  <lpage>92</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.jamda.2016.01.021</pub-id>
                  <pub-id pub-id-type="pmid">27012368</pub-id>
                </element-citation>
              </ref>
              <ref id="CR6">
                <label>6</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Brackenridge</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Bradnam</surname>
                      <given-names>LV</given-names>
                    </name>
                    <name>
                      <surname>Lennon</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Costi</surname>
                      <given-names>JJ</given-names>
                    </name>
                    <name>
                      <surname>Hobbs</surname>
                      <given-names>DA</given-names>
                    </name>
                  </person-group>
                  <article-title>A review of rehabilitation devices to promote upper limb function following stroke</article-title>
                  <source>Neurosci Biomed Eng</source>
                  <year>2016</year>
                  <volume>4</volume>
                  <issue>1</issue>
                  <fpage>25</fpage>
                  <lpage>42</lpage>
                  <pub-id pub-id-type="doi">10.2174/2213385204666160303220102</pub-id>
                </element-citation>
              </ref>
              <ref id="CR7">
                <label>7</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Fasola</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Matarić</surname>
                      <given-names>MJ</given-names>
                    </name>
                  </person-group>
                  <article-title>Using socially assistive human–robot interaction to motivate physical exercise for older adults</article-title>
                  <source>Proc IEEE</source>
                  <year>2012</year>
                  <volume>100</volume>
                  <issue>8</issue>
                  <fpage>2512</fpage>
                  <lpage>26</lpage>
                  <pub-id pub-id-type="doi">10.1109/JPROC.2012.2200539</pub-id>
                </element-citation>
              </ref>
              <ref id="CR8">
                <label>8</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Kashi</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Levy-Tzedek</surname>
                      <given-names>S</given-names>
                    </name>
                  </person-group>
                  <article-title>Smooth leader or sharp follower? playing the mirror game with a robot</article-title>
                  <source>Restor Neurol Neurosci</source>
                  <year>2018</year>
                  <volume>36</volume>
                  <issue>2</issue>
                  <fpage>147</fpage>
                  <lpage>59</lpage>
                  <?supplied-pmid 29036853?>
                  <pub-id pub-id-type="pmid">29036853</pub-id>
                </element-citation>
              </ref>
              <ref id="CR9">
                <label>9</label>
                <mixed-citation publication-type="other">Fitter NT, Kuchenbecker KJ. Equipping the Baxter robot with human-inspired hand-clapping skills. In: Proc. IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN): 2016. p. 105–12. 10.1109/roman.2016.7745097.</mixed-citation>
              </ref>
              <ref id="CR10">
                <label>10</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Fitter</surname>
                      <given-names>NT</given-names>
                    </name>
                    <name>
                      <surname>Kuchenbecker</surname>
                      <given-names>KJ</given-names>
                    </name>
                  </person-group>
                  <article-title>Teaching a robot bimanual hand-clapping games via wrist-worn imus</article-title>
                  <source>Frontiers Robot AI</source>
                  <year>2018</year>
                  <volume>5</volume>
                  <fpage>85</fpage>
                  <pub-id pub-id-type="doi">10.3389/frobt.2018.00085</pub-id>
                </element-citation>
              </ref>
              <ref id="CR11">
                <label>11</label>
                <mixed-citation publication-type="other">Fitter NT, Hawkes DT, Johnson MJ, Kuchenbecker KJ. Designing human-robot exercise games for Baxter. In: Late-Breaking Results Report in Proc. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE conference proceedings: 2016. p. 3434–5.</mixed-citation>
              </ref>
              <ref id="CR12">
                <label>12</label>
                <mixed-citation publication-type="other">Fitter NT, Kuchenbecker KJ. Hand-clapping games with a Baxter robot. In: Demonstration in Proc. ACM/IEEE International Conference on Human-Robot Interaction (HRI). ACM conference proceedings: 2017. p. 40.</mixed-citation>
              </ref>
              <ref id="CR13">
                <label>13</label>
                <mixed-citation publication-type="other">Sonneveld MH, Schifferstein HNJ. The tactual experience of objects. Prod Experience. 2008;41–67. <ext-link ext-link-type="uri" xlink:href="https://www.sciencedirect.com/book/9780080450896/product-experience#book-info">https://www.sciencedirect.com/book/9780080450896/product-experience#book-info</ext-link>.</mixed-citation>
              </ref>
              <ref id="CR14">
                <label>14</label>
                <mixed-citation publication-type="other">Klemmer SR, Hartmann B, Takayama L. How bodies matter: five themes for interaction design. In: Proc. ACM Conference on Designing Interactive Systems: 2006. p. 140–9. 10.1145/1142405.1142429.</mixed-citation>
              </ref>
              <ref id="CR15">
                <label>15</label>
                <mixed-citation publication-type="other">Yohanan S, MacLean KE. The Haptic Creature Project: Social human-robot interaction through affective touch. In: Proc. The Society for the Study of Artificial Intelligence and Simulation of Behavior (AISB) Symposium on the Role of Virtual Creatures in a Computerized Society: 2008. p. 7–11.</mixed-citation>
              </ref>
              <ref id="CR16">
                <label>16</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Shibata</surname>
                      <given-names>T</given-names>
                    </name>
                    <name>
                      <surname>Wada</surname>
                      <given-names>K</given-names>
                    </name>
                  </person-group>
                  <article-title>Robot therapy: a new approach for mental healthcare of the elderly–a mini-review</article-title>
                  <source>Gerontology</source>
                  <year>2011</year>
                  <volume>57</volume>
                  <issue>4</issue>
                  <fpage>378</fpage>
                  <lpage>86</lpage>
                  <pub-id pub-id-type="doi">10.1159/000319015</pub-id>
                  <pub-id pub-id-type="pmid">20639620</pub-id>
                </element-citation>
              </ref>
              <ref id="CR17">
                <label>17</label>
                <mixed-citation publication-type="other">Stiehl WD, Breazeal C, Han K-H, Lieberman J, Lalla L, Maymin A, Salinas J, Fuentes D, Toscano R, Tong CH, Kishore A, Berlin M, Gray J. The Huggable: A therapeutic robotic companion for relational, affective touch. In: Proc. ACM SIGGRAPH Conference, Emerging Technologies: 2006. p. 15. 10.1109/ccnc.2006.1593253.</mixed-citation>
              </ref>
              <ref id="CR18">
                <label>18</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Block</surname>
                      <given-names>AE</given-names>
                    </name>
                    <name>
                      <surname>Kuchenbecker</surname>
                      <given-names>KJ</given-names>
                    </name>
                  </person-group>
                  <article-title>Softness, warmth, and responsiveness improve robot hugs</article-title>
                  <source>Int J Soc Robot</source>
                  <year>2019</year>
                  <volume>11</volume>
                  <issue>1</issue>
                  <fpage>49</fpage>
                  <lpage>64</lpage>
                  <pub-id pub-id-type="doi">10.1007/s12369-018-0495-2</pub-id>
                </element-citation>
              </ref>
              <ref id="CR19">
                <label>19</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Deutsch</surname>
                      <given-names>JE</given-names>
                    </name>
                    <name>
                      <surname>Borbely</surname>
                      <given-names>M</given-names>
                    </name>
                    <name>
                      <surname>Filler</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Huhn</surname>
                      <given-names>K</given-names>
                    </name>
                    <name>
                      <surname>Guarrera-Bowlby</surname>
                      <given-names>P</given-names>
                    </name>
                  </person-group>
                  <article-title>Use of a low-cost, commercially available gaming console (Wii) for rehabilitation of an adolescent with cerebral palsy</article-title>
                  <source>Phys Ther</source>
                  <year>2008</year>
                  <volume>88</volume>
                  <issue>10</issue>
                  <fpage>1196</fpage>
                  <lpage>207</lpage>
                  <pub-id pub-id-type="doi">10.2522/ptj.20080062</pub-id>
                  <pub-id pub-id-type="pmid">18689607</pub-id>
                </element-citation>
              </ref>
              <ref id="CR20">
                <label>20</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Combs</surname>
                      <given-names>SA</given-names>
                    </name>
                    <name>
                      <surname>Diehl</surname>
                      <given-names>MD</given-names>
                    </name>
                    <name>
                      <surname>Staples</surname>
                      <given-names>WH</given-names>
                    </name>
                    <name>
                      <surname>Conn</surname>
                      <given-names>L</given-names>
                    </name>
                    <name>
                      <surname>Davis</surname>
                      <given-names>K</given-names>
                    </name>
                    <name>
                      <surname>Lewis</surname>
                      <given-names>N</given-names>
                    </name>
                    <name>
                      <surname>Schaneman</surname>
                      <given-names>K</given-names>
                    </name>
                  </person-group>
                  <article-title>Boxing training for patients with Parkinson disease: a case series</article-title>
                  <source>Phys Ther</source>
                  <year>2011</year>
                  <volume>91</volume>
                  <issue>1</issue>
                  <fpage>132</fpage>
                  <lpage>42</lpage>
                  <pub-id pub-id-type="doi">10.2522/ptj.20100142</pub-id>
                  <pub-id pub-id-type="pmid">21088118</pub-id>
                </element-citation>
              </ref>
              <ref id="CR21">
                <label>21</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Ren</surname>
                      <given-names>Y</given-names>
                    </name>
                    <name>
                      <surname>Kang</surname>
                      <given-names>SH</given-names>
                    </name>
                    <name>
                      <surname>Park</surname>
                      <given-names>H-S</given-names>
                    </name>
                    <name>
                      <surname>Wu</surname>
                      <given-names>Y-N</given-names>
                    </name>
                    <name>
                      <surname>Zhang</surname>
                      <given-names>L-Q</given-names>
                    </name>
                  </person-group>
                  <article-title>Developing a multi-joint upper limb exoskeleton robot for diagnosis, therapy, and outcome evaluation in neurorehabilitation</article-title>
                  <source>IEEE Trans Neural Syst Rehabil Eng</source>
                  <year>2012</year>
                  <volume>21</volume>
                  <issue>3</issue>
                  <fpage>490</fpage>
                  <lpage>9</lpage>
                  <?supplied-pmid 23096119?>
                  <pub-id pub-id-type="pmid">23096119</pub-id>
                </element-citation>
              </ref>
              <ref id="CR22">
                <label>22</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Riener</surname>
                      <given-names>R</given-names>
                    </name>
                    <name>
                      <surname>Guidali</surname>
                      <given-names>M</given-names>
                    </name>
                    <name>
                      <surname>Keller</surname>
                      <given-names>U</given-names>
                    </name>
                    <name>
                      <surname>Duschau-Wicke</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Klamroth</surname>
                      <given-names>V</given-names>
                    </name>
                    <name>
                      <surname>Nef</surname>
                      <given-names>T</given-names>
                    </name>
                  </person-group>
                  <article-title>Transferring ARMin to the clinics and industry</article-title>
                  <source>Top Spinal Cord Inj Rehabil</source>
                  <year>2011</year>
                  <volume>17</volume>
                  <issue>1</issue>
                  <fpage>54</fpage>
                  <lpage>9</lpage>
                  <pub-id pub-id-type="doi">10.1310/sci1701-54</pub-id>
                </element-citation>
              </ref>
              <ref id="CR23">
                <label>23</label>
                <mixed-citation publication-type="other">Rodgers H, Bosomworth H, Krebs HI, van Wijck F, Howel D, Wilson N, Aird L, Alvarado N, Andole S, Cohen DL, et al.Robot assisted training for the upper limb after stroke (ratuls): A multicentre randomised controlled trial. Lancet. 2019. 10.1016/s0140-6736(19)31055-4.</mixed-citation>
              </ref>
              <ref id="CR24">
                <label>24</label>
                <mixed-citation publication-type="other">Guneysu Ozgur A, Wessel MJ, Johal W, Sharma K, Özgür A, Vuadens P, Mondada F, Hummel FC, Dillenbourg P. Iterative design of an upper limb rehabilitation game with tangible robots. In: Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction. ACM: 2018. p. 241–50. 10.1145/3171221.3171262.</mixed-citation>
              </ref>
              <ref id="CR25">
                <label>25</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Baur</surname>
                      <given-names>K</given-names>
                    </name>
                    <name>
                      <surname>Speth</surname>
                      <given-names>F</given-names>
                    </name>
                    <name>
                      <surname>Nagle</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Riener</surname>
                      <given-names>R</given-names>
                    </name>
                    <name>
                      <surname>Klamroth-Marganska</surname>
                      <given-names>V</given-names>
                    </name>
                  </person-group>
                  <article-title>Music meets robotics: a prospective randomized study on motivation during robot aided therapy</article-title>
                  <source>J Neuroengineering Rehabil</source>
                  <year>2018</year>
                  <volume>15</volume>
                  <issue>1</issue>
                  <fpage>79</fpage>
                  <pub-id pub-id-type="doi">10.1186/s12984-018-0413-8</pub-id>
                </element-citation>
              </ref>
              <ref id="CR26">
                <label>26</label>
                <mixed-citation publication-type="other">Johnson MJ, Johnson MA, Sefcik JS, Cacchione PZ, Mucchiani C, Lau T, Yim M. Task and design requirements for an affordable mobile service robot for elder care in an all-inclusive care for elders assisted-living setting. Int J Soc Robot. 2017:1–20. 10.1007/s12369-017-0436-5.</mixed-citation>
              </ref>
              <ref id="CR27">
                <label>27</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Chen</surname>
                      <given-names>TL</given-names>
                    </name>
                    <name>
                      <surname>Bhattacharjee</surname>
                      <given-names>T</given-names>
                    </name>
                    <name>
                      <surname>Beer</surname>
                      <given-names>JM</given-names>
                    </name>
                    <name>
                      <surname>Ting</surname>
                      <given-names>LH</given-names>
                    </name>
                    <name>
                      <surname>Hackney</surname>
                      <given-names>ME</given-names>
                    </name>
                    <name>
                      <surname>Rogers</surname>
                      <given-names>WA</given-names>
                    </name>
                    <name>
                      <surname>Kemp</surname>
                      <given-names>CC</given-names>
                    </name>
                  </person-group>
                  <article-title>Older adults’ acceptance of a robot for partner dance-based exercise</article-title>
                  <source>PloS ONE</source>
                  <year>2017</year>
                  <volume>12</volume>
                  <issue>10</issue>
                  <fpage>0182736</fpage>
                </element-citation>
              </ref>
              <ref id="CR28">
                <label>28</label>
                <mixed-citation publication-type="other">Cooney MD, Becker-Asano C, Kanda T, Alissandrakis A, Ishiguro H. Full-body gesture recognition using inertial sensors for playful interaction with small humanoid robot. In: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS): 2010. p. 2276–82. 10.1109/iros.2010.5650081.</mixed-citation>
              </ref>
              <ref id="CR29">
                <label>29</label>
                <mixed-citation publication-type="other">Nuñez D, Tempest M, Viola E, Breazeal C. An initial discussion of timing considerations raised during development of a magician-robot interaction. In: ACM/IEEE International Conference on Human-Robot Interaction (HRI) Workshop on Timing in HRI: 2014. <ext-link ext-link-type="uri" xlink:href="https://marcotempest.com/wp-content/uploads/2015/10/timinghri-2014.pdf">https://marcotempest.com/wp-content/uploads/2015/10/timinghri-2014.pdf</ext-link>.</mixed-citation>
              </ref>
              <ref id="CR30">
                <label>30</label>
                <mixed-citation publication-type="other">Pearce AJ, Adair B, Miller K, Ozanne E, Said C, Santamaria N, Morris ME. Robotics to enable older adults to remain living at home. J Aging Res. 2012; 2012. 10.1155/2012/538169.</mixed-citation>
              </ref>
              <ref id="CR31">
                <label>31</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Kachouie</surname>
                      <given-names>R</given-names>
                    </name>
                    <name>
                      <surname>Sedighadeli</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Khosla</surname>
                      <given-names>R</given-names>
                    </name>
                    <name>
                      <surname>Chu</surname>
                      <given-names>M-T</given-names>
                    </name>
                  </person-group>
                  <article-title>Socially assistive robots in elderly care: a mixed-method systematic literature review</article-title>
                  <source>Int J Hum Comput Interact</source>
                  <year>2014</year>
                  <volume>30</volume>
                  <issue>5</issue>
                  <fpage>369</fpage>
                  <lpage>93</lpage>
                  <pub-id pub-id-type="doi">10.1080/10447318.2013.873278</pub-id>
                </element-citation>
              </ref>
              <ref id="CR32">
                <label>32</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Takemoto</surname>
                      <given-names>M</given-names>
                    </name>
                    <name>
                      <surname>Manini</surname>
                      <given-names>TM</given-names>
                    </name>
                    <name>
                      <surname>Rosenberg</surname>
                      <given-names>DE</given-names>
                    </name>
                    <name>
                      <surname>Lazar</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Zlatar</surname>
                      <given-names>ZZ</given-names>
                    </name>
                    <name>
                      <surname>Das</surname>
                      <given-names>SK</given-names>
                    </name>
                    <name>
                      <surname>Kerr</surname>
                      <given-names>J</given-names>
                    </name>
                  </person-group>
                  <article-title>Diet and activity assessments and interventions using technology in older adults</article-title>
                  <source>Am J Prev Med</source>
                  <year>2018</year>
                  <volume>55</volume>
                  <issue>4</issue>
                  <fpage>105</fpage>
                  <lpage>15</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.amepre.2018.06.005</pub-id>
                </element-citation>
              </ref>
              <ref id="CR33">
                <label>33</label>
                <mixed-citation publication-type="other">Sabelli AM, Kanda T, Hagita N. A conversational robot in an elderly care center: an ethnographic study. In: Proc. ACM/IEEE International Conference on Human-Robot Interaction (HRI): 2011. p. 37–44. 10.1145/1957656.1957669.</mixed-citation>
              </ref>
              <ref id="CR34">
                <label>34</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Backonja</surname>
                      <given-names>U</given-names>
                    </name>
                    <name>
                      <surname>Hall</surname>
                      <given-names>AK</given-names>
                    </name>
                    <name>
                      <surname>Painter</surname>
                      <given-names>I</given-names>
                    </name>
                    <name>
                      <surname>Kneale</surname>
                      <given-names>L</given-names>
                    </name>
                    <name>
                      <surname>Lazar</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Cakmak</surname>
                      <given-names>M</given-names>
                    </name>
                    <name>
                      <surname>Thompson</surname>
                      <given-names>HJ</given-names>
                    </name>
                    <name>
                      <surname>Demiris</surname>
                      <given-names>G</given-names>
                    </name>
                  </person-group>
                  <article-title>Comfort and attitudes towards robots among young, middle-aged, and older adults: A cross-sectional study</article-title>
                  <source>J Nurs Sch</source>
                  <year>2018</year>
                  <volume>50</volume>
                  <issue>6</issue>
                  <fpage>623</fpage>
                  <lpage>33</lpage>
                  <pub-id pub-id-type="doi">10.1111/jnu.12430</pub-id>
                </element-citation>
              </ref>
              <ref id="CR35">
                <label>35</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Eizicovits</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Edan</surname>
                      <given-names>Y</given-names>
                    </name>
                    <name>
                      <surname>Tabak</surname>
                      <given-names>I</given-names>
                    </name>
                    <name>
                      <surname>Levy-Tzedek</surname>
                      <given-names>S</given-names>
                    </name>
                  </person-group>
                  <article-title>Robotic gaming prototype for upper limb exercise: Effects of age and embodiment on user preferences and movement</article-title>
                  <source>Restor Neurol Neurosci</source>
                  <year>2018</year>
                  <volume>36</volume>
                  <issue>2</issue>
                  <fpage>261</fpage>
                  <lpage>74</lpage>
                  <?supplied-pmid 29526862?>
                  <pub-id pub-id-type="pmid">29526862</pub-id>
                </element-citation>
              </ref>
              <ref id="CR36">
                <label>36</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Feingold-Polak</surname>
                      <given-names>R</given-names>
                    </name>
                    <name>
                      <surname>Elishay</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Shahar</surname>
                      <given-names>Y</given-names>
                    </name>
                    <name>
                      <surname>Stein</surname>
                      <given-names>M</given-names>
                    </name>
                    <name>
                      <surname>Edan</surname>
                      <given-names>Y</given-names>
                    </name>
                    <name>
                      <surname>Levy-Tzedek</surname>
                      <given-names>S</given-names>
                    </name>
                  </person-group>
                  <article-title>Differences between young and old users when interacting with a humanoid robot: A qualitative usability study</article-title>
                  <source>Paladyn J Behav Robot</source>
                  <year>2018</year>
                  <volume>9</volume>
                  <issue>1</issue>
                  <fpage>183</fpage>
                  <lpage>92</lpage>
                  <pub-id pub-id-type="doi">10.1515/pjbr-2018-0013</pub-id>
                </element-citation>
              </ref>
              <ref id="CR37">
                <label>37</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Lee</surname>
                      <given-names>HR</given-names>
                    </name>
                    <name>
                      <surname>Riek</surname>
                      <given-names>LD</given-names>
                    </name>
                  </person-group>
                  <article-title>Reframing assistive robots to promote successful aging</article-title>
                  <source>Trans Hum Robot Interact (THRI)</source>
                  <year>2018</year>
                  <volume>7</volume>
                  <issue>1</issue>
                  <fpage>11</fpage>
                </element-citation>
              </ref>
              <ref id="CR38">
                <label>38</label>
                <mixed-citation publication-type="other">Fitter NT, Kuchenbecker KJ. Designing and assessing expressive open-source faces for the Baxter robot. In: Proc. International Conference on Social Robotics (ICSR). Springer: 2016. p. 340–50. 10.1007/978-3-319-47437-3_33.</mixed-citation>
              </ref>
              <ref id="CR39">
                <label>39</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Lohse</surname>
                      <given-names>K</given-names>
                    </name>
                    <name>
                      <surname>Shirzad</surname>
                      <given-names>N</given-names>
                    </name>
                    <name>
                      <surname>Verster</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Hodges</surname>
                      <given-names>N</given-names>
                    </name>
                    <name>
                      <surname>Van der Loos</surname>
                      <given-names>HM</given-names>
                    </name>
                  </person-group>
                  <article-title>Video games and rehabilitation: Using design principles to enhance engagement in physical therapy</article-title>
                  <source>J Neurologic Phys Ther</source>
                  <year>2013</year>
                  <volume>37</volume>
                  <issue>4</issue>
                  <fpage>166</fpage>
                  <lpage>75</lpage>
                  <pub-id pub-id-type="doi">10.1097/NPT.0000000000000017</pub-id>
                </element-citation>
              </ref>
              <ref id="CR40">
                <label>40</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Barrett</surname>
                      <given-names>N</given-names>
                    </name>
                    <name>
                      <surname>Swain</surname>
                      <given-names>I</given-names>
                    </name>
                    <name>
                      <surname>Gatzidis</surname>
                      <given-names>C</given-names>
                    </name>
                    <name>
                      <surname>Mecheraoui</surname>
                      <given-names>C</given-names>
                    </name>
                  </person-group>
                  <article-title>The use and effect of video game design theory in the creation of game-based systems for upper limb stroke rehabilitation</article-title>
                  <source>J Rehabil Assist Technol Eng</source>
                  <year>2016</year>
                  <volume>3</volume>
                  <fpage>1</fpage>
                  <lpage>16</lpage>
                  <pub-id pub-id-type="doi">10.2196/rehab.5079</pub-id>
                </element-citation>
              </ref>
              <ref id="CR41">
                <label>41</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Novak</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Nagle</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Keller</surname>
                      <given-names>U</given-names>
                    </name>
                    <name>
                      <surname>Riener</surname>
                      <given-names>R</given-names>
                    </name>
                  </person-group>
                  <article-title>Increasing motivation in robot-aided arm rehabilitation with competitive and cooperative gameplay</article-title>
                  <source>J Neuroengineering Rehabil</source>
                  <year>2014</year>
                  <volume>11</volume>
                  <issue>1</issue>
                  <fpage>64</fpage>
                  <pub-id pub-id-type="doi">10.1186/1743-0003-11-64</pub-id>
                </element-citation>
              </ref>
              <ref id="CR42">
                <label>42</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Mathiowetz</surname>
                      <given-names>V</given-names>
                    </name>
                    <name>
                      <surname>Volland</surname>
                      <given-names>G</given-names>
                    </name>
                    <name>
                      <surname>Kashman</surname>
                      <given-names>N</given-names>
                    </name>
                    <name>
                      <surname>Weber</surname>
                      <given-names>K</given-names>
                    </name>
                  </person-group>
                  <article-title>Adult norms for the box and block test of manual dexterity</article-title>
                  <source>Am J Occup Ther</source>
                  <year>1985</year>
                  <volume>39</volume>
                  <issue>6</issue>
                  <fpage>386</fpage>
                  <lpage>91</lpage>
                  <pub-id pub-id-type="doi">10.5014/ajot.39.6.386</pub-id>
                  <pub-id pub-id-type="pmid">3160243</pub-id>
                </element-citation>
              </ref>
              <ref id="CR43">
                <label>43</label>
                <element-citation publication-type="book">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Beck</surname>
                      <given-names>AT</given-names>
                    </name>
                  </person-group>
                  <source>Cognitive therapy of depression</source>
                  <year>1979</year>
                  <publisher-loc>New York</publisher-loc>
                  <publisher-name>Guilford Press</publisher-name>
                </element-citation>
              </ref>
              <ref id="CR44">
                <label>44</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Nasreddine</surname>
                      <given-names>ZS</given-names>
                    </name>
                    <name>
                      <surname>Phillips</surname>
                      <given-names>NA</given-names>
                    </name>
                    <name>
                      <surname>Bédirian</surname>
                      <given-names>V</given-names>
                    </name>
                    <name>
                      <surname>Charbonneau</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Whitehead</surname>
                      <given-names>V</given-names>
                    </name>
                    <name>
                      <surname>Collin</surname>
                      <given-names>I</given-names>
                    </name>
                    <name>
                      <surname>Cummings</surname>
                      <given-names>JL</given-names>
                    </name>
                    <name>
                      <surname>Chertkow</surname>
                      <given-names>H</given-names>
                    </name>
                  </person-group>
                  <article-title>The Montreal cognitive assessment, MoCA: a brief screening tool for mild cognitive impairment</article-title>
                  <source>J Am Geriatr Soc</source>
                  <year>2005</year>
                  <volume>53</volume>
                  <issue>4</issue>
                  <fpage>695</fpage>
                  <lpage>99</lpage>
                  <pub-id pub-id-type="doi">10.1111/j.1532-5415.2005.53221.x</pub-id>
                  <pub-id pub-id-type="pmid">15817019</pub-id>
                </element-citation>
              </ref>
              <ref id="CR45">
                <label>45</label>
                <mixed-citation publication-type="other">Weiss A, Bernhaupt R, Tscheligi M, Wollherr D, Kuhnlenz K, Buss M. A methodological variation for acceptance evaluation of human-robot interaction in public places. In: Proc. IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN): 2008. p. 713–8. 10.1109/roman.2008.4600751.</mixed-citation>
              </ref>
              <ref id="CR46">
                <label>46</label>
                <mixed-citation publication-type="other">Heerink M, Krose B, Evers V, Wielinga B. Measuring acceptance of an assistive social robot: a suggested toolkit. In: Proc. IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN): 2009. p. 528–33. 10.1109/roman.2009.5326320.</mixed-citation>
              </ref>
              <ref id="CR47">
                <label>47</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Bradley</surname>
                      <given-names>MM</given-names>
                    </name>
                    <name>
                      <surname>Lang</surname>
                      <given-names>PJ</given-names>
                    </name>
                  </person-group>
                  <article-title>Measuring emotion: the self-assessment manikin and the semantic differential</article-title>
                  <source>J Behav Ther Exp Psychiatr</source>
                  <year>1994</year>
                  <volume>25</volume>
                  <issue>1</issue>
                  <fpage>49</fpage>
                  <lpage>59</lpage>
                  <pub-id pub-id-type="doi">10.1016/0005-7916(94)90063-9</pub-id>
                </element-citation>
              </ref>
              <ref id="CR48">
                <label>48</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Hart</surname>
                      <given-names>SG</given-names>
                    </name>
                    <name>
                      <surname>Staveland</surname>
                      <given-names>LE</given-names>
                    </name>
                  </person-group>
                  <article-title>Development of NASA-TLX (Task Load Index): results of empirical and theoretical research</article-title>
                  <source>Adv Psychol</source>
                  <year>1988</year>
                  <volume>52</volume>
                  <fpage>139</fpage>
                  <lpage>83</lpage>
                  <pub-id pub-id-type="doi">10.1016/S0166-4115(08)62386-9</pub-id>
                </element-citation>
              </ref>
              <ref id="CR49">
                <label>49</label>
                <mixed-citation publication-type="other">Heerink M, Krose B, Evers V, Wielinga B. The influence of social presence on enjoyment and intention to use of a robot and screen agent by elderly users. In: Proc. IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN): 2008. p. 695–700. 10.1109/roman.2008.4600748.</mixed-citation>
              </ref>
              <ref id="CR50">
                <label>50</label>
                <mixed-citation publication-type="other">Heath EM. Borg’s perceived exertion and pain scales. Med Sci Sports Exerc. 1998; 30(9). 10.1097/00005768-199809000-00018.</mixed-citation>
              </ref>
              <ref id="CR51">
                <label>51</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Garra</surname>
                      <given-names>G</given-names>
                    </name>
                    <name>
                      <surname>Singer</surname>
                      <given-names>AJ</given-names>
                    </name>
                    <name>
                      <surname>Taira</surname>
                      <given-names>BR</given-names>
                    </name>
                    <name>
                      <surname>Chohan</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Cardoz</surname>
                      <given-names>H</given-names>
                    </name>
                    <name>
                      <surname>Chisena</surname>
                      <given-names>E</given-names>
                    </name>
                    <name>
                      <surname>Thode Jr</surname>
                      <given-names>HC</given-names>
                    </name>
                  </person-group>
                  <article-title>Validation of the Wong-Baker FACES pain rating scale in pediatric emergency department patients</article-title>
                  <source>Acad Emerg Med</source>
                  <year>2010</year>
                  <volume>17</volume>
                  <issue>1</issue>
                  <fpage>50</fpage>
                  <lpage>4</lpage>
                  <pub-id pub-id-type="doi">10.1111/j.1553-2712.2009.00620.x</pub-id>
                  <pub-id pub-id-type="pmid">20003121</pub-id>
                </element-citation>
              </ref>
              <ref id="CR52">
                <label>52</label>
                <mixed-citation publication-type="other">Fitter NT, Chase EDZ, Kuchenbecker KJ. Exercise Games with a Baxter Robot YouTube Video. https://www.youtube.com/watch?v=5zlaqlJJpts&amp;feature=youtu.be. Accessed 7 Mar 2019.</mixed-citation>
              </ref>
              <ref id="CR53">
                <label>53</label>
                <mixed-citation publication-type="other">Fitter NT, Hawkes DT, Kuchenbecker KJ. Baxter Exercise Games GitHub Repository. <ext-link ext-link-type="uri" xlink:href="https://github.com/shareresearchteam/baxter-exercise-games">https://github.com/shareresearchteam/baxter-exercise-games</ext-link>.</mixed-citation>
              </ref>
              <ref id="CR54">
                <label>54</label>
                <mixed-citation publication-type="other">Schermerhorn P, Scheutz M, Crowell CR. Robot social presence and gender: Do females view robots differently than males? In: Proc. ACM/IEEE International Conference on Human-Robot Interaction (HRI): 2008. p. 263–70. 10.1145/1349822.1349857.</mixed-citation>
              </ref>
              <ref id="CR55">
                <label>55</label>
                <mixed-citation publication-type="other">Kuo IH, Rabindran JM, Broadbent E, Lee YI, Kerse N, Stafford R, MacDonald BA. Age and gender factors in user acceptance of healthcare robots. In: Proc. IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN): 2009. p. 214–9. 10.1109/roman.2009.5326292.</mixed-citation>
              </ref>
              <ref id="CR56">
                <label>56</label>
                <mixed-citation publication-type="other">Halpern D, Katz JE. Unveiling robotophobia and cyber-dystopianism: The role of gender, technology and religion on attitudes towards robots. In: Proc. ACM/IEEE International Conference on Human-Robot Interaction (HRI): 2012. p. 139–40. 10.1145/2157689.2157724.</mixed-citation>
              </ref>
              <ref id="CR57">
                <label>57</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Nomura</surname>
                      <given-names>T</given-names>
                    </name>
                    <name>
                      <surname>Kanda</surname>
                      <given-names>T</given-names>
                    </name>
                    <name>
                      <surname>Suzuki</surname>
                      <given-names>T</given-names>
                    </name>
                    <name>
                      <surname>Kato</surname>
                      <given-names>K</given-names>
                    </name>
                  </person-group>
                  <article-title>Prediction of human behavior in human–robot interaction using psychological scales for anxiety and negative attitudes toward robots</article-title>
                  <source>IEEE Trans Robot</source>
                  <year>2008</year>
                  <volume>24</volume>
                  <issue>2</issue>
                  <fpage>442</fpage>
                  <lpage>51</lpage>
                  <pub-id pub-id-type="doi">10.1109/TRO.2007.914004</pub-id>
                </element-citation>
              </ref>
              <ref id="CR58">
                <label>58</label>
                <element-citation publication-type="book">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Cohen</surname>
                      <given-names>J</given-names>
                    </name>
                  </person-group>
                  <source>Statistical Power Analysis for the Behavioral Sciences</source>
                  <year>2013</year>
                  <publisher-loc>New York</publisher-loc>
                  <publisher-name>Routledge</publisher-name>
                </element-citation>
              </ref>
              <ref id="CR59">
                <label>59</label>
                <mixed-citation publication-type="other">Čaić M, Avelino J, Mahr D, Odekerken-Schröder G, Bernardino A. Robotic versus human coaches for active aging: An automated social presence perspective. Int J Soc Robot. 2019:1–16. 10.1007/s12369-018-0507-2.</mixed-citation>
              </ref>
              <ref id="CR60">
                <label>60</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Bandura</surname>
                      <given-names>A</given-names>
                    </name>
                  </person-group>
                  <article-title>Self-efficacy mechanism in human agency</article-title>
                  <source>Am Psychol</source>
                  <year>1982</year>
                  <volume>37</volume>
                  <issue>2</issue>
                  <fpage>122</fpage>
                  <lpage>47</lpage>
                  <pub-id pub-id-type="doi">10.1037/0003-066X.37.2.122</pub-id>
                </element-citation>
              </ref>
            </ref-list>
          </back>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
