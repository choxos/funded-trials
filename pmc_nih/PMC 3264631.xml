<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2024-05-03T05:41:17Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:3264631" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:3264631</identifier>
        <datestamp>2012-01-30</datestamp>
        <setSpec>plosone</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" article-type="research-article">
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
              <journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id>
              <journal-id journal-id-type="publisher-id">plos</journal-id>
              <journal-id journal-id-type="pmc">plosone</journal-id>
              <journal-title-group>
                <journal-title>PLoS ONE</journal-title>
              </journal-title-group>
              <issn pub-type="epub">1932-6203</issn>
              <publisher>
                <publisher-name>Public Library of Science</publisher-name>
                <publisher-loc>San Francisco, USA</publisher-loc>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC3264631</article-id>
              <article-id pub-id-type="pmcid">PMC3264631</article-id>
              <article-id pub-id-type="pmc-uid">3264631</article-id>
              <article-id pub-id-type="pmid">22292057</article-id>
              <article-id pub-id-type="pmid">22292057</article-id>
              <article-id pub-id-type="publisher-id">PONE-D-11-12461</article-id>
              <article-id pub-id-type="doi">10.1371/journal.pone.0030845</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Research Article</subject>
                </subj-group>
                <subj-group subj-group-type="Discipline-v2">
                  <subject>Biology</subject>
                  <subj-group>
                    <subject>Computational Biology</subject>
                  </subj-group>
                  <subj-group>
                    <subject>Neuroscience</subject>
                    <subj-group>
                      <subject>Computational Neuroscience</subject>
                    </subj-group>
                    <subj-group>
                      <subject>Sensory Systems</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>Efficient Coding and Statistically Optimal Weighting of Covariance among Acoustic Attributes in Novel Sounds</article-title>
                <alt-title alt-title-type="running-head">Efficient Coding of Stimulus Covariance</alt-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author">
                  <name>
                    <surname>Stilp</surname>
                    <given-names>Christian E.</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff1"/>
                  <xref ref-type="corresp" rid="cor1">
                    <sup>*</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Kluender</surname>
                    <given-names>Keith R.</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff1"/>
                </contrib>
              </contrib-group>
              <aff id="aff1">
                <addr-line>Department of Psychology, University of Wisconsin – Madison, Madison, Wisconsin, United States of America</addr-line>
              </aff>
              <contrib-group>
                <contrib contrib-type="editor">
                  <name>
                    <surname>Vicario</surname>
                    <given-names>David S.</given-names>
                  </name>
                  <role>Editor</role>
                  <xref ref-type="aff" rid="edit1"/>
                </contrib>
              </contrib-group>
              <aff id="edit1">Rutgers University, United States of America</aff>
              <author-notes>
                <corresp id="cor1">* E-mail: <email>christian.stilp@gmail.com</email></corresp>
                <fn fn-type="con">
                  <p>Conceived and designed the experiments: CS KK. Performed the experiments: CS. Analyzed the data: CS KK. Wrote the paper: CS KK. Conducted computational modeling: CS.</p>
                </fn>
              </author-notes>
              <pub-date pub-type="collection">
                <year>2012</year>
              </pub-date>
              <pub-date pub-type="epub">
                <day>23</day>
                <month>1</month>
                <year>2012</year>
              </pub-date>
              <volume>7</volume>
              <issue>1</issue>
              <elocation-id>e30845</elocation-id>
              <history>
                <date date-type="received">
                  <day>2</day>
                  <month>7</month>
                  <year>2011</year>
                </date>
                <date date-type="accepted">
                  <day>29</day>
                  <month>12</month>
                  <year>2011</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>Stilp, Kluender.</copyright-statement>
                <copyright-year>2012</copyright-year>
                <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
                  <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are properly credited.</license-p>
                </license>
              </permissions>
              <abstract>
                <p>To the extent that sensorineural systems are efficient, redundancy should be extracted to optimize transmission of information, but perceptual evidence for this has been limited. Stilp and colleagues recently reported efficient coding of robust correlation (<italic>r</italic> = .97) among complex acoustic attributes (attack/decay, spectral shape) in novel sounds. Discrimination of sounds orthogonal to the correlation was initially inferior but later comparable to that of sounds obeying the correlation. These effects were attenuated for less-correlated stimuli (<italic>r</italic> = .54) for reasons that are unclear. Here, statistical properties of correlation among acoustic attributes essential for perceptual organization are investigated. Overall, simple strength of the principal correlation is inadequate to predict listener performance. Initial superiority of discrimination for statistically consistent sound pairs was relatively insensitive to decreased physical acoustic/psychoacoustic range of evidence supporting the correlation, and to more frequent presentations of the same orthogonal test pairs. However, increased range supporting an orthogonal dimension has substantial effects upon perceptual organization. Connectionist simulations and Eigenvalues from closed-form calculations of principal components analysis (PCA) reveal that perceptual organization is near-optimally weighted to shared versus unshared covariance in experienced sound distributions. Implications of reduced perceptual dimensionality for speech perception and plausible neural substrates are discussed.</p>
              </abstract>
              <counts>
                <page-count count="13"/>
              </counts>
            </article-meta>
          </front>
          <body>
            <sec id="s1">
              <title>Introduction</title>
              <p>To the extent that characteristics of a structured world are predictably related, inputs to sensory systems are redundant. It has long been proposed that the role of early sensory processing is to detect, extract, and exploit redundancy in the input <xref rid="pone.0030845-Attneave1" ref-type="bibr">[1]</xref>, <xref rid="pone.0030845-Barlow1" ref-type="bibr">[2]</xref>. Through processes of evolution and experience, response properties of sensorineural systems should complement statistical regularities of the stimuli to which they are exposed <xref rid="pone.0030845-Attneave1" ref-type="bibr">[1]</xref>–<xref rid="pone.0030845-Schwartz1" ref-type="bibr">[8]</xref>. These claims of ‘efficient coding’ enjoy a long history in vision research, although direct evidence from perceptual experiments is not abundant <xref rid="pone.0030845-Simoncelli1" ref-type="bibr">[9]</xref>. There is physiological evidence that responses of neurons at successive stages of processing become increasingly independent from one another <xref rid="pone.0030845-Vinje1" ref-type="bibr">[10]</xref>, <xref rid="pone.0030845-Vinje2" ref-type="bibr">[11]</xref>, with such demonstrations clearest in the auditory system. For example, Chechik and colleagues <xref rid="pone.0030845-Chechik1" ref-type="bibr">[12]</xref>, <xref rid="pone.0030845-Chechik2" ref-type="bibr">[13]</xref> report redundancy-reducing transformations of neural responses to bird call stimuli in the ascending auditory pathway of the cat. Auditory cortex responses shared less mutual information (less redundancy, or more independence) compared to neural responses in the inferior colliculus.</p>
              <p>Reduction of redundancy has often been inferred from perceptual findings. The most well-known example is the McCollough effect <xref rid="pone.0030845-McCollough1" ref-type="bibr">[14]</xref>, where observers adapt to a contingency between line orientation (horizontal, vertical) and color (red, green), but not to either dimension singly (see <xref rid="pone.0030845-Durgin1" ref-type="bibr">[15]</xref> for review). Adaptation to complex visual patterns <xref rid="pone.0030845-Barlow3" ref-type="bibr">[16]</xref>–<xref rid="pone.0030845-Movshon1" ref-type="bibr">[18]</xref> or to initially arbitrary but thoroughly trained crossmodal contingencies (between luminance and stiffness <xref rid="pone.0030845-Ernst1" ref-type="bibr">[19]</xref>) provide further examples from which redundancy reduction has been inferred.</p>
              <p>One limitation to broad application of efficient coding models is the nearly exclusive investigation of such processes in visual perception. Just as it is true for the optical world, lawful constraints on sound-producing events give rise to natural sounds that are acoustically complex with multiple, redundant attributes. For sounds created by real structures including musical instruments and vocal tracts, changes in different acoustic dimensions cohere in accordance with physical laws governing sound-producing sources. For example, articulatory maneuvers that produce consonant and vowel sounds give rise to multiple acoustic attributes, and changes among these attributes are often correlated <xref rid="pone.0030845-Lisker1" ref-type="bibr">[20]</xref>, <xref rid="pone.0030845-Repp1" ref-type="bibr">[21]</xref>.</p>
              <p>To investigate whether and how auditory perception is sensitive to correlations (redundancy) among acoustic properties, Stilp <italic>et al.</italic>
<xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref> created novel stimuli (heavily edited mixtures of French horn and tenor saxophone samples) that varied along two complex dimensions: attack/decay (AD; <xref ref-type="fig" rid="pone-0030845-g001">Figures 1A–1C</xref>) and spectral shape (SS; <xref ref-type="fig" rid="pone-0030845-g001">Figures 1D–1F</xref>). Each dimension was independently normed so that all pairs of sounds separated by a fixed number of stimulus steps were approximately equally discriminable. Series were fully crossed to generate a stimulus matrix from which subsets of stimuli were selected to present listeners with either a robust (<italic>r</italic> = ±0.97) or weaker correlation (<italic>r</italic> = ±0.54) between changes in AD and SS. Listeners completed AXB discrimination trials without feedback on stimulus pairs that either respected (Consistent condition) or violated the correlation (Orthogonal, Single-cue conditions). When AD and SS were highly correlated, discriminability of sound pairs obeying the correlation maintained, but became significantly worse for pairs that violate the correlation. This difference in discrimination was evident early in testing, and performance on Orthogonal and Single-cue pairs recovered by the end of the experiment. Conversely, when AD and SS were relatively weakly correlated (<italic>r</italic> = ±0.54), discrimination was equivalent throughout the experiment, suggesting that correlation must be relatively robust to produce differences in discriminability.</p>
              <fig id="pone-0030845-g001" position="float">
                <object-id pub-id-type="doi">10.1371/journal.pone.0030845.g001</object-id>
                <label>Figure 1</label>
                <caption>
                  <title>Example stimuli used in the present experiments.</title>
                  <p>The first row shows steps 1 (A; shortest attack/longest decay), 9 (B; intermediate attack/decay) and 18 (C; longest attack/shortest decay) out of 18 in the AD series. The second row shows steps 1 (D; most-French-horn-like), 9 (E; intermediate mixture) and 18 (F; most-tenor-saxophone-like) out of 18 in the SS series, with frequency axes magnified (shown only up to 6 kHz) to emphasize differences in spectral envelopes. The third row shows examples of the two experimental conditions. Black circles depict stimuli that obey a positive correlation between AD and SS (<italic>i.e.</italic>, lie on a main diagonal of the stimulus matrix; Consistent condition). Grey circles depict stimuli that violate that correlation (<italic>i.e.</italic>, lie on the perpendicular diagonal; Orthogonal condition). Examples in 1G depict no overall correlation between AD and SS, but experiments present a high ratio of Consistent∶Orthogonal sounds to introduce correlation among complex acoustic attributes. In counterbalanced conditions, grey sounds support a negative correlation between AD and SS while black sounds directly violate it. <xref ref-type="fig" rid="pone-0030845-g001">Figures 1A and 1D</xref> correspond to the black circle in the lower-left corner of 1G, <xref ref-type="fig" rid="pone-0030845-g001">figure 1C</xref> to the grey circle in the upper-left corner, and <xref ref-type="fig" rid="pone-0030845-g001">figure 1F</xref> to the grey circle in the lower-right corner.</p>
                </caption>
                <graphic xlink:href="pone.0030845.g001"/>
              </fig>
              <p>Stilp and colleagues tested three unsupervised neural network models, each testing a different hypothesis of how sensorineural systems exploit covariance, to examine how they accounted for listener performance. A Hebbian model <xref rid="pone.0030845-Hebb1" ref-type="bibr">[23]</xref>, <xref rid="pone.0030845-Oja1" ref-type="bibr">[24]</xref>, in which connection weights adjust in proportion to the correlation between input and output unit activations, predicted reduced discriminability of sounds violating the correlation, but not recovery to baseline levels later in the experiment as observed in listener data. An anti-Hebbian or decorrelation model <xref rid="pone.0030845-Barlow3" ref-type="bibr">[16]</xref>, <xref rid="pone.0030845-Clifford2" ref-type="bibr">[25]</xref>, in which output dimensions become orthogonal via symmetric inhibition between output units proportional to their correlation, predicted superior discrimination of sounds violating the correlation (Orthogonal), contrary to listener performance. Finally, a connectionist simulation of principal components analysis (PCA) <xref rid="pone.0030845-Sanger1" ref-type="bibr">[26]</xref> predicted the full pattern of results across experiments.</p>
              <p>In the PCA network, the first output inhibits inputs to subsequent outputs, thereby removing the principal component from the input pattern and leaving remaining outputs to capture residual covariance. Consistent with listener performance, network outputs initially organized with respect to the principal component (correlation) in the stimulus set, only gradually coming to discriminate or encode remaining variance (orthogonal and single-cue changes).</p>
              <p>The statistical purpose of PCA is to linearly transform input data to a new coordinate system for which the greatest amount of variance lies along the first coordinate, or principal component. The second coordinate must be uncorrelated with (orthogonal to) the first and under this restriction, captures the greatest amount of variance not accounted for by the first component. The same restrictions of orthogonality and maximization of variance not yet explained hold for subsequent components. In practice, PCA provides a highly efficient way to represent multidimensional data because derived component dimensions are orthogonal (share no variance), and relatively few components are typically necessary to capture most of the variance in the data. In the present application, there are only two input variables (AD and SS) and thus two components capture all of the variance.</p>
              <p>The linear algebraic solution to PCA yields an ordered set of orthogonal components (Eigenvectors) with accompanying weights (Eigenvalues). Each Eigenvalue is proportional to the variance that is accounted for by its associated Eigenvector, and these can be derived from either the covariance matrix or correlation matrix of the input variables. Because covariance among variables is sensitive to units (<italic>e.g.</italic>, degrees Fahrenheit versus Celsius), it is more common to solve for components and weights from a correlation matrix (normalized covariance.) Extending earlier work by Oja <xref rid="pone.0030845-Oja1" ref-type="bibr">[24]</xref> and others, Sanger <xref rid="pone.0030845-Sanger1" ref-type="bibr">[26]</xref> demonstrated that the model employed by Stilp and colleagues <xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref> finds the Eigenvectors of the input correlation matrix, and is certain to converge to the same solution as closed-form PCA.</p>
              <p>To the extent that listener performance can be predicted by PCA, one may infer that redundant attributes are efficiently coded into experience-driven perceptual dimensions at the expense of physical acoustic dimensions. Changes in performance reported by Stilp <italic>et al.</italic>
<xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref> are predicted by correlations between attributes, not attributes AD or SS <italic>per se</italic>. Further, changes in discriminability consequent to nearly-perfect, but not weaker, correlation are functionally sensible. Perceptual representation of the correlation is restricted to cases with sufficiently reliable evidence to limit the perceptual costs (error) of reduced dimensionality.</p>
              <p>Why efficient coding was not observed for stimuli with less robust but still notable correlation among attributes (<italic>r</italic> = ±0.54) remains unclear. Relative to the highly-correlated stimulus set presented in Experiment 2 of Stilp <italic>et al.</italic>
<xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref>, the less-correlated stimulus set (Experiment 3 in <xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref>): tested fewer correlated sounds (six versus 18), tested more orthogonal sounds (four versus two), and presented more orthogonal trials overall (three times as many, owing to testing three orthogonal pairs rather than just one). Each manipulation reflects distinct statistical properties that attenuate correlation between AD and SS. As such, each manipulation may contribute differently to perceptual organization and subsequent effects on discrimination, but the perceptual significance of each manipulation is unknown because all were made in concert.</p>
              <p>Redundancy between acoustic attributes is attenuated systematically across the following experiments to determine perceptual consequences of different statistical properties of correlations among stimulus attributes that are less than nearly-perfect (Expt. 2, <xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref>) but greater than that for which no difference in discrimination is observed (Expt. 3, <xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref>). Separate manipulations of stimulus sets are performed to investigate how strong correlations must be to elicit differential discriminability, and whether different means of attenuating correlation are perceptually equivalent. Predictions made by the PCA neural network are compared to listener performance in each experiment. The model's sensitivity to these manipulations and intermediate correlations is a strong test of its ability to predict listener performance. Finally, how different model predictions, operating on correlation versus covariance matrices, relate to listener performance are explored. Behavioral and computational results support near-optimal weighting of covariance among acoustic attributes.</p>
            </sec>
            <sec sec-type="materials|methods" id="s2">
              <title>Materials and Methods</title>
              <sec id="s2a">
                <title>1. Ethics Statement</title>
                <p>All experiments were approved by the Education and Social &amp; Behavioral Sciences Institutional Review Board at the University of Wisconsin. Written informed consent was obtained from all participants.</p>
              </sec>
              <sec id="s2b">
                <title>2. Listeners</title>
                <p>Two hundred undergraduates (40 per experiment, five experiments) from the University of Wisconsin – Madison participated, with no individual participating in multiple experiments. All reported normal hearing, and received course credit in exchange for their participation.</p>
              </sec>
              <sec id="s2c">
                <title>3. Stimuli</title>
                <p>All stimuli are novel complex sounds described in detail in Stilp <italic>et al.</italic>
<xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref>. Briefly, one waveform period (3.78 ms duration = 264 Hz fundamental frequency) from samples of a French horn and a tenor saxophone <xref rid="pone.0030845-Opolko1" ref-type="bibr">[27]</xref> was iterated to 500-ms duration. Samples were then edited to vary along one of two complex acoustic dimensions: attack/decay (AD) or spectral shape (SS), dimensions that are in principle relatively independent both perceptually and in early neural encoding <xref rid="pone.0030845-Caclin1" ref-type="bibr">[28]</xref>. AD was manipulated by varying the amplitude envelope of the stimulus which was set to zero at stimulus onset and offset, with linear ramps from onset to peak and back to offset without any steady state (<xref ref-type="fig" rid="pone-0030845-g001">Figure 1A–C</xref>). Attack duration in AD ranged from 20–390 ms in 17 steps (18 stimuli), with decay duration being the remainder of 500 ms (total duration) minus attack duration. SS was manipulated by mixing instrument samples in different proportions, ranging from 0.2 to 0.8 for each instrument and always summing to 1.0 across instruments (<italic>e.g.</italic>, adding 0.4 [French horn]+0.6 [tenor saxophone] to form a new spectral shape). Proportions were derived such that neighboring sounds in the SS series (17 pairs, 18 stimuli total) had equal Euclidean distances between their ERB-scaled magnitude spectra <xref rid="pone.0030845-Glasberg1" ref-type="bibr">[29]</xref> that had been processed through a bank of auditory filters <xref rid="pone.0030845-Patterson1" ref-type="bibr">[30]</xref> (<xref ref-type="fig" rid="pone-0030845-g001">Figure 1 D–F</xref>). Euclidean distance between spectra processed in such a manner has been shown to correspond well with perceptually significant change over time in speech <xref rid="pone.0030845-Stilp2" ref-type="bibr">[31]</xref>. Specific values for AD and SS series reported above were derived following exhaustive adjustment across hundreds of participants until every pair of sounds separated by three stimulus steps was equally discriminable to every other pair within and across stimulus series (≈65% correct for changes along one dimension, ≈69% for changes along both dimensions; see <xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref> for details). AD and SS series were fully crossed to generate a 324-sound stimulus matrix. Subsets of this matrix are presented to listeners in all of the following experiments (<xref ref-type="fig" rid="pone-0030845-g001">Figure 1G</xref>).</p>
              </sec>
              <sec id="s2d">
                <title>4. Experimental Design</title>
                <sec id="s2d1">
                  <title>a. All experiments</title>
                  <p>All experiments employ designs similar to those reported by Stilp <italic>et al.</italic>
<xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref> with one notable change. While Stilp <italic>et al.</italic>
<xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref> also assessed discrimination of sounds varying along AD or SS with the other dimension fixed (Single-cue stimuli), those trials are eliminated here so that all performance comparisons are made between experimental conditions in which both acoustic cues change. Stimuli belong to one of two conditions: sounds that lay along the main diagonal of the stimulus matrix, conforming to the robust correlation between AD and SS (Consistent condition), or sounds that lay along the perpendicular diagonal that bisects the matrix, directly violating this correlation (Orthogonal condition; see <xref ref-type="fig" rid="pone-0030845-g001">Figure 1G</xref>). Each experiment is counterbalanced such that twenty participants discriminated stimuli with a positive correlation between AD and SS, and twenty discriminated stimuli with a negative correlation (<italic>i.e.</italic>, 90° rotation of stimuli depicted in <xref ref-type="fig" rid="pone-0030845-g002">Figure 2</xref>). Thus, one group's Orthogonal stimuli serve as Consistent stimuli to the other group and <italic>vice versa</italic>. Sounds in the Consistent condition are arranged into pairs each separated by three stimulus steps, and likewise for Orthogonal sounds. Each stimulus pair was presented in all possible AXB triads (AAB, ABB, BAA, BBA) with 250-ms ISIs.</p>
                  <fig id="pone-0030845-g002" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pone.0030845.g002</object-id>
                    <label>Figure 2</label>
                    <caption>
                      <title>Stimuli and behavioral results for all experiments (black = Consistent condition, grey = Orthogonal condition).</title>
                      <p>Stimulus representations follow <xref ref-type="fig" rid="pone-0030845-g001">Figure 1G</xref>. While only positive correlations are shown, experiments were counterbalanced between positive and negative correlations. All behavioral results depict proportion correct discrimination on the ordinate and testing block number on the abscissa. Stimuli (A) and results (B) for Experiment 1 (base design; <italic>r</italic> = ±0.98). Stimuli (C) and results (D) for Experiment 2 (truncation of evidence supporting the correlation; <italic>r</italic> = ±0.81). Stimuli (E) and results (F) for Experiment 3 (expansion of evidence supporting the orthogonal dimension; <italic>r</italic> = ±0.83). Stimuli (G) and results (H) for Experiment 4 (threefold increase in sampling Orthogonal stimuli; <italic>r</italic> = ±0.95). Stimuli (I) and results (J) for Experiment 5 (tenfold increase in sampling Orthogonal stimuli; <italic>r</italic> = ±0.83). * indicates significant difference (<italic>p</italic>&lt;.05) as assessed by paired-sample two-tailed <italic>t</italic>-tests.</p>
                    </caption>
                    <graphic xlink:href="pone.0030845.g002"/>
                  </fig>
                  <p>Correlation coefficients were calculated for each stimulus set using nominal values from 1 to 18 to represent AD and SS values. Without any sounds along the perpendicular (orthogonal) diagonal, the correlation between AD and SS would equal 1. Across experiments, different stimuli presented in the Orthogonal condition attenuate this correlation to varying degrees.</p>
                </sec>
                <sec id="s2d2">
                  <title>b. Experiment 1</title>
                  <p>Experiment 1 serves as a replication of Experiment 2 in Stilp <italic>et al.</italic>
<xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref>, but without any Single-cue stimuli. Successful replication permits Experiment 1 to serve as the base design for Experiments 2 through 5, in which the correlation among acoustic attributes is systematically violated to evaluate the perceptual significance of different statistical characteristics of the stimulus set and whether they promote or hinder efficient coding. The Consistent condition was comprised of all 18 sounds (15 pairs) along the main diagonal of the stimulus matrix, and the Orthogonal condition was comprised of 2 sounds (one pair) along the perpendicular diagonal, resulting in a nearly-perfect correlation between AD and SS (<italic>r</italic> = ±0.98; <xref ref-type="fig" rid="pone-0030845-g002">Figure 2A</xref>).</p>
                </sec>
                <sec id="s2d3">
                  <title>c. Experiment 2</title>
                  <p>Experiment 2 tests the degree to which differences in discriminability (Consistent versus Orthogonal) are sensitive to the physical acoustic/psychoacoustic range of exemplars supporting the correlation (<italic>i.e.</italic>, the diagonal bisecting the stimulus matrix) relative to the variability supporting the orthogonal dimension. By reducing the extent of evidence supporting the correlation, listeners may more quickly discover variability not explained by the correlation, resulting in comparable discrimination across conditions throughout the experiment. Two sounds on the Orthogonal diagonal are arranged into one stimulus pair as before, but the range over which AD and SS covary is truncated from 18 to eight sounds (15 pairs to five), reducing the correlation between AD and SS (<italic>r</italic> = ±0.81; <xref ref-type="fig" rid="pone-0030845-g002">Figure 2C</xref>).</p>
                </sec>
                <sec id="s2d4">
                  <title>d. Experiment 3</title>
                  <p>Experiment 3 examines whether perception is sensitive to the range of variance orthogonal to the correlation. Stimulus sets tested in Experiments 1 and 2 included only two Orthogonal sounds, both located very close to the correlated diagonal in the stimulus matrix. However, the less-correlated stimulus set tested in Experiment 3 of Stilp <italic>et al.</italic>
<xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref> included both these two proximal Orthogonal sounds and two more extreme sounds, presenting a wider range of evidence violating the correlation. Presentation of Orthogonal sounds increasingly distinct from the correlation (<italic>i.e.</italic>, located further away from the diagonal in the stimulus matrix) may contribute to listeners discovering this variance more quickly, reducing or even eliminating significant differences in discrimination early in testing. In a review of visual adaptation studies, Kohn <xref rid="pone.0030845-Kohn1" ref-type="bibr">[32]</xref> notes that adaptation effects are directly affected by the similarity between adaptor and test item. By decreasing similarity between conditions through presentation of more extreme Orthogonal sounds, listeners' adaptation to the contingency between AD and SS (<italic>i.e.</italic>, differences in discriminability depending on whether trials respect or violate the correlation) should reduce in magnitude, duration, or both. Stimuli in Experiment 3 consist of 18 sounds on the correlated diagonal (15 pairs) and the same four sounds on the orthogonal diagonal (3 pairs) as presented in Experiment 3 of <xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref> (<italic>r</italic> = ±0.83; <xref ref-type="fig" rid="pone-0030845-g002">Figure 2E</xref>).</p>
                </sec>
                <sec id="s2d5">
                  <title>e. Experiment 4</title>
                  <p>By adding more extreme Orthogonal sounds to the stimulus set, Experiment 3 tests three Orthogonal pairs rather than the one pair tested in Experiments 1 and 2, thus conflating the extent of Orthogonal evidence with increased probability of Orthogonal pairs. Experiment 4 unconfounds these factors, examining changes in discriminability as a function of the simple probability of Orthogonal test trials. The lone Orthogonal pair presented in Experiments 1 and 2 was tested three times as often as each of the 15 Consistent pairs, producing the same ratio of Consistent-to-Orthogonal test trials as in Experiment 3. Increasing the probability of the Orthogonal pair threefold only slightly reduces the correlation between AD and SS (<italic>r</italic> = ±0.95; <xref ref-type="fig" rid="pone-0030845-g002">Figure 2G</xref>).</p>
                </sec>
                <sec id="s2d6">
                  <title>f. Experiment 5</title>
                  <p>The possibility exists that any significant differences in discriminability in Experiment 4 may be attributable to the robustness of correlation (<italic>r</italic> = ±0.95) rather than probability of Orthogonal test trials (presented three times as often as any Consistent trial). Experiment 5 presents a stronger test by increasing the frequency of Orthogonal test trials until the strength of correlation is equated to that of Experiment 3 (<italic>r</italic> = ±0.83). This was accomplished by presenting the lone Orthogonal pair 10 times as often as any given Consistent pair (15 total; <xref ref-type="fig" rid="pone-0030845-g002">Figure 2I</xref>).</p>
                </sec>
              </sec>
              <sec id="s2e">
                <title>4. Procedure</title>
                <p>Sounds were upsampled to 48828 Hz, D/A converted (Tucker-Davis Technology RP2.1), amplified (TDT HB4), and presented diotically over circumaural headphones (Beyer Dynamic DT-150) at 72 dB SPL. Following acquisition of informed consent, between one and three individuals participated concurrently in single-subject soundproof booths. Each participant heard trials in a different randomized order. Trials were presented twice in each of three blocks in Experiments 1 and 3, and were presented three times per block in Experiment 2 in order to produce an experimental session of comparable overall duration. In Experiments 4 and 5, the Orthogonal pair is deliberately oversampled. No feedback was provided. Listeners were given the opportunity to take a short break between testing blocks. Owing to the varying numbers of trials presented (E1: 128 trials/block, 384 trials total; E2: 72 trials/block, 216 trials total; E3: 144 trials/block, 432 trials total; E4: 144 trials/block, 432 trials total; E5: 200 trials/block, 600 trials total), experiments had different durations (E1: 25 min; E2: 15 min; E3: 30 min; E4: 30 min; E5: 40 min).</p>
              </sec>
              <sec id="s2f">
                <title>5. Computational Modeling</title>
                <sec id="s2f1">
                  <title>a. Correlation-based model</title>
                  <p>The same unsupervised PCA network model <xref rid="pone.0030845-Sanger1" ref-type="bibr">[26]</xref> employed by Stilp <italic>et al.</italic>
<xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref> was used. This model discovers Eigenvectors based on the correlation matrix of the inputs. The present experiments demonstrate this aspect of the standard model (versus calculating Eigenvectors from the covariance matrix of the inputs) to be a perceptually important one, and its success predicting results of Stilp <italic>et al.</italic>
<xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref> makes it an appropriate starting point. The model featured two input units (one corresponding to AD, the other to SS) which were fully connected in a feed-forward manner to two output units with no hidden layer and no bias (<xref ref-type="fig" rid="pone-0030845-g003">Figure 3</xref>). Inhibitory connections projected from the first output back to input units at a fixed value of 1. Output activations and subsequent effects on input states were implemented serially: the first output unit was activated; its activation was “subtracted out” of the input values; then, the second output unit was activated. Feed-forward weights were trained using standard Hebbian learning, resulting in the first output unit representing the principal component of the inputs while the second output captured residual (orthogonal) covariance. Importantly, while closed-form (linear algebraic) PCA calculates Eigenvectors and corresponding components simultaneously, the model calculates these elements iteratively. The rate at which the model learns the second component (as reflected by decreased Euclidean distances between Orthogonal stimuli compared to Consistent stimuli before returning to baseline) is of key interest in the comparison to listener data.</p>
                  <fig id="pone-0030845-g003" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pone.0030845.g003</object-id>
                    <label>Figure 3</label>
                    <caption>
                      <title>PCA network architecture.</title>
                      <p>Two input units (one corresponding to AD, one to SS) are fully connected to two output units via feed-forward excitatory weights (solid arrows) without any hidden layer or bias. The first output unit projects inhibitory weights (dashed lines) back to the inputs, effectively removing the principal component from the inputs and leaving the second output to encode remaining (orthogonal) covariance. Euclidean distances among output patterns were calculated after each epoch.</p>
                    </caption>
                    <graphic xlink:href="pone.0030845.g003"/>
                  </fig>
                  <p>The model was initialized with weights (2-by-2 identity matrix) that ensured output patterns initially mirrored input patterns. Weights ultimately converge to Eigenvectors of the input correlation matrix, organized in decreasing Eigenvalue order. Simulations were comprised of continuous testing with a small learning rate. The model was trained with analogs of each stimulus set, with 18 steps of AD and SS normalized and coded as values −8.5 through 8.5. Euclidean distances calculated between output patterns (<italic>i.e.</italic>, representations of stimulus pairs) after each epoch provide a model analog of perceptual discriminability.</p>
                  <p>Simulations were conducted for a standard duration of 500 epochs for ease of visualization and comparison across experiments. Simulation of all experiments achieved convergence (no further changes in weights) following this duration except for Experiment 1, which reached convergence after 600 epochs. The reasons for portraying the first 500 epochs of this simulation are twofold. First, the first 500 epochs are plotted to better illustrate changes in Euclidean distances early in the simulation, which are of principal interest as discriminability is predicted to be equivalent across conditions later in the experiment. Second, Euclidean distances and weights associated with the second Eigenvector (Orthogonal stimuli) were within 2% of their final values at 500 epochs, so the model makes qualitatively the same prediction at both points in the simulation – that Consistent and Orthogonal stimuli should be equally discriminable. Simulation results are presented in the left (solid lines) column of <xref ref-type="fig" rid="pone-0030845-g004">Figure 4</xref>.</p>
                  <fig id="pone-0030845-g004" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pone.0030845.g004</object-id>
                    <label>Figure 4</label>
                    <caption>
                      <title>PCA network simulations (left column) and choice model performance (center, right columns) for all experiments (black = Consistent condition, grey = Orthogonal condition).</title>
                      <p>The first row corresponds to Experiment 1, the second row to Experiment 2, <italic>etc.</italic> In PCA simulations (A, D, G, J, M), Euclidean distance between test stimuli is on the ordinate and simulation epoch on the abscissa. Solid lines portray predictions made by the correlation-based model, while (often highly overlapping) dashed lines portray predictions of the covariance-based model. Choice model performance (center, right columns) plots proportion correct discrimination on the ordinate and testing block number on the abscissa. Choice model performance based on the correlation-based PCA model is shown in the center column (B, E, H, K, N), and performance based on the covariance-based PCA model is shown in the right column (C, F, I, L, O). Choice model patterns of performance for both correlation and covariance are identical for Experiments 1–4. However, the correlation model fails to predict listeners' superior discrimination of statistically consistent sound pairs (O) early in Experiment 5 (N) while the covariance-based model successfully predicts this performance.</p>
                    </caption>
                    <graphic xlink:href="pone.0030845.g004"/>
                  </fig>
                </sec>
                <sec id="s2f2">
                  <title>b. Covariance-based model</title>
                  <p>The present effort reveals an important limitation of Sanger's <xref rid="pone.0030845-Sanger1" ref-type="bibr">[26]</xref> PCA model. By calculating Eigenvectors of the inputs based on their correlation matrix, the model will produce identical predictions for dissimilar stimulus sets that have the same correlation coefficients. Correlation is the normalized version of covariance, calculated as the covariance between two variables divided by the product of their standard deviations. Thus, one stimulus set with greater covariance between variables and greater standard deviations may produce the same correlation coefficient as a different stimulus set with lesser covariance between variables with smaller standard deviations.</p>
                  <p>For example, consider the case for the model predictions of Experiments 3 and 5 (<xref ref-type="fig" rid="pone-0030845-g004">Figure 4</xref>). Relatively few stimuli in Experiment 3 violate the correlation (four Orthogonal sounds), contributing to covariance of 20.93. However, inclusion of more extreme Orthogonal sounds with greater distances away from the main (correlated) diagonal results in a higher standard deviation of 5.02 for AD and for SS. Conversely, extreme oversampling of the lone Orthogonal pair in Experiment 5 reduces the covariance between AD and SS (11.88). However, the proximity of these stimuli to the diagonal decreases stimulus variability, as reflected by smaller standard deviations (3.78). Despite stark differences in the Orthogonal information in each stimulus set, each experiment maintains the same correlation between AD and SS (20.93/5.02<sup>2</sup> = 11.88/3.78<sup>2</sup> = 0.83). Despite different covariances and covariance matrices, these stimulus sets possess the same correlation coefficients and correlation matrices, and the correlation-based PCA model makes identical predictions for both despite any potential differences in listener performance across experiments.</p>
                  <p>It is common to conduct PCA using the correlation matrix in order to normalize out effects of scaling. However, acoustic dimensions AD and SS were thoroughly piloted by Stilp <italic>et al.</italic>
<xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref> to assure that steps along each dimension were equally discriminable absent experimental effects of redundancy among attributes. Thus, stimuli are designed to be psychophysically normalized. Using the correlation-based model imposes additional normalization on stimuli that have already been perceptually normalized. Subsequently, covariance among attributes may better reflect perceptual processes for the present stimuli. Models of Hebbian-type learning based on covariance have been used to model long-term depression of synaptic strength in the hippocampus <xref rid="pone.0030845-Sejnowski1" ref-type="bibr">[33]</xref>–<xref rid="pone.0030845-Stanton1" ref-type="bibr">[35]</xref>. Further, a covariance-based model is capable of making different predictions for stimuli with the same correlation matrices but different covariance matrices. Thus, a PCA model that operates on the covariance matrix of the inputs may be a more appropriate means of predicting listener performance.</p>
                  <p>Sanger's <xref rid="pone.0030845-Sanger1" ref-type="bibr">[26]</xref> PCA model was modified to operate on the covariance matrix of the inputs in the following manner. Equation 1 depicts Sanger's original algorithm (<xref rid="pone.0030845-Sanger1" ref-type="bibr">[26]</xref>, p. 465):<disp-formula><graphic xlink:href="pone.0030845.e001.jpg" mimetype="image" position="float"/><label>(1)</label></disp-formula>where <italic>C</italic> represents the weight (Eigenvector) matrix, <italic>Q</italic> represents the correlation matrix of the inputs, diag indicates elements on the main diagonal of the matrix, and <sup>T</sup> denotes matrix transposition. In the present application, weight changes are calculated at each epoch of the simulation, so (<italic>t</italic>) is implied and thus omitted for simplicity. Through the mathematical proof that the Generalized Hebbian Algorithm produces Eigenvectors of the input correlation matrix ordered by decreasing Eigenvalue, Sanger (<xref rid="pone.0030845-Sanger1" ref-type="bibr">[26]</xref>, p. 462) expressed Equation 1 in terms of each row of the weight matrix as follows:<disp-formula><graphic xlink:href="pone.0030845.e002.jpg" mimetype="image" position="float"/><label>(2)</label></disp-formula>where <italic>c<sub>i</sub></italic> represents the <italic>i</italic>th row of the weight matrix, and <italic>c<sub>k</sub></italic> represents the <italic>k</italic>th row of the weight matrix, which spans from 1 to <italic>i</italic>. The reader will note that <italic>c<sub>i</sub></italic>
<sup>T</sup> represents a row in Sanger's notation and <italic>c<sub>i</sub></italic> represents a column; these notations are reversed here for ease of reading so that row elements are assumed and transpositions denote columns. Expanding Equation 2 into a separate equation for each row of the weight matrix yields Equations 3.1 (principal component) and 3.2 (second component):<disp-formula><graphic xlink:href="pone.0030845.e003.jpg" mimetype="image" position="float"/><label>(3.1)</label></disp-formula>
<disp-formula><graphic xlink:href="pone.0030845.e004.jpg" mimetype="image" position="float"/><label>(3.2)</label></disp-formula>Equations use multiplicative normalization (subtraction of (<italic>c</italic>
<sub>1</sub>
<italic>Q c</italic>
<sub>1</sub>
<sup>T</sup>)<italic>c</italic>
<sub>1</sub> in Equation 3.1 and (<italic>c</italic>
<sub>2</sub>
<italic>Q c</italic>
<sub>2</sub>
<sup>T</sup>)<italic>c</italic>
<sub>2</sub> in Equation 3.2) so the sum of squared weights remains constant; otherwise weights grow without bound. Subtraction of the term (<italic>c</italic>
<sub>2</sub>
<italic>Q c</italic>
<sub>1</sub>
<sup>T</sup>)<italic>c</italic>
<sub>1</sub> in Equation 3.2 removes the principal component from calculations so that weight changes are derived solely from unshared covariance. These equations were revised by substituting the covariance matrix of the inputs, represented by <italic>E</italic>, for the correlation matrix <italic>Q</italic>, as shown in Equations 4.1 and 4.2:<disp-formula><graphic xlink:href="pone.0030845.e005.jpg" mimetype="image" position="float"/><label>(4.1)</label></disp-formula>
<disp-formula><graphic xlink:href="pone.0030845.e006.jpg" mimetype="image" position="float"/><label>(4.2)</label></disp-formula>Weight changes are scaled by a small learning rate (<italic>η</italic> = 0.01). To compare simulations of a given experiment using covariance and correlation versions of the PCA model, covariance-based simulations continued until reaching a specified criterion: matching the ratio between Orthogonal and Consistent Euclidean distances at the 500<sup>th</sup> epoch of the simulation of Experiment 1 using the correlation-based model (ratio = 0.9848). This criterion was selected to make depictions of correlation- and covariance-based model simulations comparable, as all begin and end with the same relationships (ratios) between Orthogonal and Consistent Euclidean distances. This criterion was met at the 1015<sup>th</sup> epoch of simulating Experiment 1 using the covariance-based model, thus all covariance-based model simulations span 1015 epochs. Simulation results are presented in the left column of <xref ref-type="fig" rid="pone-0030845-g004">Figure 4</xref> (dashed lines) superimposed atop results for the correlation-matrix-based model (solid lines) for comparison.</p>
                </sec>
                <sec id="s2f3">
                  <title>c. Comparison to listener performance</title>
                  <p>Neural network model predictions were quantitatively tested using the general metric learning procedure of Xu, Zhu, and Rogers <xref rid="pone.0030845-Xu1" ref-type="bibr">[36]</xref>, which translates computed distances between stimuli into probability of a correct response in a discrimination task. This ‘choice model’ assumes that stimulus confusions (errors in a two-alternative forced-choice [AXB] task) decrease as a function of distance between two stimuli, such that increasing distances result in improved discriminability (<xref ref-type="fig" rid="pone-0030845-g005">Figure 5</xref>). This function is expressed in Equation 5:<disp-formula><graphic xlink:href="pone.0030845.e007.jpg" mimetype="image" position="float"/><label>(5)</label></disp-formula>with <italic>z</italic> corresponding to distance between stimuli and Ψ the probability of an incorrect response on a discrimination trial. While error probability can decay in either exponential or Gaussian manners with increasing distance, the former is employed here (see <xref rid="pone.0030845-Xu1" ref-type="bibr">[36]</xref> for discussion). Baseline performance, or discriminability of experimental stimuli absent effects of correlation, corresponds to an error rate of 0.31 (69% correct discrimination <xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref>). Distances along the abscissa of <xref ref-type="fig" rid="pone-0030845-g005">Figure 5</xref> were scaled so that Euclidean distances at the beginning and convergence of the PCA model simulation corresponded to this baseline error rate.</p>
                  <fig id="pone-0030845-g005" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pone.0030845.g005</object-id>
                    <label>Figure 5</label>
                    <caption>
                      <title>The choice model of Xu <italic>et al.</italic>
<xref rid="pone.0030845-Xu1" ref-type="bibr">[<bold>36</bold>]</xref>, where the probability of error in a two-alternative forced-choice (AXB) task decreases exponentially with increasing distance between stimuli (solid line).</title>
                      <p>Dashed lines correspond to error probability of 0.31, or baseline discriminability between experimental stimuli absent effects of correlation among attributes <xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref>, and the corresponding inter-stimulus distance.</p>
                    </caption>
                    <graphic xlink:href="pone.0030845.g005"/>
                  </fig>
                  <p>The output of PCA model simulations (respective Euclidean distances between Consistent and Orthogonal stimuli measured at each epoch) served as inputs to the choice model. At each epoch, for Consistent and Orthogonal conditions, Euclidean distance between stimuli was converted into the corresponding error rate (Ψ). A random number uniformly distributed between 0 and 1 was then generated (<italic>n</italic>). Each ‘trial’ was scored as correct if <italic>n</italic>&gt;Ψ and incorrect if <italic>n</italic>≤Ψ. Similar to human data, ‘trials’ were divided into three blocks of equal size, and error rates were averaged across all ‘trials’ within a block. This process was repeated 40 times with different random seeds to simulate data from 40 human participants. Results were averaged across these 40 runs of the choice model, and means and standard errors for proportion of trials correctly discriminated (calculated as 1 minus error rate, matching portrayal of listener data) are presented in <xref ref-type="fig" rid="pone-0030845-g004">Figure 4</xref>. Simulation results are assessed using paired-sample <italic>t</italic>-tests, following analysis of listener performance. Choice model simulations were conducted separately for distances calculated by the correlation-matrix-based and covariance-matrix-based versions of the PCA model.</p>
                </sec>
              </sec>
            </sec>
            <sec id="s3">
              <title>Results</title>
              <sec id="s3a">
                <title>1. Listener performance</title>
                <p>Behavioral results from all experiments are presented in the right column of <xref ref-type="fig" rid="pone-0030845-g002">Figure 2</xref>, with discrimination accuracy (proportion correct) on the ordinate and testing block number on the abscissa. Given that Orthogonal discriminability is predicted to recover by the end of the experiment, omnibus analysis of variance (ANOVA) tests are likely to result in Type II error. Consequently, to retain sensitivity to differences in discriminability across conditions at different phases of the experiment, results are analyzed using planned-comparison paired-sample <italic>t</italic>-tests.</p>
                <sec id="s3a1">
                  <title>a. Experiment 1</title>
                  <p>Discrimination of Consistent pairs in the first block of testing (mean = 0.67, s.e. = .01) was significantly better than discrimination of Orthogonal pairs (mean = 0.60, s.e. = .03) (<italic>t</italic>
<sub>39</sub> = 2.36, <italic>p</italic>&lt;.025, Cohen's <italic>d</italic> = 0.44; <xref ref-type="fig" rid="pone-0030845-g002">Figure 2B</xref>). While discrimination accuracy of Consistent pairs was numerically greater than that of Orthogonal pairs in the second (mean of 0.68 versus 0.63) and third testing blocks (0.69 versus 0.65), <italic>t</italic>-tests did not reach statistical significance (second block: <italic>t</italic>
<sub>39</sub> = 1.58, <italic>p</italic> = .12; third block: <italic>t</italic>
<sub>39</sub> = 1.27, <italic>p</italic> = .21). This pattern of results replicates Experiment 2 of Stilp <italic>et al.</italic>
<xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref>; discrimination of Orthogonal test pairs is initially inferior to that of Consistent test pairs supporting a robust correlation, and performance recovers through further testing so that discrimination across conditions is comparable by the final testing block. It bears mention that in their Expt. 2 (<italic>r</italic> = 0.97), Stilp <italic>et al.</italic>
<xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref> report superior discrimination of Consistent sound pairs relative to Orthogonal sound pairs in the first as well as second testing block. Relative to that experimental design, Expt. 1 in the present report removes Single-cue stimuli while maintaining 18 Consistent sounds and 2 Orthogonal sounds yielding nearly the same correlation (<italic>r</italic> = 0.98). In the present experiment, Consistent discrimination was significantly more accurate than Orthogonal discrimination in the first testing block (<italic>p</italic>&lt;.025) with only a trend toward significance in the second testing block (<italic>p</italic> = 0.12). It is unclear why the full pattern of significance was not fully replicated despite highly similar stimuli and correlation coefficients. Independent-samples <italic>t</italic>-test indicates that the difference in Consistent and Orthogonal discrimination in the second testing block did not significantly differ across experiments (<italic>t</italic>
<sub>78</sub> = 0.73, <italic>p</italic> = 0.47), suggesting patterns of results are not fundamentally different from one another. Results indicate that both the correlated and orthogonal dimensions appear to become weighted proportional to the amount of variance accounted for by each dimension.</p>
                </sec>
                <sec id="s3a2">
                  <title>b. Experiment 2</title>
                  <p>Discrimination of Consistent pairs in the first block of testing (mean = 0.66, s.e. = .02) was again significantly better than discrimination of Orthogonal pairs (mean = 0.60, s.e. = .03) (<italic>t</italic>
<sub>39</sub> = 2.71, <italic>p</italic>&lt;.01, Cohen's <italic>d</italic> = 0.43; <xref ref-type="fig" rid="pone-0030845-g002">Figure 2D</xref>). Despite restricting the range of acoustic evidence supporting the correlation, this early difference in discrimination persisted. Experiment 2 also reveals that correlation among stimulus attributes need not be nearly perfect (<italic>r</italic>≥0.97) for efficient coding to occur. Discrimination did not significantly differ in either the second (Consistent mean = 0.71, s.e. = .02, Orthogonal mean = 0.69, s.e. = .03; <italic>t</italic>
<sub>39</sub> = 0.67, <italic>n.s.</italic>) or third block (Consistent mean = 0.74, s.e. = .02, Orthogonal mean = 0.77, s.e. = .02; <italic>t</italic>
<sub>39</sub> = 1.27, <italic>n.s.</italic>).</p>
                  <p>Unlike previous experiments, discrimination in both conditions improved markedly across testing blocks. Owing to the inability to separate learning (improvement throughout the experiment) from effects of the correlation between AD and SS on Orthogonal discriminability (initially inferior but later comparable to that of Consistent sound pairs), performance was assessed through paired-sample <italic>t</italic>-tests contrasting early versus late (<italic>i.e.</italic>, first versus third testing block) discrimination of Consistent pairs, which are predicted to remain equally discriminable throughout the experiment. Consistent discrimination significantly improved from the first to third block of Experiment 2 (<italic>t</italic>
<sub>39</sub> = 4.39, <italic>p</italic>&lt;.0001, Cohen's <italic>d</italic> = 0.60), but this learning effect was not consistent across experiments. Participants in Experiment 3 exhibited a significant but more modest learning effect for Consistent trials (<italic>t</italic>
<sub>39</sub> = 3.23, <italic>p</italic>&lt;.01, Cohen's <italic>d</italic> = 0.35), but no significant differences were observed in Experiments 1, 4, or 5 (all <italic>t</italic>≤1.21, <italic>n.s.</italic>, Cohen's <italic>d</italic>&lt;0.18). The magnitude of the learning effect in Experiment 2 may be due to one or both of the following factors. First, reducing variability in AD and SS cues by truncating the correlation may facilitate discrimination over time. Second, listeners in Experiment 2 were presented more repetitions of stimulus pairs in a given block (12) than in other experiments (8) in the effort to make overall number of trials comparable. Nevertheless, the principal finding is superior discrimination of Consistent pairs relative to Orthogonal pairs early in testing.</p>
                </sec>
                <sec id="s3a3">
                  <title>c. Experiment 3</title>
                  <p>Unlike previous experiments, discrimination was comparable across Consistent (mean = 0.63, s.e. = .01) and Orthogonal conditions (mean = 0.61, s.e. = .02) in the first testing block (<italic>t</italic>
<sub>39</sub> = 0.75, <italic>n.s.</italic>, Cohen's <italic>d</italic> = 0.12; <xref ref-type="fig" rid="pone-0030845-g002">Figure 2F</xref>). By testing more extreme Orthogonal test pairs (<italic>i.e.</italic>, less similar to Consistent pairs), differences in discrimination observed in previous experiments were extinguished. Roughly equivalent discrimination persisted throughout the experiment (Block 2: Consistent mean = 0.66, s.e. = .02, Orthogonal mean = 0.64, s.e. = .02 [<italic>t</italic>
<sub>39</sub> = 0.86, <italic>n.s.</italic>]; Block 3: Consistent mean = 0.66, s.e. = .02, Orthogonal mean = 0.64, s.e. = .02 [<italic>t</italic>
<sub>39</sub> = 1.54, <italic>n.s.</italic>]). This demonstrates that efficient coding of correlated acoustic attributes is sensitive to the range of physical acoustic/psychoacoustic evidence inconsistent with the primary correlation and consistent with a second orthogonal dimension. Results also demonstrate that simple strength of the primary correlation is insufficient to attenuate discriminability of orthogonal stimulus differences, as all stimulus pairs presented in Experiment 3 (<italic>r</italic> = ±0.83) were relatively equally discriminable, but pairs presented in Experiment 2 (<italic>r</italic> = ±0.81) produced significant differences in early performance. The explanatory power of simple strength of correlation between acoustic attributes, absent consideration of both the quantity and quality (range) of evidence that is inconsistent with the correlation, is challenged by these results.</p>
                </sec>
                <sec id="s3a4">
                  <title>d. Experiment 4</title>
                  <p>Despite a three-fold increase in presentations, discrimination of the Orthogonal pair (mean = 0.59, s.e. = .02) was still significantly worse than that of Consistent pairs (mean = 0.63, s.e. = .01) in the first testing block (<italic>t</italic>
<sub>39</sub> = 2.06, <italic>p</italic>&lt;.05, Cohen's <italic>d</italic> = 0.37; <xref ref-type="fig" rid="pone-0030845-g002">Figure 2H</xref>). This negligible effect of probability sheds light on the results of Experiment 3, that efficient coding was likely extinguished due to increased range of acoustic evidence supporting orthogonal variability and not the concurrent increase in Orthogonal test trials. Similar to previous experiments, performance across conditions was equivalent in the second (Consistent mean = 0.64, s.e. = .02, Orthogonal mean = 0.64, s.e. = .02 [<italic>t</italic>
<sub>39</sub> = 0.36, <italic>n.s.</italic>]) and third testing blocks (Consistent mean = 0.64, s.e. = .01, Orthogonal mean = 0.61, s.e. = .02 [<italic>t</italic>
<sub>39</sub> = 1.58, <italic>n.s.</italic>]).</p>
                </sec>
                <sec id="s3a5">
                  <title>e. Experiment 5</title>
                  <p>Even with ten-fold oversampling, discrimination of the Orthogonal pair (mean = 0.60, s.e. = .02) was modestly worse than that of Consistent pairs (mean = 0.63, s.e. = .01) in the first testing block (<italic>t</italic>
<sub>39</sub> = 1.87, <italic>p</italic> = .07, Cohen's <italic>d</italic> = 0.36; <xref ref-type="fig" rid="pone-0030845-g002">Figure 2J</xref>). It bears note that paired-sample <italic>t</italic>-tests used in all analyses are two-tailed. One could use a one-tailed <italic>t</italic>-test based on the prediction that discrimination of Consistent pairs will be greater than that of Orthogonal pairs, in which case the difference would be statistically significant (one-tailed <italic>p</italic>&lt;.05). However, performance in the first block does not significantly differ in Experiment 5 versus Experiment 3 as indicated by independent samples <italic>t</italic>-tests on orthogonal discrimination performance (<italic>t</italic>
<sub>78</sub> = 0.63, <italic>n.s.</italic>) and differences between Consistent and Orthogonal discrimination (<italic>t</italic>
<sub>78</sub> = 0.71, <italic>n.s.</italic>). Perhaps surprisingly, testing the Orthogonal sound pair ten times as often as any Consistent sound pair failed to produce practice effects sufficient to promote Orthogonal discrimination exceeding Consistent discrimination (second block: Consistent mean = 0.64, s.e. = .02, Orthogonal mean = 0.62, s.e. = .02 [<italic>t</italic>
<sub>39</sub> = 0.69, <italic>n.s.</italic>]; third block: Consistent mean = 0.64, s.e. = .01, Orthogonal mean = 0.62, s.e. = .02 [<italic>t</italic>
<sub>39</sub> = 0.54, <italic>n.s.</italic>]). Thus, the conservative conclusion one can draw from this marginal effect is that manipulation of Orthogonal stimulus probability has little effect on listener discrimination.</p>
                </sec>
              </sec>
              <sec id="s3b">
                <title>2. Model predictions</title>
                <sec id="s3b1">
                  <title>a. Experiment 1</title>
                  <p>Predictions from the PCA models are presented in the first column of <xref ref-type="fig" rid="pone-0030845-g004">Figure 4</xref>, with Euclidean distance between Consistent (black) versus Orthogonal (grey) stimulus pairs on the ordinate and training epoch on the abscissa. Simulation timecourses for correlation-matrix-based (solid lines) and covariance-matrix-based (dashed lines) models are scaled to share comparable abscissas. Similar to <xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref>, the PCA model quickly discovered the principal component (the Consistent dimension) and distances between Orthogonal pairs initially decreased considerably (<xref ref-type="fig" rid="pone-0030845-g004">Figure 4A</xref>). With further exposure to the stimulus set, the PCA model gradually captured the modest variance not explained by the first component, progressively increasing distances between Orthogonal pairs until reaching original relative values by the end of the simulation. Thus, the PCA model initially captures only variability along the principal component in the two-dimensional stimulus space at the expense of the orthogonal component, incrementally coming to capture remaining variance, matching the pattern observed in listener performance. Predictions from the correlation-based (solid lines) and covariance-based (dashed lines) versions of the PCA model were nearly identical, with a slightly larger initial decrease in Orthogonal distances predicted by the covariance model.</p>
                  <p>Simulation results using the choice model are depicted in the middle (correlation) and right (covariance) columns of <xref ref-type="fig" rid="pone-0030845-g004">Figure 4</xref>, with percent correct discrimination along the ordinate and testing block number along the abscissa. Predictions across 40 simulations exhibited markedly less variability than listener data, but patterns of results remain excellent fits to human performance. Both correlation and covariance models predicted significantly poorer discrimination of Orthogonal stimuli in the first block of testing (correlation model [<xref ref-type="fig" rid="pone-0030845-g004">Figure 4B</xref>]: Consistent: mean = 0.69, s.e. = .006; Orthogonal: mean = 0.58, s.e. = .006, <italic>t</italic>
<sub>39</sub> = 14.92, <italic>p</italic>&lt;1e-17, Cohen's <italic>d</italic> = 3.15; covariance model [<xref ref-type="fig" rid="pone-0030845-g004">Figure 4C</xref>]: Consistent: mean = 0.69, s.e. = .004; Orthogonal: mean = 0.57, s.e. = .004, <italic>t</italic>
<sub>39</sub> = 21.50, <italic>p</italic>&lt;4e-23, Cohen's <italic>d</italic> = 5.09). Marked improvement in Orthogonal discrimination was evident in the second block, but this was still inferior to Consistent discrimination (correlation model: Consistent: mean = 0.69, s.e. = .007; Orthogonal: mean = 0.65, s.e. = .005, <italic>t</italic>
<sub>39</sub> = 5.23, <italic>p</italic>&lt;6e-6, Cohen's <italic>d</italic> = 1.19; covariance model: Consistent: mean = 0.69, s.e. = .004; Orthogonal: mean = 0.63, s.e. = .004, <italic>t</italic>
<sub>39</sub> = 10.12, <italic>p</italic>&lt;2e-12, Cohen's <italic>d</italic> = 2.38). Finally, Consistent and Orthogonal stimuli were relatively equally discriminable in the third block (correlation model: Consistent: mean = 0.69, s.e. = .005; Orthogonal: mean = 0.68, s.e. = .006, <italic>t</italic>
<sub>39</sub> = 0.62, <italic>n.s.</italic>; covariance model: Consistent: mean = 0.69, s.e. = .004; Orthogonal: mean = 0.68, s.e. = .004, <italic>t</italic>
<sub>39</sub> = 0.39, <italic>n.s.</italic>).</p>
                </sec>
                <sec id="s3b2">
                  <title>b. Experiment 2</title>
                  <p>The initial decrease in distance between Orthogonal stimuli is smaller and recovery to baseline distances sooner than that observed for Experiment 1 (<xref ref-type="fig" rid="pone-0030845-g004">Figure 4D</xref>). These outcomes are anticipated given simulation of a more weakly correlated stimulus set (<italic>r</italic> = ±0.81). Simulations by Stilp <italic>et al.</italic>
<xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref> and Experiment 1 suggest that principal and second components become weighted in proportion to the amount of covariance captured by each dimension, and model predictions for Experiment 2 reveal more weight being attributed to the second (Orthogonal) dimension as it captures relatively more unshared covariance here than in other, more highly-correlated stimulus sets. Both correlation-based and covariance-based models predict significantly poorer Orthogonal discrimination in the first testing block, but models make different predictions regarding the rate of recovery to baseline distances between stimuli. The correlation-based model predicts a more extended recovery, which contributes to a larger predicted effect size in the first block (Consistent: mean = 0.69, s.e. = .006; Orthogonal: mean = 0.64, s.e. = .006, <italic>t</italic>
<sub>39</sub> = 5.65, <italic>p</italic>&lt;2e-6, Cohen's <italic>d</italic> = 1.40; <xref ref-type="fig" rid="pone-0030845-g004">Figure 4E</xref>) than that predicted by the covariance-based model (Consistent: mean = 0.69, s.e. = .004; Orthogonal: mean = 0.65, s.e. = .005, <italic>t</italic>
<sub>39</sub> = 4.95, <italic>p</italic>&lt;2e-5, Cohen's <italic>d</italic> = 1.12; <xref ref-type="fig" rid="pone-0030845-g004">Figure 4F</xref>), which predicts more rapid recovery to baseline distances. Nevertheless, both models correctly predict significantly poorer Orthogonal discrimination in the first testing block, and comparable discrimination in the second (correlation model: Consistent: mean = 0.69, s.e. = .004; Orthogonal: mean = 0.68, s.e. = .007, <italic>t</italic>
<sub>39</sub> = 1.12, <italic>n.s.</italic>; covariance model: Consistent: mean = 0.69, s.e. = .004; Orthogonal: mean = 0.69, s.e. = .004, <italic>t</italic>
<sub>39</sub> = 0.62, <italic>n.s.</italic>) and third testing blocks (correlation model: Consistent: mean = 0.69, s.e. = .006; Orthogonal: mean = 0.69, s.e. = .005, <italic>t</italic>
<sub>39</sub> = 0.38, <italic>n.s.</italic>; covariance model: Consistent: mean = 0.69, s.e. = .004; Orthogonal: mean = 0.69, s.e. = .004, <italic>t</italic>
<sub>39</sub> = 0.48, <italic>n.s.</italic>), matching listener performance. Finally, neither version of the PCA model predicts overall improved performance later in the simulation (<italic>i.e.</italic>, Euclidean distances in both conditions increasing over time) as observed in listener performance, suggesting insensitivity to some practice effects.</p>
                </sec>
                <sec id="s3b3">
                  <title>c. Experiment 3</title>
                  <p>Both versions of the PCA model predict a shallow and very short-lived decrease in Orthogonal distances, with the vast majority of the simulation predicting equal discriminability across conditions (<xref ref-type="fig" rid="pone-0030845-g004">Figure 4G</xref>). Virtually identical simulation results both predict comparable performance across conditions in the first (correlation model [<xref ref-type="fig" rid="pone-0030845-g004">Figure 4H</xref>]: Consistent: mean = 0.68, s.e. = .006; Orthogonal: mean = 0.68, s.e. = .005, <italic>t</italic>
<sub>39</sub> = 0.26, <italic>n.s.</italic>; covariance model [<xref ref-type="fig" rid="pone-0030845-g004">Figure 4I</xref>]: Consistent: mean = 0.68, s.e. = .004; Orthogonal: mean = 0.68, s.e. = .004, <italic>t</italic>
<sub>39</sub> = 0.75, <italic>n.s.</italic>), second (correlation model: Consistent: mean = 0.69, s.e. = .005; Orthogonal: mean = 0.69, s.e. = .006, <italic>t</italic>
<sub>39</sub> = 0.08, <italic>n.s.</italic>; covariance model: Consistent: mean = 0.69, s.e. = .003; Orthogonal: mean = 0.69, s.e. = .004, <italic>t</italic>
<sub>39</sub> = 0.60, <italic>n.s.</italic>), and third testing blocks (correlation model: Consistent: mean = 0.69, s.e. = .005; Orthogonal: mean = 0.69, s.e. = .006, <italic>t</italic>
<sub>39</sub> = 0.25, <italic>n.s.</italic>; covariance model: Consistent: mean = 0.69, s.e. = .004; Orthogonal: mean = 0.69, s.e. = .004, <italic>t</italic>
<sub>39</sub> = 0.26, <italic>n.s.</italic>). These predictions mirror listener performance, and support the idea that both listeners and the model quickly exploited covariance in more extreme Orthogonal stimuli to discover the second component and facilitate Orthogonal discrimination.</p>
                </sec>
                <sec id="s3b4">
                  <title>d. Experiment 4</title>
                  <p>Both versions of the PCA model predict a sizable initial decrease in Orthogonal distances before later recovery to original relative distances (<xref ref-type="fig" rid="pone-0030845-g004">Figure 4J</xref>). These predictions resemble those of Experiment 1, where the early difference in discrimination was both predicted and behaviorally observed, in contrast to those of Experiment 3, where largely equal discrimination throughout was both predicted and observed. Recovery to original relative distances for Orthogonal stimuli occurred much more quickly in Experiment 4 than Experiment 1, revealing some sensitivity to the fact that Orthogonal stimuli were sampled more frequently. Further, the covariance model predictions displayed a slightly larger magnitude of initial decrease in Orthogonal distances and slightly longer recovery to baseline distances than that observed for the correlation model, resulting in a slightly larger effect size in the first testing block (correlation model (<xref ref-type="fig" rid="pone-0030845-g004">Figure 4K</xref>): Consistent: mean = 0.70, s.e. = .005; Orthogonal: mean = 0.64, s.e. = .005, <italic>t</italic>
<sub>39</sub> = 6.94, <italic>p</italic>&lt;3e-8, Cohen's <italic>d</italic> = 1.65; covariance model (<xref ref-type="fig" rid="pone-0030845-g004">Figure 4L</xref>): Consistent: mean = 0.69, s.e. = .004; Orthogonal: mean = 0.63, s.e. = .005, <italic>t</italic>
<sub>39</sub> = 7.85, <italic>p</italic>&lt;2e-9, Cohen's <italic>d</italic> = 1.89). Both versions of the model predicted equal discriminability in the second (correlation model: Consistent: mean = 0.69, s.e. = .006; Orthogonal: mean = 0.69, s.e. = .005, <italic>t</italic>
<sub>39</sub> = 0.14, <italic>n.s.</italic>; covariance model: Consistent: mean = 0.69, s.e. = .004; Orthogonal: mean = 0.68, s.e. = .005, <italic>t</italic>
<sub>39</sub> = 1.20, <italic>n.s.</italic>) and third testing blocks (correlation model: Consistent: mean = 0.69, s.e. = .006; Orthogonal: mean = 0.69, s.e. = .005, <italic>t</italic>
<sub>39</sub> = 0.12, <italic>n.s.</italic>; covariance model: Consistent: mean = 0.70, s.e. = .005; Orthogonal: mean = 0.69, s.e. = .004, <italic>t</italic>
<sub>39</sub> = 0.62, <italic>n.s.</italic>).</p>
                </sec>
                <sec id="s3b5">
                  <title>e. Experiment 5</title>
                  <p>The correlation-based PCA model predicts a shallow and very short-lived decrease in Orthogonal distances, with all but the first few epochs of the simulation predicting equal discriminability across conditions (<xref ref-type="fig" rid="pone-0030845-g004">Figure 4M</xref>). These predictions are identical to those made for Experiment 3, such that equal discriminability of Consistent and Orthogonal stimuli is predicted in all blocks of testing (Block 1: Consistent: mean = 0.69, s.e. = .005; Orthogonal: mean = 0.69, s.e. = .006, <italic>t</italic>
<sub>39</sub> = 0.13, <italic>n.s.</italic>; Block 2: Consistent: mean = 0.69, s.e. = .005; Orthogonal: mean = 0.69, s.e. = .007, <italic>t</italic>
<sub>39</sub> = 0.06, <italic>n.s.</italic>; Block 3: Consistent: mean = 0.69, s.e. = .006; Orthogonal: mean = 0.69, s.e. = .006, <italic>t</italic>
<sub>39</sub> = 0.09, <italic>n.s.</italic>; <xref ref-type="fig" rid="pone-0030845-g004">Figure 4N</xref>).</p>
                  <p>Similar to Experiment 4, the covariance-based PCA model predicts a slightly larger magnitude of initial decrease in Orthogonal distances and slightly longer recovery to baseline distances than that observed for the correlation model (<xref ref-type="fig" rid="pone-0030845-g004">Figure 4M</xref>). These differ from other model predictions in two significant ways. First, similar to listeners and unlike the correlation model, the covariance model predicts inferior discrimination of Orthogonal stimuli in the first testing block of Experiment 5 (Consistent: mean = 0.69, s.e. = .004; Orthogonal: mean = 0.67, s.e. = .004, <italic>t</italic>
<sub>39</sub> = 4.02, <italic>p</italic>&lt;.0005, Cohen's <italic>d</italic> = 0.87; <xref ref-type="fig" rid="pone-0030845-g004">Figure 4O</xref>). Second, the covariance model displays sensitivity to (and thus makes different predictions for) stimuli with the same correlation matrix but different covariance matrices (<italic>i.e.</italic>, stimuli presented in Experiments 3 and 5). An independent-samples <italic>t</italic>-test confirms that the predicted difference in Consistent and Orthogonal discrimination in the first testing block of Experiment 5 (mean difference = .023) is significantly larger than the difference observed in the first block of Experiment 3 (mean difference = .005; <italic>t</italic>
<sub>78</sub> = 2.11, <italic>p</italic>&lt;.05). Predictions made by the correlation model for the first block of Experiment 3 versus Experiment 5 did not differ (independent-samples <italic>t</italic>-test on mean differences: <italic>t</italic>
<sub>78</sub> = 0.28, <italic>n.s.</italic>). These results demonstrate that while the PCA model based on the correlation matrix of the inputs <xref rid="pone.0030845-Sanger1" ref-type="bibr">[26]</xref> is useful for predicting discriminability of some stimulus sets, the covariance-based PCA model is a better predictor of listener performance overall. Finally, the covariance model predicted comparable performance across conditions for remaining test blocks (Block 2: Consistent: mean = 0.69, s.e. = .004; Orthogonal: mean = 0.69, s.e. = .004, <italic>t</italic>
<sub>39</sub> = 0.08, <italic>n.s.</italic>; Block 3: Consistent: mean = 0.69, s.e. = .004; Orthogonal: mean = 0.69, s.e. = .004, <italic>t</italic>
<sub>39</sub> = 0.42, <italic>n.s.</italic>).</p>
                </sec>
                <sec id="s3b6">
                  <title>f. Across all experiments</title>
                  <p>The predictive power of covariance-based PCA is further demonstrated through closed-form linear algebraic solutions in <xref ref-type="table" rid="pone-0030845-t001">Table 1</xref>. <xref ref-type="table" rid="pone-0030845-t001">Table 1</xref> orders stimulus sets from Experiments 1–5 to reflect performance differences in discriminability of Consistent versus Orthogonal sound pairs in the first testing block as measured by effect size (rightmost column). Eigenvalues calculated from the correlation matrix versus covariance matrix of stimulus set before the simulation are also provided. The success with which listeners discriminate Orthogonal pairs is well predicted by the second Eigenvalue calculated from the covariance matrix reflecting true psychoacoustic distances: as the second Eigenvalue increases, greater perceptual weighting is reflected in improved listener performance on Orthogonal trials and subsequently decreased effect sizes early in the experiment (<italic>r</italic> = −0.95, <italic>p</italic>&lt;.025). This relationship with performance is not observed for the second Eigenvalue of correlation matrices, the first Eigenvalue of correlation or covariance matrices, or simple strength of the principal correlation. The relationship between the second Eigenvalue of the covariance matrix and effect size is similarly robust if calculated on model representations of the inputs after the first one-third of the simulation (akin to the first testing block for listeners; <italic>r</italic> = −0.94, <italic>p</italic>&lt;.025). No other metric calculated after one-third of the simulation reliably predicts effect sizes for the first block of testing. While some caution is warranted in generalizing this relationship given that the second Eigenvalue can be increased by multiple manipulations (removal of Consistent sounds, addition of more extreme Orthogonal sounds, oversampling of Orthogonal sounds), it does provide promising extensions of the present work in optimal weighting of statistically derived dimensions in complex sounds.</p>
                  <table-wrap id="pone-0030845-t001" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pone.0030845.t001</object-id>
                    <label>Table 1</label>
                    <caption>
                      <title>Correlation coefficients (<italic>r</italic>), first and second Eigenvalues (λ<sub>1</sub>, λ<sub>2</sub>), covariance between AD and SS (σ<sub>AD,SS</sub>), and effect sizes (Consistent versus Orthogonal discrimination in the first testing block, as measured by Cohen's <italic>d</italic>) for each experiment.</title>
                    </caption>
                    <alternatives>
                      <graphic id="pone-0030845-t001-1" xlink:href="pone.0030845.t001"/>
                      <table frame="hsides" rules="groups">
                        <colgroup span="1">
                          <col align="left" span="1"/>
                          <col align="center" span="1"/>
                          <col align="center" span="1"/>
                          <col align="center" span="1"/>
                          <col align="center" span="1"/>
                          <col align="center" span="1"/>
                          <col align="center" span="1"/>
                          <col align="center" span="1"/>
                        </colgroup>
                        <thead>
                          <tr>
                            <td align="left" rowspan="1" colspan="1"/>
                            <td align="left" rowspan="1" colspan="1"/>
                            <td colspan="2" align="left" rowspan="1">Correlation Model</td>
                            <td align="left" rowspan="1" colspan="1"/>
                            <td colspan="2" align="left" rowspan="1">Covariance Model</td>
                            <td align="left" rowspan="1" colspan="1">Effect</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1"/>
                            <td align="left" rowspan="1" colspan="1">
                              <italic>r</italic>
                            </td>
                            <td align="left" rowspan="1" colspan="1">λ<sub>1</sub>
</td>
                            <td align="left" rowspan="1" colspan="1">λ<sub>2</sub>
</td>
                            <td align="left" rowspan="1" colspan="1">σ<sub>AD,SS</sub>
</td>
                            <td align="left" rowspan="1" colspan="1">λ<sub>1</sub>
</td>
                            <td align="left" rowspan="1" colspan="1">λ<sub>2</sub>
</td>
                            <td align="left" rowspan="1" colspan="1">Size</td>
                          </tr>
                        </thead>
                        <tbody>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Exp. 1</td>
                            <td align="left" rowspan="1" colspan="1">0.98</td>
                            <td align="left" rowspan="1" colspan="1">1.98</td>
                            <td align="left" rowspan="1" colspan="1">0.02</td>
                            <td align="left" rowspan="1" colspan="1">25.26</td>
                            <td align="left" rowspan="1" colspan="1">51.00</td>
                            <td align="left" rowspan="1" colspan="1">
                              <bold>0.47</bold>
                            </td>
                            <td align="left" rowspan="1" colspan="1">0.44</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Exp. 2</td>
                            <td align="left" rowspan="1" colspan="1">0.81</td>
                            <td align="left" rowspan="1" colspan="1">1.81</td>
                            <td align="left" rowspan="1" colspan="1">0.19</td>
                            <td align="left" rowspan="1" colspan="1">4.17</td>
                            <td align="left" rowspan="1" colspan="1">9.33</td>
                            <td align="left" rowspan="1" colspan="1">
                              <bold>1.00</bold>
                            </td>
                            <td align="left" rowspan="1" colspan="1">0.43</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Exp. 4</td>
                            <td align="left" rowspan="1" colspan="1">0.95</td>
                            <td align="left" rowspan="1" colspan="1">1.95</td>
                            <td align="left" rowspan="1" colspan="1">0.05</td>
                            <td align="left" rowspan="1" colspan="1">20.48</td>
                            <td align="left" rowspan="1" colspan="1">42.13</td>
                            <td align="left" rowspan="1" colspan="1">
                              <bold>1.17</bold>
                            </td>
                            <td align="left" rowspan="1" colspan="1">0.37</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Exp. 5</td>
                            <td align="left" rowspan="1" colspan="1">0.83</td>
                            <td align="left" rowspan="1" colspan="1">1.83</td>
                            <td align="left" rowspan="1" colspan="1">0.17</td>
                            <td align="left" rowspan="1" colspan="1">11.88</td>
                            <td align="left" rowspan="1" colspan="1">26.19</td>
                            <td align="left" rowspan="1" colspan="1">
                              <bold>2.43</bold>
                            </td>
                            <td align="left" rowspan="1" colspan="1">0.36</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Exp. 3</td>
                            <td align="left" rowspan="1" colspan="1">0.83</td>
                            <td align="left" rowspan="1" colspan="1">1.83</td>
                            <td align="left" rowspan="1" colspan="1">0.17</td>
                            <td align="left" rowspan="1" colspan="1">20.93</td>
                            <td align="left" rowspan="1" colspan="1">46.14</td>
                            <td align="left" rowspan="1" colspan="1">
                              <bold>4.29</bold>
                            </td>
                            <td align="left" rowspan="1" colspan="1">0.12</td>
                          </tr>
                        </tbody>
                      </table>
                    </alternatives>
                    <table-wrap-foot>
                      <fn id="nt101">
                        <label/>
                        <p>Correlation Model indicates Eigenvalues calculated from the correlation matrix of the stimulus sets before the simulation, while Covariance Model indicates Eigenvalues calculated from the input covariance matrix before simulations. The order of experiments is intentionally transposed to highlight the robust negative correlation between the second Eigenvalue of the covariance matrix of the experimental stimuli with listener performance.</p>
                      </fn>
                    </table-wrap-foot>
                  </table-wrap>
                </sec>
              </sec>
            </sec>
            <sec id="s4">
              <title>Discussion</title>
              <p>The present results replicate and extend reports by Stilp <italic>et al.</italic>
<xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref> of rapid efficient coding of redundancy among acoustic dimensions in novel complex sounds. Three manipulations, each of which attenuates correlation among attributes, were tested separately to examine the perceptual significance of each. Overall, simple strength of the primary correlation (principal component) is inadequate to predict listener performance. Initial superiority of discrimination for statistically consistent sound pairs was relatively insensitive to truncation of evidence supporting the correlation (Experiment 2) and to increases in the frequency of Orthogonal test trials (Experiments 4, 5). However, increased evidence of an orthogonal dimension provided by greater acoustic/psychoacoustic range (Experiment 3) proved highly salient, resulting in equivalent discrimination performance throughout the experiment.</p>
              <p>Patterns of performance cannot be explained by independent weighting of acoustic dimensions (AD, SS), as changes in discriminability can only be attributed to the correlation or covariance orthogonal to it. This perceptual adherence to derived statistical structure, and not physical acoustic dimensions <italic>per se</italic>, is not without precedent. There is good evidence that auditory cortical representations decreasingly correspond to physical stimulus dimensions <xref rid="pone.0030845-Nelken1" ref-type="bibr">[37]</xref>–<xref rid="pone.0030845-Wang1" ref-type="bibr">[39]</xref>. Wang <xref rid="pone.0030845-Wang1" ref-type="bibr">[39]</xref> refers to this as “non-isomorphic” transformations of the input. Examples of non-isomorphic stimulus representations in auditory cortex include encoding spectral shape across varying absolute frequencies <xref rid="pone.0030845-Barbour1" ref-type="bibr">[38]</xref>, gross representation of rapid change in click trains with short inter-click intervals versus phase-locking to trains with slower inter-click intervals <xref rid="pone.0030845-Lu1" ref-type="bibr">[40]</xref>, <xref rid="pone.0030845-Lu2" ref-type="bibr">[41]</xref>, and encoding pitch versus individual frequency components <xref rid="pone.0030845-Bendor1" ref-type="bibr">[42]</xref>, <xref rid="pone.0030845-Bendor2" ref-type="bibr">[43]</xref>. Such non-isomorphic transformations may be similar to the loss of acoustic dimensions (AD, SS) seen here, as more efficient dimensions better capture perceptual performance. Results are in agreement with Stilp and Kluender <xref rid="pone.0030845-Stilp3" ref-type="bibr">[44]</xref>, who report efficient coding of redundant acoustic dimensions in the face of unrelated variability in a third acoustic feature.</p>
              <p>Optimal combination and weighting of individual stimulus dimensions has received considerable attention in vision research. Models of Bayesian inference and ideal perceptual performance have been shown to effectively capture aspects of perception of objects <xref rid="pone.0030845-Kersten1" ref-type="bibr">[45]</xref>, <xref rid="pone.0030845-Kersten2" ref-type="bibr">[46]</xref>, edges <xref rid="pone.0030845-Geisler1" ref-type="bibr">[47]</xref>, movement <xref rid="pone.0030845-Stocker1" ref-type="bibr">[48]</xref>, and slant or orientation <xref rid="pone.0030845-Girshick1" ref-type="bibr">[49]</xref>–<xref rid="pone.0030845-Knill1" ref-type="bibr">[52]</xref>. These ideal observer models have been extended to perceptual combination of sensory cues from different modalities, such as integrating visual and auditory cues to location <xref rid="pone.0030845-Alais1" ref-type="bibr">[53]</xref>, visual and motor cues to performing certain actions <xref rid="pone.0030845-Faisal1" ref-type="bibr">[54]</xref>–<xref rid="pone.0030845-Turnham1" ref-type="bibr">[57]</xref>, and visual and haptic cues to height <xref rid="pone.0030845-Ernst2" ref-type="bibr">[58]</xref>, shape <xref rid="pone.0030845-Helbig1" ref-type="bibr">[59]</xref>, and even thoroughly trained arbitrary associations such as one between luminance and stiffness <xref rid="pone.0030845-Ernst1" ref-type="bibr">[19]</xref>.</p>
              <p>Three important points distinguish these earlier studies from the present findings in auditory perception. First, such studies often must address inherent weights or biases ascribed to each cue. For example, visual information is habitually weighted more heavily than auditory or haptic information. Here, acoustic dimensions AD and SS were adjusted through extensive control studies to be equally available perceptually, so <italic>a priori</italic> perceptual weights are equated. Second, many cue weighting studies examine performance as a function of relative noisiness (relative σ) of respective cues. Sensibly, when multiple cues are available but one is or becomes more noisy (larger σ), perceptual weights are greater for less noisy cues that better inform behavior. Optimal cue combination occurs when one cue (typically the one weighted more heavily absent experimental manipulation) is made noisier and perceptual weights shift toward a less noisy source of information (<italic>e.g.</italic>, making the visual signal noisier and observing increased weight attributed to haptic information <xref rid="pone.0030845-Ernst2" ref-type="bibr">[58]</xref>). Cues AD and SS share equal psychoacoustic variability as measured by JNDs. Third and most importantly, these examples from vision or multimodal research demonstrate optimal weighting of individual physical stimulus dimensions. The present findings indicate optimal weighting of derived dimensions that capture statistical relationships between attributes. This likely suggests a more sophisticated level of processing than that observed for reports of combination or integration of individual physical stimulus cues.</p>
              <p>Behavioral results were consistently predicted by the PCA network model <xref rid="pone.0030845-Sanger1" ref-type="bibr">[26]</xref>. Perceptual processes first capture the principal component of variation in the two-dimensional stimulus space at the expense of the orthogonal component <xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref>. From listener performance and models, it appears that both principal and second components become weighted proportional to the amount of variance accounted for by each. In the stimulus sets tested here, this entailed relatively modest weights on the second component, corresponding to initially reduced discriminability. Following further exposure to the stimulus set, variance not explained by the principal correlation is detected and exploited, improving discrimination of Orthogonal sound pairs back to baseline levels. Only when evidence for the orthogonal dimension was increased through greater covariance not shared with the principal component (Experiment 3) was sufficient weight attributed to the second component, extinguishing early differences in discriminability. Otherwise, given that correlations tested here were attenuated in different manners, simulations primarily varied in how the initial decrease in Euclidean distance between Orthogonal stimuli gets smaller and/or recovery to baseline distances occurs sooner.</p>
              <p>One shortcoming of Sanger's <xref rid="pone.0030845-Sanger1" ref-type="bibr">[26]</xref> network model is that it assumes the correlation matrix of the inputs. PCA can operate over either a correlation or covariance matrix, and there are reasons to prefer a covariance matrix for psychoacoustically-normed experimental materials employed here. The predictive power of the PCA model <xref rid="pone.0030845-Sanger1" ref-type="bibr">[26]</xref> was improved when modified to operate on the covariance matrix of the input rather than the correlation matrix. The modified model provided predictions that better fit listener performance. Further, Eigenvalues from covariance- but not correlation-based PCA analyses closely reflect listener performance (<xref ref-type="table" rid="pone-0030845-t001">Table 1</xref>). Greater Eigenvalues on the second component (orthogonal to the main correlation) predicted better discrimination of orthogonal variation. At least for these stimuli, covariance among acoustic attributes appears to be a better estimate of perceptual performance than correlation, but given markedly different ways to manipulate covariance captured by a particular component in PCA (stimulus addition/deletion, over/undersampling, <italic>etc.</italic>), further studies are required to better understand this relationship.</p>
              <p>The particular PCA model investigated here <xref rid="pone.0030845-Sanger1" ref-type="bibr">[26]</xref> is certainly oversimplified and is unlikely to precisely reflect neural learning mechanisms. Dimensions of AD and SS are almost certainly encoded across a large number of neurons and not the localist representation tested here. A more serious challenge is to identify neurally plausible mechanisms for instantiating PCA-like performance. Conceivably, circuitry of auditory cortical and association areas may provide the required connectivities. Precortical processes might also be implicated, given that PCA has proven practical for depicting correlations across neurons in the vibrissal sensory area of rat thalamus <xref rid="pone.0030845-Chapin1" ref-type="bibr">[60]</xref>. Lower subcortical auditory nuclei are also candidates given that, relative to the visual system, much more processing (more synapses and hence greater neural recoding) occurs within the brainstem before cortex <xref rid="pone.0030845-Nelken1" ref-type="bibr">[37]</xref>. Identification of neural substrates supporting perceptual changes demonstrated here and by Stilp and colleagues <xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref> would facilitate development of more authentic computational models.</p>
              <p>The present experiments have investigated how listeners adapt to strong covariance structure coupled with varying types of orthogonal variation. This form of structure is particularly amenable to decomposition via PCA, but other models are better suited for a broader array of cases such as those presented by statistical distributions for some speech sounds (<italic>e.g.</italic> distributions of vowels in formant (F<sub>1</sub>-F<sub>2</sub>-F<sub>3</sub>) space are not orthogonal). For extraction of independent dimensions that are not necessarily orthogonal, techniques such as linear independent component analysis (ICA), which efficiently encodes structure into latent components that minimize mutual information (redundancy) between outputs (<italic>e.g.</italic>, <xref rid="pone.0030845-Bell1" ref-type="bibr">[61]</xref>), may provide a better statistical analog to perceptual organization.</p>
              <p>The present results could provide insights into models of perceptual organization for complex sounds such as speech. While the novel sounds tested here only varied along two complex dimensions, patterns of covariance naturally scale to high-dimensional feature spaces. In complex natural stimuli such as speech, multiple forms of stimulus attribute redundancy exist concurrently and successively <xref rid="pone.0030845-Lisker1" ref-type="bibr">[20]</xref>, <xref rid="pone.0030845-Repp1" ref-type="bibr">[21]</xref>, <xref rid="pone.0030845-Delattre1" ref-type="bibr">[62]</xref>–<xref rid="pone.0030845-Sussman2" ref-type="bibr">[65]</xref>. To the extent that patterns of covariance among acoustic attributes in natural sounds are efficiently coded, the present results may inform how the auditory system exploits different patterns of redundancy to learn and distinguish different speech sounds.</p>
              <p>While some have suggested the importance of correlations among stimulus attributes are central to perceptual organization for speech <xref rid="pone.0030845-Stilp1" ref-type="bibr">[22]</xref>, <xref rid="pone.0030845-Kluender1" ref-type="bibr">[63]</xref>, <xref rid="pone.0030845-Kluender2" ref-type="bibr">[66]</xref>–<xref rid="pone.0030845-Kluender4" ref-type="bibr">[68]</xref>, it has been more common to emphasize 1<sup>st</sup>-order statistics (<italic>e.g.</italic>, probability density) as a means to characterize distributions of speech sounds <xref rid="pone.0030845-Anderson1" ref-type="bibr">[69]</xref>–<xref rid="pone.0030845-McMurray1" ref-type="bibr">[73]</xref> or cues <xref rid="pone.0030845-Holt1" ref-type="bibr">[74]</xref>–<xref rid="pone.0030845-Cristia1" ref-type="bibr">[77]</xref>. In experiments that oversampled the Orthogonal sound pair (Experiments 4 and 5), manipulations of probability density had little to no effect on patterns of performance. At least in this particular paradigm, higher-order redundancy (covariance) was more perceptually salient than lower-order redundancy (probability density). Future research that explores relative influences of these different types of statistical structure will inform models of perceptual organization and categorization of speech.</p>
              <p>Covariance among complex acoustic attributes in novel stimuli is exploited quickly and automatically in the present experiments. Perception only later comes to encode residual variability in ways that reflect optimal statistical weighting of covariance not accounted for by the principal component of the stimuli. Results illuminate stimulus characteristics that support coding of stimulus redundancy that is rapid, unsupervised, efficient, and statistically optimal.</p>
            </sec>
          </body>
          <back>
            <ack>
              <p>The authors are grateful to Tim Rogers, Bas Rokers, Rob Nowak, Jenny Saffran, and two anonymous reviewers for valuable feedback on a previous draft of this manuscript, and to Kyira Hauer and Ray Kluender for assistance in conducting these studies.</p>
            </ack>
            <fn-group>
              <fn fn-type="COI-statement">
                <p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
              </fn>
              <fn fn-type="financial-disclosure">
                <p><bold>Funding: </bold>CS was funded by DC 009532, and KK was funded by DC 004072, both through the National Institute on Deafness and Other Communication Disorders at the National Institutes of Health (<ext-link ext-link-type="uri" xlink:href="http://www.nidcd.nih.gov/">http://www.nidcd.nih.gov/</ext-link>). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p>
              </fn>
            </fn-group>
            <ref-list>
              <title>References</title>
              <ref id="pone.0030845-Attneave1">
                <label>1</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Attneave</surname>
                      <given-names>F</given-names>
                    </name>
                  </person-group>
                  <year>1954</year>
                  <article-title>Some informational aspects of visual perception.</article-title>
                  <source>Psych Rev</source>
                  <volume>61</volume>
                  <fpage>183</fpage>
                  <lpage>193</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Barlow1">
                <label>2</label>
                <element-citation publication-type="book">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Barlow</surname>
                      <given-names>HB</given-names>
                    </name>
                  </person-group>
                  <year>1959</year>
                  <article-title>Sensory mechanisms, the reduction of redundancy, and intelligence.</article-title>
                  <source>NPL Symposium on the Mechanization of Thought Process</source>
                  <publisher-loc>London</publisher-loc>
                  <publisher-name>HM Stationery Office</publisher-name>
                  <fpage>535</fpage>
                  <lpage>539</lpage>
                  <comment>10:</comment>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Barlow2">
                <label>3</label>
                <element-citation publication-type="book">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Barlow</surname>
                      <given-names>HB</given-names>
                    </name>
                  </person-group>
                  <year>1961</year>
                  <article-title>Possible principles underlying the transformations of sensory messages.</article-title>
                  <person-group person-group-type="editor">
                    <name>
                      <surname>Rosenblith</surname>
                      <given-names>WA</given-names>
                    </name>
                  </person-group>
                  <source>Sensory Communication</source>
                  <publisher-loc>Cambridge</publisher-loc>
                  <publisher-name>MIT Press, New York: John Wiley</publisher-name>
                  <fpage>53</fpage>
                  <lpage>85</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Fairhall1">
                <label>4</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Fairhall</surname>
                      <given-names>AL</given-names>
                    </name>
                    <name>
                      <surname>Lewen</surname>
                      <given-names>GD</given-names>
                    </name>
                    <name>
                      <surname>Bialek</surname>
                      <given-names>W</given-names>
                    </name>
                    <name>
                      <surname>de Ruyter van Steveninck</surname>
                      <given-names>RR</given-names>
                    </name>
                  </person-group>
                  <year>2001</year>
                  <article-title>Efficiency and ambiguity in an adaptive neural code.</article-title>
                  <source>Nature</source>
                  <volume>412</volume>
                  <fpage>787</fpage>
                  <lpage>792</lpage>
                  <pub-id pub-id-type="pmid">11518957</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Olshausen1">
                <label>5</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Olshausen</surname>
                      <given-names>BA</given-names>
                    </name>
                    <name>
                      <surname>Field</surname>
                      <given-names>DJ</given-names>
                    </name>
                  </person-group>
                  <year>1996a</year>
                  <article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images.</article-title>
                  <source>Nature</source>
                  <volume>381</volume>
                  <fpage>607</fpage>
                  <lpage>609</lpage>
                  <pub-id pub-id-type="pmid">8637596</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Olshausen2">
                <label>6</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Olshausen</surname>
                      <given-names>BA</given-names>
                    </name>
                    <name>
                      <surname>Field</surname>
                      <given-names>DJ</given-names>
                    </name>
                  </person-group>
                  <year>1996b</year>
                  <article-title>Natural image statistics and efficient encoding.</article-title>
                  <source>Network: Comp Neural Sys</source>
                  <volume>7</volume>
                  <fpage>333</fpage>
                  <lpage>339</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Olshausen3">
                <label>7</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Olshausen</surname>
                      <given-names>BA</given-names>
                    </name>
                    <name>
                      <surname>Field</surname>
                      <given-names>DJ</given-names>
                    </name>
                  </person-group>
                  <year>1997</year>
                  <article-title>Sparse coding with an overcomplete basis set: A strategy employed by V1?</article-title>
                  <source>Vis Res</source>
                  <volume>37</volume>
                  <fpage>3311</fpage>
                  <lpage>3325</lpage>
                  <pub-id pub-id-type="pmid">9425546</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Schwartz1">
                <label>8</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Schwartz</surname>
                      <given-names>O</given-names>
                    </name>
                    <name>
                      <surname>Hsu</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Dayan</surname>
                      <given-names>P</given-names>
                    </name>
                  </person-group>
                  <year>2007</year>
                  <article-title>Space and time in visual context.</article-title>
                  <source>Nat Neurosci</source>
                  <volume>8</volume>
                  <fpage>522</fpage>
                  <lpage>535</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Simoncelli1">
                <label>9</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Simoncelli</surname>
                      <given-names>EP</given-names>
                    </name>
                  </person-group>
                  <year>2003</year>
                  <article-title>Vision and the statistics of the visual environment.</article-title>
                  <source>Curr Op Neurobio</source>
                  <volume>13</volume>
                  <fpage>144</fpage>
                  <lpage>149</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Vinje1">
                <label>10</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Vinje</surname>
                      <given-names>WE</given-names>
                    </name>
                    <name>
                      <surname>Gallant</surname>
                      <given-names>JL</given-names>
                    </name>
                  </person-group>
                  <year>2000</year>
                  <article-title>Sparse coding and decorrelation in primary visual cortex during natural vision.</article-title>
                  <source>Science</source>
                  <volume>287</volume>
                  <fpage>1273</fpage>
                  <lpage>1276</lpage>
                  <pub-id pub-id-type="pmid">10678835</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Vinje2">
                <label>11</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Vinje</surname>
                      <given-names>WE</given-names>
                    </name>
                    <name>
                      <surname>Gallant</surname>
                      <given-names>JL</given-names>
                    </name>
                  </person-group>
                  <year>2002</year>
                  <article-title>Natural stimulation of the nonclassical receptive field increases information transmission efficiency in V1.</article-title>
                  <source>J Neurosci</source>
                  <volume>22</volume>
                  <fpage>2904</fpage>
                  <lpage>2915</lpage>
                  <pub-id pub-id-type="pmid">11923455</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Chechik1">
                <label>12</label>
                <element-citation publication-type="book">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Chechik</surname>
                      <given-names>G</given-names>
                    </name>
                    <name>
                      <surname>Globerson</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Tishby</surname>
                      <given-names>N</given-names>
                    </name>
                    <name>
                      <surname>Andseron</surname>
                      <given-names>MJ</given-names>
                    </name>
                    <name>
                      <surname>Young</surname>
                      <given-names>ED</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <year>2002</year>
                  <article-title>Group redundancy measures reveal redundancy reduction in the auditory pathway.</article-title>
                  <person-group person-group-type="editor">
                    <name>
                      <surname>Dietterich</surname>
                      <given-names>TG</given-names>
                    </name>
                    <name>
                      <surname>Becker</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Ghahramani</surname>
                      <given-names>Z</given-names>
                    </name>
                  </person-group>
                  <source>Advances in Neural Information Processing Systems</source>
                  <publisher-loc>Cambridge</publisher-loc>
                  <publisher-name>MIT Press</publisher-name>
                  <fpage>27</fpage>
                  <lpage>33</lpage>
                  <comment>14:</comment>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Chechik2">
                <label>13</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Chechik</surname>
                      <given-names>G</given-names>
                    </name>
                    <name>
                      <surname>Anderson</surname>
                      <given-names>MJ</given-names>
                    </name>
                    <name>
                      <surname>Bar-Yosef</surname>
                      <given-names>O</given-names>
                    </name>
                    <name>
                      <surname>Young</surname>
                      <given-names>ED</given-names>
                    </name>
                    <name>
                      <surname>Tishby</surname>
                      <given-names>N</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <year>2006</year>
                  <article-title>Reduction of information redundancy in the ascending auditory pathway.</article-title>
                  <source>Neuron</source>
                  <volume>51</volume>
                  <fpage>359</fpage>
                  <lpage>368</lpage>
                  <pub-id pub-id-type="pmid">16880130</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-McCollough1">
                <label>14</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>McCollough</surname>
                      <given-names>C</given-names>
                    </name>
                  </person-group>
                  <year>1965</year>
                  <article-title>Color adaptation of edge-detectors in the human visual system.</article-title>
                  <source>Science</source>
                  <volume>149</volume>
                  <issue>3688</issue>
                  <fpage>1115</fpage>
                  <lpage>1116</lpage>
                  <pub-id pub-id-type="pmid">17737844</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Durgin1">
                <label>15</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Durgin</surname>
                      <given-names>FH</given-names>
                    </name>
                  </person-group>
                  <year>1996</year>
                  <article-title>Visual aftereffect of texture density contingent on color of frame.</article-title>
                  <source>Percept Psychophys</source>
                  <volume>58</volume>
                  <issue>2</issue>
                  <fpage>207</fpage>
                  <lpage>223</lpage>
                  <pub-id pub-id-type="pmid">8838165</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Barlow3">
                <label>16</label>
                <element-citation publication-type="book">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Barlow</surname>
                      <given-names>HB</given-names>
                    </name>
                    <name>
                      <surname>Földiák</surname>
                      <given-names>P</given-names>
                    </name>
                  </person-group>
                  <year>1989</year>
                  <article-title>Adaptation and decorrelation in the cortex.</article-title>
                  <source>The Computing Neuron</source>
                  <publisher-loc>Boston</publisher-loc>
                  <publisher-name>Addison-Wesley</publisher-name>
                  <fpage>54</fpage>
                  <lpage>72</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Clifford1">
                <label>17</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Clifford</surname>
                      <given-names>CWG</given-names>
                    </name>
                    <name>
                      <surname>Webster</surname>
                      <given-names>MA</given-names>
                    </name>
                    <name>
                      <surname>Stanley</surname>
                      <given-names>GB</given-names>
                    </name>
                    <name>
                      <surname>Stocker</surname>
                      <given-names>AA</given-names>
                    </name>
                    <name>
                      <surname>Kohn</surname>
                      <given-names>A</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <year>2007</year>
                  <article-title>Visual adaptation: Neural, psychological and computational aspects.</article-title>
                  <source>Vis Res</source>
                  <volume>47</volume>
                  <fpage>3125</fpage>
                  <lpage>3131</lpage>
                  <pub-id pub-id-type="pmid">17936871</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Movshon1">
                <label>18</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Movshon</surname>
                      <given-names>JA</given-names>
                    </name>
                    <name>
                      <surname>Lennie</surname>
                      <given-names>P</given-names>
                    </name>
                  </person-group>
                  <year>1979</year>
                  <article-title>Pattern-selective adaptation in visual cortical neurons.</article-title>
                  <source>Nature</source>
                  <volume>278</volume>
                  <fpage>850</fpage>
                  <lpage>852</lpage>
                  <pub-id pub-id-type="pmid">440411</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Ernst1">
                <label>19</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Ernst</surname>
                      <given-names>MO</given-names>
                    </name>
                  </person-group>
                  <year>2007</year>
                  <article-title>Learning to integrate arbitrary signals from vision and touch.</article-title>
                  <source>J Vis</source>
                  <volume>7</volume>
                  <issue>5</issue>
                  <fpage>1</fpage>
                  <lpage>14</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Lisker1">
                <label>20</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Lisker</surname>
                      <given-names>L</given-names>
                    </name>
                  </person-group>
                  <year>1978</year>
                  <article-title>Rapid versus rabid: A catalogue of acoustical features that may cue the distinction.</article-title>
                  <source>Haskins Lab Status Report Speech Res</source>
                  <volume>SR-54</volume>
                  <fpage>127</fpage>
                  <lpage>132</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Repp1">
                <label>21</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Repp</surname>
                      <given-names>BH</given-names>
                    </name>
                  </person-group>
                  <year>1982</year>
                  <article-title>Phonetic trading relations and context effects: New experimental evidence for a speech mode of perception.</article-title>
                  <source>Psych Bull</source>
                  <volume>92</volume>
                  <fpage>81</fpage>
                  <lpage>110</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Stilp1">
                <label>22</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Stilp</surname>
                      <given-names>CE</given-names>
                    </name>
                    <name>
                      <surname>Rogers</surname>
                      <given-names>TT</given-names>
                    </name>
                    <name>
                      <surname>Kluender</surname>
                      <given-names>KR</given-names>
                    </name>
                  </person-group>
                  <year>2010</year>
                  <article-title>Rapid efficient coding of correlated complex acoustic properties.</article-title>
                  <source>Proc Natl Acad Sci U S A</source>
                  <volume>107</volume>
                  <issue>50</issue>
                  <fpage>21914</fpage>
                  <lpage>21919</lpage>
                  <pub-id pub-id-type="pmid">21098293</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Hebb1">
                <label>23</label>
                <element-citation publication-type="book">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Hebb</surname>
                      <given-names>DO</given-names>
                    </name>
                  </person-group>
                  <year>1949</year>
                  <source>Organization of Behavior</source>
                  <publisher-loc>New York</publisher-loc>
                  <publisher-name>Wiley</publisher-name>
                  <size units="page">335</size>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Oja1">
                <label>24</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Oja</surname>
                      <given-names>E</given-names>
                    </name>
                  </person-group>
                  <year>1982</year>
                  <article-title>A simplified neuron model as a principal component analyzer.</article-title>
                  <source>J Math Bio</source>
                  <volume>15</volume>
                  <fpage>267</fpage>
                  <lpage>273</lpage>
                  <pub-id pub-id-type="pmid">7153672</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Clifford2">
                <label>25</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Clifford</surname>
                      <given-names>CWG</given-names>
                    </name>
                    <name>
                      <surname>Wenderoth</surname>
                      <given-names>P</given-names>
                    </name>
                    <name>
                      <surname>Spehar</surname>
                      <given-names>B</given-names>
                    </name>
                  </person-group>
                  <year>2000</year>
                  <article-title>A functional angle on some after-effects in cortical vision.</article-title>
                  <source>Proc Royal Soc London B</source>
                  <volume>267</volume>
                  <fpage>1705</fpage>
                  <lpage>1710</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Sanger1">
                <label>26</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Sanger</surname>
                      <given-names>TD</given-names>
                    </name>
                  </person-group>
                  <year>1989</year>
                  <article-title>Optimal unsupervised learning in a single-layer linear feedforward neural network.</article-title>
                  <source>Neural Netw</source>
                  <volume>2</volume>
                  <fpage>459</fpage>
                  <lpage>473</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Opolko1">
                <label>27</label>
                <element-citation publication-type="book">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Opolko</surname>
                      <given-names>F</given-names>
                    </name>
                    <name>
                      <surname>Wapnick</surname>
                      <given-names>J</given-names>
                    </name>
                  </person-group>
                  <year>1989</year>
                  <source>McGill University master samples user's manual</source>
                  <publisher-loc>Montreal</publisher-loc>
                  <publisher-name>McGill University, Faculty of Music</publisher-name>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Caclin1">
                <label>28</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Caclin</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Brattico</surname>
                      <given-names>E</given-names>
                    </name>
                    <name>
                      <surname>Tervaniemi</surname>
                      <given-names>M</given-names>
                    </name>
                    <name>
                      <surname>Näätänen</surname>
                      <given-names>R</given-names>
                    </name>
                    <name>
                      <surname>Morlet</surname>
                      <given-names>D</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <year>2006</year>
                  <article-title>Separate neural processing of timbre dimensions in auditory sensory memory.</article-title>
                  <source>J Cogn Neurosci</source>
                  <volume>18</volume>
                  <fpage>1959</fpage>
                  <lpage>1972</lpage>
                  <pub-id pub-id-type="pmid">17129184</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Glasberg1">
                <label>29</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Glasberg</surname>
                      <given-names>BR</given-names>
                    </name>
                    <name>
                      <surname>Moore</surname>
                      <given-names>BCJ</given-names>
                    </name>
                  </person-group>
                  <year>1990</year>
                  <article-title>Derivation of auditory filter shapes from notched-noise data.</article-title>
                  <source>Hear Res</source>
                  <volume>47</volume>
                  <fpage>103</fpage>
                  <lpage>138</lpage>
                  <pub-id pub-id-type="pmid">2228789</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Patterson1">
                <label>30</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Patterson</surname>
                      <given-names>RD</given-names>
                    </name>
                    <name>
                      <surname>Nimmo-Smith</surname>
                      <given-names>I</given-names>
                    </name>
                    <name>
                      <surname>Weber</surname>
                      <given-names>DL</given-names>
                    </name>
                    <name>
                      <surname>Milroy</surname>
                      <given-names>D</given-names>
                    </name>
                  </person-group>
                  <year>1982</year>
                  <article-title>The deterioration of hearing with age: Frequency selectivity, the critical ratio, the audiogram, and speech threshold.</article-title>
                  <source>J Acoust Soc Am</source>
                  <volume>72</volume>
                  <fpage>1788</fpage>
                  <lpage>1803</lpage>
                  <pub-id pub-id-type="pmid">7153426</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Stilp2">
                <label>31</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Stilp</surname>
                      <given-names>CE</given-names>
                    </name>
                    <name>
                      <surname>Kluender</surname>
                      <given-names>KR</given-names>
                    </name>
                  </person-group>
                  <year>2010</year>
                  <article-title>Cochlea-scaled spectral entropy, not consonants, vowels, or time, best predicts speech intelligibility.</article-title>
                  <source>Proc Natl Acad Sci U S A</source>
                  <volume>107</volume>
                  <issue>27</issue>
                  <fpage>12387</fpage>
                  <lpage>12392</lpage>
                  <pub-id pub-id-type="pmid">20566842</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Kohn1">
                <label>32</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Kohn</surname>
                      <given-names>A</given-names>
                    </name>
                  </person-group>
                  <year>2007</year>
                  <article-title>Visual adaptation: physiology, mechanisms, and functional benefits.</article-title>
                  <source>J Neurophys</source>
                  <volume>97</volume>
                  <fpage>3155</fpage>
                  <lpage>3164</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Sejnowski1">
                <label>33</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Sejnowski</surname>
                      <given-names>TJ</given-names>
                    </name>
                  </person-group>
                  <year>1977a</year>
                  <article-title>Storing covariance with nonlinearly interacting neurons.</article-title>
                  <source>J Math Bio</source>
                  <volume>4</volume>
                  <fpage>303</fpage>
                  <lpage>321</lpage>
                  <pub-id pub-id-type="pmid">925522</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Sejnowski2">
                <label>34</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Sejnowski</surname>
                      <given-names>TJ</given-names>
                    </name>
                  </person-group>
                  <year>1977b</year>
                  <article-title>Statistical constraints on synaptic plasticity.</article-title>
                  <source>J Theor Biol</source>
                  <volume>69</volume>
                  <fpage>385</fpage>
                  <lpage>389</lpage>
                  <pub-id pub-id-type="pmid">592884</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Stanton1">
                <label>35</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Stanton</surname>
                      <given-names>PK</given-names>
                    </name>
                    <name>
                      <surname>Sejnowski</surname>
                      <given-names>TH</given-names>
                    </name>
                  </person-group>
                  <year>1989</year>
                  <article-title>Associative long-term depression in the hippocampus induced by Hebbian covariance.</article-title>
                  <source>Nature</source>
                  <volume>339</volume>
                  <fpage>215</fpage>
                  <lpage>219</lpage>
                  <pub-id pub-id-type="pmid">2716848</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Xu1">
                <label>36</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Xu</surname>
                      <given-names>J-M</given-names>
                    </name>
                    <name>
                      <surname>Zhu</surname>
                      <given-names>X</given-names>
                    </name>
                    <name>
                      <surname>Rogers</surname>
                      <given-names>TT</given-names>
                    </name>
                  </person-group>
                  <year>in press</year>
                  <article-title>Metric learning for estimating psychological similarities.</article-title>
                  <source>ACM Trans Embed Comp Sys</source>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Nelken1">
                <label>37</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Nelken</surname>
                      <given-names>I</given-names>
                    </name>
                    <name>
                      <surname>Fishbach</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Las</surname>
                      <given-names>L</given-names>
                    </name>
                    <name>
                      <surname>Ulanovsky</surname>
                      <given-names>N</given-names>
                    </name>
                    <name>
                      <surname>Farkas</surname>
                      <given-names>D</given-names>
                    </name>
                  </person-group>
                  <year>2003</year>
                  <article-title>Primary auditory cortex of cats: Feature detection or something else?</article-title>
                  <source>Biol Cybern</source>
                  <volume>89</volume>
                  <fpage>397</fpage>
                  <lpage>406</lpage>
                  <pub-id pub-id-type="pmid">14669020</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Barbour1">
                <label>38</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Barbour</surname>
                      <given-names>DL</given-names>
                    </name>
                    <name>
                      <surname>Wang</surname>
                      <given-names>X</given-names>
                    </name>
                  </person-group>
                  <year>2003</year>
                  <article-title>Contrast tuning in auditory cortex.</article-title>
                  <source>Science</source>
                  <volume>299</volume>
                  <fpage>1073</fpage>
                  <lpage>1075</lpage>
                  <pub-id pub-id-type="pmid">12586943</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Wang1">
                <label>39</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Wang</surname>
                      <given-names>X</given-names>
                    </name>
                  </person-group>
                  <year>2007</year>
                  <article-title>Neural coding strategies in auditory cortex.</article-title>
                  <source>Hear Res</source>
                  <volume>229</volume>
                  <fpage>81</fpage>
                  <lpage>93</lpage>
                  <pub-id pub-id-type="pmid">17346911</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Lu1">
                <label>40</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Lu</surname>
                      <given-names>T</given-names>
                    </name>
                    <name>
                      <surname>Liang</surname>
                      <given-names>L</given-names>
                    </name>
                    <name>
                      <surname>Wang</surname>
                      <given-names>X</given-names>
                    </name>
                  </person-group>
                  <year>2001</year>
                  <article-title>Temporal and rate representations of time-varying signals in the auditory cortex of awake primates.</article-title>
                  <source>Nature Neurosci</source>
                  <volume>4</volume>
                  <fpage>1131</fpage>
                  <lpage>1138</lpage>
                  <pub-id pub-id-type="pmid">11593234</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Lu2">
                <label>41</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Lu</surname>
                      <given-names>T</given-names>
                    </name>
                    <name>
                      <surname>Wang</surname>
                      <given-names>X</given-names>
                    </name>
                  </person-group>
                  <year>2000</year>
                  <article-title>Temporal discharge patterns evoked by rapid sequences of wide- and narrow-band clicks in the primary auditory cortex of cat.</article-title>
                  <source>J Neurophys</source>
                  <volume>84</volume>
                  <fpage>236</fpage>
                  <lpage>246</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Bendor1">
                <label>42</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Bendor</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Wang</surname>
                      <given-names>X</given-names>
                    </name>
                  </person-group>
                  <year>2005</year>
                  <article-title>The neuronal representation of pitch in primary auditory cortex.</article-title>
                  <source>Nature</source>
                  <volume>436</volume>
                  <issue>7054</issue>
                  <fpage>1161</fpage>
                  <lpage>1165</lpage>
                  <pub-id pub-id-type="pmid">16121182</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Bendor2">
                <label>43</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Bendor</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Wang</surname>
                      <given-names>X</given-names>
                    </name>
                  </person-group>
                  <year>2006</year>
                  <article-title>Cortical representations of pitch in monkeys and humans.</article-title>
                  <source>Curr Op Neurobio</source>
                  <volume>16</volume>
                  <fpage>391</fpage>
                  <lpage>399</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Stilp3">
                <label>44</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Stilp</surname>
                      <given-names>CE</given-names>
                    </name>
                    <name>
                      <surname>Kluender</surname>
                      <given-names>KR</given-names>
                    </name>
                  </person-group>
                  <year>2011</year>
                  <article-title>Non-isomorphism in efficient coding of complex sound properties.</article-title>
                  <source>J Acoust Soc Am</source>
                  <volume>130</volume>
                  <issue>5</issue>
                  <fpage>EL352</fpage>
                  <lpage>EL357</lpage>
                  <pub-id pub-id-type="pmid">22088040</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Kersten1">
                <label>45</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Kersten</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Mamassian</surname>
                      <given-names>P</given-names>
                    </name>
                    <name>
                      <surname>Yuille</surname>
                      <given-names>A</given-names>
                    </name>
                  </person-group>
                  <year>2004</year>
                  <article-title>Object perception as Bayesian Inference.</article-title>
                  <source>Ann Rev Psych</source>
                  <volume>55</volume>
                  <fpage>271</fpage>
                  <lpage>304</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Kersten2">
                <label>46</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Kersten</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Yuille</surname>
                      <given-names>A</given-names>
                    </name>
                  </person-group>
                  <year>2003</year>
                  <article-title>Bayesian models of object perception.</article-title>
                  <source>Curr Op Neurobio</source>
                  <volume>13</volume>
                  <issue>2</issue>
                  <fpage>150</fpage>
                  <lpage>158</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Geisler1">
                <label>47</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Geisler</surname>
                      <given-names>WS</given-names>
                    </name>
                    <name>
                      <surname>Perry</surname>
                      <given-names>JS</given-names>
                    </name>
                    <name>
                      <surname>Super</surname>
                      <given-names>BJ</given-names>
                    </name>
                    <name>
                      <surname>Gallogly</surname>
                      <given-names>DP</given-names>
                    </name>
                  </person-group>
                  <year>2001</year>
                  <article-title>Edge co-occurrence in natural images predicts contour grouping performance.</article-title>
                  <source>Vis Res</source>
                  <volume>41</volume>
                  <fpage>711</fpage>
                  <lpage>724</lpage>
                  <pub-id pub-id-type="pmid">11248261</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Stocker1">
                <label>48</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Stocker</surname>
                      <given-names>AA</given-names>
                    </name>
                    <name>
                      <surname>Simoncelli</surname>
                      <given-names>EP</given-names>
                    </name>
                  </person-group>
                  <year>2006</year>
                  <article-title>Noise characteristics and prior expectations in human visual speed perception.</article-title>
                  <source>Nat Neurosci</source>
                  <volume>9</volume>
                  <issue>4</issue>
                  <fpage>578</fpage>
                  <lpage>585</lpage>
                  <pub-id pub-id-type="pmid">16547513</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Girshick1">
                <label>49</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Girshick</surname>
                      <given-names>AR</given-names>
                    </name>
                    <name>
                      <surname>Banks</surname>
                      <given-names>MS</given-names>
                    </name>
                  </person-group>
                  <year>2009</year>
                  <article-title>Probabilistic combination of slant information: Weighted averaging and robustness as optimal percepts.</article-title>
                  <source>J Vis</source>
                  <volume>9</volume>
                  <issue>9</issue>
                  <fpage>1</fpage>
                  <lpage>20</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Hillis1">
                <label>50</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Hillis</surname>
                      <given-names>JM</given-names>
                    </name>
                    <name>
                      <surname>Ernst</surname>
                      <given-names>MO</given-names>
                    </name>
                    <name>
                      <surname>Banks</surname>
                      <given-names>MS</given-names>
                    </name>
                    <name>
                      <surname>Landy</surname>
                      <given-names>MS</given-names>
                    </name>
                  </person-group>
                  <year>2002</year>
                  <article-title>Combining sensory information: Mandatory fusion within, but not between, senses.</article-title>
                  <source>Science</source>
                  <volume>298</volume>
                  <issue>5598</issue>
                  <fpage>1627</fpage>
                  <lpage>1630</lpage>
                  <pub-id pub-id-type="pmid">12446912</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Hillis2">
                <label>51</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Hillis</surname>
                      <given-names>JM</given-names>
                    </name>
                    <name>
                      <surname>Watt</surname>
                      <given-names>SJ</given-names>
                    </name>
                    <name>
                      <surname>Landy</surname>
                      <given-names>MS</given-names>
                    </name>
                    <name>
                      <surname>Banks</surname>
                      <given-names>MS</given-names>
                    </name>
                  </person-group>
                  <year>2004</year>
                  <article-title>Slant from texture and disparity cues: optimal cue combination.</article-title>
                  <source>J Vis</source>
                  <volume>4</volume>
                  <issue>12</issue>
                  <fpage>967</fpage>
                  <lpage>992</lpage>
                  <pub-id pub-id-type="pmid">15669906</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Knill1">
                <label>52</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Knill</surname>
                      <given-names>DC</given-names>
                    </name>
                    <name>
                      <surname>Saunders</surname>
                      <given-names>JA</given-names>
                    </name>
                  </person-group>
                  <year>2003</year>
                  <article-title>Do humans optimally integrate stereo and texture information for judgments of surface slant?</article-title>
                  <source>Vis Res</source>
                  <volume>32</volume>
                  <fpage>2539</fpage>
                  <lpage>2558</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Alais1">
                <label>53</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Alais</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Burr</surname>
                      <given-names>D</given-names>
                    </name>
                  </person-group>
                  <year>2004</year>
                  <article-title>The ventriloquist effect results from near-optimal bimodal integration.</article-title>
                  <source>Curr Bio</source>
                  <volume>14</volume>
                  <fpage>257</fpage>
                  <lpage>262</lpage>
                  <pub-id pub-id-type="pmid">14761661</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Faisal1">
                <label>54</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Faisal</surname>
                      <given-names>AA</given-names>
                    </name>
                    <name>
                      <surname>Wolpert</surname>
                      <given-names>DM</given-names>
                    </name>
                  </person-group>
                  <year>2009</year>
                  <article-title>Near optimal combination of sensory and motor uncertainty in time during a naturalistic perception-action task.</article-title>
                  <source>J Neurophys</source>
                  <volume>101</volume>
                  <fpage>1901</fpage>
                  <lpage>1912</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Krding1">
                <label>55</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Körding</surname>
                      <given-names>KP</given-names>
                    </name>
                    <name>
                      <surname>Wolpert</surname>
                      <given-names>DM</given-names>
                    </name>
                  </person-group>
                  <year>2004</year>
                  <article-title>Bayesian integration in sensorimotor learning.</article-title>
                  <source>Nature</source>
                  <volume>427</volume>
                  <issue>15</issue>
                  <fpage>244</fpage>
                  <lpage>247</lpage>
                  <pub-id pub-id-type="pmid">14724638</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Krding2">
                <label>56</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Körding</surname>
                      <given-names>KP</given-names>
                    </name>
                    <name>
                      <surname>Wolpert</surname>
                      <given-names>DM</given-names>
                    </name>
                  </person-group>
                  <year>2006</year>
                  <article-title>Bayesian decision theory in sensorimotor control.</article-title>
                  <source>Trends Cogn Sci</source>
                  <volume>10</volume>
                  <issue>7</issue>
                  <fpage>319</fpage>
                  <lpage>326</lpage>
                  <pub-id pub-id-type="pmid">16807063</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Turnham1">
                <label>57</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Turnham</surname>
                      <given-names>EJA</given-names>
                    </name>
                    <name>
                      <surname>Braun</surname>
                      <given-names>DA</given-names>
                    </name>
                    <name>
                      <surname>Wolpert</surname>
                      <given-names>DM</given-names>
                    </name>
                  </person-group>
                  <year>2011</year>
                  <article-title>Inferring visuomotor priors for sensorimotor learning.</article-title>
                  <source>PLoS Comp Bio</source>
                  <volume>7</volume>
                  <issue>3</issue>
                  <fpage>e1001112</fpage>
                  <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1001112">10.1371/journal.pcbi.1001112</ext-link></comment>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Ernst2">
                <label>58</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Ernst</surname>
                      <given-names>MO</given-names>
                    </name>
                    <name>
                      <surname>Banks</surname>
                      <given-names>MS</given-names>
                    </name>
                  </person-group>
                  <year>2002</year>
                  <article-title>Humans integrate visual and haptic information in a statistically optimal fashion.</article-title>
                  <source>Nature</source>
                  <volume>415</volume>
                  <fpage>429</fpage>
                  <lpage>433</lpage>
                  <pub-id pub-id-type="pmid">11807554</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Helbig1">
                <label>59</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Helbig</surname>
                      <given-names>HB</given-names>
                    </name>
                    <name>
                      <surname>Ernst</surname>
                      <given-names>MO</given-names>
                    </name>
                  </person-group>
                  <year>2007</year>
                  <article-title>Optimal integration of shape information from vision and touch.</article-title>
                  <source>Exptal Brain Res</source>
                  <volume>179</volume>
                  <fpage>595</fpage>
                  <lpage>606</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Chapin1">
                <label>60</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Chapin</surname>
                      <given-names>JK</given-names>
                    </name>
                    <name>
                      <surname>Nicolelis</surname>
                      <given-names>MAL</given-names>
                    </name>
                  </person-group>
                  <year>1999</year>
                  <article-title>Principal components analysis of neuronal ensemble activity reveals multidimensional somatosensory representations.</article-title>
                  <source>J Neurosci Methods</source>
                  <volume>94</volume>
                  <fpage>121</fpage>
                  <lpage>140</lpage>
                  <pub-id pub-id-type="pmid">10638820</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Bell1">
                <label>61</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Bell</surname>
                      <given-names>AJ</given-names>
                    </name>
                    <name>
                      <surname>Sejnowski</surname>
                      <given-names>TJ</given-names>
                    </name>
                  </person-group>
                  <year>1995</year>
                  <article-title>An information-maximization approach to blind separation and blind deconvolution.</article-title>
                  <source>Neural Comp</source>
                  <volume>7</volume>
                  <fpage>1129</fpage>
                  <lpage>1159</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Delattre1">
                <label>62</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Delattre</surname>
                      <given-names>PC</given-names>
                    </name>
                    <name>
                      <surname>Liberman</surname>
                      <given-names>AM</given-names>
                    </name>
                    <name>
                      <surname>Cooper</surname>
                      <given-names>FS</given-names>
                    </name>
                  </person-group>
                  <year>1955</year>
                  <article-title>Acoustic loci and transitional cues for consonants.</article-title>
                  <source>J Acoust Soc Am</source>
                  <volume>27</volume>
                  <issue>4</issue>
                  <fpage>769</fpage>
                  <lpage>773</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Kluender1">
                <label>63</label>
                <element-citation publication-type="book">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Kluender</surname>
                      <given-names>KR</given-names>
                    </name>
                    <name>
                      <surname>Stilp</surname>
                      <given-names>CE</given-names>
                    </name>
                    <name>
                      <surname>Kiefte</surname>
                      <given-names>M</given-names>
                    </name>
                  </person-group>
                  <year>in press</year>
                  <article-title>Perception of vowel sounds within a biologically realistic model of efficient coding.</article-title>
                  <person-group person-group-type="editor">
                    <name>
                      <surname>Morrison</surname>
                      <given-names>G</given-names>
                    </name>
                    <name>
                      <surname>Assmann</surname>
                      <given-names>P</given-names>
                    </name>
                  </person-group>
                  <source>Vowel Inherent Spectral Change</source>
                  <publisher-name>Springer</publisher-name>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Sussman1">
                <label>64</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Sussman</surname>
                      <given-names>HM</given-names>
                    </name>
                    <name>
                      <surname>McCaffrey</surname>
                      <given-names>HA</given-names>
                    </name>
                    <name>
                      <surname>Matthews</surname>
                      <given-names>SA</given-names>
                    </name>
                  </person-group>
                  <year>1991</year>
                  <article-title>An investigation of locus equations as a source of relational invariance for stop place categorization.</article-title>
                  <source>J Acoust Soc Am</source>
                  <volume>90</volume>
                  <fpage>1309</fpage>
                  <lpage>1325</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Sussman2">
                <label>65</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Sussman</surname>
                      <given-names>HM</given-names>
                    </name>
                    <name>
                      <surname>Fruchter</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Hilbert</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Sirosh</surname>
                      <given-names>J</given-names>
                    </name>
                  </person-group>
                  <year>1998</year>
                  <article-title>Linear correlates in the speech signal: The orderly output constraint.</article-title>
                  <source>Behav Brain Sci</source>
                  <volume>21</volume>
                  <fpage>241</fpage>
                  <lpage>259</lpage>
                  <pub-id pub-id-type="pmid">10097014</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Kluender2">
                <label>66</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Kluender</surname>
                      <given-names>KR</given-names>
                    </name>
                    <name>
                      <surname>Lotto</surname>
                      <given-names>AJ</given-names>
                    </name>
                  </person-group>
                  <year>1999</year>
                  <article-title>Virtues and perils of empiricist approaches to speech perception.</article-title>
                  <source>J Acoust Soc Am</source>
                  <volume>105</volume>
                  <fpage>503</fpage>
                  <lpage>511</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Kluender3">
                <label>67</label>
                <element-citation publication-type="book">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Kluender</surname>
                      <given-names>KR</given-names>
                    </name>
                    <name>
                      <surname>Kiefte</surname>
                      <given-names>M</given-names>
                    </name>
                  </person-group>
                  <year>2006</year>
                  <article-title>Speech perception within a biologically-realistic information-theoretic framework.</article-title>
                  <person-group person-group-type="editor">
                    <name>
                      <surname>Gernsbacher</surname>
                      <given-names>MA</given-names>
                    </name>
                    <name>
                      <surname>Traxler</surname>
                      <given-names>M</given-names>
                    </name>
                  </person-group>
                  <source>Handbook of Psycholinguistics</source>
                  <publisher-loc>London</publisher-loc>
                  <publisher-name>Elsevier</publisher-name>
                  <fpage>153</fpage>
                  <lpage>199</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Kluender4">
                <label>68</label>
                <element-citation publication-type="book">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Kluender</surname>
                      <given-names>KR</given-names>
                    </name>
                    <name>
                      <surname>Alexander</surname>
                      <given-names>JM</given-names>
                    </name>
                  </person-group>
                  <year>2008</year>
                  <article-title>Perception of speech sounds.</article-title>
                  <person-group person-group-type="editor">
                    <name>
                      <surname>Dallos</surname>
                      <given-names>P</given-names>
                    </name>
                    <name>
                      <surname>Oertel</surname>
                      <given-names>D</given-names>
                    </name>
                  </person-group>
                  <source>The Senses: A Comprehensive Reference, Vol. 3, Audition</source>
                  <publisher-loc>San Diego</publisher-loc>
                  <publisher-name>Academic Press</publisher-name>
                  <fpage>829</fpage>
                  <lpage>860</lpage>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Anderson1">
                <label>69</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Anderson</surname>
                      <given-names>JL</given-names>
                    </name>
                    <name>
                      <surname>Morgan</surname>
                      <given-names>JL</given-names>
                    </name>
                    <name>
                      <surname>White</surname>
                      <given-names>KS</given-names>
                    </name>
                  </person-group>
                  <year>2003</year>
                  <article-title>A statistical basis for speech sound discrimination.</article-title>
                  <source>Lang Speech</source>
                  <volume>46</volume>
                  <issue>2–3</issue>
                  <fpage>155</fpage>
                  <lpage>182</lpage>
                  <pub-id pub-id-type="pmid">14748443</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Kluender5">
                <label>70</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Kluender</surname>
                      <given-names>KR</given-names>
                    </name>
                    <name>
                      <surname>Lotto</surname>
                      <given-names>AJ</given-names>
                    </name>
                    <name>
                      <surname>Holt</surname>
                      <given-names>LL</given-names>
                    </name>
                    <name>
                      <surname>Bloedel</surname>
                      <given-names>SL</given-names>
                    </name>
                  </person-group>
                  <year>1998</year>
                  <article-title>Role of experience for language-specific functional mappings of vowel sounds.</article-title>
                  <source>J Acoust Soc Am</source>
                  <volume>104</volume>
                  <fpage>3568</fpage>
                  <lpage>3582</lpage>
                  <pub-id pub-id-type="pmid">9857515</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Maye1">
                <label>71</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Maye</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Weiss</surname>
                      <given-names>DJ</given-names>
                    </name>
                    <name>
                      <surname>Aslin</surname>
                      <given-names>RN</given-names>
                    </name>
                  </person-group>
                  <year>2008</year>
                  <article-title>Statistical phonetic learning in infants: facilitation and feature generalization.</article-title>
                  <source>Dev Sci</source>
                  <volume>11</volume>
                  <issue>1</issue>
                  <fpage>122</fpage>
                  <lpage>134</lpage>
                  <pub-id pub-id-type="pmid">18171374</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Maye2">
                <label>72</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Maye</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Werker</surname>
                      <given-names>JF</given-names>
                    </name>
                    <name>
                      <surname>Gerken</surname>
                      <given-names>L</given-names>
                    </name>
                  </person-group>
                  <year>2002</year>
                  <article-title>Infant sensitivity to distributional information can affect phonetic discrimination.</article-title>
                  <source>Cognition</source>
                  <volume>82</volume>
                  <issue>3</issue>
                  <fpage>B101</fpage>
                  <lpage>B111</lpage>
                  <pub-id pub-id-type="pmid">11747867</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-McMurray1">
                <label>73</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>McMurray</surname>
                      <given-names>B</given-names>
                    </name>
                    <name>
                      <surname>Aslin</surname>
                      <given-names>RN</given-names>
                    </name>
                    <name>
                      <surname>Toscano</surname>
                      <given-names>JC</given-names>
                    </name>
                  </person-group>
                  <year>2009</year>
                  <article-title>Statistical learning of phonetic categories: insights from a computational approach.</article-title>
                  <source>Dev Sci</source>
                  <volume>12</volume>
                  <issue>3</issue>
                  <fpage>369</fpage>
                  <lpage>378</lpage>
                  <pub-id pub-id-type="pmid">19371359</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Holt1">
                <label>74</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Holt</surname>
                      <given-names>LL</given-names>
                    </name>
                    <name>
                      <surname>Lotto</surname>
                      <given-names>AJ</given-names>
                    </name>
                  </person-group>
                  <year>2006</year>
                  <article-title>Cue weighting in auditory categorization: Implications for first and second language acquisition.</article-title>
                  <source>J Acoust Soc Am</source>
                  <volume>119</volume>
                  <fpage>3059</fpage>
                  <lpage>3071</lpage>
                  <pub-id pub-id-type="pmid">16708961</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Sullivan1">
                <label>75</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Sullivan</surname>
                      <given-names>SC</given-names>
                    </name>
                    <name>
                      <surname>Kittleson</surname>
                      <given-names>MM</given-names>
                    </name>
                    <name>
                      <surname>Lotto</surname>
                      <given-names>AJ</given-names>
                    </name>
                    <name>
                      <surname>Diehl</surname>
                      <given-names>RL</given-names>
                    </name>
                  </person-group>
                  <year>2010</year>
                  <article-title>Sensitivity to characteristics of Gaussian-shaped stimulus distributions in auditory categorization.</article-title>
                  <source>J Acoust Soc Am</source>
                  <volume>128</volume>
                  <volume>2455</volume>
                  <issue>4</issue>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Toscano1">
                <label>76</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Toscano</surname>
                      <given-names>JC</given-names>
                    </name>
                    <name>
                      <surname>McMurray</surname>
                      <given-names>B</given-names>
                    </name>
                  </person-group>
                  <year>2010</year>
                  <article-title>Cue integration with categories: Weighting acoustic cues in speech using unsupervised learning and distributional statistics.</article-title>
                  <source>Cogn Sci</source>
                  <volume>34</volume>
                  <fpage>434</fpage>
                  <lpage>464</lpage>
                  <pub-id pub-id-type="pmid">21339861</pub-id>
                </element-citation>
              </ref>
              <ref id="pone.0030845-Cristia1">
                <label>77</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Cristia</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>McGuire</surname>
                      <given-names>GL</given-names>
                    </name>
                    <name>
                      <surname>Seidl</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Francis</surname>
                      <given-names>AL</given-names>
                    </name>
                  </person-group>
                  <year>2011</year>
                  <article-title>Effects of the distribution of acoustic cues on infants' perception of sibilants.</article-title>
                  <source>J Phon</source>
                  <volume>39</volume>
                  <fpage>388</fpage>
                  <lpage>402</lpage>
                  <pub-id pub-id-type="pmid">21804656</pub-id>
                </element-citation>
              </ref>
            </ref-list>
          </back>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
