<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2024-05-03T01:52:21Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:10462953" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:10462953</identifier>
        <datestamp>2023-08-30</datestamp>
        <setSpec>bmjo</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" dtd-version="1.3" xml:lang="en" article-type="research-article">
          <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
            <restricted-by>pmc</restricted-by>
          </processing-meta>
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">BMJ Open</journal-id>
              <journal-id journal-id-type="iso-abbrev">BMJ Open</journal-id>
              <journal-id journal-id-type="hwp">bmjopen</journal-id>
              <journal-id journal-id-type="publisher-id">bmjopen</journal-id>
              <journal-title-group>
                <journal-title>BMJ Open</journal-title>
              </journal-title-group>
              <issn pub-type="epub">2044-6055</issn>
              <publisher>
                <publisher-name>BMJ Publishing Group</publisher-name>
                <publisher-loc>BMA House, Tavistock Square, London, WC1H 9JR</publisher-loc>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC10462953</article-id>
              <article-id pub-id-type="pmcid">PMC10462953</article-id>
              <article-id pub-id-type="pmc-uid">10462953</article-id>
              <article-id pub-id-type="pmid">37640467</article-id>
              <article-id pub-id-type="pmid">37640467</article-id>
              <article-id pub-id-type="publisher-id">bmjopen-2023-076297</article-id>
              <article-id pub-id-type="doi">10.1136/bmjopen-2023-076297</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Research Methods</subject>
                </subj-group>
                <subj-group subj-group-type="hwp-journal-coll">
                  <subject>1506</subject>
                  <subject>1730</subject>
                </subj-group>
                <series-title>Protocol</series-title>
              </article-categories>
              <title-group>
                <article-title>SocialBit: protocol for a prospective observational study to validate a wearable social sensor for stroke survivors with diverse neurological abilities</article-title>
              </title-group>
              <contrib-group>
                <contrib id="author-108628797" contrib-type="author">
                  <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-0761-549X</contrib-id>
                  <name>
                    <surname>White</surname>
                    <given-names>Kelly</given-names>
                  </name>
                  <xref rid="aff1" ref-type="aff">1</xref>
                  <xref rid="aff2" ref-type="aff">2</xref>
                </contrib>
                <contrib id="author-108628798" contrib-type="author">
                  <name>
                    <surname>Tate</surname>
                    <given-names>Samuel</given-names>
                  </name>
                  <xref rid="aff3" ref-type="aff">3</xref>
                </contrib>
                <contrib id="author-108628799" contrib-type="author">
                  <name>
                    <surname>Zafonte</surname>
                    <given-names>Ross</given-names>
                  </name>
                  <xref rid="aff4" ref-type="aff">4</xref>
                </contrib>
                <contrib id="author-108628800" contrib-type="author">
                  <name>
                    <surname>Narayanan</surname>
                    <given-names>Shrikanth</given-names>
                  </name>
                  <xref rid="aff5" ref-type="aff">5</xref>
                </contrib>
                <contrib id="author-89154175" contrib-type="author">
                  <name>
                    <surname>Mehl</surname>
                    <given-names>Matthias R</given-names>
                  </name>
                  <xref rid="aff6" ref-type="aff">6</xref>
                </contrib>
                <contrib id="author-108628801" contrib-type="author">
                  <name>
                    <surname>Shin</surname>
                    <given-names>Min</given-names>
                  </name>
                  <xref rid="aff3" ref-type="aff">3</xref>
                </contrib>
                <contrib id="author-108628765" contrib-type="author" corresp="yes">
                  <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-6470-7548</contrib-id>
                  <name>
                    <surname>Dhand</surname>
                    <given-names>Amar</given-names>
                  </name>
                  <xref rid="aff1" ref-type="aff">1</xref>
                  <xref rid="aff2" ref-type="aff">2</xref>
                </contrib>
              </contrib-group>
              <aff id="aff1"><label>1</label><institution content-type="department">Department of Neurology</institution>, <institution specific-use="Ringgold_1861">Brigham and Women's Hospital</institution>, <addr-line content-type="city">Boston</addr-line>, <addr-line content-type="state">Massachusetts</addr-line>, <country>USA</country></aff>
              <aff id="aff2"><label>2</label><institution specific-use="Ringgold_1811">Harvard Medical School</institution>, <addr-line content-type="city">Boston</addr-line>, <addr-line content-type="state">Massachusetts</addr-line>, <country>USA</country></aff>
              <aff id="aff3"><label>3</label><institution content-type="department">Department of Computer Science</institution>, <institution specific-use="Ringgold_14727">The University of North Carolina at Charlotte</institution>, <addr-line content-type="city">Charlotte</addr-line>, <addr-line content-type="state">North Carolina</addr-line>, <country>USA</country></aff>
              <aff id="aff4"><label>4</label><institution content-type="department">Department of Physical Medicine and Rehabilitation</institution>, <institution specific-use="Ringgold_24498">Spaulding Rehabilitation Hospital Boston</institution>, <addr-line content-type="city">Boston</addr-line>, <addr-line content-type="state">Massachusetts</addr-line>, <country>USA</country></aff>
              <aff id="aff5"><label>5</label><institution content-type="department">Department of Engineering</institution>, <institution specific-use="Ringgold_5116">University of Southern California</institution>, <addr-line content-type="city">Los Angeles</addr-line>, <addr-line content-type="state">California</addr-line>, <country>USA</country></aff>
              <aff id="aff6"><label>6</label><institution content-type="department">Department of Psychology</institution>, <institution>University of Arizona</institution>, <addr-line content-type="city">Tucson</addr-line>, <addr-line content-type="state">Arizona</addr-line>, <country>USA</country></aff>
              <author-notes>
                <corresp><label>Correspondence to</label> Dr Amar Dhand; <email>adhand@bwh.harvard.edu</email></corresp>
              </author-notes>
              <pub-date pub-type="collection">
                <year>2023</year>
              </pub-date>
              <pub-date pub-type="epub">
                <day>28</day>
                <month>8</month>
                <year>2023</year>
              </pub-date>
              <volume>13</volume>
              <issue>8</issue>
              <elocation-id>e076297</elocation-id>
              <history>
                <date date-type="received">
                  <day>02</day>
                  <month>6</month>
                  <year>2023</year>
                </date>
                <date date-type="accepted">
                  <day>08</day>
                  <month>8</month>
                  <year>2023</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>© Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.</copyright-statement>
                <copyright-year>2023</copyright-year>
                <ali:free_to_read/>
                <license>
                  <ali:license_ref specific-use="textmining" content-type="ccbynclicense" start_date="2023-08-28">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
                  <license-p>This is an open access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited, appropriate credit is given, any changes made indicated, and the use is non-commercial. See: <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>.</license-p>
                </license>
              </permissions>
              <self-uri xlink:title="pdf" xlink:href="bmjopen-2023-076297.pdf"/>
              <self-uri content-type="reviewers-comments-pdf" xlink:href="bmjopen-2023-076297.reviewer_comments.pdf"/>
              <self-uri content-type="draft-revisions-pdf" xlink:href="bmjopen-2023-076297.draft_revisions.pdf"/>
              <abstract>
                <sec>
                  <title>Introduction</title>
                  <p>Social isolation has been found to be a significant risk factor for health outcomes, on par with traditional risk factors. This isolation is characterised by reduced social interactions, which can be detected acoustically. To accomplish this, we created a machine learning algorithm called SocialBit. SocialBit runs on a smartwatch and detects minutes of social interaction based on vocal features from ambient audio samples without natural language processing.</p>
                </sec>
                <sec>
                  <title>Methods and analysis</title>
                  <p>In this study, we aim to validate the accuracy of SocialBit in stroke survivors with varying speech, cognitive and physical deficits. Training and testing on persons with diverse neurological abilities allows SocialBit to be a universally accessible social sensor. We are recruiting 200 patients and following them for up to 8 days during hospitalisation and rehabilitation, while they wear a SocialBit-equipped smartwatch and engage in naturalistic daily interactions. Human observers tally the interactions via a video livestream (ground truth) to analyse the performance of SocialBit against it. We also examine the association of social interaction time with stroke characteristics and outcomes. If successful, SocialBit would be the first social sensor available on commercial devices for persons with diverse abilities.</p>
                </sec>
                <sec>
                  <title>Ethics and dissemination</title>
                  <p>This study has received ethical approval from the Institutional Review Board of Mass General Brigham (Protocol #2020P003739). The results of this study will be published in a peer-reviewed journal.</p>
                </sec>
              </abstract>
              <kwd-group>
                <kwd>stroke</kwd>
                <kwd>social interaction</kwd>
                <kwd>quality of life</kwd>
              </kwd-group>
              <funding-group specific-use="FundRef">
                <award-group id="funding-1">
                  <funding-source>
                    <institution-wrap>
                      <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id>
                      <institution>National Institutes of Health</institution>
                    </institution-wrap>
                  </funding-source>
                  <award-id>R01HD099176</award-id>
                </award-group>
              </funding-group>
              <custom-meta-group>
                <custom-meta>
                  <meta-name>special-feature</meta-name>
                  <meta-value>unlocked</meta-value>
                </custom-meta>
              </custom-meta-group>
            </article-meta>
          </front>
          <body>
            <boxed-text id="BX1" position="float">
              <caption>
                <title>STRENGTHS AND LIMITATIONS OF THIS STUDY</title>
              </caption>
              <list list-type="bullet">
                <list-item>
                  <p>This study introduces a novel machine learning algorithm to detect and quantify social isolation.</p>
                </list-item>
                <list-item>
                  <p>The SocialBit wearable sensor accommodates individuals with diverse neurological abilities, promoting inclusivity in social monitoring technologies.</p>
                </list-item>
                <list-item>
                  <p>By detecting isolation in real time, this study allows for future interventions to minimise the negative effects of isolation on health outcomes.</p>
                </list-item>
                <list-item>
                  <p>Although this study is conducted in a hospital environment, future studies could validate the algorithm in a more naturalistic home setting.</p>
                </list-item>
                <list-item>
                  <p>To maintain patient privacy, the SocialBit algorithm does not record raw audio, which poses challenges to the machine learning process.</p>
                </list-item>
              </list>
            </boxed-text>
            <sec sec-type="intro" id="s1">
              <title>Introduction</title>
              <p>Social connection has a large role in health outcomes.<xref rid="R1" ref-type="bibr">1</xref> This effect is independent of socioeconomic status, smoking, alcohol consumption, obesity, physical activity and utilisation of preventive health services.<xref rid="R2" ref-type="bibr">2</xref> Three decades ago, a meta-analysis concluded that social isolation was a major risk factor for health, and rivalled the effect of cigarette smoking, blood pressure, blood lipids, obesity and physical activity.<xref rid="R3" ref-type="bibr">3</xref> More recently, a meta-analysis of 148 studies showed that persons with stronger social relationships had a 50% increased likelihood of survival, an OR higher than the effect of smoking, alcohol consumption and body mass index on health.<xref rid="R4" ref-type="bibr">4</xref></p>
              <p>This study is developing and validating a novel social interaction detection framework and an algorithmic implementation, SocialBit. SocialBit is a smartwatch-based mobile sensing application intended to passively and automatically track the amount of daily interactions of the primary person wearing the device. The application tracks social interactions by sampling ambient audio. Importantly, the application never stores the raw audio but rather stores a series of audio features to serve as input for classification by the SocialBit algorithm. Study investigators collect data from inpatient stroke survivors at Brigham and Women’s Hospital and Spaulding Rehabilitation Hospital in Boston, Massachusetts, capitalising on the ability to monitor patients’ social interactions in real time for multiple days.</p>
              <p>SocialBit is the first wearable social interaction detection sensor customised for, and specifically validated with, stroke survivors. After stroke, patients are vulnerable to reduced social interactions and social isolation, which may have negative implications on their physical recovery.<xref rid="R5" ref-type="bibr">5–7</xref> This is due to multiple factors, including changing social desires, language dysfunction, loss of shared activities, reduced energy levels, physical disability, depression, anxiety, motor impairment, environmental barriers, embarrassment and social stigma.<xref rid="R8" ref-type="bibr">8 9</xref> The period immediately after stroke may be considered a particularly vulnerable time for social isolation because of the inability of family or friends to travel to the hospital, a belief that the patient needs to ‘heal’, and the initial severity of deficits that limit time away from home.<xref rid="R10" ref-type="bibr">10</xref></p>
              <p>It is specifically challenging to detect social interactions in patients with stroke who have cognitive or language deficits (aphasia). Usual methods of social isolation or social network characterisation rely on retrospective surveys or momentary self-report questionnaires.<xref rid="R11" ref-type="bibr">11</xref> Patients with cognitive or language deficits cannot complete these instruments and are typically left out of such studies. Over 35% of patients with stroke have language deficits immediately after stroke,<xref rid="R12" ref-type="bibr">12</xref> and over 50% of patients have cognitive impairment at 6 months after stroke.<xref rid="R13" ref-type="bibr">13</xref> Such deficits make individuals incapable of providing a valid self-report, a limitation to our prior work on social network characterisation.<xref rid="R14" ref-type="bibr">14</xref> The lack of data on patients with aphasia is especially concerning because of this population’s increased likelihood of social isolation after stroke due to multiple challenges with social integration.<xref rid="R6" ref-type="bibr">6</xref> Our goal is to overcome this selection bias by developing a framework to detect interactions regardless of whether the patient is contributing distinguishable words to the conversation, thereby rendering it a viable interaction tracking solution that is universally accessible and inclusive for people with disabilities.</p>
              <p>Previous attempts at measuring social interactions have shown promising results under particular assumptions.<xref rid="R15" ref-type="bibr">15–17</xref> These assumptions, unfortunately, limit the scope of application. For example, one algorithm required mobile apps with access to Global Positioning System (GPS) information as well as the individuals' calendar events to analyse social interactions.<xref rid="R16" ref-type="bibr">16</xref> Another application assumed that each individual wear a sensing device in a bounded environment (e.g., workplace).<xref rid="R15" ref-type="bibr">15</xref> Another team used cameras to sense interactions, increasing privacy concerns.<xref rid="R17" ref-type="bibr">17</xref> Another study used a smartphone-based conversation classifier, which assumes close proximity of smartphone to user.<xref rid="R18" ref-type="bibr">18</xref> Here, we seek a technically parsimonious, privacy-protective and broadly applicable solution to automated social interaction tracking that does not require access to private information (i.e., it does not store raw ambient audio) and only requires the individual in question to be wearing a commercial smartwatch.</p>
              <p>The goal of this study is to establish the validity and utility of this tool in detecting social isolation in stroke survivors in the period after stroke when patients may be observed in the hospital. This allows human observation of social interactions via video-streaming for ground truth determination. There are many implications. Unlike previously tested sensors,<xref rid="R19" ref-type="bibr">19 20</xref> SocialBit requires only the patient to wear the device and not conversation partners. The algorithm maintains privacy of conversation content. SocialBit could run on widely accessible commercial devices. The application can be downloaded onto other WearOS devices, and in the future, it may be possible to download onto other platforms such as the Apple Watch, aligning with the vision of such wearables to become health monitoring tools. Lastly, SocialBit can lead to interventions to improve stroke recovery. With accurate social interaction data, SocialBit can provide real-time feedback and coaching to patients, family and clinicians.</p>
            </sec>
            <sec sec-type="methods" id="s2">
              <title>Methods</title>
              <sec id="s2-1">
                <title>SocialBit algorithm</title>
                <p>The SocialBit algorithm detects social interactions through classifying acoustic features. Specifically, it analyses the temporal change of vocal acoustic behaviour, such as pitch and intensity. It promotes privacy because it does not rely on lexical information or natural language processing (i.e., what words were spoken). Rather, it uses a ‘sound signature’ machine learning method in which features of sound are extracted, analysed and classified as social interaction or not social interaction. The result is quantification of the number of social interaction minutes per day.</p>
                <p>In <xref rid="F1" ref-type="fig">figure 1</xref>, we depict the SocialBit algorithm machine learning approach. First, the algorithm converts the audio data into log mel spectrogram representations and passes them through a pretrained neural network called YAMNet,<xref rid="R21" ref-type="bibr">21</xref> which is capable of classifying over 500 audio events from the public AudioSet data set.<xref rid="R22" ref-type="bibr">22</xref> YAMNet produces feature vectors for each 0.96 s segment of audio, which are then combined and fed through a transformer network<xref rid="R23" ref-type="bibr">23</xref> to determine whether the sequence contains a social interaction. Additionally, SocialBit collects voiceprint features unique to each patient and passes them to ECAPA,<xref rid="R24" ref-type="bibr">24</xref> a neural network that helps identify when the primary device wearer is speaking. The speech sample used are five short sentences from the National Institutes of Health Stroke Scale (NIHSS).<xref rid="R25" ref-type="bibr">25</xref> In summary, YAMNet discriminates general acoustic features of human voices versus other sounds, and ECAPA identifies when the primary device wearer is talking.</p>
                <fig position="float" id="F1">
                  <label>Figure 1</label>
                  <caption>
                    <p>Machine learning algorithm that detects the probability of a social interaction.</p>
                  </caption>
                  <graphic xlink:href="bmjopen-2023-076297f01" position="float"/>
                </fig>
              </sec>
              <sec id="s2-2">
                <title>Study design</title>
                <p>This is a prospective, observational study of 200 patients with stroke. The data collection includes up to eight inpatient observation days per participant, and a 3-month follow-up assessment for study completion. We observe participants at Brigham and Women’s Hospital until they are discharged or for a maximum of 5 days. We collect up to 3 additional days of data if a patient transitions to Spaulding Rehabilitation Hospital Boston. At Brigham and Women’s Hospital, participants usually stay in shared rooms with one roommate. The focus is on acute care with modest inpatient rehabilitation services. At Spaulding Rehabilitation Hospital, Boston, participants stay in private rooms and receive at least 3 hours of intensive therapy (physical therapy, occupational therapy and speech therapy). We enrol caregivers of patients for those who cannot engage in surveys or are otherwise available for auxiliary data. We collect data at two time points: (1) In hospital, when research staff collect survey data and ground truth data, and (2) At the 3-month follow-up clinic appointment, when research staff collect additional survey data. <xref rid="F2" ref-type="fig">Figure 2</xref> shows the timeline of the study. This study was approved by the Institutional Review Board of Mass General Brigham (Protocol #2020P003739).</p>
                <fig position="float" id="F2">
                  <label>Figure 2</label>
                  <caption>
                    <p>Timeline for the SocialBit study spanning 3 months.</p>
                  </caption>
                  <graphic xlink:href="bmjopen-2023-076297f02" position="float"/>
                </fig>
                <p>This project has three primary aims: (1) Establish the accuracy of the SocialBit application for use in research with stroke survivors. (2) Determine the association between social interaction times and social isolation and stroke outcomes at 3 months (e.g., physical function, mood, disability). (3) Examine the influence of medical factors (e.g., depression, delirium and stroke severity) on social interaction time. The central hypothesis is that the SocialBit algorithm accurately detects social interactions of stroke survivors in hospital.</p>
              </sec>
              <sec id="s2-3">
                <title>Recruitment</title>
                <p>One goal of this project is to create social sensing technology universally accessible and inclusive for people with disabilities. Therefore, we focus on people with a range of neurological deficits after stroke as an integral part of the development process. Beginning on 15 June 2021, and continuing to early 2025, we are recruiting patients with acute ischaemic stroke at Brigham and Women’s Hospital in Boston, Massachusetts, USA. This urban setting provides a racially and economically diverse sample population for the study. We aim to recruit patients with a variety of neurological deficits including aphasia, dysarthria, cognitive changes and paralysis.</p>
                <p>The following inclusion criteria apply: (1) Diagnosed with an acute ischaemic stroke defined clinically with support from imaging and (2) 18 years old or older. Exclusion criteria include the following: (1) On Comfort Measures Only (a patient end-of-life care plan that focuses on pain relief and quality of life), (2) Diagnosed with dementia prior to stroke in the medical record, (3) Unable to obtain informed consent from the patient or patient decision maker, and (4) Patient or patient decision maker is unable to understand or speak English well enough to complete surveys.</p>
                <p>We screen patients for eligibility daily via the Brigham and Women’s Hospital inpatient neurology lists on Epic Systems. The research staff then request permission from the nursing staff to approach patients who meet formal inclusion and exclusion criteria for the study. The nurse presents the study to the patient and asks if the patient is willing to discuss the study further with the research team. After acquiring appropriate permission through the nursing staff, research staff approach qualifying patients and/or their family members to further explain the study.</p>
                <p>We obtain signed informed consent from all patients who are consentable, meaning they do not have aphasia or confusion. For the patients who do have aphasia, we collect signed informed consent from caregivers who are willing to participate and answer survey questions on behalf of the patient. Patients who agree to participate complete about 1 hour of surveys with the research staff, including an NIHSS, a Montreal Cognitive Assessment (MoCA), and additional surveys about their social network, their perceived loneliness and depression, their subjective physical function, their life satisfaction, and their personality. We ask patients these same survey questions when they return for their follow-up appointment with the study’s principal investigator, AD, at~90 days. At this visit, the patient completes his/her participation in the study and is compensated for his/her time.</p>
                <p>After the patient completes the initial surveys, we ask the patient to wear a SocialBit-equipped Samsung Galaxy Watch5 Pro from 9:00 to 17:00 until he/she is discharged or for a maximum of 5 days during their inpatient stay at Brigham and Women’s Hospital. Additionally, if the patient is discharged to Spaulding Rehabilitation Hospital in Boston, we collect data in that setting for up to 3 days. On average, we aim to collect 2–3 days (16–24 hours) of data per patient (i.e., around 8 hours of expected monitoring per day, a constraint imposed by both the ground-truth data collection and watch battery considerations).</p>
                <p>To identify the primary speaker, the patient creates a voice profile on the SocialBit application by reading five short sentences from the NIHSS. We ask the patient to read the five sentences aloud for 30 s. For patients who cannot read or speak, no voice profile is created. Following the voice profile, SocialBit runs in the background for passive detection of interactions without any interface with users. If the patient were to take a shower, leave for imaging or perform another task that may interfere with the functioning of the smartwatch, we instruct the patient and/or nursing staff to take the watch off before leaving and put the watch back on upon return.</p>
                <p>Study staff set up an iPad with a Zoom livestream in the patient’s room and put signage in the room to alert other people of the livestream video and provide people with a contact number in case they have any questions or concerns. A Health Insurance Portability and Accountability Act (HIPAA) certified research staff member is on the other side of the livestream manually coding, with a temporal resolution of 1 min, all social interactions that the patient has throughout the day. If there are any moments throughout the day that the patient does not want their conversation to be overheard, we encourage the patient and/or nursing staff to cover up the iPad, signalling to the research team to pause data collection and stop listening.</p>
              </sec>
              <sec id="s2-4">
                <title>Exposure and outcome measurements</title>
                <p>To address the three aims of this study, we collect a variety of measures about patients’ social interactions, social connectedness, stroke severity, physical function and cognitive function. This section outlines all the measures we collect with patients and their caregivers during both the hospitalisation period and the 3-month follow-up appointment.</p>
                <sec id="s2-4-1">
                  <title>Ground truth coding system</title>
                  <p>To accomplish the primary aim of this study, establishing the accuracy of the SocialBit algorithm in detecting social interaction, the SocialBit algorithm and trained research staff independently collect social interaction data. <xref rid="T1" ref-type="table">Table 1</xref> shows the ground truth data coded by research staff, including the questions answered each minute. <xref rid="T2" ref-type="table">Table 2</xref> lists the guidelines for making coding judgements for each question.</p>
                  <table-wrap position="float" id="T1">
                    <label>Table 1</label>
                    <caption>
                      <p>Ground truth data collection recorded every minute from 9:00 to 17:00</p>
                    </caption>
                    <table frame="hsides" rules="groups">
                      <thead>
                        <tr>
                          <td align="left" valign="bottom" rowspan="1" colspan="1">Ground truth table question (per minute)</td>
                          <td align="left" valign="bottom" rowspan="1" colspan="1">Answer (per minute)</td>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">Was the patient talking to another person?</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">
                            <list list-type="bullet">
                              <list-item>
                                <p>Yes</p>
                              </list-item>
                              <list-item>
                                <p>No</p>
                              </list-item>
                            </list>
                          </td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">Who was the patient talking with?</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">
                            <list list-type="bullet">
                              <list-item>
                                <p>Medical personnel</p>
                              </list-item>
                              <list-item>
                                <p>Caregiver</p>
                              </list-item>
                              <list-item>
                                <p>Other family and friends, adult or child</p>
                              </list-item>
                              <list-item>
                                <p>Patient in other bed</p>
                              </list-item>
                              <list-item>
                                <p>Stranger/other</p>
                              </list-item>
                              <list-item>
                                <p>Can’t tell</p>
                              </list-item>
                            </list>
                          </td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">How was the patient talking with the person(s)?</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">
                            <list list-type="bullet">
                              <list-item>
                                <p>In person</p>
                              </list-item>
                              <list-item>
                                <p>Phone call</p>
                              </list-item>
                              <list-item>
                                <p>Videoconference/chat</p>
                              </list-item>
                            </list>
                          </td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">How many people was the patient talking with? (i.e., actively in conversation)</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">
                            <list list-type="bullet">
                              <list-item>
                                <p>1</p>
                              </list-item>
                              <list-item>
                                <p>2</p>
                              </list-item>
                              <list-item>
                                <p>3 or more</p>
                              </list-item>
                            </list>
                          </td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">Does the conversation contain foreign language?</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">
                            <list list-type="bullet">
                              <list-item>
                                <p>Yes</p>
                              </list-item>
                              <list-item>
                                <p>No</p>
                              </list-item>
                            </list>
                          </td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">What was the tone of the interaction? (−2=negative, 0=neutral, 2=positive)</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">
                            <list list-type="bullet">
                              <list-item>
                                <p>−2</p>
                              </list-item>
                              <list-item>
                                <p>−1</p>
                              </list-item>
                              <list-item>
                                <p>0</p>
                              </list-item>
                              <list-item>
                                <p>1</p>
                              </list-item>
                              <list-item>
                                <p>2</p>
                              </list-item>
                              <list-item>
                                <p>Can’t tell</p>
                              </list-item>
                            </list>
                          </td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">What was the depth of the conversation? (1=superficial to 5=deep)</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">
                            <list list-type="bullet">
                              <list-item>
                                <p>1</p>
                              </list-item>
                              <list-item>
                                <p>2</p>
                              </list-item>
                              <list-item>
                                <p>3</p>
                              </list-item>
                              <list-item>
                                <p>4</p>
                              </list-item>
                              <list-item>
                                <p>5</p>
                              </list-item>
                              <list-item>
                                <p>Can’t tell</p>
                              </list-item>
                            </list>
                          </td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">Was the TV on? (TV includes computer or other devices playing entertainment in a way that is audible in the room)</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">
                            <list list-type="bullet">
                              <list-item>
                                <p>Yes</p>
                              </list-item>
                              <list-item>
                                <p>No</p>
                              </list-item>
                            </list>
                          </td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">Was there a conversation happening that the patient was not part of?</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">
                            <list list-type="bullet">
                              <list-item>
                                <p>Yes</p>
                              </list-item>
                              <list-item>
                                <p>No</p>
                              </list-item>
                            </list>
                          </td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">Was the patient completely silent during this minute? (did not contribute any words or sounds)</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">
                            <list list-type="bullet">
                              <list-item>
                                <p>Yes</p>
                              </list-item>
                              <list-item>
                                <p>No</p>
                              </list-item>
                            </list>
                          </td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">Anything else that was noteworthy? (i.e., was the patient talking with you, the observer)</td>
                          <td align="left" valign="top" rowspan="1" colspan="1"> </td>
                        </tr>
                      </tbody>
                    </table>
                  </table-wrap>
                  <table-wrap position="float" id="T2">
                    <label>Table 2</label>
                    <caption>
                      <p>Guidelines for making coding judgements for each question of the ground truth table</p>
                    </caption>
                    <table frame="hsides" rules="groups">
                      <thead>
                        <tr>
                          <td align="left" valign="bottom" rowspan="1" colspan="1">Question</td>
                          <td align="left" valign="bottom" rowspan="1" colspan="1">Approach</td>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">Was the patient talking with another person?</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">If any social interaction occurs with the patient, even for a couple of seconds, during this 1 min timeframe, the research staff select ‘Yes’. All utterances spoken by or to a patient imply that a social interaction is occurring with the patient, meaning that even patients with aphasia who are limited to fragmented speech or grunts are included as having talked with another person for this question. If no words or sounds are exchanged between the patient and another person, research staff select ‘No’.</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">Who was the patient talking with?</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">The research staff categorise the person(s) that the patient is interacting with during each minute. ‘Medical Personnel‘ includes any person involved in delivery of medical care, such as doctors, nurses, phlebotomists, medical assistants and certified nursing assistants. The ‘caregiver’ is a single person, often a spouse, who is usually listed as the patient’s healthcare proxy in his/her chart. ‘Stranger/Other’ includes auxiliary staff, such as research staff, food delivery and housekeeping.</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">How was the patient talking with the person(s)?</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">The research staff choose the mode of communication that occurs for the majority of time during the minute. If multiple modes of communication are being used throughout the minute, research staff note that in the ‘Anything else that was noteworthy?’ section.</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">How many people was the patient talking with?</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">The research staff select the total number of people that are talking with the patient throughout the minute. If the patient is speaking to only one person, staff select ‘1’. If the patient is on the phone with someone and a medical professional speaks to them outside of their phone conversation in the same minute, staff select ‘2’.</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">Does the conversation contain foreign language?</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">The research staff select ‘Yes’ if even one word spoken is foreign. It does not matter if the foreign language is spoken by the patient or someone speaking with the patient. Incomprehensible speech does not count as a foreign language.</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">What was the tone of the interaction?</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">The research staff select one answer from a 5-point scale by making a judgement about the tone of a conversation. Study staff consider the tone, actual speech, and ‘feeling’ of the conversation. The rating is made on a scale from −2 (very negative) to +2 (very positive), with 0 being neutral (−1: somewhat negative; +1: somewhat positive). This is coded even when the participant is minimally involved in the conversation. Most conversations are neutral or mildly positive in tone. ‘Can’t tell’ is coded when the coder is not able to make a tone determination, which may happen when the conversation is too short to be able to tell the tone. The tone coding should reflect the predominant tone during the captured segment. Positive tones include cheerful, upbeat, excited, loving, caring, supportive. Negative tones include tense, irritated, disapproving, sad/depressed, unsupportive, mean, sarcastic, angry and frustrated.</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">What was the depth of the conversation?</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">The research staff select one answer from a 5-point scale by making a judgement about the depth of a conversation. Research staff consider the extent of the thoughts, information, values or ideas being exchanged. The rating is made on a scale from 1 (very superficial) to 5 (very deep), with 3 being a conversation at mid-level depth (2: somewhat superficial; 4: somewhat deep). This is coded even when the participant is minimally involved in the conversation. Many routine interactions are mildly or very superficial (eg, standard greetings). In these interactions, no real information is exchanged; if the conversation had not happened, the involved parties would know the same about each other. Some conversations neither stand out as superficial nor deep (3; ‘midway’). Other conversations are deep with substantial/meaningful information exchange, sharing and disclosure. Few conversations are very deep with personally meaningful information being exchanged. ‘Can’t tell’ is coded when the coder is not able to make a depth determination due to inability to understand conversation. The depth coding should reflect the predominant depth during the captured segment.</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">Was the TV on?</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Regardless of if an interaction occurs within the minute, research staff answer ‘Yes’ if a television is audible. Staff also answer ‘Yes’ to this question if a computer or other device is playing entertainment that is audible in the room.</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">Was there a conversation happening that the patient was not part of?</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">The research staff select ‘Yes’ if they can hear a conversation that the patient is not a part of, such as a conversation between the patient’s roommate and their provider or a hallway conversation among nurses. Staff select ‘Yes’ to this question even if the outside conversation is barely audible.</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">Was the patient completely silent during this minute?</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">If the patient makes no noise and the other person in the interaction is the only one speaking, research staff select ‘Yes’. If the patient says anything or makes any noise during the minute, research staff select ‘No’.</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1">Anything else that was noteworthy?</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">The research staff include anything here that is important for collaborators. For example, staff note if the observation was halted, if there were any unusual noise (eg, medical alarms). Additionally, staff note whether a patient was on speakerphone during a phone call.</td>
                        </tr>
                      </tbody>
                    </table>
                  </table-wrap>
                  <p>To ensure study staff are taking a standardised approach to coding the ground truth table, we provide training to all new study staff. First, current staff teach new study staff how to code the ground truth table and new staff observe the coding process for at least two full days. Then, new study staff watch two 15-minute-long sample videos and complete sample ground truth tables for each scenario. The principal investigator and team created these two sample videos along with a standardised answer key. The new study staff’s ground truth coding should match the key, except for coding ±1 for tone and depth due to the subjectivity of these variables. If new study staff members do not accurately fill out the practice ground truth tables, they must complete further practice and training before coding for an actual patient. Study staff also continually work together to ensure that they are consistently answering the ground truth questions similarly. The study lead coordinator re-trains auxiliary study staff every 6 months.</p>
                </sec>
                <sec id="s2-4-2">
                  <title>Subjective social connectedness</title>
                  <p>To address the second aim of determining the association between social isolation and stroke outcomes, we perform a series of self-report surveys (<xref rid="T3" ref-type="table">table 3</xref>) with the participants (or caregivers) to get their subjective interpretation of their social networks and social connectedness. We use the Personal Network Survey for Clinical Research, developed by Dhand <italic toggle="yes">et al</italic>,<xref rid="R26" ref-type="bibr">26</xref> to assess the social connectedness of patients with stroke. We also administer the 20-item UCLA Loneliness Scale<xref rid="R27" ref-type="bibr">27</xref> and 20-item Center for Epidemiological Studies Depression Scale<xref rid="R28" ref-type="bibr">28</xref> to assess patients’ subjective feelings of loneliness and depression. These surveys are conducted at patient enrolment as well as at their 3-month follow-up visit, to evaluate trends in stroke survivors’ social connectedness during recovery.</p>
                  <table-wrap position="float" id="T3">
                    <label>Table 3</label>
                    <caption>
                      <p>List of all measures collected in the SocialBit Study, including measures for exposures, outcomes and covariates</p>
                    </caption>
                    <table frame="hsides" rules="groups">
                      <thead>
                        <tr>
                          <td align="left" valign="bottom" rowspan="1" colspan="1">Construct</td>
                          <td align="left" valign="bottom" rowspan="1" colspan="1">Measure</td>
                          <td align="left" valign="bottom" rowspan="1" colspan="1">Participant</td>
                          <td align="left" valign="bottom" rowspan="1" colspan="1">T1 at intake</td>
                          <td align="left" valign="bottom" rowspan="1" colspan="1">T2 at 3 months</td>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td align="left" valign="top" colspan="5" rowspan="1">Exposures</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1"><named-content content-type="indent"> </named-content>Social Interaction time—SocialBit</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Interaction detected by SocialBit application</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Patient</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                          <td align="left" valign="top" rowspan="1" colspan="1"/>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1"><named-content content-type="indent"> </named-content>Social interaction time—ground truth coded</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Ground truth data collected by study staff</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Patient</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                          <td align="left" valign="top" rowspan="1" colspan="1"/>
                        </tr>
                        <tr>
                          <td align="left" valign="top" colspan="5" rowspan="1">Outcomes</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1"><named-content content-type="indent"> </named-content>Social isolation (objective)</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Personal Network Survey for Clinical Research (PERSNET)</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Patient and caregiver</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1"><named-content content-type="indent"> </named-content>Social isolation (subjective)</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">UCLA Loneliness Scale</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Patient and caregiver</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1"><named-content content-type="indent"> </named-content>Disability</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Modified Rankin Scale</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Patient and caregiver</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1"><named-content content-type="indent"> </named-content>Physical function (subjective)</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">NIH Patient-Reported Outcome Measurement Information System<break/>(PROMIS), Physical Function</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Patient and caregiver</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1"><named-content content-type="indent"> </named-content>Depression</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Centre for Epidemiological Studies Depression (CES-D)</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Patient and caregiver</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1"><named-content content-type="indent"> </named-content>Life satisfaction</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Satisfaction with Life Scale</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Patient and caregiver</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1"><named-content content-type="indent"> </named-content>Cognition</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Montreal Cognitive Assessment</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Patient</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1"><named-content content-type="indent"> </named-content>Stroke severity</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">National Institutes of Health Stroke Scale (NIHSS)</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Patient</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1"><named-content content-type="indent"> </named-content>Delirium</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Confusion assessment method</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Patient</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1"><named-content content-type="indent"> </named-content>Caregiver burden</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Caregiver Burden Scale</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Caregiver</td>
                          <td align="left" valign="top" rowspan="1" colspan="1"/>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" colspan="5" rowspan="1">Covariates</td>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1"><named-content content-type="indent"> </named-content>Demographics</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Demographics</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Patient and caregiver</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                          <td align="left" valign="top" rowspan="1" colspan="1"/>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1"><named-content content-type="indent"> </named-content>Comorbidities</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Charlson Comorbidity Index</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Patient</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                          <td align="left" valign="top" rowspan="1" colspan="1"/>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1"><named-content content-type="indent"> </named-content>Lesion characteristics</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Medical record, neuroimaging</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Patient</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                          <td align="left" valign="top" rowspan="1" colspan="1"/>
                        </tr>
                        <tr>
                          <td align="left" valign="top" rowspan="1" colspan="1"><named-content content-type="indent"> </named-content>Big Five Personality</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Big Five Inventory-2 XS</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">Patient and caregiver</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                          <td align="left" valign="top" rowspan="1" colspan="1">X</td>
                        </tr>
                      </tbody>
                    </table>
                    <table-wrap-foot>
                      <fn id="T3_FN1">
                        <p>NIH, National Institutes of Health.</p>
                      </fn>
                    </table-wrap-foot>
                  </table-wrap>
                </sec>
                <sec id="s2-4-3">
                  <title>Subjective physical function</title>
                  <p>To understand patients’ stroke outcomes, we use the simplified Modified Rankin Scale<xref rid="R29" ref-type="bibr">29</xref> and National Institutes of Health Patient-Reported Outcome Measurement Information System (PROMIS) Physical Function Surveys through self-report with patients and/or their caregivers (<xref rid="T3" ref-type="table">table 3</xref>). These measures are widely used and consensually accepted measures of functional ability in patients with stroke.<xref rid="R30" ref-type="bibr">30–32</xref> The Modified Rankin Scale is a 6-point disability scale using dichotomous questions<xref rid="R29" ref-type="bibr">29</xref> and the PROMIS Physical Function is a computer adaptive test that selects items from a large PROMIS bank.<xref rid="R33" ref-type="bibr">33</xref> We conduct these surveys at patient enrolment as well as at their 3-month follow-up visit. Data from enrolment is compared with data at the 3-month follow-up to assess the patient’s physical improvements over the 3-month period.</p>
                </sec>
                <sec id="s2-4-4">
                  <title>Stroke severity and cognitive function</title>
                  <p>To address the third aim of determining the impact of medical factors on social interaction time, we assess stroke severity through the broadly used NIHSS<xref rid="R34" ref-type="bibr">34</xref> and cognitive abilities through the reliable and validated MoCA (<xref rid="T3" ref-type="table">table 3</xref>).<xref rid="R35" ref-type="bibr">35 36</xref> The NIHSS is a 15-item scale used to assess the physical and cognitive effects of an acute stroke.<xref rid="R25" ref-type="bibr">25</xref> The MoCA is a short screening tool for cognitive impairment.<xref rid="R35" ref-type="bibr">35</xref> We compare NIHSS and MoCA scores at enrolment and at the 3-month follow-up to determine a patient’s physical and cognitive improvement over the first 3 months of recovery. We also record patient’s delirium from the Confusion Assessment Method,<xref rid="R37" ref-type="bibr">37</xref> an instrument used in a clinical setting to detect delirium, noted in patients’ charts by nursing staff during their inpatient stay.</p>
                </sec>
                <sec id="s2-4-5">
                  <title>Caregiver burden</title>
                  <p>At the 3-month follow-up, we ask caregivers who agree to participate in the study a series of questions regarding the burden they have felt since taking care of their loved one after their stroke. The Caregiver Burden Scale (<xref rid="T3" ref-type="table">table 3</xref>) used in this study is a short-form 6-item scale adopted from the Zarit Burden Interview. Previous studies have validated the reliability and usefulness of the shortened scale in detecting caregiver burden.<xref rid="R38" ref-type="bibr">38 39</xref> These data are useful information to put into perspective how illness and disease have an impact on not only the patient but also their social network.</p>
                </sec>
                <sec id="s2-4-6">
                  <title>Covariates</title>
                  <p>We also collect data on explanatory variables that may impact health outcomes (<xref rid="T3" ref-type="table">table 3</xref>). In this category, we collect sociodemographic information, including age, sex, ethnicity, race, education level, household income, employment status and marital status. We also collect a patient’s personality index by using the validated 15-item Big Five Inventory2 XS Survey.<xref rid="R40" ref-type="bibr">40</xref> Caregivers who agree to participate answer this personality survey twice, once regarding the patient’s personality and once regarding their own personality. This provides the research team with a better understanding of the personality traits of both the patient and their caregiver. We collect information on comorbidities and stroke characteristics, which can impact stroke severity and recovery time, from the patient’s chart.</p>
                </sec>
              </sec>
              <sec id="s2-5">
                <title>Analysis plan</title>
                <p>The analysis focuses on determining the accuracy of the SocialBit algorithm in detecting social interactions between the primary device wearer and others. Second, we determine the correlation between the amount of social interaction and stroke outcomes, as well as the association of medical factors with the amount of social interaction.</p>
                <sec id="s2-5-1">
                  <title>Quantitative data analysis</title>
                  <p>The overall analysis plan is to evaluate accuracy (% of correct classification), specificity, sensitivity, positive predicted value (PPV) and negative predictive value (NPV) of the social interaction times measured by the SocialBit algorithm versus the ground truth. For the machine learning, fivefold cross validation is used with 40 patients per fold. The unit of analysis is social interaction or no social interaction in every 1 min interval for 8 hours a day. If social interaction occurs partially within an interval, then the entire 1 min interval is marked as social interaction. To be consistent with the ground truth, the automated algorithm processes at the 1-min interval as well. However, only 1 min every 5 min or 6 min depending on the battery capacity is analysed by the algorithm. We minimise the overfitting to training data through optimising hyperparameters (eg, regularisation and stop training when the validation set is maximum). To increase the diversity of the training corpus, we add audio extracts of voices with different pitch, tone and volume from public data sets. We also train using examples of TV shows and ambient healthcare setting noise from recordings in empty hospital rooms.</p>
                  <p>We are conducting all regression and longitudinal statistical analyses in R with biostatistical consultation at Harvard Medical School. For the primary outcome, we are assessing baseline characteristics and any differences between patients. We are also performing checks for outlying values. For diagnostic accuracy determination, we are constructing a 2-by-2 table, and then determining overall accuracy, sensitivity, specificity, PPV, NPV and diagnostic OR. For the secondary outcomes, we are using multivariate linear regression to determine the association between social interactions and stroke outcomes and the influence of medical factors on social interaction times. All analyses are accounting for gender and socioeconomic status variables at baseline including education, income and occupation. We aim to include a diverse set of participants including both men and women and a mix of race and ethnicity. We are completing stratified and interaction analyses by these variables to assess whether patterns are seen within and across these categories.</p>
                </sec>
                <sec id="s2-5-2">
                  <title>Power analysis</title>
                  <p>In machine learning projects, high-quality and diverse data with positive and negative examples are needed for successful model building. Therefore, contrary to traditional power analysis, sample size determination is based on iterative performance metrics during training. In our project, we plan for 200 patients × 24 hours × 60 min/hour divided by 6 (to conserve battery life) which is equal to 48 000 samples. The ratio of social interaction to non-social interaction samples is unknown, but even at extreme levels (9 to 1), this results in 4800 samples in a minority class. Based on the literature, this sample size is comparable to gold standard studies such as Audio Set (most classes contain less than 10 000 samples)<xref rid="R22" ref-type="bibr">22</xref> and ImageNet (~1000 average samples per class, ~3000 for the mode).<xref rid="R41" ref-type="bibr">41</xref> Furthermore, deep learning algorithms have achieved good accuracy for each of these data sets. For example, a deep learning algorithm like ours achieved an Area Under the Curve (AUC) level of 0.96 for Audio Set.<xref rid="R42" ref-type="bibr">42</xref> Therefore, our strong preliminary data and literature-based estimates justify our sample size determination. For future use of these data, we also plan to analyse the data set size needed to reach reliable classification. We will compute a learning curve that measures the trade-off between the size of training set and the classification accuracy.<xref rid="R43" ref-type="bibr">43</xref> This would allow evaluation of the feasibility and scalability of the algorithm.</p>
                </sec>
              </sec>
              <sec id="s2-6">
                <title>Data management</title>
                <p>One of the audio features collected through the SocialBit application includes the patient reading a passage. This is considered a voice print, or a visual record of speech, which is Protected Health Information (PHI) as defined by HIPAA.<xref rid="R44" ref-type="bibr">44</xref> We treat such data in the same way as other PHI in terms of privacy and security when collecting and transferring their PHI. In general, all audio features are encrypted and only temporarily stored on the watch. These encrypted audio features are uploaded to Amazon Web Services (AWS), which is a HIPAA-compliant platform. To respect two-party consent laws and to avoid storing PHI from anyone other than the patient, we store only the similarity score (0–1) between the primary device wearer’s voice print and subsequent audio recordings. Only authorised study staff and our collaborators at the University of North Carolina at Charlotte have access to the data on AWS.</p>
                <p>We collect and store ground truth data and survey data in a secure online database, Research Electronic Data Capture (REDCap).<xref rid="R45" ref-type="bibr">45 46</xref> REDCap is a commonly used platform in clinical research with HIPAA-compliant data security. Only authorised study staff access the REDCap database.</p>
              </sec>
              <sec id="s2-7">
                <title>Patient and public involvement</title>
                <p>Patients and the public were not involved in the design of this study. Study participants can request information on the results on study completion.</p>
              </sec>
            </sec>
            <sec sec-type="discussion" id="s3">
              <title>Discussion and expected impact</title>
              <p>SocialBit is a machine learning algorithmic framework designed to detect and quantify social interactions, and as inverse measure, social isolation. The goal of SocialBit is to be an objective, valid and easy-to-interpret metric of social interactions for individuals with diverse abilities. The current study aims to validate the accuracy of SocialBit in detecting social interactions in a sample of stroke survivors with a variety of speech, cognitive and physical impairments. This study takes advantage of the unique opportunity to directly observe patients for multiple days in a hospital setting.</p>
              <p>The implications of this technology are multifold. SocialBit could be a useful tool for social sensing in individuals with diverse abilities, as well as detecting social isolation in vulnerable individuals with high accuracy. The algorithm could be used as a basis for social therapeutics in which social isolation is detected and acted on quickly, leading to improved health outcomes. These ideas connect with trends in the social sensing literature including the importance of social sensing for disease surveillance, health behaviour monitoring and intervention design.<xref rid="R47" ref-type="bibr">47</xref> These measurement possibilities also answer the call for greater understanding of the effects of social isolation and loneliness on public health.<xref rid="R48" ref-type="bibr">48</xref></p>
              <p>There are some limitations to the current study. First, the hospital environment in which the study is conducted is not entirely natural, and interaction frequency, types of persons and types of interactions may differ from what an individual experiences in their day-to-day life. Additionally, the hospital environment is often noisy with monitors and televisions, which may interfere with the algorithm’s ability to detect social interactions. Lastly, due to HIPAA concerns, the algorithm does not store raw audio, missing the ability to understand pitfalls in specific cases.</p>
              <p>In conclusion, the validation of SocialBit in stroke survivors represents an important step forward in the development of an objective, valid and easy-to-interpret metric of social interactions. The ability to detect social isolation with high accuracy and sensitivity could lead to improved health outcomes for vulnerable individuals. Further studies are needed to determine the utility of SocialBit in other populations and settings, and to determine how best to use SocialBit in social therapeutics to improve health outcomes.</p>
              <sec id="s3-1">
                <title>Ethics and dissemination</title>
                <p>We received ethical approval from the Institutional Review Board at Mass General Brigham (Protocol #2020P003739). We obtain written informed consent from patients and their caregivers, and we reimburse patients who complete the study with a $100 cheque for their time. We offer a $50 cheque to patients who do not complete the entire study.</p>
                <p>Once this study is complete, results will be submitted for publication in a peer-reviewed journal and data will be available from the corresponding author on reasonable request.</p>
              </sec>
            </sec>
            <sec sec-type="supplementary-material">
              <title>Supplementary Material</title>
              <supplementary-material content-type="local-data" id="d64e207">
                <caption>
                  <title>Reviewer comments</title>
                </caption>
                <media xlink:href="bmjopen-2023-076297.reviewer_comments.pdf"/>
              </supplementary-material>
              <supplementary-material content-type="local-data" id="d64e208">
                <caption>
                  <title>Author's
manuscript</title>
                </caption>
                <media xlink:href="bmjopen-2023-076297.draft_revisions.pdf"/>
              </supplementary-material>
            </sec>
          </body>
          <back>
            <ack>
              <p>The authors thank all past, current and future participants in the SocialBit Study for their contributions towards creating a metric of social interactions to help detect social isolation.</p>
            </ack>
            <fn-group>
              <fn fn-type="other">
                <p><bold>Contributors:</bold> AD, MRM and MS are responsible for the conceptualisation and design of the study. KW wrote the manuscript. AD, ST, RZ, SN, MRM and MS made substantial contributions to the manuscript. KW, ST, RZ, SN, MRM, MS and AD reviewed and edited the manuscript.</p>
              </fn>
              <fn fn-type="other">
                <p><bold>Funding:</bold> This work is supported by the National Institutes of Health (grant number R01HD099176).</p>
              </fn>
              <fn fn-type="COI-statement">
                <p><bold>Competing interests:</bold> None declared.</p>
              </fn>
              <fn fn-type="other">
                <p><bold>Patient and public involvement:</bold> Patients and/or the public were not involved in the design, or conduct, or reporting, or dissemination plans of this research.</p>
              </fn>
              <fn fn-type="other">
                <p><bold>Provenance and peer review:</bold> Not commissioned; externally peer reviewed.</p>
              </fn>
            </fn-group>
            <sec sec-type="ethics-statement">
              <title>Ethics statements</title>
              <sec>
                <title>Patient consent for publication</title>
                <p content-type="ethics-consent-to-publish">Consent obtained directly from patient(s)</p>
              </sec>
            </sec>
            <ref-list>
              <title>References</title>
              <ref id="R1">
                <label>1</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pantell</surname><given-names>M</given-names></string-name>, <string-name><surname>Rehkopf</surname><given-names>D</given-names></string-name>, <string-name><surname>Jutte</surname><given-names>D</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>Social isolation: a predictor of mortality comparable to traditional clinical risk factors</article-title>. <source>Am J Public Health</source><year>2013</year>;<volume>103</volume>:<fpage>2056</fpage>–<lpage>62</lpage>. <pub-id pub-id-type="doi">10.2105/AJPH.2013.301261</pub-id><pub-id pub-id-type="pmid">24028260</pub-id></mixed-citation>
              </ref>
              <ref id="R2">
                <label>2</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Berkman</surname><given-names>LF</given-names></string-name>, <string-name><surname>Syme</surname><given-names>SL</given-names></string-name></person-group>. <article-title>Social networks, host resistance, and mortality: a nine-year follow-up study of Alameda County residents</article-title>. <source>Am J Epidemiol</source><year>1979</year>;<volume>109</volume>:<fpage>186</fpage>–<lpage>204</lpage>. <pub-id pub-id-type="doi">10.1093/oxfordjournals.aje.a112674</pub-id><pub-id pub-id-type="pmid">425958</pub-id></mixed-citation>
              </ref>
              <ref id="R3">
                <label>3</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>House</surname><given-names>JS</given-names></string-name>, <string-name><surname>Landis</surname><given-names>KR</given-names></string-name>, <string-name><surname>Umberson</surname><given-names>D</given-names></string-name></person-group>. <article-title>Social relationships and health</article-title>. <source>Science</source><year>1988</year>;<volume>241</volume>:<fpage>540</fpage>–<lpage>5</lpage>. <pub-id pub-id-type="doi">10.1126/science.3399889</pub-id><pub-id pub-id-type="pmid">3399889</pub-id></mixed-citation>
              </ref>
              <ref id="R4">
                <label>4</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Holt-Lunstad</surname><given-names>J</given-names></string-name>, <string-name><surname>Smith</surname><given-names>TB</given-names></string-name>, <string-name><surname>Layton</surname><given-names>JB</given-names></string-name></person-group>. <article-title>Social relationships and mortality risk: a meta-analytic review</article-title>. <source>PLOS Med</source><year>2010</year>;<volume>7</volume>:<elocation-id>e1000316</elocation-id>. <pub-id pub-id-type="doi">10.1371/journal.pmed.1000316</pub-id><comment>Available</comment>: <pub-id pub-id-type="doi">10.1371/journal.pmed.1000316</pub-id><pub-id pub-id-type="pmid">20668659</pub-id></mixed-citation>
              </ref>
              <ref id="R5">
                <label>5</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dhand</surname><given-names>A</given-names></string-name>, <string-name><surname>Longstreth</surname><given-names>WT</given-names></string-name>, <string-name><surname>Chaves</surname><given-names>PHM</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>Social network trajectories in myocardial infarction versus ischemic stroke</article-title>. <source>J Am Heart Assoc</source><year>2018</year>;<volume>7</volume>:<elocation-id>e008029</elocation-id>. <pub-id pub-id-type="doi">10.1161/JAHA.117.008029</pub-id><pub-id pub-id-type="pmid">29654192</pub-id></mixed-citation>
              </ref>
              <ref id="R6">
                <label>6</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Northcott</surname><given-names>S</given-names></string-name>, <string-name><surname>Marshall</surname><given-names>J</given-names></string-name>, <string-name><surname>Hilari</surname><given-names>K</given-names></string-name></person-group>. <article-title>What factors predict who will have a strong social network following a stroke</article-title><source>J Speech Lang Hear Res</source><year>2016</year>;<volume>59</volume>:<fpage>772</fpage>–<lpage>83</lpage>. <pub-id pub-id-type="doi">10.1044/2016_JSLHR-L-15-0201</pub-id><pub-id pub-id-type="pmid">27401538</pub-id></mixed-citation>
              </ref>
              <ref id="R7">
                <label>7</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hilari</surname><given-names>K</given-names></string-name>, <string-name><surname>Northcott</surname><given-names>S</given-names></string-name></person-group>. <article-title>Struggling to stay connected”: comparing the social relationships of healthy older people and people with stroke and aphasia</article-title>. <source>Aphasiology</source><year>2017</year>;<volume>31</volume>:<fpage>674</fpage>–<lpage>87</lpage>. <pub-id pub-id-type="doi">10.1080/02687038.2016.1218436</pub-id></mixed-citation>
              </ref>
              <ref id="R8">
                <label>8</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Northcott</surname><given-names>S</given-names></string-name>, <string-name><surname>Hilari</surname><given-names>K</given-names></string-name></person-group>. <article-title>Why do people lose their friends after a stroke</article-title><source>Int J Lang Commun Disord</source><year>2011</year>;<volume>46</volume>:<fpage>524</fpage>–<lpage>34</lpage>. <pub-id pub-id-type="doi">10.1111/j.1460-6984.2011.00079.x</pub-id><pub-id pub-id-type="pmid">21899670</pub-id></mixed-citation>
              </ref>
              <ref id="R9">
                <label>9</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Northcott</surname><given-names>S</given-names></string-name>, <string-name><surname>Hirani</surname><given-names>SP</given-names></string-name>, <string-name><surname>Hilari</surname><given-names>K</given-names></string-name></person-group>. <article-title>A typology to explain changing social networks post stroke</article-title>. <source>Gerontologist</source><year>2018</year>;<volume>58</volume>:<fpage>500</fpage>–<lpage>11</lpage>. <pub-id pub-id-type="doi">10.1093/geront/gnx011</pub-id><pub-id pub-id-type="pmid">28329823</pub-id></mixed-citation>
              </ref>
              <ref id="R10">
                <label>10</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Longman</surname><given-names>J</given-names></string-name>, <string-name><surname>Passey</surname><given-names>M</given-names></string-name>, <string-name><surname>Singer</surname><given-names>J</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>The role of social isolation in frequent and/or avoidable hospitalisation: rural community-based service providers' perspectives</article-title>. <source>Aust Health Rev</source><year>2013</year>;<volume>37</volume>:<fpage>223</fpage>–<lpage>31</lpage>. <pub-id pub-id-type="doi">10.1071/AH12152</pub-id><pub-id pub-id-type="pmid">23490000</pub-id></mixed-citation>
              </ref>
              <ref id="R11">
                <label>11</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Reis</surname><given-names>HT</given-names></string-name>, <string-name><surname>Wheeler</surname><given-names>L</given-names></string-name></person-group>. <article-title>Studying social interaction with the Rochester interaction record</article-title>. <source>Adv Exp Soc Psychol</source><year>1991</year>;<volume>24</volume>:<fpage>269</fpage>–<lpage>318</lpage>.</mixed-citation>
              </ref>
              <ref id="R12">
                <label>12</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Berthier</surname><given-names>ML</given-names></string-name></person-group>. <article-title>Poststroke Aphasia epidemiology, pathophysiology and treatment</article-title>. <source>Drugs Aging</source><year>2005</year>;<volume>22</volume>:<fpage>163</fpage>–<lpage>82</lpage>. <pub-id pub-id-type="doi">10.2165/00002512-200522020-00006</pub-id><pub-id pub-id-type="pmid">15733022</pub-id></mixed-citation>
              </ref>
              <ref id="R13">
                <label>13</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mellon</surname><given-names>L</given-names></string-name>, <string-name><surname>Brewer</surname><given-names>L</given-names></string-name>, <string-name><surname>Hall</surname><given-names>P</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>Cognitive impairment six months after ischaemic stroke: a profile from the ASPIRE-S study</article-title>. <source>BMC Neurol</source><year>2015</year>;<volume>15</volume>:<elocation-id>31</elocation-id>. <pub-id pub-id-type="doi">10.1186/s12883-015-0288-2</pub-id><pub-id pub-id-type="pmid">25879880</pub-id></mixed-citation>
              </ref>
              <ref id="R14">
                <label>14</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dhand</surname><given-names>A</given-names></string-name>, <string-name><surname>Luke</surname><given-names>D</given-names></string-name>, <string-name><surname>Lang</surname><given-names>C</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>Social networks and risk of delayed hospital arrival after acute stroke</article-title>. <source>Nat Commun</source><year>2019</year>;<volume>10</volume>:<elocation-id>1206</elocation-id>. <pub-id pub-id-type="doi">10.1038/s41467-019-09073-5</pub-id><pub-id pub-id-type="pmid">30872570</pub-id></mixed-citation>
              </ref>
              <ref id="R15">
                <label>15</label>
                <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Choudhury</surname><given-names>T</given-names></string-name>, <string-name><surname>Pentland</surname><given-names>A</given-names></string-name></person-group>. <article-title>Sensing and modeling human networks using the sociometer</article-title>. <conf-name>Seventh IEEE International Symposium on Wearable Computers, 2003</conf-name>; :<fpage>216</fpage>–<lpage>22</lpage><conf-loc>White Plains, NY, USA</conf-loc>. <pub-id pub-id-type="doi">10.1109/ISWC.2003.1241414</pub-id></mixed-citation>
              </ref>
              <ref id="R16">
                <label>16</label>
                <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Q</given-names></string-name>, <string-name><surname>Chen</surname><given-names>S</given-names></string-name>, <string-name><surname>Stankovic</surname><given-names>JA</given-names></string-name></person-group>. <article-title>Multi-modal in-person interaction monitoring using smartphone and on-body sensors</article-title></mixed-citation>
              </ref>
              <ref id="R17">
                <label>17</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>D</given-names></string-name>, <string-name><surname>Yang</surname><given-names>J</given-names></string-name>, <string-name><surname>Malkin</surname><given-names>R</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>Detecting social interactions of the elderly in a nursing home environment</article-title>. <source>ACM Trans Multimedia Comput Commun Appl</source><year>2007</year>;<volume>3</volume>:<fpage>6</fpage>. <pub-id pub-id-type="doi">10.1145/1198302.1198308</pub-id></mixed-citation>
              </ref>
              <ref id="R18">
                <label>18</label>
                <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>R</given-names></string-name>, <string-name><surname>Chen</surname><given-names>F</given-names></string-name>, <string-name><surname>Chen</surname><given-names>Z</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>Studentlife: assessing mental health, academic performance and behavioral trends of college students using smartphones. in: proceedings of the 2014 ACM international joint conference on pervasive and Ubiqitous computing (Ubicomp ’14)</article-title>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Association for Computing Machinery</publisher-name>, <month>September</month><day>13</day>, <year>2014</year>:<fpage>3</fpage>–<lpage>14</lpage>
<pub-id pub-id-type="doi">10.1145/2632048.2632054</pub-id></mixed-citation>
              </ref>
              <ref id="R19">
                <label>19</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dhand</surname><given-names>A</given-names></string-name>, <string-name><surname>Dalton</surname><given-names>AE</given-names></string-name>, <string-name><surname>Luke</surname><given-names>DA</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>Accuracy of wearable cameras to track social interactions in stroke survivors</article-title>. <source>J Stroke Cerebrovasc Dis</source><year>2016</year>;<volume>25</volume>:<fpage>2907</fpage>–<lpage>10</lpage>. <pub-id pub-id-type="doi">10.1016/j.jstrokecerebrovasdis.2016.08.004</pub-id><pub-id pub-id-type="pmid">27622865</pub-id></mixed-citation>
              </ref>
              <ref id="R20">
                <label>20</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Onnela</surname><given-names>J-P</given-names></string-name>, <string-name><surname>Waber</surname><given-names>BN</given-names></string-name>, <string-name><surname>Pentland</surname><given-names>A</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>Using sociometers to quantify social interaction patterns</article-title>. <source>Sci Rep</source><year>2014</year>;<volume>4</volume>:<fpage>6278</fpage>. <pub-id pub-id-type="doi">10.1038/srep06278</pub-id></mixed-citation>
              </ref>
              <ref id="R21">
                <label>21</label>
                <mixed-citation publication-type="webpage"><person-group person-group-type="author"><string-name><surname>Plakal</surname><given-names>M</given-names></string-name>, <string-name><surname>Ellis</surname><given-names>D</given-names></string-name></person-group>. <source>Yamnet</source>. <year>2020</year>. <comment>Available</comment>: <uri xlink:href="https://github.com/tensorflow/models/tree/master/research/audioset/yamnet">https://github.com/tensorflow/models/tree/master/research/audioset/yamnet</uri></mixed-citation>
              </ref>
              <ref id="R22">
                <label>22</label>
                <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Gemmeke</surname><given-names>JF</given-names></string-name>, <string-name><surname>Ellis</surname><given-names>DPW</given-names></string-name>, <string-name><surname>Freedman</surname><given-names>D</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>Audio set: an ontology and human-labeled dataset for Audio events</article-title>. <conf-name>2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</conf-name>; <publisher-loc>New Orleans, LA</publisher-loc>, <conf-loc>New Orleans, LA</conf-loc>. <pub-id pub-id-type="doi">10.1109/ICASSP.2017.7952261</pub-id></mixed-citation>
              </ref>
              <ref id="R23">
                <label>23</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vaswani</surname><given-names>A</given-names></string-name>, <string-name><surname>Shazeer</surname><given-names>N</given-names></string-name>, <string-name><surname>Parmar</surname><given-names>N</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>Attention is all you need</article-title>. <source>NIPS</source><year>2017</year>.</mixed-citation>
              </ref>
              <ref id="R24">
                <label>24</label>
                <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Dawalatabad</surname><given-names>N</given-names></string-name>, <string-name><surname>Ravanelli</surname><given-names>M</given-names></string-name>, <string-name><surname>Grondin</surname><given-names>F</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>ECAPA-TDNN embeddings for speaker diarization</article-title>. <conf-name>Interspeech 2021</conf-name>; <publisher-loc>ISCA</publisher-loc>, :<fpage>3560</fpage>–<lpage>4</lpage>
<pub-id pub-id-type="doi">10.21437/Interspeech.2021-941</pub-id></mixed-citation>
              </ref>
              <ref id="R25">
                <label>25</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ortiz</surname><given-names>GA</given-names></string-name>, <string-name><surname>Sacco</surname><given-names>RL</given-names></string-name></person-group>. <article-title>National Institutes of health stroke scale (NIHSS)</article-title>. <source>Wiley StatsRef: Statistics Reference</source><year>2014</year>. <pub-id pub-id-type="doi">10.1002/9781118445112</pub-id><comment>Available</comment>: <pub-id pub-id-type="doi">10.1002/9781118445112.stat06823</pub-id></mixed-citation>
              </ref>
              <ref id="R26">
                <label>26</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dhand</surname><given-names>A</given-names></string-name>, <string-name><surname>White</surname><given-names>CC</given-names></string-name>, <string-name><surname>Johnson</surname><given-names>C</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>A Scalable online tool for quantitative social network assessment reveals potentially modifiable social environmental risks</article-title>. <source>Nat Commun</source><year>2018</year>;<volume>9</volume>:<elocation-id>3930</elocation-id>. <pub-id pub-id-type="doi">10.1038/s41467-018-06408-6</pub-id><pub-id pub-id-type="pmid">30258103</pub-id></mixed-citation>
              </ref>
              <ref id="R27">
                <label>27</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Russell</surname><given-names>DW</given-names></string-name></person-group>. <article-title>UCLA loneliness scale (version 3): reliability, validity, and factor structure</article-title>. <source>J Pers Assess</source><year>1996</year>;<volume>66</volume>:<fpage>20</fpage>–<lpage>40</lpage>. <pub-id pub-id-type="doi">10.1207/s15327752jpa6601_2</pub-id><pub-id pub-id-type="pmid">8576833</pub-id></mixed-citation>
              </ref>
              <ref id="R28">
                <label>28</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Radloff</surname><given-names>LS</given-names></string-name></person-group>. <article-title>The CES-D scale: a self-report depression scale for research in the general population</article-title>. <source>Appl Psychol Meas</source><year>1977</year>;<volume>1</volume>:<fpage>385</fpage>–<lpage>401</lpage>. <pub-id pub-id-type="doi">10.1177/014662167700100306</pub-id></mixed-citation>
              </ref>
              <ref id="R29">
                <label>29</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bruno</surname><given-names>A</given-names></string-name>, <string-name><surname>Akinwuntan</surname><given-names>AE</given-names></string-name>, <string-name><surname>Lin</surname><given-names>C</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>Simplified modified Rankin scale questionnaire</article-title>. <source>Stroke</source><year>2011</year>;<volume>42</volume>:<fpage>2276</fpage>–<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1161/STROKEAHA.111.613273</pub-id><pub-id pub-id-type="pmid">21680905</pub-id></mixed-citation>
              </ref>
              <ref id="R30">
                <label>30</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Banks</surname><given-names>JL</given-names></string-name>, <string-name><surname>Marotta</surname><given-names>CA</given-names></string-name></person-group>. <article-title>Outcomes validity and reliability of the modified rankin scale: implications for stroke clinical trials</article-title>. <source>Stroke</source><year>2007</year>;<volume>38</volume>:<fpage>1091</fpage>–<lpage>6</lpage>. <pub-id pub-id-type="doi">10.1161/01.STR.0000258355.23810.c6</pub-id><pub-id pub-id-type="pmid">17272767</pub-id></mixed-citation>
              </ref>
              <ref id="R31">
                <label>31</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Katzan</surname><given-names>IL</given-names></string-name>, <string-name><surname>Fan</surname><given-names>Y</given-names></string-name>, <string-name><surname>Uchino</surname><given-names>K</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>The PROMIS physical function scale: a promising scale for use in patients with ischemic stroke</article-title>. <source>Neurology</source><year>2016</year>;<volume>86</volume>:<fpage>1801</fpage>–<lpage>7</lpage>. <pub-id pub-id-type="doi">10.1212/WNL.0000000000002652</pub-id><pub-id pub-id-type="pmid">27164715</pub-id></mixed-citation>
              </ref>
              <ref id="R32">
                <label>32</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van Swieten</surname><given-names>JC</given-names></string-name>, <string-name><surname>Koudstaal</surname><given-names>PJ</given-names></string-name>, <string-name><surname>Visser</surname><given-names>MC</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>Interobserver agreement for the assessment of handicap in stroke patients</article-title>. <source>Stroke</source><year>1988</year>;<volume>19</volume>:<fpage>604</fpage>–<lpage>7</lpage>. <pub-id pub-id-type="doi">10.1161/01.str.19.5.604</pub-id><pub-id pub-id-type="pmid">3363593</pub-id></mixed-citation>
              </ref>
              <ref id="R33">
                <label>33</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cella</surname><given-names>D</given-names></string-name>, <string-name><surname>Riley</surname><given-names>W</given-names></string-name>, <string-name><surname>Stone</surname><given-names>A</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>The patient-reported outcomes measurement information system (PROMIS) developed and tested its first wave of adult self-reported health outcome item banks: 2005-2008</article-title>. <source>J Clin Epidemiol</source><year>2010</year>;<volume>63</volume>:<fpage>1179</fpage>–<lpage>94</lpage>. <pub-id pub-id-type="doi">10.1016/j.jclinepi.2010.04.011</pub-id><pub-id pub-id-type="pmid">20685078</pub-id></mixed-citation>
              </ref>
              <ref id="R34">
                <label>34</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lyden</surname><given-names>P</given-names></string-name></person-group>. <article-title>Using the National Institutes of health stroke scale</article-title>. <source>Stroke</source><year>2017</year>;<volume>48</volume>:<fpage>513</fpage>–<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1161/STROKEAHA.116.015434</pub-id><pub-id pub-id-type="pmid">28077454</pub-id></mixed-citation>
              </ref>
              <ref id="R35">
                <label>35</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nasreddine</surname><given-names>ZS</given-names></string-name>, <string-name><surname>Phillips</surname><given-names>NA</given-names></string-name>, <string-name><surname>Bédirian</surname><given-names>V</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>The Montreal cognitive assessment, Moca: a brief screening tool for mild cognitive impairment</article-title>. <source>J Am Geriatr Soc</source><year>2005</year>;<volume>53</volume>:<fpage>695</fpage>–<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1111/j.1532-5415.2005.53221.x</pub-id><pub-id pub-id-type="pmid">15817019</pub-id></mixed-citation>
              </ref>
              <ref id="R36">
                <label>36</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Julayanont</surname><given-names>P</given-names></string-name>, <string-name><surname>Phillips</surname><given-names>N</given-names></string-name>, <string-name><surname>Chertkow</surname><given-names>H</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>Montreal cognitive assessment (Moca): concept and clinical review</article-title>. <source>Cognitive Screening Instruments: A Practical Approach</source><year>2013</year>:<fpage>111</fpage>–<lpage>51</lpage>. <pub-id pub-id-type="doi">10.1007/978-1-4471-2452-8</pub-id></mixed-citation>
              </ref>
              <ref id="R37">
                <label>37</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Inouye</surname><given-names>SK</given-names></string-name>, <string-name><surname>van Dyck</surname><given-names>CH</given-names></string-name>, <string-name><surname>Alessi</surname><given-names>CA</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>Clarifying confusion: the confusion assessment method. A new method for detection of delirium</article-title>. <source>Ann Intern Med</source><year>1990</year>;<volume>113</volume>:<fpage>941</fpage>–<lpage>8</lpage>. <pub-id pub-id-type="doi">10.7326/0003-4819-113-12-941</pub-id><pub-id pub-id-type="pmid">2240918</pub-id></mixed-citation>
              </ref>
              <ref id="R38">
                <label>38</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Higginson</surname><given-names>IJ</given-names></string-name>, <string-name><surname>Gao</surname><given-names>W</given-names></string-name>, <string-name><surname>Jackson</surname><given-names>D</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>Short-form Zarit Caregiver burden interviews were valid in advanced conditions</article-title>. <source>J Clin Epidemiol</source><year>2010</year>;<volume>63</volume>:<fpage>535</fpage>–<lpage>42</lpage>. <pub-id pub-id-type="doi">10.1016/j.jclinepi.2009.06.014</pub-id><pub-id pub-id-type="pmid">19836205</pub-id></mixed-citation>
              </ref>
              <ref id="R39">
                <label>39</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yu</surname><given-names>J</given-names></string-name>, <string-name><surname>Yap</surname><given-names>P</given-names></string-name>, <string-name><surname>Liew</surname><given-names>TM</given-names></string-name></person-group>. <article-title>The optimal short version of the Zarit burden interview for dementia caregivers: diagnostic utility and externally validated cutoffs</article-title>. <source>Aging Ment Health</source><year>2019</year>;<volume>23</volume>:<fpage>706</fpage>–<lpage>10</lpage>. <pub-id pub-id-type="doi">10.1080/13607863.2018.1450841</pub-id><pub-id pub-id-type="pmid">29553806</pub-id></mixed-citation>
              </ref>
              <ref id="R40">
                <label>40</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Soto</surname><given-names>CJ</given-names></string-name>, <string-name><surname>John</surname><given-names>OP</given-names></string-name></person-group>. <article-title>Short and extra-short forms of the big five Inventory-2: the BFI-2-S and BFI- 2-XS</article-title>. <source>J Res Personal</source><year>2017</year>;<volume>68</volume>:<fpage>69</fpage>–<lpage>81</lpage>. <pub-id pub-id-type="doi">10.1016/j.jrp.2017.02.004</pub-id></mixed-citation>
              </ref>
              <ref id="R41">
                <label>41</label>
                <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Deng</surname><given-names>J</given-names></string-name>, <string-name><surname>Dong</surname><given-names>W</given-names></string-name>, <string-name><surname>Socher</surname><given-names>R</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>Imagenet: a large-scale Hierarchical image database</article-title>. <conf-name>2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops)</conf-name>; <conf-loc>Miami, FL</conf-loc>.<publisher-loc>Miami, Florida</publisher-loc>, <month>June</month><day>20</day>, <year>2009</year><pub-id pub-id-type="doi">10.1109/CVPR.2009.5206848</pub-id></mixed-citation>
              </ref>
              <ref id="R42">
                <label>5</label>
                <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Hershey</surname><given-names>S</given-names></string-name>, <string-name><surname>Chaudhuri</surname><given-names>S</given-names></string-name>, <string-name><surname>Ellis</surname><given-names>DPW</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>CNN architectures for large-scale audio classification</article-title>. <conf-name>2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</conf-name>; <conf-loc>New Orleans, LA</conf-loc>. <pub-id pub-id-type="doi">10.1109/ICASSP.2017.7952132</pub-id></mixed-citation>
              </ref>
              <ref id="R43">
                <label>43</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Figueroa</surname><given-names>RL</given-names></string-name>, <string-name><surname>Zeng-Treitler</surname><given-names>Q</given-names></string-name>, <string-name><surname>Kandula</surname><given-names>S</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>Predicting sample size required for classification performance</article-title>. <source>BMC Med Inform Decis Mak</source><year>2012</year>;<volume>12</volume>:<elocation-id>8</elocation-id>. <pub-id pub-id-type="doi">10.1186/1472-6947-12-8</pub-id><pub-id pub-id-type="pmid">22336388</pub-id></mixed-citation>
              </ref>
              <ref id="R44">
                <label>44</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><collab>United States Department of Health and Human Services</collab></person-group>. <article-title>Standards for privacy of individually identifiable health information. office of the federal register, national archives and records administration</article-title>. <year>2002</year>;<volume>67</volume>:<fpage>53181</fpage>–<lpage>273</lpage>.</mixed-citation>
              </ref>
              <ref id="R45">
                <label>45</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Harris</surname><given-names>PA</given-names></string-name>, <string-name><surname>Taylor</surname><given-names>R</given-names></string-name>, <string-name><surname>Thielke</surname><given-names>R</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>Research electronic data capture (Redcap) – A Metadata-driven methodology and Workflow process for providing Translational research Informatics support</article-title>. <source>J Biomed Inform</source><year>2009</year>;<volume>42</volume>:<fpage>377</fpage>–<lpage>81</lpage>. <pub-id pub-id-type="doi">10.1016/j.jbi.2008.08.010</pub-id><pub-id pub-id-type="pmid">18929686</pub-id></mixed-citation>
              </ref>
              <ref id="R46">
                <label>46</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Harris</surname><given-names>PA</given-names></string-name>, <string-name><surname>Taylor</surname><given-names>R</given-names></string-name>, <string-name><surname>Minor</surname><given-names>BL</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>The Redcap consortium: building an international community of software platform partners</article-title>. <source>J Biomed Inform</source><year>2019</year>;<volume>95</volume>:<elocation-id>S1532-0464(19)30126-1</elocation-id>. <pub-id pub-id-type="doi">10.1016/j.jbi.2019.103208</pub-id></mixed-citation>
              </ref>
              <ref id="R47">
                <label>47</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dhand</surname><given-names>A</given-names></string-name>, <string-name><surname>Podury</surname><given-names>A</given-names></string-name>, <string-name><surname>Choudhry</surname><given-names>N</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>Leveraging social networks for the assessment and management of neurological patients</article-title>. <source>Semin Neurol</source><year>2022</year>;<volume>42</volume>:<fpage>136</fpage>–<lpage>48</lpage>. <pub-id pub-id-type="doi">10.1055/s-0042-1744532</pub-id><pub-id pub-id-type="pmid">35675821</pub-id></mixed-citation>
              </ref>
              <ref id="R48">
                <label>48</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Holt-Lunstad</surname><given-names>J</given-names></string-name>, <string-name><surname>Perissinotto</surname><given-names>C</given-names></string-name></person-group>. <article-title>Social isolation and loneliness as medical issues</article-title>. <source>N Engl J Med</source><year>2023</year>;<volume>388</volume>:<fpage>193</fpage>–<lpage>5</lpage>. <pub-id pub-id-type="doi">10.1056/NEJMp2208029</pub-id><pub-id pub-id-type="pmid">36648080</pub-id></mixed-citation>
              </ref>
            </ref-list>
          </back>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
