<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2024-05-03T03:39:16Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:6695097" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:6695097</identifier>
        <datestamp>2019-08-16</datestamp>
        <setSpec>plosone</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" article-type="research-article">
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
              <journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id>
              <journal-id journal-id-type="publisher-id">plos</journal-id>
              <journal-id journal-id-type="pmc">plosone</journal-id>
              <journal-title-group>
                <journal-title>PLoS ONE</journal-title>
              </journal-title-group>
              <issn pub-type="epub">1932-6203</issn>
              <publisher>
                <publisher-name>Public Library of Science</publisher-name>
                <publisher-loc>San Francisco, CA USA</publisher-loc>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC6695097</article-id>
              <article-id pub-id-type="pmcid">PMC6695097</article-id>
              <article-id pub-id-type="pmc-uid">6695097</article-id>
              <article-id pub-id-type="pmid">31415624</article-id>
              <article-id pub-id-type="doi">10.1371/journal.pone.0220928</article-id>
              <article-id pub-id-type="publisher-id">PONE-D-19-07245</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Research Article</subject>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Social Sciences</subject>
                  <subj-group>
                    <subject>Linguistics</subject>
                    <subj-group>
                      <subject>Speech</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Medicine and Health Sciences</subject>
                  <subj-group>
                    <subject>Mental Health and Psychiatry</subject>
                    <subj-group>
                      <subject>Mood Disorders</subject>
                      <subj-group>
                        <subject>Depression</subject>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Social Sciences</subject>
                  <subj-group>
                    <subject>Linguistics</subject>
                    <subj-group>
                      <subject>Linguistic Morphology</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Social Sciences</subject>
                  <subj-group>
                    <subject>Linguistics</subject>
                    <subj-group>
                      <subject>Grammar</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Social Sciences</subject>
                  <subj-group>
                    <subject>Sociology</subject>
                    <subj-group>
                      <subject>Communications</subject>
                      <subj-group>
                        <subject>Social Communication</subject>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Social Sciences</subject>
                  <subj-group>
                    <subject>Linguistics</subject>
                    <subj-group>
                      <subject>Neurolinguistics</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Biology and Life Sciences</subject>
                  <subj-group>
                    <subject>Neuroscience</subject>
                    <subj-group>
                      <subject>Neurolinguistics</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Engineering and Technology</subject>
                  <subj-group>
                    <subject>Signal Processing</subject>
                    <subj-group>
                      <subject>Speech Signal Processing</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Social Sciences</subject>
                  <subj-group>
                    <subject>Linguistics</subject>
                    <subj-group>
                      <subject>Cognitive Linguistics</subject>
                      <subj-group>
                        <subject>Word Recognition</subject>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>Impact of depression on speech perception in noise</article-title>
                <alt-title alt-title-type="running-head">Depression and speech perception in noise</alt-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author">
                  <contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-6851-7554</contrib-id>
                  <name>
                    <surname>Xie</surname>
                    <given-names>Zilong</given-names>
                  </name>
                  <role content-type="http://credit.casrai.org/">Conceptualization</role>
                  <role content-type="http://credit.casrai.org/">Data curation</role>
                  <role content-type="http://credit.casrai.org/">Formal analysis</role>
                  <role content-type="http://credit.casrai.org/">Investigation</role>
                  <role content-type="http://credit.casrai.org/">Methodology</role>
                  <role content-type="http://credit.casrai.org/">Visualization</role>
                  <role content-type="http://credit.casrai.org/">Writing – original draft</role>
                  <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
                  <xref ref-type="aff" rid="aff001">
                    <sup>1</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Zinszer</surname>
                    <given-names>Benjamin D.</given-names>
                  </name>
                  <role content-type="http://credit.casrai.org/">Formal analysis</role>
                  <role content-type="http://credit.casrai.org/">Methodology</role>
                  <role content-type="http://credit.casrai.org/">Software</role>
                  <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
                  <xref ref-type="aff" rid="aff002">
                    <sup>2</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Riggs</surname>
                    <given-names>Meredith</given-names>
                  </name>
                  <role content-type="http://credit.casrai.org/">Formal analysis</role>
                  <role content-type="http://credit.casrai.org/">Methodology</role>
                  <role content-type="http://credit.casrai.org/">Software</role>
                  <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
                  <xref ref-type="aff" rid="aff003">
                    <sup>3</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Beevers</surname>
                    <given-names>Christopher G.</given-names>
                  </name>
                  <role content-type="http://credit.casrai.org/">Conceptualization</role>
                  <role content-type="http://credit.casrai.org/">Data curation</role>
                  <role content-type="http://credit.casrai.org/">Formal analysis</role>
                  <role content-type="http://credit.casrai.org/">Funding acquisition</role>
                  <role content-type="http://credit.casrai.org/">Methodology</role>
                  <role content-type="http://credit.casrai.org/">Project administration</role>
                  <role content-type="http://credit.casrai.org/">Resources</role>
                  <role content-type="http://credit.casrai.org/">Supervision</role>
                  <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
                  <xref ref-type="aff" rid="aff004">
                    <sup>4</sup>
                  </xref>
                  <xref ref-type="aff" rid="aff005">
                    <sup>5</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Chandrasekaran</surname>
                    <given-names>Bharath</given-names>
                  </name>
                  <role content-type="http://credit.casrai.org/">Conceptualization</role>
                  <role content-type="http://credit.casrai.org/">Data curation</role>
                  <role content-type="http://credit.casrai.org/">Formal analysis</role>
                  <role content-type="http://credit.casrai.org/">Funding acquisition</role>
                  <role content-type="http://credit.casrai.org/">Methodology</role>
                  <role content-type="http://credit.casrai.org/">Resources</role>
                  <role content-type="http://credit.casrai.org/">Software</role>
                  <role content-type="http://credit.casrai.org/">Supervision</role>
                  <role content-type="http://credit.casrai.org/">Writing – original draft</role>
                  <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
                  <xref ref-type="aff" rid="aff006">
                    <sup>6</sup>
                  </xref>
                  <xref ref-type="corresp" rid="cor001">*</xref>
                </contrib>
              </contrib-group>
              <aff id="aff001">
                <label>1</label>
                <addr-line>Department of Hearing and Speech Sciences, University of Maryland, Maryland, United States of America</addr-line>
              </aff>
              <aff id="aff002">
                <label>2</label>
                <addr-line>Department of Linguistics and Cognitive Science, University of Delaware, Newark, Delaware, United States of America</addr-line>
              </aff>
              <aff id="aff003">
                <label>3</label>
                <addr-line>Department of Communication Sciences and Disorders, The University of Texas at Austin, Austin, Texas, United States of America</addr-line>
              </aff>
              <aff id="aff004">
                <label>4</label>
                <addr-line>Department of Psychology, The University of Texas at Austin, Austin, Texas, United States of America</addr-line>
              </aff>
              <aff id="aff005">
                <label>5</label>
                <addr-line>Institute for Mental Health Research, Austin, Texas, United States of America</addr-line>
              </aff>
              <aff id="aff006">
                <label>6</label>
                <addr-line>Department of Communication Science and Disorders, School of Health and Rehabilitation Sciences, University of Pittsburgh, Pittsburgh, Pennsylvania, United States of America</addr-line>
              </aff>
              <contrib-group>
                <contrib contrib-type="editor">
                  <name>
                    <surname>Lindsay</surname>
                    <given-names>Shane</given-names>
                  </name>
                  <role>Editor</role>
                  <xref ref-type="aff" rid="edit1"/>
                </contrib>
              </contrib-group>
              <aff id="edit1">
                <addr-line>University of Hull, UNITED KINGDOM</addr-line>
              </aff>
              <author-notes>
                <fn fn-type="COI-statement" id="coi001">
                  <p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
                </fn>
                <corresp id="cor001">* E-mail: <email>b.chandra@pitt.edu</email></corresp>
              </author-notes>
              <pub-date pub-type="epub">
                <day>15</day>
                <month>8</month>
                <year>2019</year>
              </pub-date>
              <pub-date pub-type="collection">
                <year>2019</year>
              </pub-date>
              <volume>14</volume>
              <issue>8</issue>
              <elocation-id>e0220928</elocation-id>
              <history>
                <date date-type="received">
                  <day>12</day>
                  <month>3</month>
                  <year>2019</year>
                </date>
                <date date-type="accepted">
                  <day>26</day>
                  <month>7</month>
                  <year>2019</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>© 2019 Xie et al</copyright-statement>
                <copyright-year>2019</copyright-year>
                <copyright-holder>Xie et al</copyright-holder>
                <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
                  <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
                </license>
              </permissions>
              <self-uri content-type="pdf" xlink:href="pone.0220928.pdf"/>
              <abstract>
                <p>Effective speech communication is critical to everyday quality of life and social well-being. In addition to the well-studied deficits in cognitive and motor function, depression also impacts communication. Here, we examined speech perception in individuals who were clinically diagnosed with major depressive disorder (MDD) relative to neurotypical controls. Forty-two normal-hearing (NH) individuals with MDD and 41 NH neurotypical controls performed sentence recognition tasks across three conditions with maskers varying in the extent of linguistic content (high, low, and none): 1-talker masker (1T), reversed 1-talker masker (1T_tr), and speech-shaped noise (SSN). Individuals with MDD, relative to neurotypical controls, demonstrated lower recognition accuracy in the 1T condition but not in the 1T_tr or SSN condition. To examine the nature of the listening condition-specific speech perception deficit, we analyzed speech recognition errors. Errors as a result of interference from masker sentences were higher for individuals with MDD (vs. neurotypical controls) in the 1T condition. This depression-related listening condition-specific pattern in recognition errors was not observed for other error types. We posit that this depression-related listening condition-specific deficit in speech perception may be related to heightened distractibility due to linguistic interference from background talkers.</p>
              </abstract>
              <funding-group>
                <award-group id="award001">
                  <funding-source>
                    <institution-wrap>
                      <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000026</institution-id>
                      <institution>National Institute on Drug Abuse</institution>
                    </institution-wrap>
                  </funding-source>
                  <award-id>DA032457</award-id>
                  <principal-award-recipient>
                    <name>
                      <surname>Beevers</surname>
                      <given-names>Christopher G.</given-names>
                    </name>
                  </principal-award-recipient>
                </award-group>
                <award-group id="award002">
                  <funding-source>
                    <institution-wrap>
                      <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000055</institution-id>
                      <institution>National Institute on Deafness and Other Communication Disorders</institution>
                    </institution-wrap>
                  </funding-source>
                  <award-id>R01DC013315</award-id>
                  <principal-award-recipient>
                    <name>
                      <surname>Chandrasekaran</surname>
                      <given-names>Bharath</given-names>
                    </name>
                  </principal-award-recipient>
                </award-group>
                <funding-statement>This work was supported by grant DA032457 to CGB from the National Institute on Drug Abuse (<ext-link ext-link-type="uri" xlink:href="https://www.drugabuse.gov/">https://www.drugabuse.gov/</ext-link>) and grant R01DC013315 to BC from National Institute on Deafness and Other Communication Disorders (<ext-link ext-link-type="uri" xlink:href="https://www.nidcd.nih.gov/">https://www.nidcd.nih.gov/</ext-link>). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
              </funding-group>
              <counts>
                <fig-count count="4"/>
                <table-count count="2"/>
                <page-count count="17"/>
              </counts>
              <custom-meta-group>
                <custom-meta id="data-availability">
                  <meta-name>Data Availability</meta-name>
                  <meta-value>All relevant data are within the manuscript.</meta-value>
                </custom-meta>
              </custom-meta-group>
            </article-meta>
            <notes>
              <title>Data Availability</title>
              <p>All relevant data are within the manuscript.</p>
            </notes>
          </front>
          <body>
            <sec sec-type="intro" id="sec001">
              <title>Introduction</title>
              <p>Depression is a leading cause of disability worldwide [<xref rid="pone.0220928.ref001" ref-type="bibr">1</xref>]. It is characterized by impairments in cognitive, psychomotor speed, and speech communicative behaviors [<xref rid="pone.0220928.ref002" ref-type="bibr">2</xref>,<xref rid="pone.0220928.ref003" ref-type="bibr">3</xref>]. To date, however, communicative behaviors remains the least characterized deficits in depression, despite the fact that effective communication is critical to social well-being and communication deficits may exacerbate depressive symptoms [<xref rid="pone.0220928.ref004" ref-type="bibr">4</xref>]. Extant work on speech communication has mainly focused on speech output in individuals with depression [<xref rid="pone.0220928.ref005" ref-type="bibr">5</xref>]. For example, verbal fluency is shown to be reduced in individuals with major depressive disorder (MDD) [<xref rid="pone.0220928.ref003" ref-type="bibr">3</xref>]. Speech rates in individuals with MDD are predictive of depression severity as well as response to treatment [<xref rid="pone.0220928.ref006" ref-type="bibr">6</xref>]. Relative to the rich literature on speech production, much less is known about speech perception in individuals with MDD. Hence, the current study aims to examine the effect of depression on speech perception in conditions that mimic everyday listening environments.</p>
              <p>In typical communication situations, speech perception is often affected by the speech of other unattended talkers (often referred to as a ‘cocktail party’ situation [<xref rid="pone.0220928.ref007" ref-type="bibr">7</xref>]). Speech maskers contain linguistic information that is highly confusable with the target speech [<xref rid="pone.0220928.ref008" ref-type="bibr">8</xref>,<xref rid="pone.0220928.ref009" ref-type="bibr">9</xref>]. For successful speech perception, listeners are required to segregate the target speech from the mixture of acoustic inputs (i.e., object formation [<xref rid="pone.0220928.ref008" ref-type="bibr">8</xref>]); and to exert top-down attention to select the target speech and inhibit the interference from the speech maskers (i.e., object selection [<xref rid="pone.0220928.ref008" ref-type="bibr">8</xref>,<xref rid="pone.0220928.ref009" ref-type="bibr">9</xref>]). In contrast to speech maskers, other sources of noise may contain limited linguistic information (non-speech ‘energetic’ maskers), but can still disrupt speech perception [<xref rid="pone.0220928.ref009" ref-type="bibr">9</xref>–<xref rid="pone.0220928.ref014" ref-type="bibr">14</xref>]. For example, noise from construction sites or airplanes does not contain linguistic maskers but can still impact perception. In the extant literature, the two types of noise interference are distinguished as ‘informational’ masking and ‘energetic’ masking [<xref rid="pone.0220928.ref015" ref-type="bibr">15</xref>,<xref rid="pone.0220928.ref016" ref-type="bibr">16</xref>]. Speech maskers are posited to produce informational masking, in addition to energetic masking, while non-speech maskers produce relatively greater energetic interference. Recent work suggests that, in addition to informational and energetic masking, noise can compromise speech perception due to a third form of masking, i.e., modulation masking [<xref rid="pone.0220928.ref017" ref-type="bibr">17</xref>,<xref rid="pone.0220928.ref018" ref-type="bibr">18</xref>].</p>
              <p>Hearing impairment (HI) and aging are two widely studied factors that can independently impoverish a listener’s ability to understand speech, particularly in the presence of interfering talkers [<xref rid="pone.0220928.ref019" ref-type="bibr">19</xref>–<xref rid="pone.0220928.ref023" ref-type="bibr">23</xref>]. Interestingly, HI is also associated with higher levels of depression [<xref rid="pone.0220928.ref024" ref-type="bibr">24</xref>–<xref rid="pone.0220928.ref027" ref-type="bibr">27</xref>]. For example, Li et al. (2014) reported that the prevalence of developing moderate to severe depression increased by 5.5% for adults with self-reported HI relative to those without HI. Depression is also common in older adults [<xref rid="pone.0220928.ref028" ref-type="bibr">28</xref>–<xref rid="pone.0220928.ref031" ref-type="bibr">31</xref>], and the prevalence of MDD for adults 65 and older ranges from 1% to 5% in large-scale samples from the United States [<xref rid="pone.0220928.ref028" ref-type="bibr">28</xref>]. Hence, the current investigation supports depression as a factor that can affect speech perception in noise (SPIN) independent of HI or aging. This suggests a critical need to separate out the unique mechanisms of SPIN deficits associated with HI, aging, and depression.</p>
              <p>Chandrasekaran et al. (2015) examined the relationship between depression and SPIN in a nonclinical population. They found that normal hearing (NH) young adults with self-reported elevated depressive symptoms show a deficit of speech perception in conditions with speech maskers, but not with non-speech maskers. Hence, the first goal of this study was to replicate the effect of depression on SPIN in a clinical population. Specifically, we compared performance on SPIN in NH adults with a clinical diagnosis of MDD relative to a carefully matched group of neurotypical NH individuals. Prior work suggests a close link between sub-clinical elevated depressive symptoms and MDD, such that individuals with elevated depressive symptoms have a higher probability of developing MDD [<xref rid="pone.0220928.ref032" ref-type="bibr">32</xref>,<xref rid="pone.0220928.ref033" ref-type="bibr">33</xref>]. Considering these findings, we predicted that individuals with MDD would also exhibit a selective speech perception deficit in speech maskers but not in non-speech maskers.</p>
              <p>Additionally, this study examined speech recognition errors from the SPIN data to understand the mechanisms underlying the hypothesized depression-related listening condition-specific (i.e., speech maskers) deficit in speech perception. In the literature related to SPIN, there is always interest in the examination of the errors in speech recognition produced by listeners, though a limited number of studies have actually implemented speech recognition error analyses [<xref rid="pone.0220928.ref034" ref-type="bibr">34</xref>–<xref rid="pone.0220928.ref043" ref-type="bibr">43</xref>]. The analysis of speech recognition errors can provide information not only about whether a listener recognizes words, but also about how the degraded speech signals are perceived and resolved by the listener [<xref rid="pone.0220928.ref034" ref-type="bibr">34</xref>]. Thus, the speech recognition error analysis is potentially useful in revealing the mechanisms underlying a listener’s speech perception performance [<xref rid="pone.0220928.ref043" ref-type="bibr">43</xref>].</p>
              <p>In the current analysis of speech recognition, we first characterized the occurrence rates of whole sentence omission error, which is operationalized as a participant’s response that did not contain any of the content words from the target sentence. For this type of error, we further characterized whether the participant’s response contains content words of a distractor (masker) sentence. If we did not observe the whole sentence omission error, we then characterized the occurrence rates of another two error categories: word-level errors, i.e., substitution, addition, or omission of content words (nouns, verbs, adjectives, adverbs) and function words (closed-class) in the target sentence; and morpheme-level errors for content words in the target sentence (e.g. tense change, pluralization). In a previous study [<xref rid="pone.0220928.ref043" ref-type="bibr">43</xref>], error rates at all three of these levels (whole sentence, word, and morpheme) significantly differed between native- and non-native listeners across a variety of mask types. This finding suggests that linguistic processes can be affected by noise at multiple levels, which may be distinguishable by detailed error analysis.</p>
              <p>Previous studies suggest increased susceptibility to distracting information in individuals with MDD [<xref rid="pone.0220928.ref044" ref-type="bibr">44</xref>–<xref rid="pone.0220928.ref047" ref-type="bibr">47</xref>]. Hence, we predicted that the occurrence rate of errors as a result of interference from the masker sentences would be increased in individuals with MDD (relative to neurotypical controls), particularly in conditions with speech maskers that contain highly distracting linguistic information [<xref rid="pone.0220928.ref008" ref-type="bibr">8</xref>,<xref rid="pone.0220928.ref009" ref-type="bibr">9</xref>].</p>
            </sec>
            <sec sec-type="materials|methods" id="sec002">
              <title>Materials and methods</title>
              <sec id="sec003">
                <title>Participants</title>
                <p>The present experiment is part of a larger project that examined emotion and cognition in major depression. Fifty-two patients with MDD and 51 neurotypical control participants were recruited from the greater Austin community. Three participants in the MDD group were excluded from the analyses because of missing data on the speech in noise task due to a software failure. Inclusion criteria for the individuals with depression were a DSM-V diagnosis of MDD by a trained native English research assistant using the structured Mini-International Neuropsychiatric Interview [<xref rid="pone.0220928.ref048" ref-type="bibr">48</xref>] and a score ≥ 16 on the Center for Epidemiological Studies Depression Scale (CES-D) [<xref rid="pone.0220928.ref049" ref-type="bibr">49</xref>] at the time of study. Note that those individuals with comorbid anxiety were not explicitly excluded from the study. Comorbid anxiety was determined as a DSM-V diagnosis of an anxiety disorder in addition to MDD using the Mini-International Neuropsychiatric Interview [<xref rid="pone.0220928.ref048" ref-type="bibr">48</xref>]. Inclusion criteria for the healthy control participants were no history of MDD and a score &lt; 16 on the CES-D [<xref rid="pone.0220928.ref049" ref-type="bibr">49</xref>] at the time of study. One participant from the MDD group and five participants from the control group were excluded from analysis due to not meeting the CES-D criteria. Additional inclusion criteria for all participants included: age between 18 and 50 years, had normal or corrected vision, and being fluent in English via self-report. The self-reported fluency in English was further confirmed as having no difficulty in completing the screening surveys via phone, by a native English research assistant. One participant from the control group was excluded because of disfluency in English. We did not collect detailed information about language experience and proficiency, e.g., whether a listener is a monolingual or bilingual speaker of English. may confound our results. However, we believe such factor (e.g., bilingualism) may not be a factor influencing our results because the performance under conditions with non-speech maskers is comparable across groups (see <xref ref-type="fig" rid="pone.0220928.g001">Fig 1</xref>). Exclusion criteria for all participants were a current or past DSM-V diagnosis of psychosis, mania, alcohol dependence, alcohol abuse, or substance dependence.</p>
                <fig id="pone.0220928.g001" orientation="portrait" position="float">
                  <object-id pub-id-type="doi">10.1371/journal.pone.0220928.g001</object-id>
                  <label>Fig 1</label>
                  <caption>
                    <p>Raincloud plots (from left to right: jittered raw data for all participants, boxplots, and probability distribution of the data) of proportion of correctly identified keywords for neurotypical controls (black) and participants with MDD (red) across three types of masker: 1T (1-talker masker), 1T_tr (reversed 1-talker masker), and SSN (speech-shaped noise). For the boxplots, the boxes and the horizontal line inside show the quartiles (1st to 3rd quartile) and the median, respectively. The whiskers denote 1.5 times the interquartile range. Outliers, defined as cases with values outside the 1.5 interquartile range, were not displayed in the boxplots. * denote <italic>p</italic> &lt; 0.05.</p>
                  </caption>
                  <graphic xlink:href="pone.0220928.g001"/>
                </fig>
                <p>All participants underwent a hearing screening. Five participants from the MDD group and four participants from the control group were further excluded for failing to meet the hearing thresholds, i.e., ≤ 25 dB hearing level for octave frequencies from 250 and 4,000 Hz for each ear. One participant from the MDD group was excluded because of incomplete data on the hearing screening.</p>
                <p>The final sample for analysis consisted of 42 MDD participants and 41 control participants. <xref rid="pone.0220928.t001" ref-type="table">Table 1</xref> displays their demographics. As shown in <xref rid="pone.0220928.t001" ref-type="table">Table 1</xref>, the MDD participants were matched as closely as possible with the control participants for age, and the ratios of sex, race, and ethnicity. All participants gave written informed consent and received monetary compensation under a protocol approved by the Institutional Review Board at the University of Texas at Austin.</p>
                <table-wrap id="pone.0220928.t001" orientation="portrait" position="float">
                  <object-id pub-id-type="doi">10.1371/journal.pone.0220928.t001</object-id>
                  <label>Table 1</label>
                  <caption>
                    <title>Demographics of the samples for analyses.</title>
                  </caption>
                  <alternatives>
                    <graphic id="pone.0220928.t001g" xlink:href="pone.0220928.t001"/>
                    <table frame="hsides" rules="groups">
                      <colgroup span="1">
                        <col align="left" valign="middle" span="1"/>
                        <col align="left" valign="middle" span="1"/>
                        <col align="left" valign="middle" span="1"/>
                        <col align="left" valign="middle" span="1"/>
                      </colgroup>
                      <thead>
                        <tr>
                          <th align="center" rowspan="1" colspan="1"/>
                          <th align="center" rowspan="1" colspan="1">MDD</th>
                          <th align="center" rowspan="1" colspan="1">Control</th>
                          <th align="center" rowspan="1" colspan="1">
                            <italic>p</italic>
                          </th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">N</td>
                          <td align="center" rowspan="1" colspan="1">42</td>
                          <td align="center" rowspan="1" colspan="1">41</td>
                          <td align="center" rowspan="1" colspan="1">-</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">Age (M, SD, min/max)</td>
                          <td align="center" rowspan="1" colspan="1">23.76, 5.84, 18/46</td>
                          <td align="center" rowspan="1" colspan="1">24.73, 7.51, 18/49</td>
                          <td align="center" rowspan="1" colspan="1">.513<xref ref-type="table-fn" rid="t001fn003"><sup>c</sup></xref></td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">Sex (female/male/other)</td>
                          <td align="center" rowspan="1" colspan="1">33/7/2</td>
                          <td align="center" rowspan="1" colspan="1">29/12/0</td>
                          <td align="center" rowspan="1" colspan="1">.179<xref ref-type="table-fn" rid="t001fn004"><sup>d</sup></xref></td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">Race (Caucasian/other/unspecified)</td>
                          <td align="center" rowspan="1" colspan="1">19/23/0</td>
                          <td align="center" rowspan="1" colspan="1">21/19/1</td>
                          <td align="center" rowspan="1" colspan="1">.582<xref ref-type="table-fn" rid="t001fn004"><sup>d</sup></xref></td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">Ethnicity (Hispanic/Non-Hispanic/unspecified)</td>
                          <td align="center" rowspan="1" colspan="1">10/31/1</td>
                          <td align="center" rowspan="1" colspan="1">6/34/1</td>
                          <td align="center" rowspan="1" colspan="1">.698<xref ref-type="table-fn" rid="t001fn004"><sup>d</sup></xref></td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">Age onset for 1<sup>st</sup> depressive episode (M, SD, min/max)</td>
                          <td align="center" rowspan="1" colspan="1">16.8, 4.78, 11/29<xref ref-type="table-fn" rid="t001fn001"><sup>a</sup></xref></td>
                          <td align="center" rowspan="1" colspan="1">NA</td>
                          <td align="center" rowspan="1" colspan="1">-</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">Number of depressive episode (single /recurrent/unspecified)</td>
                          <td align="center" rowspan="1" colspan="1">9/28/5</td>
                          <td align="center" rowspan="1" colspan="1">NA</td>
                          <td align="center" rowspan="1" colspan="1">-</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">Currently taking medication</td>
                          <td align="center" rowspan="1" colspan="1">7</td>
                          <td align="center" rowspan="1" colspan="1">0</td>
                          <td align="center" rowspan="1" colspan="1">-</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">Currently in therapy or counseling</td>
                          <td align="center" rowspan="1" colspan="1">10</td>
                          <td align="center" rowspan="1" colspan="1">0<xref ref-type="table-fn" rid="t001fn002"><sup>b</sup></xref></td>
                          <td align="center" rowspan="1" colspan="1">-</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">Comorbid anxiety</td>
                          <td align="center" rowspan="1" colspan="1">11</td>
                          <td align="center" rowspan="1" colspan="1">NA</td>
                          <td align="center" rowspan="1" colspan="1">-</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">CES-D at the day of study (M, SD, min/max)</td>
                          <td align="center" rowspan="1" colspan="1">36.67, 8.04, 19/57</td>
                          <td align="center" rowspan="1" colspan="1">4.2, 3.64, 0/14</td>
                          <td align="center" rowspan="1" colspan="1">-</td>
                        </tr>
                      </tbody>
                    </table>
                  </alternatives>
                  <table-wrap-foot>
                    <fn id="t001fn001">
                      <p><sup>a</sup>One participant did not report this information. The calculation was based on 41 participants.</p>
                    </fn>
                    <fn id="t001fn002">
                      <p><sup>b</sup>One participant did not report this information. The calculation was based on 40 participants.</p>
                    </fn>
                    <fn id="t001fn003">
                      <p><sup>c</sup>Independent sample t-test was used to test significance.</p>
                    </fn>
                    <fn id="t001fn004">
                      <p><sup>d</sup>Fisher’s Exact test was used to test significance.</p>
                    </fn>
                    <fn id="t001fn005">
                      <p>NA–Not applicable</p>
                    </fn>
                  </table-wrap-foot>
                </table-wrap>
              </sec>
              <sec id="sec004">
                <title>Speech in noise task</title>
                <p>All participants completed tasks of sentence recognition across conditions varying in the degree of linguistic information (high, low, and none): 1-talker masker (1T), reversed 1-talker masker (1T_tr) and speech-shaped noise (SSN).</p>
                <sec id="sec005">
                  <title>Target sentences</title>
                  <p>The target sentences were pooled from the Revised Bamford-Kowal-Bench (BKB) Standard Sentence Test [<xref rid="pone.0220928.ref050" ref-type="bibr">50</xref>]. Each BKB sentence (e.g., The BUCKETS HOLD WATER) contains three to four keywords (uppercase words). They were recorded by a female native speaker of American English in a sound-attenuated booth at Northwestern University [<xref rid="pone.0220928.ref051" ref-type="bibr">51</xref>]. Three BKB sentence lists (16 sentences in each list, with 50 keywords for scoring) were used in the current study. All sentences were equated for root-mean-square (RMS) amplitude.</p>
                </sec>
                <sec id="sec006">
                  <title>Maskers</title>
                  <p>The 1T and SSN were identical to those described in Chandrasekaran et al. (2015). Briefly, eight female speakers of American English were recorded in a sound-attenuated booth at Northwestern University [<xref rid="pone.0220928.ref052" ref-type="bibr">52</xref>], and produced a total of 240 simple, meaningful English sentences (30 for each speaker; e.g., for dessert he had apple pie) [<xref rid="pone.0220928.ref053" ref-type="bibr">53</xref>]. The 30 sentences from each of the eight speakers were equalized for RMS amplitude and concatenated to form a sentence string without silence between sentences. One of the eight 30-sentence strings was used as the 1T track. To create SSN, a steady-state white noise was filtered to match its spectrum with the long-term average spectrum of the full set of 240 sentences (from all eight speakers). To create the 1T_tr, we reversed the 1T track in time, to reduce the linguistic inference caused by the masker. The three masker tracks were truncated to 50s and equated for RMS amplitude.</p>
                </sec>
                <sec id="sec007">
                  <title>Mixing targets and maskers</title>
                  <p>Each of the three BKB sentence lists was mixed with one type of masker. Specifically, each target sentence was mixed with a random sample of the corresponding masker track such that the final stimulus was composed as follows: 500 ms of masker, the target and masker together, and a 500 ms masker. We set the signal-to-noise ratio SNR) at -5 dB (i.e., the noise is 5 dB more intense than the target) to avoid floor and ceiling performances on the basis of previous findings [<xref rid="pone.0220928.ref011" ref-type="bibr">11</xref>,<xref rid="pone.0220928.ref013" ref-type="bibr">13</xref>]. In total, there were 48 stimuli (16 mixed with each of the three types of masker) in the task.</p>
                </sec>
                <sec id="sec008">
                  <title>Testing procedures</title>
                  <p>During testing, the stimuli were binaurally presented to participants over Sennheiser HD-280 Pro headphones at a constant level (~70 dB sound pressure level). After each stimulus presentation, the participant was required to type out the target sentence. If they were unable to understand the whole sentence, they were encouraged to report any intelligible words and make their best guess. The order of all the 48 sentences was randomized for each participant.</p>
                </sec>
              </sec>
              <sec id="sec009">
                <title>Keyword accuracy analysis</title>
                <p>As in the majority of studies on SPIN (e.g., [<xref rid="pone.0220928.ref009" ref-type="bibr">9</xref>,<xref rid="pone.0220928.ref011" ref-type="bibr">11</xref>,<xref rid="pone.0220928.ref015" ref-type="bibr">15</xref>]) including Chandrasekaran et al. (2015), participants’ responses from the speech in noise task were scored by whether the keywords were correctly identified or not. To be considered as correct, no morphemes could be added to or deleted from the keywords. Otherwise, the responses were treated as incorrect.</p>
              </sec>
              <sec id="sec010">
                <title>Speech recognition error analysis</title>
                <p>In addition to keyword accuracy analysis, we also expanded on a prior effort from our group [<xref rid="pone.0220928.ref043" ref-type="bibr">43</xref>] to code the speech recognition errors in participants’ responses from the speech in noise task. The sample code for performing the error analysis is implemented in Python and is publicly available [<xref rid="pone.0220928.ref054" ref-type="bibr">54</xref>]. In the following paragraphs, we provide a detailed description of the speech recognition error analysis. A brief summary of the error analysis is displayed in <xref ref-type="fig" rid="pone.0220928.g002">Fig 2</xref>.</p>
                <fig id="pone.0220928.g002" orientation="portrait" position="float">
                  <object-id pub-id-type="doi">10.1371/journal.pone.0220928.g002</object-id>
                  <label>Fig 2</label>
                  <caption>
                    <title>A summary of the speech recognition error analysis.</title>
                  </caption>
                  <graphic xlink:href="pone.0220928.g002"/>
                </fig>
                <p>For each of the target sentences, participants’ typed response sentences were scored. Rather than scoring only the four keywords in each sentence (which is the gold-standard in assessing SPIN), the entire response sentence was first aligned with the target sentence and then scored for (1) whether the participant produced any content words from the target sentence at all, (2) the word-level errors (e.g., omission of a noun, substitution of a verb) and (3) morpheme-level errors (e.g. tense change, pluralization). The details of these scoring processes are described below. Examples of the various types of errors are shown in <xref rid="pone.0220928.t002" ref-type="table">Table 2</xref>.</p>
                <table-wrap id="pone.0220928.t002" orientation="portrait" position="float">
                  <object-id pub-id-type="doi">10.1371/journal.pone.0220928.t002</object-id>
                  <label>Table 2</label>
                  <caption>
                    <title>Examples of speech recognition errors.</title>
                  </caption>
                  <alternatives>
                    <graphic id="pone.0220928.t002g" xlink:href="pone.0220928.t002"/>
                    <table frame="hsides" rules="groups">
                      <colgroup span="1">
                        <col align="left" valign="middle" span="1"/>
                        <col align="left" valign="middle" span="1"/>
                        <col align="left" valign="middle" span="1"/>
                      </colgroup>
                      <thead>
                        <tr>
                          <th align="left" rowspan="1" colspan="1">Error Type</th>
                          <th align="left" rowspan="1" colspan="1">Target Sentence</th>
                          <th align="left" rowspan="1" colspan="1">Aligned Response</th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">DNH_Nothing</td>
                          <td align="left" rowspan="1" colspan="1">he broke his leg</td>
                          <td align="left" rowspan="1" colspan="1">_ _ _ _</td>
                        </tr>
                        <tr>
                          <td align="left" style="background-color:#D9D9D9" rowspan="1" colspan="1">DNH-Incorrect</td>
                          <td align="left" style="background-color:#D9D9D9" rowspan="1" colspan="1">the daughter set the table </td>
                          <td align="left" style="background-color:#D9D9D9" rowspan="1" colspan="1">_ can go very fast </td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">Omission of content word</td>
                          <td align="left" rowspan="1" colspan="1">a <underline>man</underline> is turning the faucet</td>
                          <td align="left" rowspan="1" colspan="1">_ _ is turning the faucet</td>
                        </tr>
                        <tr>
                          <td align="left" style="background-color:#D9D9D9" rowspan="1" colspan="1">Omission of function word</td>
                          <td align="left" style="background-color:#D9D9D9" rowspan="1" colspan="1"><underline>a</underline> man is turning the faucet</td>
                          <td align="left" style="background-color:#D9D9D9" rowspan="1" colspan="1">_ _ is turning the faucet</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">Addition of content word</td>
                          <td align="left" rowspan="1" colspan="1">a man is turning the faucet _</td>
                          <td align="left" rowspan="1" colspan="1">a man is turning the faucet <underline>trees</underline></td>
                        </tr>
                        <tr>
                          <td align="left" style="background-color:#D9D9D9" rowspan="1" colspan="1">Addition of function word</td>
                          <td align="left" style="background-color:#D9D9D9" rowspan="1" colspan="1">_ father forgot the bread</td>
                          <td align="left" style="background-color:#D9D9D9" rowspan="1" colspan="1"><underline>the</underline> father forgot the bread</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">Substitution of content word</td>
                          <td align="left" rowspan="1" colspan="1">the boy <underline>hurried</underline> to school</td>
                          <td align="left" rowspan="1" colspan="1">the boy <underline>went</underline> to school</td>
                        </tr>
                        <tr>
                          <td align="left" style="background-color:#D9D9D9" rowspan="1" colspan="1">Substitution of function word</td>
                          <td align="left" style="background-color:#D9D9D9" rowspan="1" colspan="1"><underline>a</underline> man is turning the faucet</td>
                          <td align="left" style="background-color:#D9D9D9" rowspan="1" colspan="1"><underline>the</underline> man is turning the faucet</td>
                        </tr>
                        <tr>
                          <td align="left" rowspan="1" colspan="1">Morpheme Error</td>
                          <td align="left" rowspan="1" colspan="1">the <underline>daughter</underline> set the table</td>
                          <td align="left" rowspan="1" colspan="1">the <underline>daughters</underline> set the table</td>
                        </tr>
                      </tbody>
                    </table>
                  </alternatives>
                  <table-wrap-foot>
                    <fn id="t002fn001">
                      <p>Note: errors are marked with underline (for words) or underscore (for gaps)</p>
                    </fn>
                  </table-wrap-foot>
                </table-wrap>
                <p>Sentence alignment was estimated using an adaptation of the Needleman-Wunsch algorithm [<xref rid="pone.0220928.ref055" ref-type="bibr">55</xref>], which uses a global alignment method to infer the best pairwise matches between units in a sequence, in this case, words in the target sentence and response sentence (see Fig 1 in [<xref rid="pone.0220928.ref043" ref-type="bibr">43</xref>] for illustration, available with additional open-source code and dataset in [<xref rid="pone.0220928.ref054" ref-type="bibr">54</xref>]). The algorithm rewards alignment of commonalities (same word) and minimizes the size of the misalignment error (word mismatches or missing words). This approach results in pairings of words or gaps (for missing words), one from the target sentence and one from the response sentence, which can be directly compared.</p>
                <p>Our present implementation of the Needleman-Wunsch global alignment algorithm permits the researcher to adjust the weights for different types of matches or mismatches. We adopted the match and mismatch weights from on our previous work with an independent dataset ([<xref rid="pone.0220928.ref043" ref-type="bibr">43</xref>], see [<xref rid="pone.0220928.ref054" ref-type="bibr">54</xref>] for full source code). Correctly matched words were rewarded with +20 because the probability of a correct word appearing in the same place in both target and response sentences by chance is very low (in contrast to other types of sequences with many fewer unique units to select from). Further, we rewarded partial matches (words with Levenshtein distance &lt; = 2, i.e., the number of additions, deletions, or substitutions necessary to match two words. See [<xref rid="pone.0220928.ref056" ref-type="bibr">56</xref>] for full explanation) with +5 to promote correct alignment even when morphological or phonological errors were present. Finally, both mismatches and gaps were penalized at -5. The cumulative result was better scoring of sentences wherein alignment of matched or nearly matched words was consistently preserved while also identifying gaps.</p>
                <p>The target and response sentences were tagged as content words (nouns, verbs, adjectives, adverbs) and function words (closed-class) using the Pattern module for Python [<xref rid="pone.0220928.ref057" ref-type="bibr">57</xref>]. Words in the response sentence that did not appear in the Pattern module’s dictionary were replaced with the first suggested spelling substitution if the replacement matched any content word in the target sentence, which allowed for alignment and matching of common typographical errors but rejected any correctly spelled words, such as homophones (consistent with criteria used by human coders in previous studies). At this stage, whole sentence omission errors were identified as “Did Not Hear” (DNH) and removed from further word- and morpheme-level analysis. If a response sentence did not contain any of the content words from the target sentence (regardless of their position in the alignment, and not including forms of the verb “to be”), the trial was marked as DNH. Sentences marked with DNH were further classified to indicate whether the participant transcribed irrelevant content (i.e., content words, but none matching the target; DNH-Incorrect) or simply failed to transcribe any content words at all (DNH-Nothing). Sentences marked as DNH were analyzed as a separate category of error and compared with the masker sentences to determine whether the subject has transcribed the masker content or just entered irrelevant words. DNH-Incorrect sentences were not included in subsequent word- and morpheme-level analyses.</p>
                <p>For the remaining trials, the aligned target and response sentences were scored by the script for word-level errors and morpheme-level errors. Word-level errors were aggregated across specific types of omissions, additions, and substitutions: If a given pair of sentences (target + response) contained a word from the target sentence but no word (a gap) from the response sentence, a word-omission was recorded for that trial. If a given pair contained a word from the response sentence but no word (a gap) from the target sentence, a word-addition was recorded for that trial. When two function words in a pair were not identical, a word-substitution was recorded. To evaluate morpheme-level errors, pairs of content words which did not match between target and response were further reduced to their root forms using the Pattern module and compared again. If two content words matched in their root forms but not in the original target and response, a morphemic error was recorded. However, if the words did not match in root form, a word-substitution error (at the word level) was recorded instead.</p>
              </sec>
              <sec id="sec011">
                <title>Statistical analysis</title>
                <sec id="sec012">
                  <title>Keyword accuracy</title>
                  <p>The keyword accuracy data were analyzed with generalized linear mixed-effects logistic regression using the lme4 package [<xref rid="pone.0220928.ref058" ref-type="bibr">58</xref>] in R version 3.2.0 [<xref rid="pone.0220928.ref059" ref-type="bibr">59</xref>] where keyword recognition accuracy (correct or incorrect) was modeled as a dichotomous dependent variable. In the model, fixed effects included the depression group (MDD or control) and masker type (1T, 1T_r, and SSN), and their interactions. To account for baseline differences in speech recognition performance across subjects and sentences, we included by-subject and by-sentence intercepts as random effects. Fixed factors were treated as categorical variables. In the model, the reference levels were the control group and 1T.</p>
                  <p>We tested the interaction between depression group and masker type by comparing a model with such interaction and the lower level effects to a model with only the lower level effects. We examined the main effects of depression group and masker type by comparing the base model (which only included the random-effects structure) to the same model but with the addition of depression group or noise. Model comparisons were achieved using the likelihood ratio [<xref rid="pone.0220928.ref060" ref-type="bibr">60</xref>]. Post hoc analysis for significant interaction or main effect, if necessary, was carried out by Tukey’s tests using the ‘glht’ function of the multcomp package [<xref rid="pone.0220928.ref061" ref-type="bibr">61</xref>]. Multiple comparisons were corrected using the Benjamini-Hochberg false discovery rate method [<xref rid="pone.0220928.ref062" ref-type="bibr">62</xref>].</p>
                </sec>
                <sec id="sec013">
                  <title>Speech recognition errors</title>
                  <p>We calculated five error types: DNH-Nothing, DNH-Incorrect, content word errors, function word errors, and morphemic errors. Specifically, for each masker condition (1T, 1T_tr, or SSN) in individual participants, first, we calculated the proportion of sentences (out of the total number of 16 sentences) that were classified as DNH-Nothing and DNH-Incorrect, respectively. For DNH-Incorrect errors, we further calculated the proportion of content words that were from the masker sentences. We restricted this analysis to the 1T condition because only masker sentences from this condition are intelligible. Second, we calculated the mean number of errors per sentence on content words, function words, and morphemes, respectively. We focused these analyses on the sentences that were not categorized as DNH-Nothing or DNH-Incorrect. For both content and function words, we combined all the three error types: substitution, addition, and omission.</p>
                  <p>For each of the five error types, the data were analyzed with linear mixed-effects regression using the lme4 package [<xref rid="pone.0220928.ref058" ref-type="bibr">58</xref>] in R version 3.2.0 [<xref rid="pone.0220928.ref059" ref-type="bibr">59</xref>]. In the model, fixed effects included the depression group (MDD or control) and masker type (1T, 1T_tr, and SSN), and their interactions. To account for baseline differences across subjects, we included by-subject intercept as random effects. Fixed factors were treated as categorical variables. In this model, the reference levels were the control group and 1T. We applied approaches similar to those for the keyword accuracy analysis as described above to test the interaction effect and the main effects of depression group and masker type. Descriptive statistics, if reported, represent mean ± standard deviation (<italic>SD</italic>).</p>
                </sec>
              </sec>
            </sec>
            <sec sec-type="results" id="sec014">
              <title>Results</title>
              <sec id="sec015">
                <title>Keyword accuracy</title>
                <p>Descriptively, as shown in <xref ref-type="fig" rid="pone.0220928.g001">Fig 1</xref>, the mean accuracy was lower in the MDD group than the control group in the 1T (MDD: 65.2% ± 15.4% vs control: 75.0% ± 11.7%) and 1T_tr condition (MDD: 81.5% ± 7.3% vs. control: 86.3% ± 7.8%), but was comparable between the two groups in the SSN condition (MDD: 73.8% ± 13.3% vs. control: 77.2% ± 11.2%). Further, performance variability was larger in the 1T condition than the two other conditions. The generalized linear mixed-effects logistic regression model yielded significant main effects for depression group [<italic>χ</italic><sup><italic>2</italic></sup> (1) = 4.285, <italic>p</italic> = 0.039] and masker type [<italic>χ</italic><sup><italic>2</italic></sup> (2) = 6.305, <italic>p</italic> = 0.043], and of primary interest, a significant interaction between depression group and masker type [<italic>χ</italic><sup><italic>2</italic></sup>(2) = 10.418, <italic>p</italic> = 0.005]. Follow-up analysis revealed that, as shown in <xref ref-type="fig" rid="pone.0220928.g001">Fig 1</xref>, word recognition in noise was significantly worse for the MDD group than for the control group in the 1T condition [<italic>β =</italic> -0.644, <italic>SE</italic> = 0.229, <italic>Z</italic> = -2.808, <italic>p</italic> = 0.025]. This depression-related deficit of word recognition was not significant in the 1T_Tr condition [<italic>β =</italic> -0.432, <italic>SE</italic> = 0.236, <italic>Z</italic> = -1.832, <italic>p</italic> = 0.143] or in the SSN condition [<italic>β =</italic> -0.267, <italic>SE</italic> = 0.232, <italic>Z</italic> = -1.15, <italic>p</italic> = 0.375].</p>
                <p>Further, we tested the model with the addition of three covariates: currently taking medication (medication: yes or no), currently in therapy or counseling (therapy: yes or no) and co-morbid anxiety (anxiety: yes or no) as covariates. One participant was excluded from this analysis because of missing data on the therapy information. The model was construed as: <italic>keyword recognition ~ depression group * masker type + medication + therapy + anxiety + (1 | sentence) + (1 | subject)</italic>. The inclusion of these covariates jointly did not significantly improve model fit, <italic>χ</italic><sup><italic>2</italic></sup>(3) = 0.785, <italic>p</italic> = 0.853, suggesting that the effects of these covariates were not significant.</p>
              </sec>
              <sec id="sec016">
                <title>Speech recognition errors</title>
                <p>First, we calculated the proportion of DNH-Nothing errors (<xref ref-type="fig" rid="pone.0220928.g003">Fig 3A</xref>) for each condition in individual participants. Descriptively, the mean proportion of DNH-Nothing errors was higher in the MDD group (5.4% ± 8.0%) than the control group (2.1% ± 3.6%) in the 1T_tr condition, but was comparable between the two groups in both the 1T (MDD: 1.0% ± 3.4% vs. control: 1.1% ± 2.8%) and SSN (MDD: 5.1% ± 8.2% vs. control: 4.3% ± 5.8%) conditions. The linear mixed-effects model showed that the main effect of depression group was not significant [<italic>χ</italic><sup><italic>2</italic></sup> (1) = 2.216, <italic>p</italic> = 0.137]. The main effect of masker type was significant [<italic>χ</italic><sup><italic>2</italic></sup> (2) = 22.356, <italic>p</italic> &lt; 0.001]. The interaction between depression group and masker type was not significant [<italic>χ</italic><sup><italic>2</italic></sup>(2) = 4.899, <italic>p</italic> = 0.086]. Post hoc analysis for the main effect of masker type revealed that the proportion of DNH-Nothing errors was significantly lower in the 1T condition relative to the other two masker conditions [1T vs. 1T_tr: <italic>β =</italic> 0.0271, <italic>SE</italic> = 0.00774, <italic>Z</italic> = 3.504, <italic>p</italic> &lt; 0.001; 1T vs. SSN: <italic>β =</italic> 0.0361, <italic>SE</italic> = 0.00774, <italic>Z</italic> = 4.672, <italic>p</italic> &lt; 0.001]. There was no significant difference between 1T_tr and SSN conditions [<italic>β =</italic> 0.00904, <italic>SE</italic> = 0.00774, <italic>Z</italic> = 1.168, <italic>p</italic> = 0.243].</p>
                <fig id="pone.0220928.g003" orientation="portrait" position="float">
                  <object-id pub-id-type="doi">10.1371/journal.pone.0220928.g003</object-id>
                  <label>Fig 3</label>
                  <caption>
                    <p>Raincloud plots (from left to right: jittered raw data for all participants, boxplots, and probability distribution of the data) for whole sentence omission errors (i.e., “Did Not Hear”; DNH) from neurotypical controls (black) and participants with MDD (red) across three types of masker: 1T (1-talker masker; left panels), 1T_tr (<italic>reversed</italic> 1-talker masker; middle panels), and SSN (speech-shaped noise; right panels). (A) Proportion of DNH-Nothing errors. This type of error refers to that participants failed to transcribe any content words. (B) Proportion of DNH-Incorrect errors. This type of error refers to that participants transcribed at least one content words but none of them matches the roots for content words from the target sentence. For the boxplots, the boxes and the horizontal line inside show the quartiles (1st to 3rd quartile) and the median, respectively. The whiskers denote 1.5 times the interquartile range. Outliers, defined as cases with values outside the 1.5 interquartile range, were not displayed in the boxplots. ** denote <italic>p</italic> &lt; 0.01.</p>
                  </caption>
                  <graphic xlink:href="pone.0220928.g003"/>
                </fig>
                <p>Second, we calculated the proportion of DNH-Incorrect errors (<xref ref-type="fig" rid="pone.0220928.g003">Fig 3B</xref>) for each condition in individual participants. Descriptively, the mean proportion of DNH-Incorrect errors was higher in the MDD group (26.5% ± 28.1%) than the control group (16.3% ± 19.1%) in the 1T condition, but comparable between the two groups in both the 1T_tr (MDD: 4.4% ± 5.7% vs. control: 3.8% ± 9.3%) and SSN (MDD: 5.2% ± 5.1% vs. control: 3.4% ± 4.4%) conditions. The linear mixed-effects model showed that the main effect of depression group was not significant [<italic>χ</italic><sup><italic>2</italic></sup> (1) = 3.222, <italic>p</italic> = 0.073]. The main effect of masker type was significant [<italic>χ</italic><sup><italic>2</italic></sup> (2) = 70.892, <italic>p</italic> &lt; 0.001]. The interaction between depression group and masker type was significant [<italic>χ</italic><sup><italic>2</italic></sup>(2) = 6.835, <italic>p</italic> = 0.033]. Follow-up analysis revealed that the proportion of DNH-Incorrect errors was significantly higher for the MDD group than for the control group in the 1T condition [<italic>β =</italic> 0.102, <italic>SE</italic> = 0.0326, <italic>Z</italic> = 3.117, <italic>p</italic> = 0.003]. However, the MDD vs. control group difference was not significant in the 1T_tr condition [<italic>β =</italic> -0.00388, <italic>SE</italic> = 0.0326, <italic>Z</italic> = -0.119, <italic>p</italic> = 0.97] or in the SSN condition [<italic>β =</italic> 0.0185, <italic>SE</italic> = 0.0326, <italic>Z</italic> = 0.568, <italic>p</italic> = 0.777]. Further, we calculated the proportion of content words in participants’ responses that match the content words from the masker sentences. We conducted this analysis only for the 1T condition. About 70% (MDD: 71.0% ± 25.5%; Control: 72.3% ± 30.3%) of content words in participants’ responses matched those from the maskers. There was no significant difference between the MDD and control group [<italic>t</italic>(58.967) = 0.187, <italic>p</italic> = 0.853].</p>
                <p>Finally, for the non-DNH errors, the mean number of errors per sentence was calculated for content words (<xref ref-type="fig" rid="pone.0220928.g004">Fig 4A</xref>), function words (<xref ref-type="fig" rid="pone.0220928.g004">Fig 4B</xref>), and morphemes (<xref ref-type="fig" rid="pone.0220928.g004">Fig 4C</xref>), respectively. Descriptively, the mean number of content and function words errors was higher in the MDD group than the control group across the three masker conditions, while the mean number of morphemic errors was comparable between the two groups across the three masker conditions. Separate statistical analysis was applied to the three error types. The linear mixed-effects models showed that, the main effect of depression group was (marginally) significant for content word errors [<italic>χ</italic><sup><italic>2</italic></sup> (1) = 3.83, <italic>p</italic> = 0.05] and function word errors [<italic>χ</italic><sup><italic>2</italic></sup> (1) = 5.223, <italic>p</italic> = 0.022], suggesting that these two types of errors were significantly higher for the MDD group than for the control group. The main effect of depression group was not significant for morphemic errors [<italic>χ</italic><sup><italic>2</italic></sup> (1) = 0.284, <italic>p</italic> = 0.594]. The main effect of masker type was significant for all three error types [content word errors: <italic>χ</italic><sup><italic>2</italic></sup> (2) = 8.258, <italic>p</italic> = 0.016; function word errors: <italic>χ</italic><sup><italic>2</italic></sup> (2) = 26.478, <italic>p</italic> &lt; 0.001; morphemic errors: <italic>χ</italic><sup><italic>2</italic></sup> (2) = 70.533, <italic>p</italic> &lt; 0.001]. The interaction between depression group and masker type was not significant for all three error types [content word errors: <italic>χ</italic><sup><italic>2</italic></sup> (2) = 2.988, <italic>p</italic> = 0.225; function word errors: <italic>χ</italic><sup><italic>2</italic></sup> (2) = 2.549, <italic>p</italic> = 0.28; morphemic errors: <italic>χ</italic><sup><italic>2</italic></sup> (2) = 0.113, <italic>p</italic> = 0.945]. Post hoc analysis for the main effect of masker type revealed that the number of content word errors and function word errors was significantly higher in the 1T and SSN conditions relative to the 1T_tr condition (all <italic>p</italic>s ranging from 6.73 × 10<sup>−6</sup> to 0.039). The number of morphemic errors was significantly higher in the SSN condition relative to the 1T condition (<italic>p</italic> &lt; 0.001) and the 1T_tr condition (<italic>p</italic> &lt; 0.001). No other comparisons were significant (all <italic>p</italic>s ranging from 0.088 to 0.805).</p>
                <fig id="pone.0220928.g004" orientation="portrait" position="float">
                  <object-id pub-id-type="doi">10.1371/journal.pone.0220928.g004</object-id>
                  <label>Fig 4</label>
                  <caption>
                    <p>Raincloud plots (from left to right: jittered raw data for all participants, boxplots, and probability distribution of the data) for word- and morpheme-level errors from neurotypical controls (black) and participants with MDD (red) across three types of masker: 1T (1-talker masker; left panels), 1T_tr (<italic>reversed</italic> 1-talker masker; middle panels), and SSN (speech-shaped noise; right panels). (A) The mean number of errors per sentence on content words. This type of error includes substitution, addition, or omission of nouns, verbs, adjectives, or adverbs. (B) The mean number of errors per sentence on function words. This type of error includes substitution, addition, or omission of closed-class word. (C) The mean number of errors per sentence on morphemes. This type of error refers to cases where the content word from participant’s response matched in the root form with the content word in the target sentence but is not the same as the target content word. For the boxplots, the boxes and the horizontal line inside show the quartiles (1st to 3rd quartile) and the median, respectively. The whiskers denote 1.5 times the interquartile range. Outliers, defined as cases with values outside the 1.5 interquartile range, were not displayed in the boxplots. * denotes <italic>p</italic> &lt; 0.05. + denotes <italic>p</italic> &lt; 0.06.</p>
                  </caption>
                  <graphic xlink:href="pone.0220928.g004"/>
                </fig>
              </sec>
            </sec>
            <sec sec-type="conclusions" id="sec017">
              <title>Discussion</title>
              <sec id="sec018">
                <title>Summary of findings</title>
                <p>In a clinical population, the current study replicated the effect of depression on SPIN observed in a population with sub-clinical elevated depressive symptoms from Chandrasekaran et al. (2015). Individuals with MDD, relative to neurotypical NH participants, exhibited lower keyword accuracy in conditions with speech maskers (1T), but not in conditions with non-speech maskers (1T_tr or SSN) (<xref ref-type="fig" rid="pone.0220928.g001">Fig 1</xref>).</p>
                <p>Critically, we applied a speech recognition error analysis approach [<xref rid="pone.0220928.ref043" ref-type="bibr">43</xref>] to analyze error patterns to understand the nature of the depression-related listening condition-specific (i.e., speech maskers) deficit in speech perception. Particularly, we calculated the occurrence rate of errors that a listener transcribed words irrelevant to the target sentences (DNH_Incorrect; <xref ref-type="fig" rid="pone.0220928.g003">Fig 3B</xref>) and found that such error type was significantly higher for individuals with MDD than the neurotypical participants in the conditions with speech maskers. In such condition (speech maskers), words from the masker sentences constituted a great proportion (~70%) of the DNH_Incorrect errors. Meanwhile, we did not observe a depression-related listening condition-specific (i.e., speech maskers) pattern for any other error types including content and function word errors and morpheme-level errors (<xref ref-type="fig" rid="pone.0220928.g004">Fig 4A</xref> to <xref ref-type="fig" rid="pone.0220928.g004">4C</xref>). Together, these findings are consistent with our prediction that the occurrence rate of errors as a result of interference from the masker sentences would be increased in individuals with MDD (relative to neurotypical controls) in conditions with speech maskers. Mechanistically, the increased interference from the masker sentences may be related to heightened susceptibility to linguistic interference from distracting talkers.</p>
              </sec>
              <sec id="sec019">
                <title>Increased susceptibility to distracting information in individuals with MDD</title>
                <p>Increased susceptibility to distracting information in individuals with MDD has been reported in both behavioral (e.g., [<xref rid="pone.0220928.ref044" ref-type="bibr">44</xref>,<xref rid="pone.0220928.ref045" ref-type="bibr">45</xref>]) and neuroimaging studies (e.g, [<xref rid="pone.0220928.ref046" ref-type="bibr">46</xref>,<xref rid="pone.0220928.ref047" ref-type="bibr">47</xref>]). For example, Lemelin et al. (1997) demonstrated that, in a Stroop color-word test, some individuals with MDD, relative to typical participants, exhibited additional delay (slower response time) in naming the color in the presence of distractor words (relative to the condition without distractors), even if the meaning of the distractors is unrelated to names of color. In an fMRI (functional magnetic resonance imaging) study, Desseilles et al. (2009) revealed that individuals with MDD (relative to control participants) showed increased BOLD (blood oxygenation level-dependent) responses to task-irrelevant visual stimuli in the visual cortices, suggesting less filtering of distracting information. In line with these prior studies, the present study suggests that individuals with MDD (vs. neurotypical controls) are more susceptible to distracting linguistic information that is highly confusable with the target stimuli (i.e., 1T condition).</p>
                <p>Note that an early study examined the ability to follow an auditorily presented story in one ear with and without the interference of competing stories from the other ear in a small group (N = 8) of individuals with MDD. Their performance to follow auditory stories was not affected by the presence of the distracting stories [<xref rid="pone.0220928.ref063" ref-type="bibr">63</xref>]. However, the power of this early study [<xref rid="pone.0220928.ref063" ref-type="bibr">63</xref>] may be limited by the small sample size, as well as the potential large variability in the susceptibility to distracting information in individuals with MDD [<xref rid="pone.0220928.ref045" ref-type="bibr">45</xref>]. Therefore, we are inclined to conform to the argument of elevated distractibility to distracting information associated with MDD. Nevertheless, future studies are needed to further elucidate the mechanisms underlying the depression-related listening condition-specific (i.e., speech maskers) deficit in speech perception.</p>
              </sec>
              <sec id="sec020">
                <title>Analyzing speech recognition errors: Past and current approaches</title>
                <p>Prior work has investigated speech recognition errors in phoneme [<xref rid="pone.0220928.ref036" ref-type="bibr">36</xref>,<xref rid="pone.0220928.ref037" ref-type="bibr">37</xref>,<xref rid="pone.0220928.ref040" ref-type="bibr">40</xref>–<xref rid="pone.0220928.ref042" ref-type="bibr">42</xref>] and word [<xref rid="pone.0220928.ref035" ref-type="bibr">35</xref>,<xref rid="pone.0220928.ref038" ref-type="bibr">38</xref>,<xref rid="pone.0220928.ref039" ref-type="bibr">39</xref>] perception tasks. To the best of our knowledge, only one recent study has examined recognition errors for sentence-level materials [<xref rid="pone.0220928.ref034" ref-type="bibr">34</xref>]. Smith and Fogerty (2017) examined two error categories specifically for the sentence keywords across different non-speech noise contexts (speech in SSN and speech periodically interrupted by SSN with 33%, 50% or 66% speech proportion preserved): Whole word error, which includes substitution, addition, and omission of keywords, and part-word error, which includes substitution, addition, and omission of phonemes in the keywords. They found the occurrence rates of whole word and part word errors were higher for speech in SSN and speech interrupted by SSN with the smallest speech proportion preserved (33%) than for speech interrupted by SSN with higher speech proportion preserved (50% and 66%).</p>
                <p>Relative to the error analysis approach in Smith and Fogerty (2017), a unique aspect of error analysis approach worth noting is that our approach codes DNH-Incorrect errors (i.e., participants transcribed at least one content words but none of them matches the roots for content words from the target sentence). The coding of DNH_Incorrect errors is meaningful because our design included a condition with speech masker (1T) wherein a listener is likely to report words from the speech masker as the targets. It should be mentioned that the characterization of interference from speech maskers in SPIN tasks has been reported in the literature (e.g., [<xref rid="pone.0220928.ref064" ref-type="bibr">64</xref>,<xref rid="pone.0220928.ref065" ref-type="bibr">65</xref>]). Those studies typically utilized matrix sentences (i.e., closed-set sentences combined from a limited sets of words) as the target and maskers. Unlike the prior work, our approach directly dealt with open-set sentences that are more realistic in daily-life scenarios. Using our approach, we found that the occurrence rate of DNH_Incorrect errors was higher in individuals with depression in the 1T condition. Thus, the error analysis, beyond the keyword accuracy analysis, helps, to some extent, pinpoint the locus of deficit in SPIN associated with depression. It is conceivable that future studies on speech perception can benefit from the combination of keyword scoring analysis and recognition error analysis.</p>
              </sec>
              <sec id="sec021">
                <title>Implications for SPIN studies with hearing impairment and aging</title>
                <p>The study of the independent effect of depression on speech perception, as in the current study, represents a meaningful contribution to the field related to SPIN. As mentioned earlier, a listener’s ability to understand speech, particularly in the presence of interfering talkers, can be independently affected by hearing impairment and aging [<xref rid="pone.0220928.ref019" ref-type="bibr">19</xref>–<xref rid="pone.0220928.ref023" ref-type="bibr">23</xref>]. Interesting, these two factors are suggested to increase risk for depression [<xref rid="pone.0220928.ref024" ref-type="bibr">24</xref>–<xref rid="pone.0220928.ref031" ref-type="bibr">31</xref>]. Hence, considering our finding of the depression-related listening condition-specific deficit in speech perception, we propose the need to understand the extent to which depression exacerbates the difficulty of speech understanding in individuals with HI or older adults. Note that the current study assessed speech perception in certain noise conditions (e.g., a fixed SNR) to avoid floor and ceiling performances, further studies are needed to extend the current findings to a range of noise conditions (e.g., a wide range of SNRs).</p>
              </sec>
              <sec id="sec022">
                <title>Larger individual variability in speech recognition under speech maskers</title>
                <p>Qualitatively, there are larger individual differences in speech recognition performance under speech maskers (1T) relative to non-speech maskers (1T_tr and SSN) (<xref ref-type="fig" rid="pone.0220928.g001">Fig 1</xref>). Such observation is consistent with our previous studies (e.g., [<xref rid="pone.0220928.ref011" ref-type="bibr">11</xref>]). As mentioned in the introduction, while speech maskers and non-speech maskers both produce energetic masking (though to a different extent), speech maskers additionally produce informational masking [<xref rid="pone.0220928.ref008" ref-type="bibr">8</xref>,<xref rid="pone.0220928.ref009" ref-type="bibr">9</xref>,<xref rid="pone.0220928.ref015" ref-type="bibr">15</xref>,<xref rid="pone.0220928.ref016" ref-type="bibr">16</xref>]. Speech recognition under informational masking places demands on individual’s executive abilities (e.g., working memory) [<xref rid="pone.0220928.ref011" ref-type="bibr">11</xref>]. Hence, individual variations in executive abilities likely contribute to the larger individual variability in speech recognition under speech maskers.</p>
              </sec>
            </sec>
            <sec sec-type="conclusions" id="sec023">
              <title>Conclusions</title>
              <p>We present evidence that individuals with MDD exhibited a listening condition-specific deficit in speech perception under speech maskers. Based on the findings from speech recognition error analysis, we posit that this listening condition-specific deficit may be related to heightened susceptibility to interferences from background talkers. Typical social conversations often transpire in environments with distracting talkers. Such listening condition-specific speech perception deficit associated with MDD could lead to (or exacerbate) social and communicative difficulties in individuals with MDD, which may in turn exacerbate their depressive symptoms [<xref rid="pone.0220928.ref004" ref-type="bibr">4</xref>].</p>
            </sec>
          </body>
          <back>
            <ack>
              <p>We thank Justin Dainer-Best and research assistants at the Mood Disorders Laboratory for data collection. We thank Kristin J. Van Engen and Jasmine E. B. Phelps in stimulus preparation. We thank the research assistants at the Soundbrain lab for their invaluable assistance in data management and analysis.</p>
            </ack>
            <ref-list>
              <title>References</title>
              <ref id="pone.0220928.ref001">
                <label>1</label>
                <mixed-citation publication-type="journal"><name><surname>Ferrari</surname><given-names>AJ</given-names></name>, <name><surname>Charlson</surname><given-names>FJ</given-names></name>, <name><surname>Norman</surname><given-names>RE</given-names></name>, <name><surname>Flaxman</surname><given-names>AD</given-names></name>, <name><surname>Patten</surname><given-names>SB</given-names></name>, <name><surname>Vos</surname><given-names>T</given-names></name>, <etal>et al</etal><article-title>The epidemiological modelling of major depressive disorder: application for the Global Burden of Disease Study 2010</article-title>. <source>PLoS One</source>. Public Library of Science; <year>2013</year>;<volume>8</volume>: <fpage>e69637</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0069637</pub-id><?supplied-pmid 23922765?><pub-id pub-id-type="pmid">23922765</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref002">
                <label>2</label>
                <mixed-citation publication-type="journal"><name><surname>Miller</surname><given-names>WR</given-names></name>. <article-title>Psychological deficit in depression</article-title>. <source>Psychol Bull</source>. American Psychological Association; <year>1975</year>;<volume>82</volume>: <fpage>238</fpage><?supplied-pmid 1096208?><pub-id pub-id-type="pmid">1096208</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref003">
                <label>3</label>
                <mixed-citation publication-type="book"><name><surname>Snyder</surname><given-names>HR</given-names></name>. <source>Major depressive disorder is associated with broad impairments on neuropsychological measures of executive function: A meta-analysis and review</source>. <publisher-name>American Psychological Association</publisher-name>; <year>2013</year>.</mixed-citation>
              </ref>
              <ref id="pone.0220928.ref004">
                <label>4</label>
                <mixed-citation publication-type="journal"><name><surname>Saito</surname><given-names>H</given-names></name>, <name><surname>Nishiwaki</surname><given-names>Y</given-names></name>, <name><surname>Michikawa</surname><given-names>T</given-names></name>, <name><surname>Kikuchi</surname><given-names>Y</given-names></name>, <name><surname>Mizutari</surname><given-names>K</given-names></name>, <name><surname>Takebayashi</surname><given-names>T</given-names></name>, <etal>et al</etal><article-title>Hearing Handicap Predicts the Development of Depressive Symptoms After 3 Years in Older Community‐Dwelling Japanese</article-title>. <source>J Am Geriatr Soc</source>. Wiley Online Library; <year>2010</year>;<volume>58</volume>: <fpage>93</fpage>–<lpage>97</lpage>. <pub-id pub-id-type="doi">10.1111/j.1532-5415.2009.02615.x</pub-id>
<?supplied-pmid 20002512?><pub-id pub-id-type="pmid">20002512</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref005">
                <label>5</label>
                <mixed-citation publication-type="journal"><name><surname>Cummins</surname><given-names>N</given-names></name>, <name><surname>Scherer</surname><given-names>S</given-names></name>, <name><surname>Krajewski</surname><given-names>J</given-names></name>, <name><surname>Schnieder</surname><given-names>S</given-names></name>, <name><surname>Epps</surname><given-names>J</given-names></name>, <name><surname>Quatieri</surname><given-names>TF</given-names></name>. <article-title>A review of depression and suicide risk assessment using speech analysis</article-title>. <source>Speech Commun</source>. Elsevier; <year>2015</year>;<volume>71</volume>: <fpage>10</fpage>–<lpage>49</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0220928.ref006">
                <label>6</label>
                <mixed-citation publication-type="journal"><name><surname>Mundt</surname><given-names>JC</given-names></name>, <name><surname>Vogel</surname><given-names>AP</given-names></name>, <name><surname>Feltner</surname><given-names>DE</given-names></name>, <name><surname>Lenderking</surname><given-names>WR</given-names></name>. <article-title>Vocal acoustic biomarkers of depression severity and treatment response</article-title>. <source>Biol Psychiatry</source>. Elsevier; <year>2012</year>;<volume>72</volume>: <fpage>580</fpage>–<lpage>587</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsych.2012.03.015</pub-id>
<?supplied-pmid 22541039?><pub-id pub-id-type="pmid">22541039</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref007">
                <label>7</label>
                <mixed-citation publication-type="journal"><name><surname>Cherry</surname><given-names>EC</given-names></name>. <article-title>Some experiments on the recognition of speech, with one and with two ears</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>1953</year>;<volume>25</volume>: <fpage>975</fpage>–<lpage>979</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0220928.ref008">
                <label>8</label>
                <mixed-citation publication-type="journal"><name><surname>Shinn-Cunningham</surname><given-names>BG</given-names></name>. <article-title>Object-based auditory and visual attention</article-title>. <source>Trends Cogn Sci</source>. Elsevier; <year>2008</year>;<volume>12</volume>: <fpage>182</fpage>–<lpage>186</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2008.02.003</pub-id>
<?supplied-pmid 18396091?><pub-id pub-id-type="pmid">18396091</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref009">
                <label>9</label>
                <mixed-citation publication-type="journal"><name><surname>Arbogast</surname><given-names>TL</given-names></name>, <name><surname>Mason</surname><given-names>CR</given-names></name>, <name><surname>Kidd</surname><given-names>G</given-names><suffix>Jr</suffix></name>. <article-title>The effect of spatial separation on informational and energetic masking of speech</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>2002</year>;<volume>112</volume>: <fpage>2086</fpage>–<lpage>2098</lpage>. <pub-id pub-id-type="doi">10.1121/1.1510141</pub-id>
<?supplied-pmid 12430820?><pub-id pub-id-type="pmid">12430820</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref010">
                <label>10</label>
                <mixed-citation publication-type="journal"><name><surname>Xie</surname><given-names>Z</given-names></name>, <name><surname>Yi</surname><given-names>H-G</given-names></name>, <name><surname>Chandrasekaran</surname><given-names>B</given-names></name>. <article-title>Nonnative audiovisual speech perception in noise: Dissociable effects of the speaker and listener</article-title>. <source>PLoS One</source>. Public Library of Science; <year>2014</year>;<volume>9</volume>: <fpage>e114439</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0114439</pub-id><?supplied-pmid 25474650?><pub-id pub-id-type="pmid">25474650</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref011">
                <label>11</label>
                <mixed-citation publication-type="journal"><name><surname>Xie</surname><given-names>Z</given-names></name>, <name><surname>Maddox</surname><given-names>WT</given-names></name>, <name><surname>Knopik</surname><given-names>VS</given-names></name>, <name><surname>McGeary</surname><given-names>JE</given-names></name>, <name><surname>Chandrasekaran</surname><given-names>B</given-names></name>. <article-title>Dopamine receptor D4 (DRD4) gene modulates the influence of informational masking on speech recognition</article-title>. <source>Neuropsychologia</source>. Elsevier; <year>2015</year>;<volume>67</volume>: <fpage>121</fpage>–<lpage>131</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2014.12.013</pub-id>
<?supplied-pmid 25497692?><pub-id pub-id-type="pmid">25497692</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref012">
                <label>12</label>
                <mixed-citation publication-type="journal"><name><surname>Reetzke</surname><given-names>R</given-names></name>, <name><surname>Lam</surname><given-names>BP-W</given-names></name>, <name><surname>Xie</surname><given-names>Z</given-names></name>, <name><surname>Sheng</surname><given-names>L</given-names></name>, <name><surname>Chandrasekaran</surname><given-names>B</given-names></name>. <article-title>Effect of Simultaneous Bilingualism on Speech Intelligibility across Different Masker Types, Modalities, and Signal-to-Noise Ratios in School-Age Children</article-title>. <source>PLoS One</source>. Public Library of Science; <year>2016</year>;<volume>11</volume>: <fpage>e0168048</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0168048</pub-id><?supplied-pmid 27936212?><pub-id pub-id-type="pmid">27936212</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref013">
                <label>13</label>
                <mixed-citation publication-type="journal"><name><surname>Chandrasekaran</surname><given-names>B</given-names></name>, <name><surname>Van Engen</surname><given-names>K</given-names></name>, <name><surname>Xie</surname><given-names>Z</given-names></name>, <name><surname>Beevers</surname><given-names>CG</given-names></name>, <name><surname>Maddox</surname><given-names>WT</given-names></name>. <article-title>Influence of depressive symptoms on speech perception in adverse listening conditions</article-title>. <source>Cogn Emot</source>. Taylor &amp; Francis; <year>2015</year>;<volume>29</volume>: <fpage>900</fpage>–<lpage>909</lpage>. <pub-id pub-id-type="doi">10.1080/02699931.2014.944106</pub-id>
<?supplied-pmid 25090306?><pub-id pub-id-type="pmid">25090306</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref014">
                <label>14</label>
                <mixed-citation publication-type="journal"><name><surname>Lam</surname><given-names>BPW</given-names></name>, <name><surname>Xie</surname><given-names>Z</given-names></name>, <name><surname>Tessmer</surname><given-names>R</given-names></name>, <name><surname>Chandrasekaran</surname><given-names>B</given-names></name>. <article-title>The Downside of Greater Lexical Influences: Selectively Poorer Speech Perception in Noise</article-title>. <source>J Speech, Lang Hear Res</source>. ASHA; <year>2017</year>; <fpage>1</fpage>–<lpage>12</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0220928.ref015">
                <label>15</label>
                <mixed-citation publication-type="journal"><name><surname>Brungart</surname><given-names>DS</given-names></name>. <article-title>Informational and energetic masking effects in the perception of two simultaneous talkers</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>2001</year>;<volume>109</volume>: <fpage>1101</fpage>–<lpage>1109</lpage>. <pub-id pub-id-type="doi">10.1121/1.1345696</pub-id>
<?supplied-pmid 11303924?><pub-id pub-id-type="pmid">11303924</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref016">
                <label>16</label>
                <mixed-citation publication-type="journal"><name><surname>Durlach</surname><given-names>N</given-names></name>. <article-title>Auditory masking: Need for improved conceptual structure a</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>2006</year>;<volume>120</volume>: <fpage>1787</fpage>–<lpage>1790</lpage>. <pub-id pub-id-type="doi">10.1121/1.2335426</pub-id>
<?supplied-pmid 17069274?><pub-id pub-id-type="pmid">17069274</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref017">
                <label>17</label>
                <mixed-citation publication-type="journal"><name><surname>Stone</surname><given-names>MA</given-names></name>, <name><surname>Canavan</surname><given-names>S</given-names></name>. <article-title>The near non-existence of “pure” energetic masking release for speech: Extension to spectro-temporal modulation and glimpsing</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>2016</year>;<volume>140</volume>: <fpage>832</fpage>–<lpage>842</lpage>. <pub-id pub-id-type="doi">10.1121/1.4960483</pub-id>
<?supplied-pmid 27586715?><pub-id pub-id-type="pmid">27586715</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref018">
                <label>18</label>
                <mixed-citation publication-type="journal"><name><surname>Stone</surname><given-names>MA</given-names></name>, <name><surname>Füllgrabe</surname><given-names>C</given-names></name>, <name><surname>Moore</surname><given-names>BCJ</given-names></name>. <article-title>Notionally steady background noise acts primarily as a modulation masker of speech</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>2012</year>;<volume>132</volume>: <fpage>317</fpage>–<lpage>326</lpage>. <pub-id pub-id-type="doi">10.1121/1.4725766</pub-id>
<?supplied-pmid 22779480?><pub-id pub-id-type="pmid">22779480</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref019">
                <label>19</label>
                <mixed-citation publication-type="journal"><name><surname>Best</surname><given-names>V</given-names></name>, <name><surname>Mason</surname><given-names>CR</given-names></name>, <name><surname>Kidd</surname><given-names>G</given-names><suffix>Jr</suffix></name>. <article-title>Spatial release from masking in normally hearing and hearing-impaired listeners as a function of the temporal overlap of competing talkers</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>2011</year>;<volume>129</volume>: <fpage>1616</fpage>–<lpage>1625</lpage>. <pub-id pub-id-type="doi">10.1121/1.3533733</pub-id>
<?supplied-pmid 21428524?><pub-id pub-id-type="pmid">21428524</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref020">
                <label>20</label>
                <mixed-citation publication-type="journal"><name><surname>Koelewijn</surname><given-names>T</given-names></name>, <name><surname>Zekveld</surname><given-names>AA</given-names></name>, <name><surname>Festen</surname><given-names>JM</given-names></name>, <name><surname>Kramer</surname><given-names>SE</given-names></name>. <article-title>The influence of informational masking on speech perception and pupil response in adults with hearing impairment</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>2014</year>;<volume>135</volume>: <fpage>1596</fpage>–<lpage>1606</lpage>. <pub-id pub-id-type="doi">10.1121/1.4863198</pub-id>
<?supplied-pmid 24606294?><pub-id pub-id-type="pmid">24606294</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref021">
                <label>21</label>
                <mixed-citation publication-type="journal"><name><surname>Helfer</surname><given-names>KS</given-names></name>, <name><surname>Freyman</surname><given-names>RL</given-names></name>. <article-title>Stimulus and listener factors affecting age-related changes in competing speech perception</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>2014</year>;<volume>136</volume>: <fpage>748</fpage>–<lpage>759</lpage>. <pub-id pub-id-type="doi">10.1121/1.4887463</pub-id>
<?supplied-pmid 25096109?><pub-id pub-id-type="pmid">25096109</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref022">
                <label>22</label>
                <mixed-citation publication-type="journal"><name><surname>Rajan</surname><given-names>R</given-names></name>, <name><surname>Cainer</surname><given-names>KE</given-names></name>. <article-title>Ageing without hearing loss or cognitive impairment causes a decrease in speech intelligibility only in informational maskers</article-title>. <source>Neuroscience</source>. Elsevier; <year>2008</year>;<volume>154</volume>: <fpage>784</fpage>–<lpage>795</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroscience.2008.03.067</pub-id>
<?supplied-pmid 18485606?><pub-id pub-id-type="pmid">18485606</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref023">
                <label>23</label>
                <mixed-citation publication-type="journal"><name><surname>Helfer</surname><given-names>KS</given-names></name>, <name><surname>Freyman</surname><given-names>RL</given-names></name>. <article-title>Aging and speech-on-speech masking</article-title>. <source>Ear Hear</source>. NIH Public Access; <year>2008</year>;<volume>29</volume>: <fpage>87</fpage><pub-id pub-id-type="doi">10.1097/AUD.0b013e31815d638b</pub-id><?supplied-pmid 18091104?><pub-id pub-id-type="pmid">18091104</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref024">
                <label>24</label>
                <mixed-citation publication-type="journal"><name><surname>Cacciatore</surname><given-names>F</given-names></name>, <name><surname>Napoli</surname><given-names>C</given-names></name>, <name><surname>Abete</surname><given-names>P</given-names></name>, <name><surname>Marciano</surname><given-names>E</given-names></name>, <name><surname>Triassi</surname><given-names>M</given-names></name>, <name><surname>Rengo</surname><given-names>F</given-names></name>. <article-title>Quality of life determinants and hearing function in an elderly population: Osservatorio Geriatrico Campano Study Group</article-title>. <source>Gerontology</source>. Karger Publishers; <year>1999</year>;<volume>45</volume>: <fpage>323</fpage>–<lpage>328</lpage>. <pub-id pub-id-type="doi">10.1159/000022113</pub-id>
<?supplied-pmid 10559650?><pub-id pub-id-type="pmid">10559650</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref025">
                <label>25</label>
                <mixed-citation publication-type="journal"><name><surname>Keidser</surname><given-names>G</given-names></name>, <name><surname>Seeto</surname><given-names>M</given-names></name>, <name><surname>Rudner</surname><given-names>M</given-names></name>, <name><surname>Hygge</surname><given-names>S</given-names></name>, <name><surname>Rönnberg</surname><given-names>J</given-names></name>. <article-title>On the relationship between functional hearing and depression</article-title>. <source>Int J Audiol</source>. Taylor &amp; Francis; <year>2015</year>;<volume>54</volume>: <fpage>653</fpage>–<lpage>664</lpage>. <pub-id pub-id-type="doi">10.3109/14992027.2015.1046503</pub-id>
<?supplied-pmid 26070470?><pub-id pub-id-type="pmid">26070470</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref026">
                <label>26</label>
                <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>C-M</given-names></name>, <name><surname>Zhang</surname><given-names>X</given-names></name>, <name><surname>Hoffman</surname><given-names>HJ</given-names></name>, <name><surname>Cotch</surname><given-names>MF</given-names></name>, <name><surname>Themann</surname><given-names>CL</given-names></name>, <name><surname>Wilson</surname><given-names>MR</given-names></name>. <article-title>Hearing impairment associated with depression in US adults, National Health and Nutrition Examination Survey 2005–2010</article-title>. <source>JAMA Otolaryngol Neck Surg</source>. American Medical Association; <year>2014</year>;<volume>140</volume>: <fpage>293</fpage>–<lpage>302</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0220928.ref027">
                <label>27</label>
                <mixed-citation publication-type="journal"><name><surname>Nachtegaal</surname><given-names>J</given-names></name>, <name><surname>Smit</surname><given-names>JH</given-names></name>, <name><surname>Smits</surname><given-names>CAS</given-names></name>, <name><surname>Bezemer</surname><given-names>PD</given-names></name>, <name><surname>Van Beek</surname><given-names>JHM</given-names></name>, <name><surname>Festen</surname><given-names>JM</given-names></name>, <etal>et al</etal><article-title>The association between hearing status and psychosocial health before the age of 70 years: results from an internet-based national survey on hearing</article-title>. <source>Ear Hear</source>. LWW; <year>2009</year>;<volume>30</volume>: <fpage>302</fpage>–<lpage>312</lpage>. <pub-id pub-id-type="doi">10.1097/AUD.0b013e31819c6e01</pub-id>
<?supplied-pmid 19322094?><pub-id pub-id-type="pmid">19322094</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref028">
                <label>28</label>
                <mixed-citation publication-type="journal"><name><surname>Fiske</surname><given-names>A</given-names></name>, <name><surname>Wetherell</surname><given-names>JL</given-names></name>, <name><surname>Gatz</surname><given-names>M</given-names></name>. <article-title>Depression in older adults</article-title>. <source>Annu Rev Clin Psychol</source>. Annual Reviews; <year>2009</year>;<volume>5</volume>: <fpage>363</fpage>–<lpage>389</lpage>. <pub-id pub-id-type="doi">10.1146/annurev.clinpsy.032408.153621</pub-id>
<?supplied-pmid 19327033?><pub-id pub-id-type="pmid">19327033</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref029">
                <label>29</label>
                <mixed-citation publication-type="journal"><name><surname>Hasin</surname><given-names>DS</given-names></name>, <name><surname>Goodwin</surname><given-names>RD</given-names></name>, <name><surname>Stinson</surname><given-names>FS</given-names></name>, <name><surname>Grant</surname><given-names>BF</given-names></name>. <article-title>Epidemiology of major depressive disorder: results from the National Epidemiologic Survey on Alcoholism and Related Conditions</article-title>. <source>Arch Gen Psychiatry</source>. American Medical Association; <year>2005</year>;<volume>62</volume>: <fpage>1097</fpage>–<lpage>1106</lpage>. <pub-id pub-id-type="doi">10.1001/archpsyc.62.10.1097</pub-id>
<?supplied-pmid 16203955?><pub-id pub-id-type="pmid">16203955</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref030">
                <label>30</label>
                <mixed-citation publication-type="journal"><name><surname>Luppa</surname><given-names>M</given-names></name>, <name><surname>Sikorski</surname><given-names>C</given-names></name>, <name><surname>Luck</surname><given-names>T</given-names></name>, <name><surname>Ehreke</surname><given-names>L</given-names></name>, <name><surname>Konnopka</surname><given-names>A</given-names></name>, <name><surname>Wiese</surname><given-names>B</given-names></name>, <etal>et al</etal><article-title>Age-and gender-specific prevalence of depression in latest-life–systematic review and meta-analysis</article-title>. <source>J Affect Disord</source>. Elsevier; <year>2012</year>;<volume>136</volume>: <fpage>212</fpage>–<lpage>221</lpage>. <pub-id pub-id-type="doi">10.1016/j.jad.2010.11.033</pub-id>
<?supplied-pmid 21194754?><pub-id pub-id-type="pmid">21194754</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref031">
                <label>31</label>
                <mixed-citation publication-type="journal"><name><surname>Roberts</surname><given-names>RE</given-names></name>, <name><surname>Kaplan</surname><given-names>GA</given-names></name>, <name><surname>Shema</surname><given-names>SJ</given-names></name>, <name><surname>Strawbridge</surname><given-names>WJ</given-names></name>. <article-title>Prevalence and correlates of depression in an aging cohort: the Alameda County Study</article-title>. <source>Journals Gerontol Ser B Psychol Sci Soc Sci</source>. The Gerontological Society of America; <year>1997</year>;<volume>52</volume>: <fpage>S252</fpage>–<lpage>S258</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0220928.ref032">
                <label>32</label>
                <mixed-citation publication-type="journal"><name><surname>Cuijpers</surname><given-names>P</given-names></name>, <name><surname>Smit</surname><given-names>F</given-names></name>. <article-title>Subthreshold depression as a risk indicator for major depressive disorder: a systematic review of prospective studies</article-title>. <source>Acta Psychiatr Scand</source>. Wiley Online Library; <year>2004</year>;<volume>109</volume>: <fpage>325</fpage>–<lpage>331</lpage>. <pub-id pub-id-type="doi">10.1111/j.1600-0447.2004.00301.x</pub-id>
<?supplied-pmid 15049768?><pub-id pub-id-type="pmid">15049768</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref033">
                <label>33</label>
                <mixed-citation publication-type="journal"><name><surname>Lewinsohn</surname><given-names>PM</given-names></name>, <name><surname>Solomon</surname><given-names>A</given-names></name>, <name><surname>Seeley</surname><given-names>JR</given-names></name>, <name><surname>Zeiss</surname><given-names>A</given-names></name>. <article-title>Clinical implications of" subthreshold" depressive symptoms</article-title>. <source>J Abnorm Psychol</source>. American Psychological Association; <year>2000</year>;<volume>109</volume>: <fpage>345</fpage><?supplied-pmid 10895574?><pub-id pub-id-type="pmid">10895574</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref034">
                <label>34</label>
                <mixed-citation publication-type="journal"><name><surname>Smith</surname><given-names>KG</given-names></name>, <name><surname>Fogerty</surname><given-names>D</given-names></name>. <article-title>Speech recognition error patterns for steady-state noise and interrupted speech</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>2017</year>;<volume>142</volume>: <fpage>EL306</fpage>–<lpage>EL312</lpage>. <pub-id pub-id-type="doi">10.1121/1.5003916</pub-id>
<?supplied-pmid 28964050?><pub-id pub-id-type="pmid">28964050</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref035">
                <label>35</label>
                <mixed-citation publication-type="journal"><name><surname>Toth</surname><given-names>MA</given-names></name>, <name><surname>García Lecumberri</surname><given-names>ML</given-names></name>, <name><surname>Tang</surname><given-names>Y</given-names></name>, <name><surname>Cooke</surname><given-names>M</given-names></name>. <article-title>A corpus of noise-induced word misperceptions for Spanish</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>2015</year>;<volume>137</volume>: <fpage>EL184</fpage>–<lpage>EL189</lpage>. <pub-id pub-id-type="doi">10.1121/1.4905877</pub-id>
<?supplied-pmid 25698048?><pub-id pub-id-type="pmid">25698048</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref036">
                <label>36</label>
                <mixed-citation publication-type="journal"><name><surname>Phatak</surname><given-names>SA</given-names></name>, <name><surname>Allen</surname><given-names>JB</given-names></name>. <article-title>Consonant and vowel confusions in speech-weighted noise</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>2007</year>;<volume>121</volume>: <fpage>2312</fpage>–<lpage>2326</lpage>. <pub-id pub-id-type="doi">10.1121/1.2642397</pub-id>
<?supplied-pmid 17471744?><pub-id pub-id-type="pmid">17471744</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref037">
                <label>37</label>
                <mixed-citation publication-type="journal"><name><surname>Miller</surname><given-names>GA</given-names></name>, <name><surname>Nicely</surname><given-names>PE</given-names></name>. <article-title>An analysis of perceptual confusions among some English consonants</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>1955</year>;<volume>27</volume>: <fpage>338</fpage>–<lpage>352</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0220928.ref038">
                <label>38</label>
                <mixed-citation publication-type="journal"><name><surname>Marxer</surname><given-names>R</given-names></name>, <name><surname>Barker</surname><given-names>J</given-names></name>, <name><surname>Cooke</surname><given-names>M</given-names></name>, <name><surname>Garcia Lecumberri</surname><given-names>ML</given-names></name>. <article-title>A corpus of noise-induced word misperceptions for English</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>2016</year>;<volume>140</volume>: <fpage>EL458</fpage>–<lpage>EL463</lpage>. <pub-id pub-id-type="doi">10.1121/1.4967185</pub-id>
<?supplied-pmid 27908057?><pub-id pub-id-type="pmid">27908057</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref039">
                <label>39</label>
                <mixed-citation publication-type="book"><name><surname>Lecumberri</surname><given-names>MLG</given-names></name>, <name><surname>Barker</surname><given-names>J</given-names></name>, <name><surname>Marxer</surname><given-names>R</given-names></name>, <name><surname>Cooke</surname><given-names>M</given-names></name>. <source>Language Effects in Noise-Induced Word Misperceptions</source>. <publisher-name>INTERSPEECH</publisher-name><year>2016</year> pp. <fpage>640</fpage>–<lpage>644</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0220928.ref040">
                <label>40</label>
                <mixed-citation publication-type="journal"><name><surname>Jürgens</surname><given-names>T</given-names></name>, <name><surname>Brand</surname><given-names>T</given-names></name>. <article-title>Microscopic prediction of speech recognition for listeners with normal hearing in noise using an auditory model</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>2009</year>;<volume>126</volume>: <fpage>2635</fpage>–<lpage>2648</lpage>. <pub-id pub-id-type="doi">10.1121/1.3224721</pub-id>
<?supplied-pmid 19894841?><pub-id pub-id-type="pmid">19894841</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref041">
                <label>41</label>
                <mixed-citation publication-type="journal"><name><surname>Geravanchizadeh</surname><given-names>M</given-names></name>, <name><surname>Fallah</surname><given-names>A</given-names></name>. <article-title>Microscopic prediction of speech intelligibility in spatially distributed speech-shaped noise for normal-hearing listeners</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>2015</year>;<volume>138</volume>: <fpage>4004</fpage>–<lpage>4015</lpage>. <pub-id pub-id-type="doi">10.1121/1.4938230</pub-id>
<?supplied-pmid 26723354?><pub-id pub-id-type="pmid">26723354</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref042">
                <label>42</label>
                <mixed-citation publication-type="journal"><name><surname>Cooke</surname><given-names>M</given-names></name>. <article-title>A glimpsing model of speech perception in noise</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>2006</year>;<volume>119</volume>: <fpage>1562</fpage>–<lpage>1573</lpage>. <pub-id pub-id-type="doi">10.1121/1.2166600</pub-id>
<?supplied-pmid 16583901?><pub-id pub-id-type="pmid">16583901</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref043">
                <label>43</label>
                <mixed-citation publication-type="journal"><name><surname>Zinszer</surname><given-names>BD</given-names></name>, <name><surname>Riggs</surname><given-names>M</given-names></name>, <name><surname>Reetzke</surname><given-names>R</given-names></name>, <name><surname>Chandrasekaran</surname><given-names>B</given-names></name>. <article-title>Error patterns of native and non-native listeners’ perception of speech in noise</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>2019</year>;<volume>145</volume>: <fpage>EL129</fpage>–<lpage>EL135</lpage>. <pub-id pub-id-type="doi">10.1121/1.5087271</pub-id>
<?supplied-pmid 30823795?><pub-id pub-id-type="pmid">30823795</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref044">
                <label>44</label>
                <mixed-citation publication-type="journal"><name><surname>Cornblatt</surname><given-names>BA</given-names></name>, <name><surname>Lenzenweger</surname><given-names>MF</given-names></name>, <name><surname>Erlenmeyer-Kimling</surname><given-names>L</given-names></name>. <article-title>The continuous performance test, identical pairs version: II. Contrasting attentional profiles in schizophrenic and depressed patients</article-title>. <source>Psychiatry Res</source>. Elsevier; <year>1989</year>;<volume>29</volume>: <fpage>65</fpage>–<lpage>85</lpage>. <?supplied-pmid 2772099?><pub-id pub-id-type="pmid">2772099</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref045">
                <label>45</label>
                <mixed-citation publication-type="journal"><name><surname>Lemelin</surname><given-names>S</given-names></name>, <name><surname>Baruch</surname><given-names>P</given-names></name>, <name><surname>Vincent</surname><given-names>A</given-names></name>, <name><surname>Everett</surname><given-names>J</given-names></name>, <name><surname>Vincent</surname><given-names>P</given-names></name>. <article-title>Distractibility and processing resource deficit in major depression. Evidence for two deficient attentional processing models</article-title>. <source>J Nerv Ment Dis</source>. LWW; <year>1997</year>;<volume>185</volume>: <fpage>542</fpage>–<lpage>548</lpage>. <pub-id pub-id-type="doi">10.1097/00005053-199709000-00002</pub-id>
<?supplied-pmid 9307615?><pub-id pub-id-type="pmid">9307615</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref046">
                <label>46</label>
                <mixed-citation publication-type="journal"><name><surname>Lepistö</surname><given-names>T</given-names></name>, <name><surname>Soininen</surname><given-names>M</given-names></name>, <name><surname>Čeponien</surname><given-names>R</given-names></name>, <name><surname>Almqvist</surname><given-names>F</given-names></name>, <name><surname>Näätänen</surname><given-names>R</given-names></name>, <name><surname>Aronen</surname><given-names>ET</given-names></name>. <article-title>Auditory event-related potential indices of increased distractibility in children with major depression</article-title>. <source>Clin Neurophysiol</source>. Elsevier; <year>2004</year>;<volume>115</volume>: <fpage>620</fpage>–<lpage>627</lpage>. <pub-id pub-id-type="doi">10.1016/j.clinph.2003.10.020</pub-id>
<?supplied-pmid 15036058?><pub-id pub-id-type="pmid">15036058</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref047">
                <label>47</label>
                <mixed-citation publication-type="journal"><name><surname>Desseilles</surname><given-names>M</given-names></name>, <name><surname>Balteau</surname><given-names>E</given-names></name>, <name><surname>Sterpenich</surname><given-names>V</given-names></name>, <name><surname>Dang-Vu</surname><given-names>TT</given-names></name>, <name><surname>Darsaud</surname><given-names>A</given-names></name>, <name><surname>Vandewalle</surname><given-names>G</given-names></name>, <etal>et al</etal><article-title>Abnormal neural filtering of irrelevant visual information in depression</article-title>. <source>J Neurosci. Soc Neuroscience</source>; <year>2009</year>;<volume>29</volume>: <fpage>1395</fpage>–<lpage>1403</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0220928.ref048">
                <label>48</label>
                <mixed-citation publication-type="journal"><name><surname>Sheehan</surname><given-names>D</given-names></name>, <name><surname>Lecrubier</surname><given-names>Y</given-names></name>, <name><surname>Sheehan</surname><given-names>KH</given-names></name>, <name><surname>Sheehan</surname><given-names>K</given-names></name>, <name><surname>Amorim</surname><given-names>P</given-names></name>, <name><surname>Janavs</surname><given-names>J</given-names></name>, <etal>et al</etal><article-title>Diagnostic Psychiatric Interview for DSM-IV and ICD-10</article-title>. <source>J Clin psychiatry</source>. <year>1998</year>;<volume>59</volume>: <fpage>22</fpage>–<lpage>33</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0220928.ref049">
                <label>49</label>
                <mixed-citation publication-type="journal"><name><surname>Radloff</surname><given-names>LS</given-names></name>. <article-title>The CES-D scale: A self-report depression scale for research in the general population</article-title>. <source>Appl Psychol Meas</source>. Sage Publications Sage CA: Thousand Oaks, CA; <year>1977</year>;<volume>1</volume>: <fpage>385</fpage>–<lpage>401</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0220928.ref050">
                <label>50</label>
                <mixed-citation publication-type="book"><name><surname>Bamford</surname><given-names>J</given-names></name>, <name><surname>Wilson</surname><given-names>I</given-names></name>, <name><surname>Bench</surname><given-names>J</given-names></name>, <name><surname>Bamford</surname><given-names>J</given-names></name>. <chapter-title>Methodological considerations and practical aspects of the BKB sentence lists</chapter-title><source>Speech-hearing tests Spok Lang Hear Child</source>. <publisher-name>Academic Press</publisher-name><publisher-loc>London</publisher-loc>; <year>1979</year>; <fpage>148</fpage>–<lpage>187</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0220928.ref051">
                <label>51</label>
                <mixed-citation publication-type="journal"><name><surname>Van Engen</surname><given-names>KJ</given-names></name>. <article-title>Speech-in-speech recognition: A training study</article-title>. <source>Lang Cogn Process</source>. Taylor &amp; Francis; <year>2012</year>;<volume>27</volume>: <fpage>1089</fpage>–<lpage>1107</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0220928.ref052">
                <label>52</label>
                <mixed-citation publication-type="journal"><name><surname>Van Engen</surname><given-names>KJ</given-names></name>, <name><surname>Baese-Berk</surname><given-names>M</given-names></name>, <name><surname>Baker</surname><given-names>RE</given-names></name>, <name><surname>Choi</surname><given-names>A</given-names></name>, <name><surname>Kim</surname><given-names>M</given-names></name>, <name><surname>Bradlow</surname><given-names>AR</given-names></name>. <article-title>The Wildcat Corpus of native-and foreign-accented English: Communicative efficiency across conversational dyads with varying language alignment profiles</article-title>. <source>Lang Speech</source>. Sage Publications; <year>2010</year>;<volume>53</volume>: <fpage>510</fpage>–<lpage>540</lpage>. <pub-id pub-id-type="doi">10.1177/0023830910372495</pub-id>
<?supplied-pmid 21313992?><pub-id pub-id-type="pmid">21313992</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref053">
                <label>53</label>
                <mixed-citation publication-type="journal"><name><surname>Bradlow</surname><given-names>AR</given-names></name>, <name><surname>Alexander</surname><given-names>JA</given-names></name>. <article-title>Semantic and phonetic enhancements for speech-in-noise recognition by native and non-native listeners</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>2007</year>;<volume>121</volume>: <fpage>2339</fpage>–<lpage>2349</lpage>. <pub-id pub-id-type="doi">10.1121/1.2642103</pub-id>
<?supplied-pmid 17471746?><pub-id pub-id-type="pmid">17471746</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref054">
                <label>54</label>
                <mixed-citation publication-type="journal"><name><surname>Riggs</surname><given-names>M</given-names></name>, <name><surname>Zinszer</surname><given-names>BD</given-names></name>, <name><surname>Reetzke</surname><given-names>R</given-names></name>., <name><surname>Chandrasekaran</surname><given-names>B</given-names></name>. <source>SPIN-Scorcerer</source> [Internet]. <year>2018</year> Available: <ext-link ext-link-type="uri" xlink:href="http://spin-scorcerer.github.io">http://spin-scorcerer.github.io</ext-link></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref055">
                <label>55</label>
                <mixed-citation publication-type="journal"><name><surname>Needleman</surname><given-names>SB</given-names></name>, <name><surname>Wunsch</surname><given-names>CD</given-names></name>. <article-title>A general method applicable to the search for similarities in the amino acid sequence of two proteins</article-title>. <source>J Mol Biol</source>. Elsevier; <year>1970</year>;<volume>48</volume>: <fpage>443</fpage>–<lpage>453</lpage>. <pub-id pub-id-type="doi">10.1016/0022-2836(70)90057-4</pub-id>
<?supplied-pmid 5420325?><pub-id pub-id-type="pmid">5420325</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref056">
                <label>56</label>
                <mixed-citation publication-type="journal"><name><surname>Levenshtein</surname><given-names>VI</given-names></name>. <article-title>Binary codes capable of correcting deletions, insertions, and reversals</article-title>. <source>Soviet physics doklady</source>. <year>1966</year> pp. <fpage>707</fpage>–<lpage>710</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0220928.ref057">
                <label>57</label>
                <mixed-citation publication-type="journal"><name><surname>Smedt</surname><given-names>T De</given-names></name>, <name><surname>Daelemans</surname><given-names>W</given-names></name>. <article-title>Pattern for python</article-title>. <source>J Mach Learn Res</source>. <year>2012</year>;<volume>13</volume>: <fpage>2063</fpage>–<lpage>2067</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0220928.ref058">
                <label>58</label>
                <mixed-citation publication-type="journal"><name><surname>Bates</surname><given-names>D</given-names></name>, <name><surname>Maechler</surname><given-names>M</given-names></name>, <name><surname>Bolker</surname><given-names>B</given-names></name>, <name><surname>Walker</surname><given-names>S</given-names></name>. <source>lme4: Linear mixed-effects models using Eigen and S4. R Packag version</source>. <year>2014</year>;<volume>1</volume>.</mixed-citation>
              </ref>
              <ref id="pone.0220928.ref059">
                <label>59</label>
                <mixed-citation publication-type="book"><collab>Team RC</collab>. <source>R: A language and environment for statistical computing</source>. <publisher-name>R Foundation for Statistical Computing</publisher-name>, <publisher-loc>Vienna, Austria</publisher-loc> 2013. <year>2014</year>.</mixed-citation>
              </ref>
              <ref id="pone.0220928.ref060">
                <label>60</label>
                <mixed-citation publication-type="journal"><name><surname>Baayen</surname><given-names>RH</given-names></name>, <name><surname>Davidson</surname><given-names>DJ</given-names></name>, <name><surname>Bates</surname><given-names>DM</given-names></name>. <article-title>Mixed-effects modeling with crossed random effects for subjects and items</article-title>. <source>J Mem Lang</source>. Elsevier; <year>2008</year>;<volume>59</volume>: <fpage>390</fpage>–<lpage>412</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0220928.ref061">
                <label>61</label>
                <mixed-citation publication-type="book"><name><surname>Hothorn</surname><given-names>T</given-names></name>, <name><surname>Bretz</surname><given-names>F</given-names></name>, <name><surname>Westfall</surname><given-names>P</given-names></name>, <name><surname>Heiberger</surname><given-names>RM</given-names></name>. <source>Multcomp: simultaneous inference in general parametric models</source>. R package version 1.0–0. <publisher-name>R Found Stat Comput Vienna</publisher-name>, <publisher-loc>Austria</publisher-loc>
<year>2008</year>;</mixed-citation>
              </ref>
              <ref id="pone.0220928.ref062">
                <label>62</label>
                <mixed-citation publication-type="journal"><name><surname>Benjamini</surname><given-names>Y</given-names></name>, <name><surname>Hochberg</surname><given-names>Y</given-names></name>. <article-title>Controlling the false discovery rate: a practical and powerful approach to multiple testing</article-title>. <source>J R Stat Soc Ser B</source>. JSTOR; <year>1995</year>; <fpage>289</fpage>–<lpage>300</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0220928.ref063">
                <label>63</label>
                <mixed-citation publication-type="journal"><name><surname>Pogue-Geile</surname><given-names>MF</given-names></name>, <name><surname>Oltmanns</surname><given-names>TF</given-names></name>. <article-title>Sentence perception and distractibility in schizophrenic, manic, and depressed patients</article-title>. <source>J Abnorm Psychol</source>. American Psychological Association; <year>1980</year>;<volume>89</volume>: <fpage>115</fpage><?supplied-pmid 7365124?><pub-id pub-id-type="pmid">7365124</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref064">
                <label>64</label>
                <mixed-citation publication-type="journal"><name><surname>Brungart</surname><given-names>DS</given-names></name>, <name><surname>Simpson</surname><given-names>BD</given-names></name>, <name><surname>Ericson</surname><given-names>MA</given-names></name>, <name><surname>Scott</surname><given-names>KR</given-names></name>. <article-title>Informational and energetic masking effects in the perception of multiple simultaneous talkers</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>2001</year>;<volume>110</volume>: <fpage>2527</fpage>–<lpage>2538</lpage>. <pub-id pub-id-type="doi">10.1121/1.1408946</pub-id>
<?supplied-pmid 11757942?><pub-id pub-id-type="pmid">11757942</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0220928.ref065">
                <label>65</label>
                <mixed-citation publication-type="journal"><name><surname>Helfer</surname><given-names>KS</given-names></name>, <name><surname>Merchant</surname><given-names>GR</given-names></name>, <name><surname>Freyman</surname><given-names>RL</given-names></name>. <article-title>Aging and the effect of target-masker alignment</article-title>. <source>J Acoust Soc Am</source>. ASA; <year>2016</year>;<volume>140</volume>: <fpage>3844</fpage>–<lpage>3853</lpage>. <pub-id pub-id-type="doi">10.1121/1.4967297</pub-id>
<?supplied-pmid 27908027?><pub-id pub-id-type="pmid">27908027</pub-id></mixed-citation>
              </ref>
            </ref-list>
          </back>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
