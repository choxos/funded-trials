<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2024-05-03T04:08:15Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:7846613" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:7846613</identifier>
        <datestamp>2021-02-01</datestamp>
        <setSpec>scirep</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" article-type="research-article">
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">Sci Rep</journal-id>
              <journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id>
              <journal-title-group>
                <journal-title>Scientific Reports</journal-title>
              </journal-title-group>
              <issn pub-type="epub">2045-2322</issn>
              <publisher>
                <publisher-name>Nature Publishing Group UK</publisher-name>
                <publisher-loc>London</publisher-loc>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC7846613</article-id>
              <article-id pub-id-type="pmcid">PMC7846613</article-id>
              <article-id pub-id-type="pmc-uid">7846613</article-id>
              <article-id pub-id-type="pmid">33514817</article-id>
              <article-id pub-id-type="publisher-id">82098</article-id>
              <article-id pub-id-type="doi">10.1038/s41598-021-82098-3</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Article</subject>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>A multilayer multimodal detection and prediction model based on explainable artificial intelligence for Alzheimer’s disease</article-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author" corresp="yes">
                  <name>
                    <surname>El-Sappagh</surname>
                    <given-names>Shaker</given-names>
                  </name>
                  <address>
                    <email>shaker.elsappagh@usc.es</email>
                  </address>
                  <xref ref-type="aff" rid="Aff1">1</xref>
                  <xref ref-type="aff" rid="Aff2">2</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Alonso</surname>
                    <given-names>Jose M.</given-names>
                  </name>
                  <xref ref-type="aff" rid="Aff3">3</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Islam</surname>
                    <given-names>S. M. Riazul</given-names>
                  </name>
                  <xref ref-type="aff" rid="Aff4">4</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Sultan</surname>
                    <given-names>Ahmad M.</given-names>
                  </name>
                  <xref ref-type="aff" rid="Aff5">5</xref>
                </contrib>
                <contrib contrib-type="author" corresp="yes">
                  <name>
                    <surname>Kwak</surname>
                    <given-names>Kyung Sup</given-names>
                  </name>
                  <address>
                    <email>kskwak@inha.ac.kr</email>
                  </address>
                  <xref ref-type="aff" rid="Aff6">6</xref>
                </contrib>
                <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.11794.3a</institution-id><institution-id institution-id-type="ISNI">0000000109410645</institution-id><institution>Centro Singular de Investigación en Tecnoloxías Intelixentes (CiTIUS), </institution><institution>Universidade de Santiago de Compostela, </institution></institution-wrap>15782 Santiago de Compostela, Spain </aff>
                <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.411660.4</institution-id><institution-id institution-id-type="ISNI">0000 0004 0621 2741</institution-id><institution>Information Systems Department, Faculty of Computers and Artificial Intelligence, </institution><institution>Benha University, </institution></institution-wrap>Banha, 13518 Egypt </aff>
                <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.11794.3a</institution-id><institution-id institution-id-type="ISNI">0000000109410645</institution-id><institution>Centro Singular de Investigación en Tecnoloxías Intelixentes, </institution><institution>Universidade de Santiago de Compostela, </institution></institution-wrap>15703 Santiago, Spain </aff>
                <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.263333.4</institution-id><institution-id institution-id-type="ISNI">0000 0001 0727 6358</institution-id><institution>Department of Computer Science and Engineering, </institution><institution>Sejong University, </institution></institution-wrap>209 Neungdong-ro, Gwangjin-gu, Seoul, 05006 Korea </aff>
                <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="GRID">grid.10251.37</institution-id><institution-id institution-id-type="ISNI">0000000103426662</institution-id><institution>Gastrointestinal Surgical Center, Faculty of Medicine, </institution><institution>Mansoura University, </institution></institution-wrap>Mansura, 35516 Egypt </aff>
                <aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="GRID">grid.202119.9</institution-id><institution-id institution-id-type="ISNI">0000 0001 2364 8385</institution-id><institution>Department of Information and Communication Engineering, </institution><institution>Inha University, </institution></institution-wrap>Incheon, 22212 South Korea </aff>
              </contrib-group>
              <pub-date pub-type="epub">
                <day>29</day>
                <month>1</month>
                <year>2021</year>
              </pub-date>
              <pub-date pub-type="pmc-release">
                <day>29</day>
                <month>1</month>
                <year>2021</year>
              </pub-date>
              <pub-date pub-type="collection">
                <year>2021</year>
              </pub-date>
              <volume>11</volume>
              <elocation-id>2660</elocation-id>
              <history>
                <date date-type="received">
                  <day>21</day>
                  <month>10</month>
                  <year>2019</year>
                </date>
                <date date-type="accepted">
                  <day>29</day>
                  <month>12</month>
                  <year>2020</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>© The Author(s) 2021</copyright-statement>
                <license license-type="OpenAccess">
                  <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
                </license>
              </permissions>
              <abstract id="Abs1">
                <p id="Par1">Alzheimer’s disease (AD) is the most common type of dementia. Its diagnosis and progression detection have been intensively studied. Nevertheless, research studies often have little effect on clinical practice mainly due to the following reasons: (1) Most studies depend mainly on a single modality, especially neuroimaging; (2) diagnosis and progression detection are usually studied separately as two independent problems; and (3) current studies concentrate mainly on optimizing the performance of complex machine learning models, while disregarding their explainability. As a result, physicians struggle to interpret these models, and feel it is hard to trust them. In this paper, we carefully develop an accurate and interpretable AD diagnosis and progression detection model. This model provides physicians with accurate decisions along with a set of explanations for every decision. Specifically, the model integrates 11 modalities of 1048 subjects from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) real-world dataset: 294 cognitively normal, 254 stable mild cognitive impairment (MCI), 232 progressive MCI, and 268 AD. It is actually a two-layer model with random forest (RF) as classifier algorithm. In the first layer, the model carries out a multi-class classification for the early diagnosis of AD patients. In the second layer, the model applies binary classification to detect possible MCI-to-AD progression within three years from a baseline diagnosis. The performance of the model is optimized with key markers selected from a large set of biological and clinical measures. Regarding explainability, we provide, for each layer, global and instance-based explanations of the RF classifier by using the SHapley Additive exPlanations (SHAP) feature attribution framework. In addition, we implement 22 explainers based on decision trees and fuzzy rule-based systems to provide complementary justifications for every RF decision in each layer. Furthermore, these explanations are represented in natural language form to help physicians understand the predictions. The designed model achieves a cross-validation accuracy of 93.95% and an F1-score of 93.94% in the first layer, while it achieves a cross-validation accuracy of 87.08% and an F1-Score of 87.09% in the second layer. The resulting system is not only accurate, but also trustworthy, accountable, and medically applicable, thanks to the provided explanations which are broadly consistent with each other and with the AD medical literature. The proposed system can help to enhance the clinical understanding of AD diagnosis and progression processes by providing detailed insights into the effect of different modalities on the disease risk.</p>
              </abstract>
              <kwd-group kwd-group-type="npg-subject">
                <title>Subject terms</title>
                <kwd>Classification and taxonomy</kwd>
                <kwd>Computational neuroscience</kwd>
                <kwd>Data mining</kwd>
                <kwd>Data processing</kwd>
                <kwd>Machine learning</kwd>
              </kwd-group>
              <funding-group>
                <award-group>
                  <funding-source>
                    <institution>National Research Foundation of Korea-Grant funded by the Korean Government (Ministry of Science and ICT)</institution>
                  </funding-source>
                  <award-id>NRF-2017R1A2B2012337</award-id>
                  <award-id>NRF-2017R1A2B2012337</award-id>
                  <award-id>NRF-2017R1A2B2012337</award-id>
                  <award-id>NRF-2017R1A2B2012337</award-id>
                  <award-id>NRF-2017R1A2B2012337</award-id>
                  <principal-award-recipient>
                    <name>
                      <surname>El-Sappagh</surname>
                      <given-names>Shaker</given-names>
                    </name>
                    <name>
                      <surname>Alonso</surname>
                      <given-names>Jose M.</given-names>
                    </name>
                    <name>
                      <surname>Islam</surname>
                      <given-names>S. M. Riazul</given-names>
                    </name>
                    <name>
                      <surname>Sultan</surname>
                      <given-names>Ahmad M.</given-names>
                    </name>
                    <name>
                      <surname>Kwak</surname>
                      <given-names>Kyung Sup</given-names>
                    </name>
                  </principal-award-recipient>
                </award-group>
              </funding-group>
              <custom-meta-group>
                <custom-meta>
                  <meta-name>issue-copyright-statement</meta-name>
                  <meta-value>© The Author(s) 2021</meta-value>
                </custom-meta>
              </custom-meta-group>
            </article-meta>
          </front>
          <body>
            <sec id="Sec1">
              <title>Introduction</title>
              <p id="Par47">Alzheimer’s disease (AD) is a chronic neurodegenerative disease. This irreversible disorder is characterized by abnormal accumulation of amyloid plaques and neurofibrillary tangles in the brain, resulting in progressive decline in memory, thinking and language skills, along with behavioral changes. With increased human life expectancy, 11 million to 16 million elderly people are likely to suffer from AD by 2050<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. As far as we know, there is no effective recovery for this disease. However, early detection is of fundamental importance for timely treatment and progression delay<sup><xref ref-type="bibr" rid="CR2">2</xref>–<xref ref-type="bibr" rid="CR4">4</xref></sup>. Furthermore, prediction of the probable progression of the disease from mild cognitive impairment (MCI) to AD is of critical importance<sup><xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR6">6</xref></sup>. MCI is considered an intermediate stage between age-associated cognitive impairment and AD. For effective treatment, it is therefore essential to detect patients with MCI at high risk of progression to AD<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>. As a result, AD diagnosis and progression detection are multistage in nature. First, physicians determine the category of the patient (MCI or AD). Second, they deeply investigate patient biomarkers to determine progression status to AD from MCI. Most studies in the literature focus either on AD diagnosis<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR8">8</xref>–<xref ref-type="bibr" rid="CR12">12</xref></sup> or MCI progression, i.e., progressive MCI (pMCI) versus stable MCI (sMCI)<sup><xref ref-type="bibr" rid="CR13">13</xref>–<xref ref-type="bibr" rid="CR15">15</xref></sup>. Even if it is highly desirable to deal simultaneously with AD diagnosis and MCI progression, this task is extremely hard mainly due to the multimodality nature that also jeopardizes explainability.</p>
              <p id="Par48">AD symptomatology is multimodal in nature<sup><xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR16">16</xref></sup> correlated with cognitive scores, neuropathology vital signs, symptoms, demographics, medical history, neuropsychological battery, lab tests, etc. Complementary information exists among the modalities, which can be exploited to build powerful classifiers<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>. Therefore, medically intuitive AD detection methods should not rely only on measurements of a unique domain, such as physiological or behavioral symptoms. Alberdi et al.<sup><xref ref-type="bibr" rid="CR1">1</xref></sup> surveyed the AD diagnosis studies based on multimodal data. The combination of multimodalities facilitates the detection of subtle changes in all modalities from the very beginning, which results in reliable diagnoses. Once in the hands of an expert, it is still a challenge to correctly diagnose AD. Usually, medical experts are not able to manually analyze all of these vast and diverse biomarkers, and recognize the so-small behavioral shifts in AD patients until it is too late<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>. AD could be diagnosed after two years of memory problems<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>. There is an emerging need for advanced AD detection and prediction models that can serve as a helping hand for medical practitioners to diagnose or detect the disease earlier and more accurately<sup><xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR19">19</xref>,<xref ref-type="bibr" rid="CR20">20</xref></sup>. These models can be used to build the inference engines of an AD clinical decision support system (CDSS). However, as far as we know there is no CDSS for AD diagnosis and progression detection ready to use at primary care. In this context, two lines of research have been conducted to address the previous challenges: (1) deep learning (DL) techniques which are able to automatically learn complex, non-linear data transformations that optimize performance metrics<sup><xref ref-type="bibr" rid="CR21">21</xref>–<xref ref-type="bibr" rid="CR23">23</xref></sup>; and (2) regular machine learning (ML) techniques, especially support vector machine (SVM) and random forest (RF)<sup><xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR24">24</xref>–<xref ref-type="bibr" rid="CR28">28</xref></sup>.</p>
              <p id="Par49">Unfortunately, all these previous studies focused mainly on improving the system performance while neglecting interpretability issues. Accordingly, although these studies achieved tremendous advances in prediction, they are not expected to be acceptable in the medical environment. There exists a significant gap between academic research outcomes and their effective utilization in medical practice due to several reasons<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>. The entire patient medical history must be considered to achieve intuitive, stable, and robust decisions<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>. Most DL-based methods only concentrate on analysis of neuroimaging, i.e., Magnetic Resonance Imaging (MRI) and Positron Emission Tomography (PET). Nevertheless, Oxtoby and Alexander<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> asserted that neuroimaging is not sufficient for AD diagnosis and studying its progression. Furthermore, it is frequently the case that physicians do not rely on the latest technical approaches and methodologies (e.g., DL and RF), despite their high accuracy<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>, because complex model performance and explainability are in apparent conflict- i.e., the search for a good performance-explainability trade-off is required. Most of these approaches and schemes are inherently opaque, not understandable, and unable to easily answer the following straightforward questions. Why/how has it reached a specific decision, and why/how is it medically relevant<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>? The patterns learned from datasets by using complex ML algorithms do not necessarily carry correct and comprehensible knowledge. Thus, medical experts do not trust decisions provided by black-box models without comprehensive and easy-to-understand explanations<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>. For these reasons, the ML techniques employed in the clinical domain normally do not consider sophisticated models, resorting instead to simpler and interpretable (e.g., linear) models at the expense of accuracy<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>. Many studies have tried to open the black box of complex models and provide an explanation of their decisions, either by understanding how the models work or by explaining their decisions<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>. This new trend is called accountable, transparent, actionable, or explainable Artificial Intelligence (AI), or just XAI for short. Explainability is the ability of ML algorithms to (mathematically) explain or justify their results using terms which are understandable to humans.</p>
              <p id="Par50">A CDSS should be based only on ML models that provide a balance between accuracy and explainability. These models are expected to provide sufficient information about the relationship between input features and predictions, and to allow users to answer questions like the following. Which features are the key players in the prediction of interest? Why am I deemed as normal/MCI/AD in the medical diagnosis? For these reasons, the second line of research introduced above (i.e., a CDSS based on regular ML techniques) seems more intuitive and medically acceptable. Regular ML techniques involving linear models and rule-induction algorithms (e.g., a decision tree [DT]<sup><xref ref-type="bibr" rid="CR34">34</xref></sup> or a fuzzy rule-based system [FRBS]<sup><xref ref-type="bibr" rid="CR35">35</xref>,<xref ref-type="bibr" rid="CR36">36</xref></sup>) are usually preferred when the priority is to generate explainable models<sup><xref ref-type="bibr" rid="CR18">18</xref>,<xref ref-type="bibr" rid="CR37">37</xref>–<xref ref-type="bibr" rid="CR39">39</xref></sup>. Unfortunately, these models are not always accurate enough<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>. One solution is to use an accurate algorithm as an oracle for the classification purpose, and a collection of carefully designed interpretable models (which behave as digital twins of the oracle, i.e., they imitate the classification behavior of the oracle) as candidates to generate explanations of the output provided by the oracle<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>. The other solution is to open the black box and collect the explanations from the opaque model itself. For example, some studies have extracted interpretable rules from black-box models such as neural networks and SVMs<sup><xref ref-type="bibr" rid="CR42">42</xref>,<xref ref-type="bibr" rid="CR43">43</xref></sup>. In the case of RF, Brieman<sup><xref ref-type="bibr" rid="CR44">44</xref></sup> asserted that it is an A + predictor for performance, but rates an F on interpretability. More recently, some authors have shown how the behavior of RF can be interpreted to some degree<sup><xref ref-type="bibr" rid="CR31">31</xref>,<xref ref-type="bibr" rid="CR45">45</xref></sup>. There exists no study in the literature, which use the RF algorithm in the core of an explainable CDSS system for AD diagnoses and progression detection.</p>
              <p id="Par51">Despite the current research effort, AD detection and progression prediction are still openly challenging problems, due to the limited accuracy and limited explainability of existing solutions. The medical domain requires both accurate and explainable AI models. In this paper, we therefore develop a new RF-based explainable AD detection and progression prediction model. Our contributions are as follows:<list list-type="order"><list-item><p id="Par52">We demonstrate how to retain interpretability, even when a complex ensemble model like RF is used. The objective of this approach is two-fold: (1) To illustrate the development and validation process of a two-layer computational framework for diagnosing AD patients and predicting pMCI within three years from baseline diagnosis; and (2) to describe how to provide detailed and multiple explanations for the ML decisions. The resulting model provides physicians with a good balance between accuracy and explainability.</p></list-item><list-item><p id="Par53">We build accurate ML ensemble classifiers based on RF for the two layers; utilizing multimodal AD datasets collected from the Alzheimer’s Disease Neuroimaging Initiative (ADNI). We employ a comprehensive list of modalities to diagnose AD and predict its progression, in agreement with a physician who was taken as domain expert.</p></list-item><list-item><p id="Par54">We build 22 explainers, based on a set of interpretable ML techniques (i.e. DT and FRBS), ready to explain to physicians the outcome of the two-layer framework. This reverse engineering method is called a black-box outcome explanation<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>. All explainers’ decisions compatible with RF decisions are used to provide physicians with a pool of plausible explanations. In analogy with a panel of experts who may have different experience and background, each explanation comes from a different explainer which pays attention to the most relevant features for different modalities, and comes along with information about the reliability of the explainer in terms of its accuracy. The consistency and coherence of such explanations are validated by domain experts and ranked according to their explainability-accuracy trade-off. Moreover, they are mapped to a human-friendly language for easy understanding.</p></list-item><list-item><p id="Par55">We provide physicians with some insights into driving factors of our prediction model from multiple points of view including natural language, visualization, and feature importance based on SHapley Additive exPlanations (SHAP).</p></list-item></list></p>
              <p id="Par56">The rest of this paper is organized as follows. Section 2 presents and discusses the main reported results. Section 3 introduces the datasets used and goes in depth with technical details of the proposed method. Section 4 concludes the paper.</p>
            </sec>
            <sec id="Sec2">
              <title>Results and discussion</title>
              <sec id="Sec3">
                <title>Identification of informative AD features</title>
                <p id="Par57">To reduce computational complexity that comes with the high dimensionality nature of the ADNI, we selected the most relevant feature set using automatic feature selection strategy. For each layer, the full dataset is stratified and randomly divided into a model development set [<inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S1$$\end{document}</tex-math><mml:math id="M2"><mml:mrow><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq1.gif"/></alternatives></inline-formula>] and a testing set [<inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S2$$\end{document}</tex-math><mml:math id="M4"><mml:mrow><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq2.gif"/></alternatives></inline-formula>]. <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S1$$\end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq3.gif"/></alternatives></inline-formula> and <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S2$$\end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq4.gif"/></alternatives></inline-formula> are filtered to create the best feature sets <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MS1$$\end{document}</tex-math><mml:math id="M10"><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq5.gif"/></alternatives></inline-formula> and <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MS2$$\end{document}</tex-math><mml:math id="M12"><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq6.gif"/></alternatives></inline-formula>, respectively (see the Feature Selection and Modeling Approach Section; in Material and Methods). The new sets are used to tune, train, and tests the utilized ML models. Training and tuning of ML models is done with cross-validation over <italic>MS1</italic> while <italic>MS2</italic> is reserved to provide readers with final test evaluation, mainly regarding some illustrative examples of the explainability of the proposed framework.</p>
                <p id="Par58">Figure <xref rid="Fig1" ref-type="fig">1</xref>A shows the performance of different subset sizes assessed with RF-RFE (A.1), SVM-RFE (A.2), and GB-RFE (A.3) for the first layer. For different combinations of features, the accuracy from RF, SVM, and GB was measured, and the subset of features with the best performance was detained. As summarized in Table <xref rid="Tab1" ref-type="table">1</xref>, for RF-RFE, we obtained a combination of 28 features [cognitive scores (8), genetics (5), lab tests (1), demographics (3), MRI (2), neuropsychological battery (6), and PET (3)] to attain the highest predictive accuracy of 94.4% (see Supplementary File [part 2], Table <xref rid="MOESM1" ref-type="media">T1</xref>). Because the optimal subset of features derived using the RFE-RF approach yields the maximum accuracy, we utilized it for training the classification model. These features form about 15% of the whole feature set. Inspired by<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>, the features selected with RF-RFE are clustered into six modality kinds: (1) cognitive scores (CS) [eight features]; (2) neuropsychological battery (NB) [six features]; (3) MRI [two features], (4) PET [three features], (5) genetics [five features], and (6) medical history (MH) (lab test and demographics) [four features]. It is worth noting that the selected features based on RF-RFE are the most discriminant and informative features for the current classification problem (<italic>P</italic> &lt; 0.05, Kruskal–Wallis test). The list of non-selected features does not add discriminative values with RFE; however, as asserted by our domain experts, many of these neglected features could provide additional knowledge to understand the made decisions (i.e., they include critical values for model’s explainability in accordance with physicians’ intuition and background). The different modalities were screened to investigate whether a cost-effective and non-invasive subset of features have a higher discriminative power than the whole dataset.<fig id="Fig1"><label>Figure 1</label><caption><p>Selected features for both layers based on three different techniques of SVM, RF, and GB. The first row is for the first layer, and the second row is for the second layer.</p></caption><graphic xlink:href="41598_2021_82098_Fig1_HTML" id="MO1"/></fig><table-wrap id="Tab1"><label>Table 1</label><caption><p>Performance of the RFE for the two layers.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Layer</th><th align="left">Model</th><th align="left">No. of features</th><th align="left">Accuracy (%)</th></tr></thead><tbody><tr><td align="left" rowspan="3">First Layer</td><td align="left"><bold>RF-RFE</bold></td><td char="." align="char"><bold>28</bold></td><td char="." align="char"><bold>94.40</bold></td></tr><tr><td align="left">SVM-RFE</td><td char="." align="char">12</td><td char="." align="char">92.40</td></tr><tr><td align="left">GB-RFE</td><td char="." align="char">14</td><td char="." align="char">92.60</td></tr><tr><td align="left" rowspan="3">Second Layer</td><td align="left"><bold>RF-RFE</bold></td><td char="." align="char"><bold>36</bold></td><td char="." align="char"><bold>86.80</bold></td></tr><tr><td align="left">SVM-RFE</td><td char="." align="char">17</td><td char="." align="char">82.60</td></tr><tr><td align="left">GB-RFE</td><td char="." align="char">39</td><td char="." align="char">86.00</td></tr></tbody></table></table-wrap></p>
                <p id="Par59">Figure <xref rid="Fig1" ref-type="fig">1</xref>B shows the performance of different subset sizes assessed with RF-RFE (B.1), SVM-RFE (B.2), and GB-RFE (B.3) for the second layer. The accuracy of RF, SVM, and GB was calculated for different combinations of features, and the subset of features with the best performance was taken. Similar to the First Layer, the RFE algorithm attained a higher performance when combined with RF than GB and SVM. With RF-RFE (see Table <xref rid="Tab1" ref-type="table">1</xref>), the combination of 36 features [cognitive scores (7), genetics (5), lab tests (6), demographics (1), MRI (5), neuropsychological battery (7), PET (3), and vital signs (2)] achieves the highest predictive accuracy at 86.8%. Accordingly, we used the RF-RFE feature set for training the classification model. These features formed about 19% of the total feature set, (see Supplementary File [part 2], Table <xref rid="MOESM1" ref-type="media">T1</xref>). Furthermore, we grouped this list of features into five modality types: (1) cognitive and functional assessments (CFA) (CS and NB), (2) MRI, (3) PET, (4) genetics, and (5) MH (lab tests, age, and vital signs). As with the First Layer, we analyzed the performance of different RF classifiers constructed using each modality (as well as their combinations).</p>
              </sec>
              <sec id="Sec4">
                <title>First layer: early AD detection performance</title>
                <p id="Par60">The First Layer in the framework is responsible for detecting AD patients from CN and MCI patients. To determine the smallest number of features that produces the most accurate results, we performed a set of experiments using different combination of modalities. Table <xref rid="Tab2" ref-type="table">2</xref> shows the performance obtained for the multiclass classification problem (i.e., CN, MCI, and AD) by using the whole training dataset and different combinations of six selected modalities (CS, NB, MRI, PET, MH, and genetics) and RF classifier (see the Random Forest for Classification Section). The models’ performance has been evaluated using the area under the receiver operating characteristic curve (AUC), precision, recall, accuracy (AC), and F1-score (F1) metrics (see the Model Performance Evaluation Metrics; in <xref rid="Sec15" ref-type="sec">Material and methods</xref>). When the whole feature set is used, the model has a multiclass classification accuracy (MCA) of 93.42 ± 2.73% based on tenfold CV. We can see that the CS modality has the highest accuracy (MCA = 92.00 ± 2.26%), compared to other single modalities. As a result, the CS modality was combined with other modalities to test the improvement in the model performance. Please note that, although adding more features could increase the model’s confidence, it also adds additional noises. The two-modality combination CS + NB improved the CS accuracy by about 1%, i.e., MCA = 93.00 ± 2.61%. We notice that the standard deviation of the combined CS + NB data slightly increased compared to the CS dataset alone, but still it is less than the standard deviation of the models based on the whole dataset. After integration of the CS + NB modality with the other types of data, the genetics data improved the accuracy of the system to 93.95 ± 2.30%. We discover that the RF shows more confidence based on the CS + NB + Genetics dataset than CS + NB dataset. This is because its performance has lower standard deviation. The resulting modality of CS + NB + Genetics was tested by combining it with MRI, PET, and MH. However, the performance was not enhanced, and the models become noisier. As a result, the combination of CS, NB, and Genetics was selected as the one producing the best performance.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Random Forest performance validation for detecting AD patients based on <italic>tenfold cross-validation</italic>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Modalities</th><th align="left" colspan="3">Precision (%)</th><th align="left" colspan="3">Recall (%)</th><th align="left" rowspan="2">MCA (%)</th><th align="left" rowspan="2">MCF (%)</th></tr><tr><th align="left">CN</th><th align="left">MCI</th><th align="left">AD</th><th align="left">CN</th><th align="left">MCI</th><th align="left">AD</th></tr></thead><tbody><tr><td align="left"><bold>All modalities</bold></td><td char="." align="char"><bold>98.83 ± 1.33</bold></td><td char="." align="char"><bold>90.91 ± 2.55</bold></td><td char="." align="char"><bold>92.41 ± 1.99</bold></td><td char="." align="char"><bold>96.21 ± 1.11</bold></td><td char="." align="char"><bold>95.45 ± 2.00</bold></td><td char="." align="char"><bold>86.61 ± 2.10</bold></td><td char="." align="char"><bold>93.42 ± 2.73</bold></td><td char="." align="char"><bold>93.39 ± 2.19</bold></td></tr><tr><td align="left"><italic>CS</italic></td><td char="." align="char"><italic>99.60</italic> ± <italic>0.17</italic></td><td char="." align="char"><italic>89.76</italic> ± <italic>1.99</italic></td><td char="." align="char"><italic>88.51</italic> ± <italic>1.04</italic></td><td char="." align="char"><italic>93.94</italic> ± <italic>0.18</italic></td><td char="." align="char"><italic>93.64</italic> ± <italic>1.08</italic></td><td char="." align="char"><italic>87.03</italic> ± <italic>2.09</italic></td><td char="." align="char"><italic>92.00</italic> ± <italic>2.26</italic></td><td char="." align="char"><italic>92.08</italic> ± <italic>2.00</italic></td></tr><tr><td align="left">NB</td><td char="." align="char">84.86 ± 1.32</td><td char="." align="char">74.11 ± 2.06</td><td char="." align="char">77.93 ± 2.00</td><td char="." align="char">80.68 ± 1.09</td><td char="." align="char">80.68 ± 1.92</td><td char="." align="char">69.46 ± 2.01</td><td char="." align="char">77.83 ± 2.33</td><td char="." align="char">77.94 ± 2.10</td></tr><tr><td align="left">MRI</td><td char="." align="char">45.19 ± 2.46</td><td char="." align="char">47.16 ± 4.34</td><td char="." align="char">48.99 ± 3.01</td><td char="." align="char">46.21 ± 2.41</td><td char="." align="char">50.91 ± 3.99</td><td char="." align="char">40.59 ± 3.31</td><td char="." align="char">46.99 ± 4.01</td><td char="." align="char">46.50 ± 3.91</td></tr><tr><td align="left">PET</td><td char="." align="char">61.59 ± 1.89</td><td char="." align="char">65.06 ± 2.22</td><td char="." align="char">70.35 ± 3.03</td><td char="." align="char">70.45 ± 1.40</td><td char="." align="char">61.36 ± 3.50</td><td char="." align="char">66.53 ± 2.87</td><td char="." align="char">65.23 ± 2.98</td><td char="." align="char">65.89 ± 2.11</td></tr><tr><td align="left">Genetics</td><td char="." align="char">61.28 ± 2.60</td><td char="." align="char">58.82 ± 3.33</td><td char="." align="char">54.90 ± 2.42</td><td char="." align="char">68.94 ± 2.00</td><td char="." align="char">59.09 ± 3.91</td><td char="." align="char">46.86 ± 2.00</td><td char="." align="char">58.75 ± 3.11</td><td char="." align="char">58.31 ± 2.89</td></tr><tr><td align="left">MH</td><td char="." align="char">46.60 ± 1.42</td><td char="." align="char">50.08 ± 2.91</td><td char="." align="char">29.29 ± 1.67</td><td char="." align="char">36.36 ± 1.79</td><td char="." align="char">67.95 ± 3.82</td><td char="." align="char">17.15 ± 1.77</td><td char="." align="char">46.22 ± 2.99</td><td char="." align="char">41.22 ± 3.00</td></tr><tr><td align="left"><italic>CS</italic> + <italic>NB</italic></td><td char="." align="char"><italic>99.22</italic> ± <italic>1.09</italic></td><td char="." align="char"><italic>90.65</italic> ± <italic>2.06</italic></td><td char="." align="char"><italic>90.79</italic> ± <italic>0.90</italic></td><td char="." align="char"><italic>95.83</italic> ± <italic>1.11</italic></td><td char="." align="char"><italic>94.77</italic> ± <italic>2.31</italic></td><td char="." align="char"><italic>86.61</italic> ± <italic>2.90</italic></td><td char="." align="char"><italic>93.00</italic> ± <italic>2.61</italic></td><td char="." align="char"><italic>92.97</italic> ± <italic>2.25</italic></td></tr><tr><td align="left">CS + MRI</td><td char="." align="char">99.20 ± 2.11</td><td char="." align="char">89.42 ± 3.62</td><td char="." align="char">89.57 ± 2.39</td><td char="." align="char">93.94 ± 2.70</td><td char="." align="char">94.09 ± 3.59</td><td char="." align="char">86.19 ± 3.20</td><td char="." align="char">92.05 ± 3.99</td><td char="." align="char">92.06 ± 4.01</td></tr><tr><td align="left">CS + PET</td><td char="." align="char">99.20 ± 2.01</td><td char="." align="char">89.25 ± 2.99</td><td char="." align="char">89.87 ± 2.51</td><td char="." align="char">94.32 ± 2.22</td><td char="." align="char">94.32 ± 3.87</td><td char="." align="char">85.36 ± 2.91</td><td char="." align="char">92.05 ± 3.33</td><td char="." align="char">92.05 ± 3.41</td></tr><tr><td align="left">CS + Genetics</td><td char="." align="char">99.20 ± 1.99</td><td char="." align="char">89.01 ± 2.53</td><td char="." align="char">89.08 ± 2.33</td><td char="." align="char">93.94 ± 1.83</td><td char="." align="char">93.86 ± 3.01</td><td char="." align="char">85.36 ± 2.43</td><td char="." align="char">91.73 ± 2.91</td><td char="." align="char">91.74 ± 3.08</td></tr><tr><td align="left">CS + MH</td><td char="." align="char">98.43 ± 1.55</td><td char="." align="char">89.15 ± 4.01</td><td char="." align="char">89.04 ± 1.92</td><td char="." align="char">94.70 ± 1.77</td><td char="." align="char">93.41 ± 4.31</td><td char="." align="char">84.94 ± 3.91</td><td char="." align="char">91.62 ± 4.00</td><td char="." align="char">91.61 ± 3.81</td></tr><tr><td align="left">CS + NB + MRI</td><td char="." align="char">99.22 ± 2.05</td><td char="." align="char">90.87 ± 3.91</td><td char="." align="char">91.19 ± 2.71</td><td char="." align="char">96.21 ± 2.09</td><td char="." align="char">95.00 ± 3.61</td><td char="." align="char">86.61 ± 2.99</td><td char="." align="char">93.21 ± 3.40</td><td char="." align="char">93.18 ± 3.47</td></tr><tr><td align="left">CS + NB + PET</td><td char="." align="char">99.22 ± 1.99</td><td char="." align="char">91.45 ± 2.06</td><td char="." align="char">90.83 ± 2.90</td><td char="." align="char">96.97 ± 1.78</td><td char="." align="char">94.77 ± 3.01</td><td char="." align="char">87.03 ± 2.72</td><td char="." align="char">93.42 ± 2.97</td><td char="." align="char">93.38 ± 2.61</td></tr><tr><td align="left"><bold>CS + NB + Genetics*</bold></td><td char="." align="char"><bold>99.22 ± 1.01</bold></td><td char="." align="char"><bold>91.72 ± 2.01</bold></td><td char="." align="char"><bold>92.54 ± 0.91</bold></td><td char="." align="char"><bold>96.21 ± 1.00</bold></td><td char="." align="char"><bold>95.68 ± 2.00</bold></td><td char="." align="char"><bold>88.28 ± 1.81</bold></td><td char="." align="char"><bold>93.95 ± 2.30</bold></td><td char="." align="char"><bold>93.94 ± 2.07</bold></td></tr><tr><td align="left">CS + NB + MH</td><td char="." align="char">99.22 ± 2.01</td><td char="." align="char">91.50 ± 3.87</td><td char="." align="char">92.07 ± 2.33</td><td char="." align="char">96.59 ± 2.33</td><td char="." align="char">95.45 ± 4.10</td><td char="." align="char">87.45 ± 3.83</td><td char="." align="char">93.74 ± 4.00</td><td char="." align="char">93.71 ± 3.61</td></tr><tr><td align="left">CS + NB + Genetics + MRI</td><td char="." align="char">99.22 ± 2.30</td><td char="." align="char">91.50 ± 4.10</td><td char="." align="char">92.11 ± 2.97</td><td char="." align="char">96.21 ± 2.22</td><td char="." align="char">95.45 ± 4.20</td><td char="." align="char">87.87 ± 4.86</td><td char="." align="char">93.74 ± 4.01</td><td char="." align="char">93.72 ± 4.44</td></tr><tr><td align="left">CS + NB + Genetics + PET</td><td char="." align="char">99.61 ± 2.03</td><td char="." align="char">90.46 ± 2.06</td><td char="." align="char">90.27 ± 3.04</td><td char="." align="char">96.59 ± 1.83</td><td char="." align="char">94.77 ± 3.31</td><td char="." align="char">85.36 ± 2.77</td><td char="." align="char">92.89 ± 2.99</td><td char="." align="char">92.84 ± 3.20</td></tr><tr><td align="left">CS + NB + Genetics + MH</td><td char="." align="char">99.22 ± 2.22</td><td char="." align="char">91.34 ± 4.39</td><td char="." align="char">92.83 ± 2.31</td><td char="." align="char">96.97 ± 2.40</td><td char="." align="char">95.91 ± 4.90</td><td char="." align="char">86.61 ± 3.09</td><td char="." align="char">93.85 ± 4.30</td><td char="." align="char">93.81 ± 4.06</td></tr><tr><td align="left">CS + NB + Genetics + MH + MRI</td><td char="." align="char">99.22 ± 2.30</td><td char="." align="char">90.93 ± 4.55</td><td char="." align="char">92.41 ± 3.60</td><td char="." align="char">96.21 ± 2.32</td><td char="." align="char">95.68 ± 4.24</td><td char="." align="char">86.61 ± 3.95</td><td char="." align="char">93.53 ± 4.32</td><td char="." align="char">93.51 ± 3.97</td></tr><tr><td align="left">CS + NB + Genetics + MH + PET</td><td char="." align="char">98.84 ± 1.89</td><td char="." align="char">91.29 ± 3.41</td><td char="." align="char">92.04 ± 2.87</td><td char="." align="char">96.59 ± 2.00</td><td char="." align="char">95.23 ± 3.05</td><td char="." align="char">87.03 ± 2.78</td><td char="." align="char">93.53 ± 3.11</td><td char="." align="char">93.50 ± 3.01</td></tr></tbody></table><table-wrap-foot><p>MCA: multiclass classification accuracy, MCF: multiclass F1 score; Asterisk ( ∗): is the subset of features with the best predictive performance; italic text is the best of single and pairs of modalities.</p></table-wrap-foot></table-wrap></p>
                <p id="Par61">The next step is to show the generalization capability of the proposed model. As shown in Table <xref rid="Tab3" ref-type="table">3</xref>, we observe the same trend already shown in Table <xref rid="Tab2" ref-type="table">2</xref>. Once again, the combination of NB, CS, and Genetics again achieved the best performance.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Random Forest performance testing for detecting AD patients (<inline-formula id="IEq120"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MS2$$\end{document}</tex-math><mml:math id="M14"><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq120.gif"/></alternatives></inline-formula>
<italic>test dataset</italic>;10% of the original data).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Modalities</th><th align="left" colspan="3">Precision (%)</th><th align="left" colspan="3">Recall (%)</th><th align="left" rowspan="2">MCA (%)</th><th align="left" rowspan="2">MCF (%)</th></tr><tr><th align="left">CN</th><th align="left">MCI</th><th align="left">AD</th><th align="left">CN</th><th align="left">MCI</th><th align="left">AD</th></tr></thead><tbody><tr><td align="left"><bold>All modalities</bold></td><td char="." align="char"><bold>100.0</bold></td><td char="." align="char"><bold>86.54</bold></td><td char="." align="char"><bold>96.30</bold></td><td char="." align="char"><bold>86.67</bold></td><td char="." align="char"><bold>97.83</bold></td><td char="." align="char"><bold>89.66</bold></td><td char="." align="char"><bold>92.38</bold></td><td char="." align="char"><bold>92.81</bold></td></tr><tr><td align="left">CS</td><td char="." align="char">100.0</td><td char="." align="char">71.43</td><td char="." align="char">93.75</td><td char="." align="char">86.61</td><td char="." align="char">97.83</td><td char="." align="char">51.72</td><td char="." align="char">81.90</td><td char="." align="char">83.29</td></tr><tr><td align="left"><italic>NB</italic></td><td char="." align="char"><italic>85.29</italic></td><td char="." align="char"><italic>81.63</italic></td><td char="." align="char"><italic>95.45</italic></td><td char="." align="char"><italic>96.60</italic></td><td char="." align="char"><italic>86.96</italic></td><td char="." align="char"><italic>72.41</italic></td><td char="." align="char"><italic>85.71</italic></td><td char="." align="char"><italic>86.39</italic></td></tr><tr><td align="left">MRI</td><td char="." align="char">50.31</td><td char="." align="char">48.28</td><td char="." align="char">72.22</td><td char="." align="char">40.01</td><td char="." align="char">91.30</td><td char="." align="char">44.83</td><td char="." align="char">52.38</td><td char="." align="char">42.61</td></tr><tr><td align="left">PET</td><td char="." align="char">50.00</td><td char="." align="char">55.22</td><td char="." align="char">73.53</td><td char="." align="char">36.67</td><td char="." align="char">80.43</td><td char="." align="char">86.21</td><td char="." align="char">60.95</td><td char="." align="char">58.66</td></tr><tr><td align="left">Genetics</td><td char="." align="char">66.67</td><td char="." align="char">49.28</td><td char="." align="char">40.21</td><td char="." align="char">80.00</td><td char="." align="char">73.91</td><td char="." align="char">35.33</td><td char="." align="char">55.24</td><td char="." align="char">44.09</td></tr><tr><td align="left">MH</td><td char="." align="char">33.33</td><td char="." align="char">52.54</td><td char="." align="char">38.46</td><td char="." align="char">36.67</td><td char="." align="char">67.39</td><td char="." align="char">17.24</td><td char="." align="char">44.76</td><td char="." align="char">40.93</td></tr><tr><td align="left"><italic>NB</italic> + <italic>CS</italic></td><td char="." align="char"><italic>100.0</italic></td><td char="." align="char"><italic>84.91</italic></td><td char="." align="char"><italic>96.15</italic></td><td char="." align="char"><italic>86.67</italic></td><td char="." align="char"><italic>97.83</italic></td><td char="." align="char"><italic>86.21</italic></td><td char="." align="char"><italic>91.43</italic></td><td char="." align="char"><italic>91.93</italic></td></tr><tr><td align="left">NB + MRI</td><td char="." align="char">73.68</td><td char="." align="char">79.55</td><td char="." align="char">95.65</td><td char="." align="char">93.33</td><td char="." align="char">76.09</td><td char="." align="char">75.86</td><td char="." align="char">80.95</td><td char="." align="char">82.36</td></tr><tr><td align="left">NB + PET</td><td char="." align="char">86.21</td><td char="." align="char">75.93</td><td char="." align="char">95.45</td><td char="." align="char">83.33</td><td char="." align="char">89.13</td><td char="." align="char">72.41</td><td char="." align="char">82.86</td><td char="." align="char">83.69</td></tr><tr><td align="left">NB + Genetics</td><td char="." align="char">87.50</td><td char="." align="char">83.67</td><td char="." align="char">95.83</td><td char="." align="char">93.33</td><td char="." align="char">89.13</td><td char="." align="char">79.31</td><td char="." align="char">87.62</td><td char="." align="char">88.12</td></tr><tr><td align="left">NB + MH</td><td char="." align="char">87.50</td><td char="." align="char">77.36</td><td char="." align="char">95.00</td><td char="." align="char">93.33</td><td char="." align="char">89.13</td><td char="." align="char">65.52</td><td char="." align="char">83.81</td><td char="." align="char">84.59</td></tr><tr><td align="left">NB + CS + MRI</td><td char="." align="char">100.0</td><td char="." align="char">83.64</td><td char="." align="char">100.0</td><td char="." align="char">86.67</td><td char="." align="char">100.0</td><td char="." align="char">82.76</td><td char="." align="char">91.43</td><td char="." align="char">92.12</td></tr><tr><td align="left">NB + CS + PET</td><td char="." align="char">100.0</td><td char="." align="char">82.14</td><td char="." align="char">100.0</td><td char="." align="char">86.67</td><td char="." align="char">100.0</td><td char="." align="char">79.31</td><td char="." align="char">90.48</td><td char="." align="char">91.27</td></tr><tr><td align="left"><bold>NB + CS + Genetics*</bold></td><td char="." align="char"><bold>100</bold>.0</td><td char="." align="char"><bold>86.79</bold></td><td char="." align="char"><bold>100</bold>.0</td><td char="." align="char"><bold>86.67</bold></td><td char="." align="char"><bold>100</bold>.0</td><td char="." align="char"><bold>89.66</bold></td><td char="." align="char"><bold>93.33</bold></td><td char="." align="char"><bold>93.82</bold></td></tr><tr><td align="left">NB + CS + MH</td><td char="." align="char">100.0</td><td char="." align="char">86.54</td><td char="." align="char">96.30</td><td char="." align="char">86.67</td><td char="." align="char">97.83</td><td char="." align="char">89.66</td><td char="." align="char">92.38</td><td char="." align="char">92.81</td></tr><tr><td align="left">NB + CS + Genetics + MRI</td><td char="." align="char">100.0</td><td char="." align="char">85.19</td><td char="." align="char">100.0</td><td char="." align="char">86.67</td><td char="." align="char">100.0</td><td char="." align="char">86.21</td><td char="." align="char">92.38</td><td char="." align="char">92.97</td></tr><tr><td align="left">NB + CS + Genetics + PET</td><td char="." align="char">100.0</td><td char="." align="char">85.19</td><td char="." align="char">100.0</td><td char="." align="char">86.67</td><td char="." align="char">100.0</td><td char="." align="char">86.21</td><td char="." align="char">92.38</td><td char="." align="char">92.97</td></tr><tr><td align="left">NB + CS + Genetics + MH</td><td char="." align="char">100.0</td><td char="." align="char">86.79</td><td char="." align="char">100.0</td><td char="." align="char">86.67</td><td char="." align="char">100.0</td><td char="." align="char">89.66</td><td char="." align="char">93.33</td><td char="." align="char">93.82</td></tr><tr><td align="left">NB + CS + Genetics + MH + MRI</td><td char="." align="char">100.0</td><td char="." align="char">86.54</td><td char="." align="char">96.30</td><td char="." align="char">86.67</td><td char="." align="char">97.83</td><td char="." align="char">89.66</td><td char="." align="char">92.38</td><td char="." align="char">92.81</td></tr><tr><td align="left">NB + CS + Genetics + MH + PET</td><td char="." align="char">96.15</td><td char="." align="char">84.62</td><td char="." align="char">96.30</td><td char="." align="char">83.33</td><td char="." align="char">95.65</td><td char="." align="char">89.66</td><td char="." align="char">90.48</td><td char="." align="char">90.93</td></tr></tbody></table><table-wrap-foot><p>MCA: multiclass classification accuracy, MCF: multiclass F1 score; Asterisk ( ∗): is the subset of features with the best predictive performance; italic text is the best of single and pairs of modalities.</p></table-wrap-foot></table-wrap></p>
              </sec>
              <sec id="Sec5">
                <title>Second layer: AD progression prediction performance</title>
                <p id="Par62">The Second Layer in our framework optimizes a binary classification problem to predict the progression to AD within three years from baseline (i.e., sMCI versus pMCI). This classifier is first validated using tenfold CV on the <inline-formula id="IEq7"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MS1$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq7.gif"/></alternatives></inline-formula> dataset. As shown in Table <xref rid="Tab4" ref-type="table">4</xref> with bold typeface, the best performance of this model was observed for the combined CFA, PET, Genetics, and MRI data, i.e. Precision = 88.07 ± 0.70%, Recall = 86.08 ± 1.30%, Accuracy = 87.09 ± 0.80%, F1-score = 87.08 ± 0.90%, and AUC = 87.08 ± 0.80%. In addition, this model achieved the lowest variance in performance compared to all models based on other combinations and the whole feature space. Regarding single modalities, CFA achieves the best performance (see Table <xref rid="Tab4" ref-type="table">4</xref>). In addition, cognitive scores and neuropsychological battery are usually considered in clinical practice. Models built using either MH or PET alone achieved the worst performance and were noisy. Based on the results from single modalities, we combined the best CFA model with each of the other modalities to see if the performance may be improved or not.<table-wrap id="Tab4"><label>Table 4</label><caption><p>Random Forest performance validation for predicting whether MCI subjects will progress to AD or not (<italic>tenfold cross-validation</italic>; Second Layer).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Modalities used</th><th align="left">Precision (%)</th><th align="left">Recall (%)</th><th align="left">Accuracy (%)</th><th align="left">F1-score (%)</th><th align="left">AUC</th></tr></thead><tbody><tr><td align="left">All</td><td char="." align="char">87.12 ± 1.52</td><td char="." align="char">81.31 ± 2.00</td><td char="." align="char">84.18 ± 1.77</td><td char="." align="char">83.21 ± 2.43</td><td char="." align="char">84.17 ± 1.99</td></tr><tr><td align="left"><italic>CFA</italic></td><td char="." align="char"><italic>82.14</italic> ± <italic>1.40</italic></td><td char="." align="char"><italic>84.19</italic> ± <italic>1.90</italic></td><td char="." align="char"><italic>82.16</italic> ± <italic>1.60</italic></td><td char="." align="char"><italic>83.15</italic> ± <italic>1.50</italic></td><td char="." align="char"><italic>82.15</italic> ± <italic>1.50</italic></td></tr><tr><td align="left">MRI</td><td char="." align="char">75.23 ± 1.88</td><td char="." align="char">72.25 ± 1.59</td><td char="." align="char">71.18 ± 2.01</td><td char="." align="char">72.17 ± 1.92</td><td char="." align="char">71.18 ± 1.89</td></tr><tr><td align="left">PET</td><td char="." align="char">68.22 ± 2.22</td><td char="." align="char">68.53 ± 1.98</td><td char="." align="char">68.25 ± 1.99</td><td char="." align="char">66.39 ± 1.99</td><td char="." align="char">68.24 ± 2.01</td></tr><tr><td align="left">Genetics</td><td char="." align="char">73.11 ± 1.73</td><td char="." align="char">68.36 ± 1.72</td><td char="." align="char">70.14 ± 1.79</td><td char="." align="char">69.24 ± 1.89</td><td char="." align="char">70.13 ± 1.80</td></tr><tr><td align="left">MH</td><td char="." align="char">58.16 ± 4.60</td><td char="." align="char">52.22 ± 4.90</td><td char="." align="char">55.15 ± 3.73</td><td char="." align="char">54.19 ± 3.76</td><td char="." align="char">55.15 ± 3.76</td></tr><tr><td align="left">CFA + MRI</td><td char="." align="char">83.11 ± 2.31</td><td char="." align="char">84.22 ± 2.20</td><td char="." align="char">83.14 ± 2.51</td><td char="." align="char">83.15 ± 2.26</td><td char="." align="char">83.14 ± 2.22</td></tr><tr><td align="left"><italic>CFA</italic> + <italic>PET</italic></td><td char="." align="char"><italic>85.17</italic> ± <italic>1.70</italic></td><td char="." align="char"><italic>84.29</italic> ± <italic>2.90</italic></td><td char="." align="char"><italic>84.19</italic> ± <italic>1.90</italic></td><td char="." align="char"><italic>84.21</italic> ± <italic>2.10</italic></td><td char="." align="char"><italic>84.19</italic> ± <italic>1.90</italic></td></tr><tr><td align="left">CFA + Genetics</td><td char="." align="char">82.14 ± 1.91</td><td char="." align="char">81.27 ± 1.98</td><td char="." align="char">81.16 ± 1.93</td><td char="." align="char">81.17 ± 1.96</td><td char="." align="char">81.16 ± 1.95</td></tr><tr><td align="left">CFA + MH</td><td char="." align="char">84.16 ± 3.77</td><td char="." align="char">82.23 ± 4.60</td><td char="." align="char">82.17 ± 3.80</td><td char="." align="char">83.18 ± 3.33</td><td char="." align="char">82.17 ± 3.80</td></tr><tr><td align="left">CFA + PET + MRI</td><td char="." align="char">86.09 ± 2.10</td><td char="." align="char">84.23 ± 2.30</td><td char="." align="char">84.11 ± 2.15</td><td char="." align="char">85.14 ± 2.22</td><td char="." align="char">85.11 ± 2.15</td></tr><tr><td align="left"><italic>CFA</italic> + <italic>PET</italic> + <italic>Genetics</italic></td><td char="." align="char"><italic>90.11</italic> ± <italic>1.50</italic></td><td char="." align="char"><italic>83.21</italic> ± <italic>2.21</italic></td><td char="." align="char"><italic>86.08</italic> ± <italic>1.04</italic></td><td char="." align="char"><italic>85.11</italic> ± <italic>2.00</italic></td><td char="." align="char"><italic>86.08</italic> ± <italic>1.05</italic></td></tr><tr><td align="left">CFA + PET + MH</td><td char="." align="char">86.09 ± 3.45</td><td char="." align="char">84.17 ± 4.20</td><td char="." align="char">84.08 ± 3.71</td><td char="." align="char">85.09 ± 4.01</td><td char="." align="char">84.08 ± 3.72</td></tr><tr><td align="left"><bold>CFA + PET + Genetics + MRI*</bold></td><td char="." align="char"><bold>88.07 ± 0.70</bold></td><td char="." align="char"><bold>86.13 ± 1.30</bold></td><td char="." align="char"><bold>87.08 ± 0.80</bold></td><td char="." align="char"><bold>87.09 ± 0.90</bold></td><td char="." align="char"><bold>87.08 ± 0.80</bold></td></tr><tr><td align="left">CFA + PET + Genetics + MH</td><td char="." align="char">86.09 ± 3.51</td><td char="." align="char">86.13 ± 4.70</td><td char="." align="char">86.08 ± 3.32</td><td char="." align="char">86.08 ± 3.99</td><td char="." align="char">86.08 ± 3.36</td></tr></tbody></table><table-wrap-foot><p>BA: Balanced accuracy. Asterisk ( ∗): is the subset of features with the best predictive performance. Performance: Mean ± standard deviation.</p></table-wrap-foot></table-wrap></p>
                <p id="Par63">The addition of PET data improves the predictive performance of our model because PET data provide complementary information about disease progression. The combination of CFA and PET modalities achieves the best performance compared to combinations of other pairs of modalities. However, the resulting model is less confident compared to the model based on CFA alone. This is probably because the PET modality added noise to the combined set. In addition, the CFA + PET modality achieved the smallest variance compared to other two modalities combinations. To check for possible improvement in model performance, the CFA + PET feature set was combined with each of the MRI, Genetics, and MH modalities. The multimodality of CFA, PET, and Genetics enhances the performance of progression prediction by about 2%, compared to the combined CFA and PET modality. In addition, the resulting model is more stable compared to the CFA + PET-based model. This is in accordance with the fact that medically, Amyloid β, PTAU, and TAU are critical biomarkers to monitor the progression of AD<sup><xref ref-type="bibr" rid="CR46">46</xref>–<xref ref-type="bibr" rid="CR51">51</xref></sup>. Finally, we check the effect of combining MRI and MH with the rest of the modalities (CFA, PET, and Genetics). Again, integrating MRI brain volume features (including the hippocampus, ICV, and others) improves the model accuracy by about 1%. MRI volume features provide vital information for effective prediction of AD progression. According to our domain experts, we believe this is medically promising because it is critical to integrate MRI features in order to measure possible AD progression. With the unseen data in <inline-formula id="IEq8"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MS2$$\end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq8.gif"/></alternatives></inline-formula> we verify the good generalization of the generated models that we already observed with tenfold CV (see Table <xref rid="Tab5" ref-type="table">5</xref>).<table-wrap id="Tab5"><label>Table 5</label><caption><p>Random Forest performance measures for AD progression prediction of MCI subjects based on CFA, MRI, PET, genetics, and MH modalities (<inline-formula id="IEq121"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MS2$$\end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq121.gif"/></alternatives></inline-formula>
<italic>test dataset</italic>; Second Layer).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Modalities used</th><th align="left">Precision (%)</th><th align="left">Recall (%)</th><th align="left">Accuracy (%)</th><th align="left">F1-score (%)</th><th align="left">AUC</th></tr></thead><tbody><tr><td align="left">All</td><td char="." align="char">87.50</td><td char="." align="char">87.50</td><td char="." align="char">87.76</td><td char="." align="char">87.75</td><td char="." align="char">0.953</td></tr><tr><td align="left"><italic>CFA</italic></td><td char="." align="char"><italic>91.30</italic></td><td char="." align="char"><italic>87.50</italic></td><td char="." align="char"><italic>89.80</italic></td><td char="." align="char"><italic>89.81</italic></td><td char="." align="char"><italic>0.926</italic></td></tr><tr><td align="left">MRI</td><td char="." align="char">56.67</td><td char="." align="char">70.83</td><td char="." align="char">59.18</td><td char="." align="char">59.66</td><td char="." align="char">0.691</td></tr><tr><td align="left">PET</td><td char="." align="char">72.73</td><td char="." align="char">66.67</td><td char="." align="char">71.43</td><td char="." align="char">71.44</td><td char="." align="char">0.812</td></tr><tr><td align="left">Genetics</td><td char="." align="char">76.00</td><td char="." align="char">79.17</td><td char="." align="char">77.55</td><td char="." align="char">77.58</td><td char="." align="char">0.787</td></tr><tr><td align="left">MH</td><td char="." align="char">57.14</td><td char="." align="char">50.00</td><td char="." align="char">57.14</td><td char="." align="char">57.07</td><td char="." align="char">0.562</td></tr><tr><td align="left">CFA + MRI</td><td char="." align="char">90.91</td><td char="." align="char">83.33</td><td char="." align="char">87.76</td><td char="." align="char">87.86</td><td char="." align="char">0.903</td></tr><tr><td align="left"><italic>CFA</italic> + <italic>PET</italic></td><td char="." align="char"><italic>95.45</italic></td><td char="." align="char"><italic>87.50</italic></td><td char="." align="char"><italic>91.84</italic></td><td char="." align="char"><italic>91.95</italic></td><td char="." align="char"><italic>0.955</italic></td></tr><tr><td align="left">CFA + genetics</td><td char="." align="char">84.00</td><td char="." align="char">87.50</td><td char="." align="char">85.71</td><td char="." align="char">85.75</td><td char="." align="char">0.926</td></tr><tr><td align="left">CFA + MH</td><td char="." align="char">91.30</td><td char="." align="char">87.50</td><td char="." align="char">89.80</td><td char="." align="char">89.81</td><td char="." align="char">0.918</td></tr><tr><td align="left">CFA + PET + MRI</td><td char="." align="char">88.00</td><td char="." align="char">91.67</td><td char="." align="char">89.80</td><td char="." align="char">89.83</td><td char="." align="char">0.949</td></tr><tr><td align="left"><italic>CFA</italic> + <italic>PET</italic> + <italic>genetics</italic></td><td char="." align="char"><italic>91.67</italic></td><td char="." align="char"><italic>91.67</italic></td><td char="." align="char"><italic>91.85</italic></td><td char="." align="char"><italic>91.83</italic></td><td char="." align="char"><italic>0.956</italic></td></tr><tr><td align="left">CFA + PET + MH</td><td char="." align="char">87.50</td><td char="." align="char">87.50</td><td char="." align="char">87.76</td><td char="." align="char">87.75</td><td char="." align="char">0.943</td></tr><tr><td align="left"><bold><italic>CFA + PET + genetics + MRI*</italic></bold></td><td char="." align="char"><italic>91.70</italic></td><td char="." align="char"><italic>91.70</italic></td><td char="." align="char"><italic>91.86</italic></td><td char="." align="char"><italic>91.84</italic></td><td char="." align="char"><italic>0.963</italic></td></tr><tr><td align="left">CFA + PET + genetics + MH</td><td char="." align="char">87.50</td><td char="." align="char">87.50</td><td char="." align="char">87.76</td><td char="." align="char">87.75</td><td char="." align="char">0.948</td></tr></tbody></table><table-wrap-foot><p>Asterisk ( ∗): is the subset of features with the best predictive performance.</p></table-wrap-foot></table-wrap></p>
              </sec>
              <sec id="Sec6">
                <title>Comparison with other classifiers</title>
                <p id="Par64">Recently, Travers et al.<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> provided a comprehensive survey of DL techniques in biology and medicine. In this context, Choi and Jin<sup><xref ref-type="bibr" rid="CR22">22</xref></sup> utilized a convolutional neural network (CNN) to detect pMCI cases based on positron emission tomography (PET) images. Spasov et al.<sup><xref ref-type="bibr" rid="CR23">23</xref></sup> proposed a multimodal DL classification model for AD progression detection based on the late fusion of magnetic resonance imaging (MRI), demographic, neuropsychological, and apolipoprotein E (APOE) e4 genetic data.</p>
                <p id="Par65">In addition, many AD studies have considered a single modality, especially MRI, to make a binary classification of sMCI versus pMCI<sup><xref ref-type="bibr" rid="CR52">52</xref>,<xref ref-type="bibr" rid="CR53">53</xref></sup>. Li et al.<sup><xref ref-type="bibr" rid="CR54">54</xref></sup> used five cognitive scores with a Cox linear regression model to build two prognostic models of AD. Moradi et al.<sup><xref ref-type="bibr" rid="CR27">27</xref></sup> achieved an area under the curve (AUC) of 0.77 in discriminating pMCI from sMCI based on RF and MRI data only; after fusing MRI features with baseline cognitive scores and age, they achieved an AUC of 0.90 for the same problem. Jin et al.<sup><xref ref-type="bibr" rid="CR55">55</xref></sup> used a Bayesian network to analyze multimodal data from ADNI data including demographics, MRI, PET, neuropsychometrics tests, and genotypes. It is worth noting that RF<sup><xref ref-type="bibr" rid="CR56">56</xref>,<xref ref-type="bibr" rid="CR57">57</xref></sup> is an ensemble classifier that can provide more accurate predictions than other ML techniques. Fernandez-Delgado et al.<sup><xref ref-type="bibr" rid="CR40">40</xref></sup> evaluated 179 classifiers using different UCI datasets, and concluded that RF outperforms other classifiers, including SVMs and neural networks. RF works well with a mixture of quantitative and categorical features, and unlike SVM, it handles multiclass problems natively. RF is able to learn wide datasets with a very large number of features, compared to the number of cases. RF has been used intensively in the AD domain<sup><xref ref-type="bibr" rid="CR26">26</xref>,<xref ref-type="bibr" rid="CR57">57</xref>,<xref ref-type="bibr" rid="CR58">58</xref></sup>. For example, Ramírez et al.<sup><xref ref-type="bibr" rid="CR58">58</xref></sup> proposed an ML model to predict MCI from normal patients. This model is based on feature standardization, analysis of variance feature selection, partial least squares feature dimension reduction, and an ensemble of one vs. rest RF classifiers. The model achieved accuracy of 56.25% based on MRI data.</p>
                <p id="Par66">To verify the goodness and robustness of our approach in each layer, we compared the performance of the RF models with other predictive models, namely the SVM, KNN, Naïve Bayes (NB), and DT models. For each layer, we use the selected features of RFE. For each selected algorithm, we tuned its hyperparameters the same way we tuned the RF algorithm. The results of the best performing parameters are shown in Tables <xref rid="Tab6" ref-type="table">6</xref> and <xref rid="Tab7" ref-type="table">7</xref>. Our proposal outperforms the rest of classifiers. It is worth noting that we did not compare our model with the artificial neural network approach because they achieved really bad performance in preliminary experiments, mainly due to the small size of the used datasets. In other words, our data is not big enough for training and testing the state-of-the-art DL architectures.<table-wrap id="Tab6"><label>Table 6</label><caption><p>Comparison of different classifiers (<inline-formula id="IEq122"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MS2$$\end{document}</tex-math><mml:math id="M22"><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq122.gif"/></alternatives></inline-formula>
<italic>test dataset</italic>; First Layer).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Classifier</th><th align="left" colspan="3">Precision (%)</th><th align="left" colspan="3">Recall (%)</th><th align="left" rowspan="2">MCA (%)</th><th align="left" rowspan="2">MCF (%)</th></tr><tr><th align="left">CN</th><th align="left">MCI</th><th align="left">AD</th><th align="left">CN</th><th align="left">MCI</th><th align="left">AD</th></tr></thead><tbody><tr><td align="left">SVM</td><td char="." align="char">100.0</td><td char="." align="char">91.43</td><td char="." align="char">83.87</td><td char="." align="char">96.67</td><td char="." align="char">89.13</td><td char="." align="char">89.66</td><td char="." align="char">91.43</td><td char="." align="char">91.74</td></tr><tr><td align="left">KNN</td><td char="." align="char">65.71</td><td char="." align="char">59.57</td><td char="." align="char">73.91</td><td char="." align="char">76.67</td><td char="." align="char">60.87</td><td char="." align="char">58.62</td><td char="." align="char">64.76</td><td char="." align="char">65.89</td></tr><tr><td align="left">DT</td><td char="." align="char">100.0</td><td char="." align="char">86.54</td><td char="." align="char">96.30</td><td char="." align="char">86.67</td><td char="." align="char">97.83</td><td char="." align="char">89.66</td><td char="." align="char">92.38</td><td char="." align="char">92.81</td></tr><tr><td align="left">NB</td><td char="." align="char">90.32</td><td char="." align="char">92.68</td><td char="." align="char">84.85</td><td char="." align="char">93.33</td><td char="." align="char">82.61</td><td char="." align="char">96.55</td><td char="." align="char">89.52</td><td char="." align="char">90.05</td></tr><tr><td align="left"><bold>RF (our model)*</bold></td><td char="." align="char"><bold>100.0</bold></td><td char="." align="char"><bold>86.79</bold></td><td char="." align="char"><bold>100.0</bold></td><td char="." align="char"><bold>86.67</bold></td><td char="." align="char"><bold>100.0</bold></td><td char="." align="char"><bold>89.66</bold></td><td char="." align="char"><bold>93.33</bold></td><td char="." align="char"><bold>93.82</bold></td></tr></tbody></table><table-wrap-foot><p>MCA: multiclass classification accuracy, MCF: multiclass F1 score; Asterisk ( ∗): is the model with the best predictive performance.</p></table-wrap-foot></table-wrap><table-wrap id="Tab7"><label>Table 7</label><caption><p>Comparison of different classifiers (<inline-formula id="IEq123"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MS2$$\end{document}</tex-math><mml:math id="M24"><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq123.gif"/></alternatives></inline-formula>
<italic>test dataset</italic>; Second Layer).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Modalities used</th><th align="left">Precision</th><th align="left">Recall</th><th align="left">Accuracy</th><th align="left">F1-score</th><th align="left">AUC</th></tr></thead><tbody><tr><td align="left">SVM</td><td char="." align="char">81.82</td><td char="." align="char">75.00</td><td char="." align="char">79.59</td><td char="." align="char">79.64</td><td char="." align="char">0.867</td></tr><tr><td align="left">KNN</td><td char="." align="char">83.33</td><td char="." align="char">83.33</td><td char="." align="char">83.67</td><td char="." align="char">83.66</td><td char="." align="char">0.869</td></tr><tr><td align="left">DT</td><td char="." align="char">85.71</td><td char="." align="char">75.00</td><td char="." align="char">81.63</td><td char="." align="char">81.82</td><td char="." align="char">0.850</td></tr><tr><td align="left">NB</td><td char="." align="char">84.00</td><td char="." align="char">84.00</td><td char="." align="char">83.67</td><td char="." align="char">83.67</td><td char="." align="char">0.907</td></tr><tr><td align="left"><bold>RF (our model)*</bold></td><td char="." align="char"><bold>87.50</bold></td><td char="." align="char"><bold>87.50</bold></td><td char="." align="char"><bold>87.76</bold></td><td char="." align="char"><bold>87.75</bold></td><td char="." align="char"><bold>0.953</bold></td></tr></tbody></table><table-wrap-foot><p>Asterisk ( ∗): is the model with the best predictive performance.</p></table-wrap-foot></table-wrap></p>
              </sec>
              <sec id="Sec7">
                <title>Models explainability</title>
                <sec id="Sec8">
                  <title>Explainability based on random forest internal logic</title>
                  <p id="Par67">Based on SHAP explainers, we calculate feature contributions of RF models (see the Explainability Capabilities Section; in <xref rid="Sec15" ref-type="sec">Material and methods</xref>). Figure <xref rid="MOESM1" ref-type="media">S1</xref> in Supplementary File (part 2) shows this rank for each class in each layer. The most influential feature for the First Layer is CDRSB followed by MMSE, and the lowest feature is TRABSCOR_PartBTimeToComplete from the neuropsychological battery group (see Supplementary File [part 2], Table <xref rid="MOESM1" ref-type="media">T2</xref>). For the Second Layer, FAQ plays the main role followed by ADNI_MEM, and Trail4Total has the lowest impact (see Supplementary File [part 2], Table <xref rid="MOESM1" ref-type="media">T2</xref>). According to our domain experts, it is medically intuitive for cognitive scores to play the main role in detecting AD patients. However, for progression detection, we can see that Hippocampus and MidTerp volumes from MRI images also play significant role, in addition to FDG and SROI from PET images. Table <xref rid="Tab8" ref-type="table">8</xref> summarizes the sensitivity of the explainer to the different feature values for both layers. For further details about these features and terminologies, readers are invited to see the Supplementary File (part 2) and ADNI at <ext-link ext-link-type="uri" xlink:href="http://adni.loni.usc.edu">http://adni.loni.usc.edu</ext-link>.<table-wrap id="Tab8"><label>Table 8</label><caption><p>Examples of the relationship between features and class prediction.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">First Layer</th><th align="left">Most influential feature</th><th align="left">CDRSB</th><th align="left">Clinical dementia rating sum of box score</th></tr></thead><tbody><tr><td align="left" rowspan="6"/><td align="left">Lowest important feature</td><td align="left">TRABSCOR PartBTimeToComplete</td><td align="left">Neuropsychological battery’s TRABSCOR trail making test (part B—time to complete)</td></tr><tr><td align="left">The best feature for AD class</td><td align="left">MMSE</td><td align="left">Mini-Mental State Examination</td></tr><tr><td align="left">The best feature for CN and MCI classes</td><td align="left">CDRSB</td><td align="left">Clinical dementia rating sum of box score</td></tr><tr><td align="left"><inline-formula id="IEq124"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uparrow$$\end{document}</tex-math><mml:math id="M26"><mml:mo stretchy="false">↑</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq124.gif"/></alternatives></inline-formula> CDRSB, <inline-formula id="IEq125"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\downarrow$$\end{document}</tex-math><mml:math id="M28"><mml:mo stretchy="false">↓</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq125.gif"/></alternatives></inline-formula> ADNI_MEM</td><td align="left"><inline-formula id="IEq126"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uparrow$$\end{document}</tex-math><mml:math id="M30"><mml:mo stretchy="false">↑</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq126.gif"/></alternatives></inline-formula> risk for the AD class</td><td align="left">Sensitivity of the AD class to this list of features</td></tr><tr><td align="left"><inline-formula id="IEq127"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\downarrow$$\end{document}</tex-math><mml:math id="M32"><mml:mo stretchy="false">↓</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq127.gif"/></alternatives></inline-formula> CDRSB, <inline-formula id="IEq128"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uparrow$$\end{document}</tex-math><mml:math id="M34"><mml:mo stretchy="false">↑</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq128.gif"/></alternatives></inline-formula> ADNI_MEM, <inline-formula id="IEq129"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uparrow$$\end{document}</tex-math><mml:math id="M36"><mml:mo stretchy="false">↑</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq129.gif"/></alternatives></inline-formula> DigitalTotalScore, <inline-formula id="IEq130"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uparrow$$\end{document}</tex-math><mml:math id="M38"><mml:mo stretchy="false">↑</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq130.gif"/></alternatives></inline-formula> MOCA</td><td align="left"><inline-formula id="IEq131"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uparrow$$\end{document}</tex-math><mml:math id="M40"><mml:mo stretchy="false">↑</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq131.gif"/></alternatives></inline-formula> chance for the CN class</td><td align="left">Sensitivity of the CN class to this list of features</td></tr><tr><td align="left"><inline-formula id="IEq132"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\downarrow$$\end{document}</tex-math><mml:math id="M42"><mml:mo stretchy="false">↓</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq132.gif"/></alternatives></inline-formula> CDRSB, <inline-formula id="IEq133"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uparrow$$\end{document}</tex-math><mml:math id="M44"><mml:mo stretchy="false">↑</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq133.gif"/></alternatives></inline-formula> FAQ,<inline-formula id="IEq134"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uparrow$$\end{document}</tex-math><mml:math id="M46"><mml:mo stretchy="false">↑</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq134.gif"/></alternatives></inline-formula> MOCA, <inline-formula id="IEq135"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uparrow$$\end{document}</tex-math><mml:math id="M48"><mml:mo stretchy="false">↑</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq135.gif"/></alternatives></inline-formula> CDGLOBAL, <inline-formula id="IEq136"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\downarrow$$\end{document}</tex-math><mml:math id="M50"><mml:mo stretchy="false">↓</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq136.gif"/></alternatives></inline-formula> ADNI_MEM</td><td align="left"><inline-formula id="IEq137"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\downarrow$$\end{document}</tex-math><mml:math id="M52"><mml:mo stretchy="false">↓</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq137.gif"/></alternatives></inline-formula> risk for the MCI class</td><td align="left">Sensitivity of the MCI class to this list of features</td></tr></tbody></table><table frame="hsides" rules="groups"><thead><tr><th align="left">Second Layer</th><th align="left">Most influential feature</th><th align="left">ADNI_MEM</th><th align="left">ADNI_MEM is composite logical memory score for the8<break/> longitudinal changes in memory</th></tr></thead><tbody><tr><td align="left" rowspan="4"/><td align="left">Lowest important feature</td><td align="left">Trail4Total</td><td align="left">Neuropsychological Battery AVTOT4 feature</td></tr><tr><td align="left"><inline-formula id="IEq138"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uparrow$$\end{document}</tex-math><mml:math id="M54"><mml:mo stretchy="false">↑</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq138.gif"/></alternatives></inline-formula> FAQ, <inline-formula id="IEq139"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uparrow$$\end{document}</tex-math><mml:math id="M56"><mml:mo stretchy="false">↑</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq139.gif"/></alternatives></inline-formula> RAVLT_immediate</td><td align="left"><inline-formula id="IEq140"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uparrow$$\end{document}</tex-math><mml:math id="M58"><mml:mo stretchy="false">↑</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq140.gif"/></alternatives></inline-formula> chance for the sMCI class</td><td align="left">Relationship between RAVLT_immediate and sMCI class</td></tr><tr><td align="left"><inline-formula id="IEq141"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uparrow$$\end{document}</tex-math><mml:math id="M60"><mml:mo stretchy="false">↑</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq141.gif"/></alternatives></inline-formula> FAQ, <inline-formula id="IEq142"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uparrow$$\end{document}</tex-math><mml:math id="M62"><mml:mo stretchy="false">↑</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq142.gif"/></alternatives></inline-formula> RAVLT_immediate</td><td align="left"><inline-formula id="IEq143"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\downarrow$$\end{document}</tex-math><mml:math id="M64"><mml:mo stretchy="false">↓</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq143.gif"/></alternatives></inline-formula> risk for the pMCI class</td><td align="left">Relationship between FAQ and RAVLT_immediate and pMCI class</td></tr><tr><td align="left"><inline-formula id="IEq144"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uparrow$$\end{document}</tex-math><mml:math id="M66"><mml:mo stretchy="false">↑</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq144.gif"/></alternatives></inline-formula> ADAS 13, <inline-formula id="IEq145"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uparrow$$\end{document}</tex-math><mml:math id="M68"><mml:mo stretchy="false">↑</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq145.gif"/></alternatives></inline-formula> ADNI_MEM, <inline-formula id="IEq146"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\downarrow$$\end{document}</tex-math><mml:math id="M70"><mml:mo stretchy="false">↓</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq146.gif"/></alternatives></inline-formula> FDG, <inline-formula id="IEq147"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\downarrow$$\end{document}</tex-math><mml:math id="M72"><mml:mo stretchy="false">↓</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq147.gif"/></alternatives></inline-formula> MOCA</td><td align="left"><inline-formula id="IEq148"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uparrow$$\end{document}</tex-math><mml:math id="M74"><mml:mo stretchy="false">↑</mml:mo></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq148.gif"/></alternatives></inline-formula> risk for the pMCI class</td><td align="left">Relationship between ADAS, ADNI_MEM, FDG, and MOCA and pMCI class</td></tr></tbody></table></table-wrap></p>
                </sec>
                <sec id="Sec9">
                  <title>Explainability of the behavior of individual features</title>
                  <p id="Par68">The global feature importance gives an abstract view about the role of each feature, but we cannot know the direction of these effects. For example, we cannot know if a high value for CDRSB will increase the probability of selecting the AD, MCI, or CN class. Using SHAP summary plots, we are able to analyze the behavior of our XAI framework with respect to different values of features. Figure <xref rid="Fig2" ref-type="fig">2</xref> shows the summary plots for every class in the first layer. Each dot represents the impact on a particular class of a particular feature for a given instance, and it is colored according to what magnitude of the value contributes to the model impact. The color represents the feature value (red = high, blue = low). We notice a different order for each class.<fig id="Fig2"><label>Figure 2</label><caption><p>SHAP summary plots for the first layer. The upper left figure represents the CN class, the upper right figure represents the MCI class, and the second row represents the AD class.</p></caption><graphic xlink:href="41598_2021_82098_Fig2_HTML" id="MO2"/></fig></p>
                  <p id="Par69">In the First Layer, we find that MMSE is more significant than CDRSB for the AD class, but CDRSB has the highest impact on the CN and MCI classes, see Table <xref rid="Tab8" ref-type="table">8</xref>. The model shows a high degree of non-linearity because the impacts of many features are spread across relatively wide ranges. We notice that the high values of CDRSB have great positive impact on the model for predicting the AD class, meaning CDRSB is a factor that increases AD risk. For the CN class, low values of CDRSB have extreme positive impact on the model. In contrast, high values of ADNI_MEM, DigitalTotalScore, and MOCA have a positive impact on predicting the CN class. For the MCI class, low values of CDRSB have an extreme negative impact on the model. The CDGLOBAL feature is less critical than MOCA for the MCI class. However, in some cases, high values of this feature have a more negative impact on MCI cases than MOCA. The same happens for FAQ, where low values have a more positive impact on a system decision for the MCI class than MOCA and CDGLOBAL. We noticed that AD and MCI classes are related to negative values of ADNI_MEM, but CN is related to positive values. In addition, by plotting the impact of a feature on every sample, we can detect the impact of outliers. For example, in the case of the picture related to AD, although CDGLOBAL is not the most important feature globally, it is critical for a subset of patients. This is indicated by the long-tailed distribution to the right. Again, the same situation applies to the DigitalTotalScore feature for the AD class.</p>
                  <p id="Par70">In the Second Layer, although HCI is globally less significant than ADNI_MEM for both sMCI and pMCI, in a subset of patients, this feature has more impact than ADNI_MEM, see Table <xref rid="Tab8" ref-type="table">8</xref> and Fig. <xref rid="Fig3" ref-type="fig">3</xref>. The same is true for CDRSB in relation to MOCA for the pMCI class, and ADAS 11 in relation to CDRSB for the sMCI class. A feature with a longer tail to the right means it has a greater positive influence, and vice versa. As a result, understanding the detailed role of each feature alone and in combination with other features is of critical importance. For example, large values of RAVLT_immediate positively impact the model toward selecting the sMCI class, but negatively impact towards the pMCI class. FAQ is the most important feature for both classes, followed by ADNI_MEM, HCI, and ADAS 13. The two classes show symmetric behaviors for all features. It is clear that low values of FAQ negatively affect the prediction of pMCI class, but they have the largest positive impact for the sMCI class. Large values of ADAS 13 have a higher positive impact on the model for predicting the pMCI than ADNI_MEM. Small values of FDG have a greater positive impact for predicting pMCI than MOCA and ADAS 11. As a result, some features are not critical globally, but extreme values for specific cases have a greater impact in the model than the globally important features. Based on the knowledge of our domain experts, this is also medically intuitive, and increases the confidence of medical experts in the behavior of our system.<fig id="Fig3"><label>Figure 3</label><caption><p>SHAP summary plots for the second layer. The left figure shows the pMCI class, and the right figure shows the sMCI class.</p></caption><graphic xlink:href="41598_2021_82098_Fig3_HTML" id="MO3"/></fig></p>
                </sec>
                <sec id="Sec10">
                  <title>Explainability of individual cases</title>
                  <p id="Par71">Figure <xref rid="Fig4" ref-type="fig">4</xref> shows examples of prediction for each class in the First Layer, and Figure <xref rid="MOESM1" ref-type="media">S2</xref> in Supplementary file (part 2) shows another example from the Second Layer. In addition, the figure illustrates supervised clustering of all cases according to their similarities.<fig id="Fig4"><label>Figure 4</label><caption><p>First layer example predictions for AD (<bold>A</bold>), CN (<bold>B</bold>), and MCI (<bold>C</bold>) and SHAP supervised clustering in model behavior for all cases in each class. Red indicates attributions that push the score higher, while blue indicates contributions that push the score lower. A few of the noticeable subgroups are annotated with the features that define them.</p></caption><graphic xlink:href="41598_2021_82098_Fig4_HTML" id="MO4"/></fig></p>
                  <p id="Par72">Each example is a vertical line, and SHAP values for all cases are ordered by similarity. We identify some critical values for each cluster. Figure <xref rid="Fig4" ref-type="fig">4</xref> (A) (part 1) shows a case with a probability of 75% for being AD. It also shows the most significant feature values that have a positive impact for that class, such as MMSE = 24, CDRSB = 3.0, MOCA = 19.3, etc. This is consistent with ADNI data, where the average values of all AD subjects are MMSE = 23.235 ± 2.015, CDRSB = 4.3 ± 1.591, and MOCA = 17.553 ± 3.377. In addition, it shows the features that push the classification away from the AD class including DigitalTotalScore = 33, CDGLOBAL = 0, etc. The features with less impact such as TAU = 347.9, PTAU = 31.64, RAVLT immediate = 27, FAQ = 5, and Trial5Total = 7 are represented with short arrows. Figure <xref rid="Fig4" ref-type="fig">4</xref> (A) (part 2) shows the behavior of the model on all the instances, and the role of each feature to support (red) or not support (blue) classification as AD. Different clusters are defined according to the values of critical features. We find that when MMSE is in the interval [27, 30] and MOCA is in [23.62, 29], this combination has the greatest role in preventing the model from selecting the AD class (blue cluster). On the other hand, when CDRSB is in the range [3.5, 6.0], FAQ is in [6–17], and ADAS 13 is in [20–36], the model will mostly classify cases as AD (red cluster).</p>
                  <p id="Par73">Figure <xref rid="Fig4" ref-type="fig">4</xref> (B) (part 1) does the same thing for the CN class. The model is 99% confident that the case is CN. Clearly defined clusters explain the model behavior in selecting the CN class. The most critical factors that push the decision towards CN class are CDRSB = 0 and DigitalTotalScore = 50. Figure <xref rid="Fig4" ref-type="fig">4</xref> (B) (part 2) shows the overall logic in detecting CN subjects. We observe some critical values of some clusters from this figure. For example, if CDRSB = 0, FAQ = 0, DigitalTotalScore is in [31, 50], MMSE is in [27, 30], and ADAS 13 is in [1, 15], the patient is mostly classified as CN (red cluster). This means that if MMSE is combined with both CDRSB and FAQ at 0, it loses a lot of its impact on AD class prediction. According to the ADNI data and our experts’ knowledge, these decisions are medically intuitive because the average values of critical factors for CN subjects are CDRSB = 0.039 ± 0.141, FAQ = 0.194 ± 0.720, and DigitalTotalScore = 48.173 ± 7.481. Figure <xref rid="Fig4" ref-type="fig">4</xref> (C) (part 1) shows the prediction of our model for an MCI case. In general, the characteristics of MCI cases are between those of CN and AD classifications. According to the model prediction, the low value of CDRSB (1 in this current case) has a high positive impact on predicting MCI cases. This subject has a negative ADNI_MEM value, which may have a significant impact on the system’s decision. By comparing the feature values of the three cases, we can say that a little change in CDRSB has a great impact on performance, and this is compatible with Fig. <xref rid="Fig2" ref-type="fig">2</xref>. Please note that the combination of different values of features could change the role of the related feature, as well as the final decision.</p>
                </sec>
                <sec id="Sec11">
                  <title>Explainability of the interaction between features</title>
                  <p id="Par74">As shown in the middle of Figs. <xref rid="Fig3" ref-type="fig">3</xref> and <xref rid="Fig4" ref-type="fig">4</xref>, many features (such as PTAU for AD class and ABETA for the CN and MCI classes), show a high degree of uncertainty. In addition, some features (such as Entorhinal and PTAU) seem to have less impact, because they are at the bottom of the list. However, these features may have a critical impact if they were combined with specific values of other features. To study the role of these types of features, we need to zoom in and study their behavior in combination with other features. Note that interaction analysis can be studied for other globally important features, as well, like CDRSB and FAQ.</p>
                  <p id="Par75">Due to space restrictions, in Figure <xref rid="MOESM1" ref-type="media">S3</xref> of Supplementary File (part 2), we give a detailed example of the interaction impacts from one of these noisy features (e.g. PTAU) in the First Layer, and we study the impact of less globally critical feature (e.g., Entorhinal) in the Second Layer to highlight its role (see Fig. <xref rid="Fig2" ref-type="fig">2</xref>). As can be seen, the domain expert is able to interpret the internal behavior of the ML model and know exactly why it makes specific decisions. We notice that some features may be globally unimportant, but in some cases, they have extreme SHAP values, and that shows the real impact of these features. In addition, the real impact of a feature can be discovered by studying its interactions with other related features. Supplementary File (part 2) (Figure <xref rid="MOESM1" ref-type="media">S4</xref> to Figure <xref rid="MOESM1" ref-type="media">S8</xref>) shows the SHAP interaction summaries for the most important features in both layers and for each class.</p>
                </sec>
                <sec id="Sec12">
                  <title>Explainability based on single explainers</title>
                  <p id="Par76">In this section, we provide explanations of the RF model decisions from other explainers and based on other data types. Domain experts often consider these biomarkers to make accountable decisions. For example, the First Layer’s model does not consider MRI and PET data. Furthermore, the Second Layer’s model does not consider medical history. In addition, both models do not consider lab tests, vital signs, and physical examinations. However, all these features are considered by our explainers. It is worth noting that we are not interested in explaining the internal behavior of the RF model but providing physicians with post-hoc explanations of every decision. In the same way, how different physicians may figure out different explanations (in terms of different features) for a given output, our explainers yield complementary, consistent and reliable explanations.</p>
                  <p id="Par77">Tables <xref rid="Tab9" ref-type="table">9</xref> and <xref rid="Tab10" ref-type="table">10</xref> summarize the quality (i.e. the performance-explainability trade-off) of the 22 explainers (11 DT and 11 FURIA) for each layer. Even if some of these explainers exhibit poor performance, they all exhibit complementary explainability because they depend on different features. In practice, these explainers provide physicians with plausible explanations in natural language. It is worth noting that given a specific data instance, only those explainers that point out at the same output class as the RF model are taken into account when generating explanations. Moreover, physicians are provided with explanations along with information about the reliability of each single explainer in terms of its balance between accuracy and explainability. At the end, the physician makes the final decision on which explainers to trust or to discard likewise she may ask for alternative opinions of different colleagues who are likely to have different experience and background. As expected, DT is clever for some modalities, while FURIA is better for others.<table-wrap id="Tab9"><label>Table 9</label><caption><p>The performance of the explainers on different modalities (First Layer).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Explainer</th><th align="left">No. of features</th><th align="left">Model</th><th align="left">Exp. (%)</th><th align="left">Precision</th><th align="left">Recall</th><th align="left">Accuracy</th><th align="left">F1-score</th><th align="left">Exp. measures</th></tr></thead><tbody><tr><td align="left" rowspan="2">Cognitive scores based</td><td align="left" rowspan="2">12</td><td align="left">DT</td><td align="left">96 (91.43)</td><td char="." align="char"><bold>0.913</bold></td><td char="." align="char"><bold>0.912</bold></td><td char="." align="char"><bold>0.912</bold></td><td char="." align="char"><bold>0.912</bold></td><td align="left"><bold>NL = 29; S = 57</bold></td></tr><tr><td align="left">FURIA</td><td align="left">97 (92.38)</td><td char="." align="char">0.910</td><td char="." align="char">0.909</td><td char="." align="char">0.909</td><td char="." align="char">0.909</td><td align="left">NR = 17</td></tr><tr><td align="left" rowspan="2">Genetics based</td><td align="left" rowspan="2">5</td><td align="left">DT</td><td align="left">61 (58.10)</td><td char="." align="char">0.553</td><td char="." align="char">0.555</td><td char="." align="char">0.555</td><td char="." align="char">0.553</td><td align="left">NL = 35; S = 69</td></tr><tr><td align="left">FURIA</td><td align="left">63 (60.00)</td><td char="." align="char"><bold>0.556</bold></td><td char="." align="char"><bold>0.559</bold></td><td char="." align="char"><bold>0.559</bold></td><td char="." align="char"><bold>0.553</bold></td><td align="left"><bold>NR = 8</bold></td></tr><tr><td align="left" rowspan="2">Lab tests based</td><td align="left" rowspan="2">41</td><td align="left">DT</td><td align="left">39 (37.14)</td><td char="." align="char">0.408</td><td char="." align="char">0.407</td><td char="." align="char">0.407</td><td char="." align="char">0.408</td><td align="left">NL = 155; S = 309</td></tr><tr><td align="left">FURIA</td><td align="left">53 (50.48)</td><td char="." align="char"><bold>0.469</bold></td><td char="." align="char"><bold>0.494</bold></td><td char="." align="char"><bold>0.494</bold></td><td char="." align="char"><bold>0.460</bold></td><td align="left"><bold>NR = 6</bold></td></tr><tr><td align="left" rowspan="2">Medical history based</td><td align="left" rowspan="2">27</td><td align="left">DT</td><td align="left">83 (79.05)</td><td char="." align="char">0.495</td><td char="." align="char">0.496</td><td char="." align="char">0.496</td><td char="." align="char">0.494</td><td align="left">NL = 173; S = 331</td></tr><tr><td align="left">FURIA</td><td align="left">67 (63.81)</td><td char="." align="char"><bold>0.521</bold></td><td char="." align="char"><bold>0.519</bold></td><td char="." align="char"><bold>0.519</bold></td><td char="." align="char"><bold>0.517</bold></td><td align="left"><bold>NR = 10</bold></td></tr><tr><td align="left" rowspan="2">MRI based</td><td align="left" rowspan="2">8</td><td align="left">DT</td><td align="left">64 (60.95)</td><td char="." align="char">0.472</td><td char="." align="char">0.471</td><td char="." align="char">0.471</td><td char="." align="char">0.468</td><td align="left">NL = 58; S = 115</td></tr><tr><td align="left">FURIA</td><td align="left">51 (48.57)</td><td char="." align="char"><bold>0.525</bold></td><td char="." align="char"><bold>0.525</bold></td><td char="." align="char"><bold>0.525</bold></td><td char="." align="char"><bold>0.524</bold></td><td align="left"><bold>NR = 5</bold></td></tr><tr><td align="left" rowspan="2">Neurological exams based</td><td align="left" rowspan="2">12</td><td align="left">DT</td><td align="left">47 (44.76)</td><td char="." align="char">0.387</td><td char="." align="char">0.451</td><td char="." align="char">0.451</td><td char="." align="char">0.335</td><td align="left">NL = 15; S = 29</td></tr><tr><td align="left">FURIA</td><td align="left">47 (44.76)</td><td char="." align="char"><bold>0.413</bold></td><td char="." align="char"><bold>0.467</bold></td><td char="." align="char"><bold>0.467</bold></td><td char="." align="char"><bold>0.350</bold></td><td align="left"><bold>NR = 3</bold></td></tr><tr><td align="left" rowspan="2">Neuropsychological battery based</td><td align="left" rowspan="2">35</td><td align="left">DT</td><td align="left">87 (82.86)</td><td char="." align="char">0.733</td><td char="." align="char">0.732</td><td char="." align="char">0.732</td><td char="." align="char">0.732</td><td align="left">NL = 85; S = 169</td></tr><tr><td align="left">FURIA</td><td align="left">85 (80.95)</td><td char="." align="char"><bold>0.771</bold></td><td char="." align="char"><bold>0.771</bold></td><td char="." align="char"><bold>0.771</bold></td><td char="." align="char"><bold>0.770</bold></td><td align="left"><bold>NR = 22</bold></td></tr><tr><td align="left" rowspan="2">PET based</td><td align="left" rowspan="2">3</td><td align="left">DT</td><td align="left">60 (57.14)</td><td char="." align="char">0.614</td><td char="." align="char">0.612</td><td char="." align="char">0.612</td><td char="." align="char">0.610</td><td align="left">NL = 22; S = 43</td></tr><tr><td align="left">FURIA</td><td align="left">66 (62.86)</td><td char="." align="char"><bold>0.621</bold></td><td char="." align="char"><bold>0.618</bold></td><td char="." align="char"><bold>0.618</bold></td><td char="." align="char"><bold>0.616</bold></td><td align="left"><bold>NR = 6</bold></td></tr><tr><td align="left" rowspan="2">Physical exams based</td><td align="left" rowspan="2">10</td><td align="left">DT</td><td align="left">48 (45.71)</td><td char="." align="char">0.291</td><td char="." align="char">0.443</td><td char="." align="char">0.443</td><td char="." align="char">0.304</td><td align="left">NL = 13; S = 25</td></tr><tr><td align="left">FURIA</td><td align="left">49 (46.67)</td><td char="." align="char"><bold>0.257</bold></td><td char="." align="char"><bold>0.461</bold></td><td char="." align="char"><bold>0.461</bold></td><td char="." align="char"><bold>0.297</bold></td><td align="left"><bold>NR = 5</bold></td></tr><tr><td align="left" rowspan="2">Symptoms based</td><td align="left" rowspan="2">27</td><td align="left">DT</td><td align="left">49 (46.67)</td><td char="." align="char"><bold>0.425</bold></td><td char="." align="char"><bold>0.449</bold></td><td char="." align="char"><bold>0.449</bold></td><td char="." align="char"><bold>0.383</bold></td><td align="left"><bold>NL = 32; S = 63</bold></td></tr><tr><td align="left">FURIA</td><td align="left">49 (46.67)</td><td char="." align="char">0.430</td><td char="." align="char">0.446</td><td char="." align="char">0.446</td><td char="." align="char">0.389</td><td align="left">NR = 3</td></tr><tr><td align="left" rowspan="2">Vital signs based</td><td align="left" rowspan="2">8</td><td align="left">DT</td><td align="left">36 (34.29)</td><td char="." align="char">0.369</td><td char="." align="char">0.417</td><td char="." align="char">0.417</td><td char="." align="char">0.367</td><td align="left">NL = 79; S = 157</td></tr><tr><td align="left">FURIA</td><td align="left">45 (42.86)</td><td char="." align="char"><bold>0.360</bold></td><td char="." align="char"><bold>0.453</bold></td><td char="." align="char"><bold>0.453</bold></td><td char="." align="char"><bold>0.329</bold></td><td align="left"><bold>NR = 2</bold></td></tr></tbody></table><table-wrap-foot><p>Exp. measures, explainability measure; NL, number of leaves; S, size of the tree; NR, number of rules; Exp. (%), the number of explained cases (percentage of coverage); values in bold indicate the best performance.</p></table-wrap-foot></table-wrap><table-wrap id="Tab10"><label>Table 10</label><caption><p>The performance of the explainers on different modalities (Second Layer).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Explainer</th><th align="left">No. of features</th><th align="left">Model</th><th align="left">Exp. (%)</th><th align="left">Precision</th><th align="left">Recall</th><th align="left">Accuracy</th><th align="left">F1-score</th><th align="left">Exp. measures</th></tr></thead><tbody><tr><td align="left" rowspan="2">Cognitive scores based</td><td align="left" rowspan="2">12</td><td align="left">DT</td><td align="left">38 (77.55)</td><td char="." align="char">0.824</td><td char="." align="char">0.824</td><td char="." align="char">0.824</td><td char="." align="char">0.824</td><td align="left">NL = 25; S = 49</td></tr><tr><td align="left">FURIA</td><td align="left">38 (77.55)</td><td char="." align="char"><bold>0.847</bold></td><td char="." align="char"><bold>0.847</bold></td><td char="." align="char"><bold>0.847</bold></td><td char="." align="char"><bold>0.847</bold></td><td align="left"><bold>NR = 9</bold></td></tr><tr><td align="left" rowspan="2">Genetics based</td><td align="left" rowspan="2">5</td><td align="left">DT</td><td align="left">32 (65.31)</td><td char="." align="char">0.729</td><td char="." align="char">0.721</td><td char="." align="char">0.721</td><td char="." align="char">0.720</td><td align="left">NL = 7; S = 13</td></tr><tr><td align="left">FURIA</td><td align="left">33 (67.35)</td><td char="." align="char"><bold>0.729</bold></td><td char="." align="char"><bold>0.728</bold></td><td char="." align="char"><bold>0.728</bold></td><td char="." align="char"><bold>0.728</bold></td><td align="left"><bold>NR = 5</bold></td></tr><tr><td align="left" rowspan="2">Lab tests based</td><td align="left" rowspan="2">41</td><td align="left">DT</td><td align="left">28 (57.14)</td><td char="." align="char">0.528</td><td char="." align="char">0.526</td><td char="." align="char">0.526</td><td char="." align="char">0.526</td><td align="left">NL = 58; S = 115</td></tr><tr><td align="left">FURIA</td><td align="left">30 (61.22)</td><td char="." align="char"><bold>0.574</bold></td><td char="." align="char"><bold>0.574</bold></td><td char="." align="char"><bold>0.574</bold></td><td char="." align="char"><bold>0.574</bold></td><td align="left"><bold>NR = 20</bold></td></tr><tr><td align="left" rowspan="2">Medical history based</td><td align="left" rowspan="2">27</td><td align="left">DT</td><td align="left">29 (59.18)</td><td char="." align="char">0.590</td><td char="." align="char">0.590</td><td char="." align="char">0.590</td><td char="." align="char">0.589</td><td align="left">NL = 51; S = 95</td></tr><tr><td align="left">FURIA</td><td align="left">31 (63.27)</td><td char="." align="char"><bold>0.643</bold></td><td char="." align="char"><bold>0.643</bold></td><td char="." align="char"><bold>0.643</bold></td><td char="." align="char"><bold>0.643</bold></td><td align="left"><bold>NR = 3</bold></td></tr><tr><td align="left" rowspan="2">MRI based</td><td align="left" rowspan="2">8</td><td align="left">DT</td><td align="left">30 (61.22)</td><td char="." align="char"><bold>0.732</bold></td><td char="." align="char"><bold>0.721</bold></td><td char="." align="char"><bold>0.721</bold></td><td char="." align="char"><bold>0.720</bold></td><td align="left"><bold>NL = 12; S = 23</bold></td></tr><tr><td align="left">FURIA</td><td align="left">33 (67.35)</td><td char="." align="char">0.687</td><td char="." align="char">0.686</td><td char="." align="char">0.686</td><td char="." align="char">0.687</td><td align="left">NR = 6</td></tr><tr><td align="left" rowspan="2">Neurological exams based</td><td align="left" rowspan="2">12</td><td align="left">DT</td><td align="left">23 (46.94)</td><td char="." align="char"><bold>0.492</bold></td><td char="." align="char"><bold>0.515</bold></td><td char="." align="char"><bold>0.515</bold></td><td char="." align="char"><bold>0.429</bold></td><td align="left"><bold>NL = 9; S = 17</bold></td></tr><tr><td align="left">FURIA</td><td align="left">24 (48.98)</td><td char="." align="char">0.457</td><td char="." align="char">0.497</td><td char="." align="char">0.497</td><td char="." align="char">0.417</td><td align="left">NR = 3</td></tr><tr><td align="left" rowspan="2">Neuropsychological battery based</td><td align="left" rowspan="2">35</td><td align="left">DT</td><td align="left">31 (63.27)</td><td char="." align="char">0.693</td><td char="." align="char">0.693</td><td char="." align="char">0.693</td><td char="." align="char">0.693</td><td align="left">NL = 52; S = 103</td></tr><tr><td align="left">FURIA</td><td align="left">35 (71.43)</td><td char="." align="char"><bold>0.764</bold></td><td char="." align="char"><bold>0.762</bold></td><td char="." align="char"><bold>0.762</bold></td><td char="." align="char"><bold>0.762</bold></td><td align="left"><bold>NR = 11</bold></td></tr><tr><td align="left" rowspan="2">PET based</td><td align="left" rowspan="2">3</td><td align="left">DT</td><td align="left">31 (63.27)</td><td char="." align="char">0.680</td><td char="." align="char">0.677</td><td char="." align="char">0.677</td><td char="." align="char">0.677</td><td align="left">NL = 8; S = 15</td></tr><tr><td align="left">FURIA</td><td align="left">34 (69.39)</td><td char="." align="char"><bold>0.710</bold></td><td char="." align="char"><bold>0.709</bold></td><td char="." align="char"><bold>0.709</bold></td><td char="." align="char"><bold>0.709</bold></td><td align="left"><bold>NR = 4</bold></td></tr><tr><td align="left" rowspan="2">Physical exams based</td><td align="left" rowspan="2">10</td><td align="left">DT</td><td align="left">31 (63.27)</td><td char="." align="char"><bold>0.552</bold></td><td char="." align="char"><bold>0.542</bold></td><td char="." align="char"><bold>0.542</bold></td><td char="." align="char"><bold>0.537</bold></td><td align="left"><bold>NL = 14; S = 27</bold></td></tr><tr><td align="left">FURIA</td><td align="left">29 (59.18)</td><td char="." align="char">0.534</td><td char="." align="char">0.529</td><td char="." align="char">0.529</td><td char="." align="char">0.526</td><td align="left">NR = 5</td></tr><tr><td align="left" rowspan="2">Symptoms based</td><td align="left" rowspan="2">27</td><td align="left">DT</td><td align="left">27 (55.10)</td><td char="." align="char">0.531</td><td char="." align="char">0.524</td><td char="." align="char">0.524</td><td char="." align="char">0.520</td><td align="left">NL = 20; S = 39</td></tr><tr><td align="left">FURIA</td><td align="left">32 (65.31)</td><td char="." align="char"><bold>0.556</bold></td><td char="." align="char"><bold>0.547</bold></td><td char="." align="char"><bold>0.547</bold></td><td char="." align="char"><bold>0.542</bold></td><td align="left"><bold>NR = 4</bold></td></tr><tr><td align="left" rowspan="2">Vital signs based</td><td align="left" rowspan="2">8</td><td align="left">DT</td><td align="left">24 (48.98)</td><td char="." align="char">0.519</td><td char="." align="char">0.526</td><td char="." align="char">0.526</td><td char="." align="char">0.461</td><td align="left">NL = 4; S = 7</td></tr><tr><td align="left">FURIA</td><td align="left">31 (63.27)</td><td char="." align="char"><bold>0.523</bold></td><td char="." align="char"><bold>0.526</bold></td><td char="." align="char"><bold>0.526</bold></td><td char="." align="char"><bold>0.519</bold></td><td align="left"><bold>NR = 3</bold></td></tr></tbody></table><table-wrap-foot><p>Exp. measures, explainability measure; NL, number of leaves; S, size of the tree; NR, number of rules; Exp. (%), the number of explained cases (percentage of coverage); values in bold indicate the best performance.</p></table-wrap-foot></table-wrap></p>
                  <p id="Par78">We analyzed each instance in the test dataset of both layers and recorded how many explainers could predict the same class as their corresponding oracle (i.e. the RF model). The test set in the First Layer was made up of 105 instances. On average, 58.1% of the instances were managed by each single explainer. Regarding the number of explainers that act for each single instance, we found there were 13 (the median value) explainers considered; being 3 the worst case and 22 the best case. Being DT (vital signs-based) the least used explainer (34.4%) and FURIA (cognitive scores based) the most used explainer (92.4%). The test set in the Second Layer was made up of 49 instances. On average, 63% of the instances were managed by each single explainer. Being DT (neurological exams-based) the least used explainer (47%) and both DT and FURIA (cognitive scores-based) the most used explainers (78%). Regarding the number of explainers which act for each single instance, we observed that 14 (the median value) explainers are considered; being 7 the worst case and 20 the best case. All in all, we can conclude that even in the worst cases, we are ready to supply physicians with more than one single explanation. Moreover, explanations are normally rich, thanks to the fact that they involve several modalities. This fact was especially well appreciated by the physicians who collaborated in our study.</p>
                </sec>
                <sec id="Sec13">
                  <title>Case studies for FURIA and DT explainers</title>
                  <p id="Par79">The supplementary file (part 3) lists a group of AD cases to tests the system explainability. The supplementary file (part 2) shows the expressiveness of the generated explanations for three illustrative case studies (see Supplementary File [part 2], Table <xref rid="MOESM1" ref-type="media">T3</xref> to <xref rid="MOESM1" ref-type="media">T7</xref>). We tested the following: (1) the ability of explainers to generate supplementary explanations, (2) their consistency with the generated explanations from SHAP, and (3) the quality of the generated natural language explanations. In case study 1, we can see that generated explanations add many values to the interpretability and confidence of the decisions made. First, the explainers reinforce the explanations from SHAP. Second, they increase the confidence physicians have about the decision made. In case study 2, physicians can investigate all the information to understand why the system makes a specific decision. We note perfect matches among SHAP and explainers’ outputs. In case study 3, we observe how explanations related to sMCI and pMCI are somehow in contrast (and in accordance with) physicians’ intuition and background.</p>
                </sec>
                <sec id="Sec14">
                  <title>Model strengths and limitations</title>
                  <p id="Par80">The proposed model is designed to comprehensively integrate high-fidelity Alzheimer’s data to predict AD and detect its possible progression within three years from baseline. We demonstrated the high predictive powers of the proposed models. The First Layer model achieves the best results by combining the NB, CS, and Genetics modalities. These modalities achieved the best cross-validations results. On the other hand, the Second Layer model shows the highest results based on CS, NB, PET, MRI, and Genetics. Both CS and NB have important roles in improving the performance of our model. Similar observations have been reported in the literature<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>. Note that not all biomarkers of these modalities are used in the training process, but only the features selected by the RFE technique. Using black-box models in the medical domain is very dangerous and not acceptable. Our model achieves superior performance, compared to other ML models; in addition, it combines high-accuracy, complex models (i.e. ensemble RF) with interpretable explanations. This combination allows physicians to receive the best possible predictions, and at the same time, gain insight into why those predictions were made. These actionable decisions increase the confidence and trust in the model’s behavior, help to debug the model, and can work as an educational tool for inexperienced physicians. Note that we used the word “<italic>confidence</italic>” to indicate that the model provided its results with small variances. In contrast, we used the word “<italic>trust</italic>” to indicate that our model provided interpretable and explainable results which improved the domain expert’s trust in the model’s decision. Moreover, when the model provided a result with high confidence, it then enhanced the domain expert’s level of trust. Consequently, in our study, more confidence resulted in more trust, in addition to the trust gained from explainability. The quantification of trust for deep learning models has been discussed recently<sup><xref ref-type="bibr" rid="CR59">59</xref></sup>. Taking this quantification process into account would be an insightful investigation.</p>
                  <p id="Par81">Training general practitioners, based on educational interventions, to recognize and manage AD has no significant impact on clinical practice<sup><xref ref-type="bibr" rid="CR60">60</xref></sup>. A CDSS can provide another solution, but current systems are mostly based on a single modality<sup><xref ref-type="bibr" rid="CR52">52</xref>,<xref ref-type="bibr" rid="CR53">53</xref></sup>, make use of binary models (e.g., CADi2)<sup><xref ref-type="bibr" rid="CR61">61</xref></sup>, or are not explainable<sup><xref ref-type="bibr" rid="CR8">8</xref>–<xref ref-type="bibr" rid="CR15">15</xref></sup>. As a result, current systems are rarely used routinely in AD management. We believe that a CDSS based on our comprehensive, accurate, and explainable model could make a difference in practice. We provide explanations from different perspectives including CS, NB, MRI, PET, Genetics, medical history, etc. In addition, we provide detailed explanations based on feature contributions. We believe that these explanations provide supplementary knowledge for physicians to fully understand the rationale behind the decisions taken. <italic>To the best of our knowledge, this is the first study that provides such a comprehensive model and with such explainability features.</italic></p>
                  <p id="Par82">Our model has a couple of limitations worth noting. <italic>First</italic>, we only considered the baseline data for making decisions. Because AD is a chronic disease, a time-series data analysis would be of critical value<sup><xref ref-type="bibr" rid="CR62">62</xref>,<xref ref-type="bibr" rid="CR63">63</xref></sup>. A future attempt will study the role of longitudinal data to enhance the model’s accuracy and explainability. We could consider some DL techniques, which are clever at handling time-series data, such as long short-term memory, in such a future study. <italic>Second</italic>, the ADNI collects data about the roles of a patient’s medication history and comorbidities on AD progression. No such research has been done previously to study these data. Another future enhancement could be the integration into the prediction ML model of semantic intelligence from ontologies. We will consider semantics from the standard ontologies (e.g. RxNorm, Systematized Nomenclature of Medicine-Clinical Terms [SNOMED CT], etc.) to encode these data and to infer hidden knowledge about the relationships between drugs, diseases, and Alzheimer’s. <italic>Third</italic>, the network science approaches have been used to characterizing the brain activities for AD patients to extract interconnectivity patterns of brain regions based on neuroimaging techniques<sup><xref ref-type="bibr" rid="CR64">64</xref>–<xref ref-type="bibr" rid="CR67">67</xref></sup>. Although these studies provided additional insights into AD pathophysiology, they come with several limitations. For example, Chen et al.,<sup><xref ref-type="bibr" rid="CR64">64</xref></sup> used a small cohort of 55 subjects for classifying subjects as AD vs. MCI vs. AD using the large-scale network analysis approach. These data have been collected at baseline visit only, and no longitudinal study has been performed. However, cross-sectional studies cannot dynamically observe changes in network patterns with disease progression. Furthermore, postmortem studies are required as the reference standard when validating the large-scale network methods. In addition, the study used simple linear regression to measure the relationship between changes in network connectivity strengths and behavioral scores. Wang et al.<sup><xref ref-type="bibr" rid="CR65">65</xref></sup> utilized a small dataset of 89 subjects to evaluate the impaired network functional connectivity with AD progression. Even though the whole brain network is complex, varied, and interrelated, this study was based on only five networks which put limitations placed on its results. Thus, the entire brain network analysis with finely defined regions is important. Also, this study is based on baseline data only. Besides, longitudinal data of multiple modalities such as functional and structural MRI, PET, genetic genotype, etc. should be fused to follow individuals to differentiate all the severity levels. In future studies, one might explore these network science approaches and integrate them with advanced XAI and deep learning techniques. In this context, we can study the roles of time series data to improve the current literature. Moreover, the role of data fusion of different modalities might be explored using different ML and DL algorithms. <italic>Finally</italic>, a web based CDSS system based on a user-friendly interface can provide medically intuitive aids for both medical experts and general practitioners. Work is currently in progress to develop such a system, which will be extended to work as a pluggable component of the electronic health record ecosystem. This design facilitates data entry by the physician, online training of the models, and automatic updates on patient status.</p>
                </sec>
              </sec>
            </sec>
            <sec id="Sec15">
              <title>Material and methods</title>
              <sec id="Sec16">
                <title>ADNI study</title>
                <p id="Par83">Data used in this work was collected from the ADNI database (<italic>adni.loni.usc.edu</italic>). Subjects have been enrolled from over 57 sites across the U.S. and Canada. The study was conducted according to the Good Clinical Practice guidelines, the Declaration of Helsinki, US 21 CFR part 50 —Protection of Human Subjects—and part 56—Institutional Review Boards. Subjects were willing and able to undergo test procedures, including neuroimaging and follow-up, and written informed consent was obtained from participants. All data are publicly available, at <ext-link ext-link-type="uri" xlink:href="http://adni.loni.usc.edu/">http://adni.loni.usc.edu/</ext-link>.</p>
                <p id="Par84">In all, 1048 subjects (54.5% male) participated in the study and were categorized into four groups based on the individual clinical diagnosis at baseline and future visits, as follows: (a) cognitively normal (CN): 294 subjects (28.1%) diagnosed as CN at baseline who remained CN at the time this manuscript is prepared. (b) sMCI: 254 subjects (24.2%) diagnosed as MCI at all-time points. (c) pMCI: 232 subjects (22.1%) evaluated as MCI at baseline visit who had progressed to AD within three years. (d) AD: 268 subjects (25.6%) who had a clinical diagnosis of AD for all visits. Subjects showing improvement in their clinical diagnosis during follow up (i.e., those clinically diagnosed as MCI but reverting to CN, or those clinically diagnosed as AD but reverting to MCI or CN) were excluded from the study because of the potential uncertainty of clinical misdiagnosis, considering that AD is considered irreversible form of dementia. In addition, cases that had a direct conversion from CN to AD were also removed. Patients taking part in this study are anonymized and the actual list of patient IDs in our study can be found in Supplementary File (part 1). The data used in this research are from the baseline visits only, no longitudinal data were considered.</p>
              </sec>
              <sec id="Sec17">
                <title>Study cohorts</title>
                <p id="Par85">Eligible participant patients were from 55 to 91 years old, fluent in English or Spanish, and had at least six years of education. Participants were categorized into three groups: CN, MCI (sMCI + pMCI), or AD. CN individuals were free of memory complaints, had a mini-mental state examination (MMSE) score of 24 to 30, and an average clinical dementia rating sum of boxes score (CDR-SB) of 0.04. MCI individuals had MMSE scores of 23 to 30, and an average CDR-SB of 1.582. MMSE and CDR-SB scores for MCI subjects were considerably different from CN subjects (<italic>P</italic> &lt; <italic>0.0001</italic>). The ages of MCI subjects were significantly different from AD and CN subjects (<italic>P</italic> &lt; <italic>0.005</italic>). The years of education for MCI subjects were significantly different from CN subjects (<italic>P</italic> &lt; <italic>0.01</italic>). AD patients fulfill diagnostic criteria for probable AD as set by the National Institute of Neurological and Communicative Disorders and Stroke of the United States and the Alzheimer’s Disease and Related Disorders Association<sup><xref ref-type="bibr" rid="CR68">68</xref></sup>, with MMSE scores of 19 to 27 and an average CDR-SB of 4.347. MMSE and CDR-SB scores of AD subjects were significantly different from CN and MCI subjects (<italic>p</italic> &lt; <italic>0.0001</italic>). The ages of AD subjects were significantly different from CN subjects (<italic>P</italic> &lt; <italic>0.05</italic>), and the education years of AD subjects were significantly different from CN subjects (<italic>P</italic> &lt; <italic>0.0001</italic>) and MCI subjects (<italic>P</italic> &lt; <italic>0.01</italic>). Available ADNI subjects (n = 1048) with both a T1-weighted MRI scan and a PET–fluorodeoxyglucose (PET-FDG) image upon preparation of this manuscript were used in this study. For the PET data, we collected only three PET-FDG features from Banner Alzheimer’s Institute (BAI)-PET Naval Medical Research Center (NMRC) summaries and University of California, Berkeley, FDG analysis<sup><xref ref-type="bibr" rid="CR69">69</xref></sup>. The MRI features used in our experiments are based on the imaging data from the ADNI database processed by a team from UCSF, who performed cortical reconstruction and volumetric segmentations with the FreeSurfer version 6.0 image analysis suite (<ext-link ext-link-type="uri" xlink:href="https://surfer.nmr.mgh.harvard.edu/">https://surfer.nmr.mgh.harvard.edu/</ext-link>) according to the atlas generated by Desikan et al.<sup><xref ref-type="bibr" rid="CR70">70</xref></sup>.</p>
                <p id="Par86">The FreeSurfer software version 6.0 (<ext-link ext-link-type="uri" xlink:href="https://surfer.nmr.mgh.harvard.edu/">https://surfer.nmr.mgh.harvard.edu/</ext-link>) was employed to automatically label cortical and subcortical tissue classes for the structural MRI scan of each subject, and to extract thickness measures of cortical regions of interest and cortical and subcortical volume measures. Based on the 312 features collected from each MRI image, we calculated seven features including ventricles, middle temporal gyrus [midTemp], fusiform, entorhinal, hippocampus, and whole brain volume. The equations used to calculate these features can be found in Supplementary File (part 2). Details of the analysis procedure are available at ADNI (<ext-link ext-link-type="uri" xlink:href="http://adni.loni.usc.edu/methods/mri-tool/mri-analysis/">http://adni.loni.usc.edu/methods/mri-tool/mri-analysis/</ext-link>). Detailed descriptions of the ADNI subjects, image acquisition protocol procedures, and post-acquisition preprocessing procedures can be found at ADNI (<ext-link ext-link-type="uri" xlink:href="http://www.adni-info.org/">http://www.adni-info.org/</ext-link>). Demographic and clinical information of the subjects is shown in Table <xref rid="Tab11" ref-type="table">11</xref>. In this study, we utilized multiple modalities that include the followings: (i) Cognitive scores, e.g. 12 features of the Alzheimer’s diseases assessment scale–cognitive subscale (ADAS-Cog) 11, ADAS-Cog 13, global CDR (CDGLOBAL), CDRSB, functional assessment questionnaire (FAQ), geriatric depression scale (GDT), MMSE, Montreal cognitive assessment (MoCA), and the neuropsychiatric inventory questionnaire score (NPISCORE). (ii) PET features, i.e. FDG, hypometabolic convergence index (HCI), and statistical region of interest [SROI]). (iii) Neuropsychological battery, i.e. 35 features of the Rey auditory verbal learning test (RAVLT), CLOCK, COPY, and AVTOT total scores and sub-scores. (iv) Neuropathology vital signs, i.e. seven features including body mass index (BMI), weight, blood pressure, etc. (v) Cerebrospinal fluid (CSF) biomarkers, i.e. TAU, phosphorylated TAU—PTAU, and amyloid-β peptide of 42 amino acids- Aβ<sub>1–42</sub>. (vi) Demographics, i.e. gender, age, number of years of education, marital status, and ethnic and racial categories. (vii) Medical history, i.e. 22 binary features to check the patient and parents histories, including smoking, allergies, malignancy, gastrointestinal problems, etc. (viii) Symptoms, i.e. 27 binary features asking about diarrhea, dizziness, falls, etc. (ix) Lab tests, i.e. 41 blood lab tests, including vitamin B12, monocytes, platelets, etc. (x) Physical examinations, i.e. 10 feature asking about problems in the head, neck, skin, chest, etc. (xi) Neurological exams, i.e. 12 binary features from the cerebellar exam, gait, motor strength, sensory capabilities, etc. (xii) MRI volumetric features, i.e. volumes of ventricles, MidTemp, fusiform, entorhinal cortex, hippocampus, total intracranial volume (ICV), and whole brain. (xiii) Genetics, i.e. APOE4. <italic>To the best of our knowledge, there are no studies in the literature, which study the role of all of these biomarkers.</italic> More details about these features can be found in Supplementary File (part 2).<table-wrap id="Tab11"><label>Table 11</label><caption><p>Descriptive statistics from the dataset used.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">CN (n = 294)</th><th align="left">sMCI (n = 254)</th><th align="left">pMCI (n = 232)</th><th align="left">AD (n = 268)</th><th align="left">Combined (n = 1048)</th></tr></thead><tbody><tr><td align="left">Gender (M/F)</td><td align="left">140 ± 154</td><td align="left">144/110</td><td align="left">136/96</td><td align="left">151 ± 117</td><td align="left">571/477</td></tr><tr><td align="left">Age (years)</td><td align="left">74.120 ± 5.890</td><td align="left">72.202 ± 07.553</td><td align="left">73.771 ± 7.0840</td><td align="left">75.241 ± 7.610</td><td align="left">73.864 ± 07.107</td></tr><tr><td align="left">Education (years)</td><td align="left">16.405 ± 2.733</td><td align="left">15.9530 ± 2.867</td><td align="left">15.784 ± 2.7830</td><td align="left">15.175 ± 2.923</td><td align="left">15.844 ± 02.858</td></tr><tr><td align="left">FAQ</td><td align="left">0.1940 ± 0.720</td><td align="left">01.539 ± 02.817</td><td align="left">5.7110 ± 4.8680</td><td align="left">13.146 ± 6.814</td><td align="left">05.053 ± 06.754</td></tr><tr><td align="left">MMSE</td><td align="left">29.085 ± 1.143</td><td align="left">27.941 ± 01.722</td><td align="left">26.7590 ± 1.736</td><td align="left">23.235 ± 2.015</td><td align="left">26.797 ± 2.7960</td></tr><tr><td align="left">MOCA</td><td align="left">25.569 ± 1.866</td><td align="left">23.493 ± 02.452</td><td align="left">20.947 ± 01.908</td><td align="left">17.553 ± 3.377</td><td align="left">21.993 ± 3.9450</td></tr><tr><td align="left">FDG</td><td align="left">6.5690 ± 0.477</td><td align="left">06.3820 ± 0.599</td><td align="left">05.800 ± 00.462</td><td align="left">5.4060 ± 0.614</td><td align="left">6.0560 ± 0.7180</td></tr><tr><td align="left">APOE4</td><td align="left">0.2520 ± 0.472</td><td align="left">0.4610 ± 0.6380</td><td align="left">0.8660 ± 00.686</td><td align="left">0.8880 ± 0.710</td><td align="left">0.6010 ± 0.6850</td></tr><tr><td align="left">CSF PTAU pg/mL</td><td align="left">19.423 ± 6.820</td><td align="left">25.640 ± 11.703</td><td align="left">35.2240 ± 13.20</td><td align="left">35.717 ± 13.11</td><td align="left">28.5940 ± 13.29</td></tr><tr><td align="left">CSF TAU pg/mL</td><td align="left">215.07 ± 67.28</td><td align="left">270.861 ± 106.4</td><td align="left">352.86 ± 116.27</td><td align="left">361.2 ± 121.41</td><td align="left">296.46 ± 120.58</td></tr><tr><td align="left">ADAS-Cog 11</td><td align="left">05.617 ± 2.784</td><td align="left">8.6260 ± 3.5200</td><td align="left">13.412 ± 4.3850</td><td align="left">19.318 ± 6.569</td><td align="left">11.576 ± 06.970</td></tr><tr><td align="left">ADAS-Cog 13</td><td align="left">08.600 ± 4.108</td><td align="left">13.791 ± 05.303</td><td align="left">21.580 ± 05.841</td><td align="left">29.706 ± 7.835</td><td align="left">18.129 ± 10.085</td></tr><tr><td align="left">RAVLT immediate</td><td align="left">045.595 ± 9.64</td><td align="left">37.705 ± 10.308</td><td align="left">27.444 ± 06.510</td><td align="left">22.466 ± 7.069</td><td align="left">33.750 ± 12.585</td></tr><tr><td align="left">RAVLT learn</td><td align="left">06.139 ± 2.143</td><td align="left">04.799 ± 02.403</td><td align="left">02.853 ± 02.219</td><td align="left">01.799 ± 1.810</td><td align="left">3.9770 ± 02.752</td></tr><tr><td align="left">RAVLT forgetting</td><td align="left">03.582 ± 2.810</td><td align="left">04.343 ± 02.497</td><td align="left">05.039 ± 02.193</td><td align="left">04.381 ± 1.783</td><td align="left">4.2930 ± 02.420</td></tr><tr><td align="left">RAVLT % forget</td><td align="left">32.612 ± 27.53</td><td align="left">50.000 ± 30.027</td><td align="left">78.188 ± 27.892</td><td align="left">88.562 ± 21.22</td><td align="left">61.223 ± 35.098</td></tr><tr><td align="left">CDR-SB</td><td align="left">0.0390 ± 0.141</td><td align="left">1.1970 ± 0.6390</td><td align="left">02.004 ± 0.9980</td><td align="left">04.347 ± 1.591</td><td align="left">01.856 ± 01.896</td></tr><tr><td align="left">GDTOTAL</td><td align="left">0.7890 ± 1.056</td><td align="left">1.7090 ± 01.462</td><td align="left">01.668 ± 01.423</td><td align="left">01.634 ± 1.454</td><td align="left">01.423 ± 01.404</td></tr><tr><td align="left">HCI</td><td align="left">8.9500 ± 3.330</td><td align="left">11.066 ± 04.080</td><td align="left">15.560 ± 04.770</td><td align="left">21.158 ± 7.384</td><td align="left">14.048 ± 06.996</td></tr><tr><td align="left">Hippo. vol. (cm<sup>3</sup>) (/1000)</td><td align="left">7.4520 ± 0.920</td><td align="left">07.106 ± 01.074</td><td align="left">06.083 ± 01.038</td><td align="left">05.713 ± 0.995</td><td align="left">06.621 ± 01.240</td></tr></tbody></table><table-wrap-foot><p>AD, Alzheimer’s disease; MCI, mild cognitive impairment; pMCI-sMCI, progressive MCI – stable MCI; CN, cognitive normal; CDR, clinical dementia rating; ADAS-Cog, Alzheimer’s Disease Assessment Scale–Cognitive Subscale test; RAVLT, Rey Auditory Verbal Learning Test; FAQ, Functional Assessment Questionnaire; MMSE, Mini–Mental State Examination; FDG, sum of mean glucose metabolism uptake in regions of angular, temporal, and posterior cingulate; TAU, CSF level of TAU; Aβ42, CSF level of amyloid β1–42 peptide; HCI, hypometabolic convergence index; AV45, Average AV45 SUVR of frontal, anterior cingulate, precuneus, and parietal cortex relative to the cerebellum; Hippo, Hippocampus; GDTOTAL, Geriatric Depression Scale.</p><p>*Data are mean ± standard deviation.</p></table-wrap-foot></table-wrap></p>
              </sec>
              <sec id="Sec18">
                <title>Feature selection and modeling approach</title>
                <p id="Par87">The proposed model has two main layers. Each layer has an oracle classifier based on RF and a set of 22 explainers. The oracle is trained to be as accurate as possible based on the fused dataset. The First Layer’s oracle classifies the patient as CN, MCI, or AD based on the whole dataset. The Second Layer’s oracle concentrates further on the MCI cases, filtered from the previous layer, to predict their probable progression to AD within three years from baseline. As such, the Second Layer classifies the MCI cases into sMCI and pMCI cases. The development process of the proposed oracles has several major steps, as presented in Fig. <xref rid="Fig5" ref-type="fig">5</xref>. These steps are applied in the same order for both layers separately. <italic>First</italic>, after fusing the raw data modalities, for each layer, the full dataset is stratified and randomly divided into a model development set [<inline-formula id="IEq9"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S1$$\end{document}</tex-math><mml:math id="M76"><mml:mrow><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq9.gif"/></alternatives></inline-formula>] (90%) and a testing set [<inline-formula id="IEq10"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S2$$\end{document}</tex-math><mml:math id="M78"><mml:mrow><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq10.gif"/></alternatives></inline-formula>] (10%) that is utilized to evaluate and compare the generality and explainability of models. This split prevents the mixing of model-selection and performance estimation, which supports the estimations of unbiased generalization performance from the models. <italic>Second</italic>, a feature standardization step is assimilated on numerical features to normalize them in the same way, which is done by standardizing the random variables with zero mean and unitary standard deviation. Note that categorical features are excluded from the normalization process.<fig id="Fig5"><label>Figure 5</label><caption><p>Development process for the oracle model in each layer.</p></caption><graphic xlink:href="41598_2021_82098_Fig5_HTML" id="MO5"/></fig></p>
                <p id="Par88"><italic>Third</italic>, for enhanced generalization performance of the models, the <inline-formula id="IEq11"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S1$$\end{document}</tex-math><mml:math id="M80"><mml:mrow><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq11.gif"/></alternatives></inline-formula> set is used to implement a feature selection process to identify the most relevant features. <italic>Fourth</italic>, most ML approaches tend to generate biased models when handling imbalanced datasets. Our Second Layer’s dataset is balanced (52.3% sMCI and 47.7% pMCI). However, the First Layer’s dataset is imbalanced (28.05% CN, 46.37% MCI, and 25.58% AD). Therefore, the synthetic minority oversampling technique (SMOTE) is used to handle the class imbalance in the <inline-formula id="IEq12"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S1$$\end{document}</tex-math><mml:math id="M82"><mml:mrow><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq12.gif"/></alternatives></inline-formula> set of the First Layer by resampling the original data and creating synthetic instances<sup><xref ref-type="bibr" rid="CR71">71</xref></sup>. <italic>Fifth</italic>, to guarantee unbiased tuning of model hyperparameters, and because our datasets are relatively small, the model selection and validation process (i.e. hyperparameter optimization) is carried out based on the grid search and <italic>nested k</italic>-fold stratified cross-validation (CV) where <italic>k</italic> = <italic>10</italic><sup><xref ref-type="bibr" rid="CR72">72</xref></sup>. The entire process has two loops: an inner loop for hyperparameter tuning, and an outer loop for evaluation of the model with selected parameters on unseen data<sup><xref ref-type="bibr" rid="CR73">73</xref></sup>. Model selection without nested CV uses the same data from parameter tuning and model evaluation, where information may leak into the model and overfit the data. The leave-one-out cross-validation (LOOCV), i.e. k-fold CV where <italic>k</italic> = <italic>n</italic><sup><xref ref-type="bibr" rid="CR72">72</xref></sup>, assures small bias but large variance<sup><xref ref-type="bibr" rid="CR74">74</xref></sup>. The tenfold CV provides the best trade-off between bias and variance<sup><xref ref-type="bibr" rid="CR75">75</xref></sup>. Keeping the <inline-formula id="IEq13"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S2$$\end{document}</tex-math><mml:math id="M84"><mml:mrow><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq13.gif"/></alternatives></inline-formula> set untouched helps us to verify that the generalization performance of the selected model thanks to tenfold CV is preserved even with unseen data. In each layer, we develop an RF classification model based on the selected features.</p>
                <p id="Par89">RF classifiers are used because they are accurate, and it is possible to get the feature contributions for the whole model (a global explanation) and calculate feature contributions for each specific instance (a local explanation). Although SVM and DL have a huge capability to fit complex nonlinear models to the data and achieve high performance, the resultant models are opaque what makes hard to explain their decisions<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>. We therefore selected RF as the oracle to classify patients in our two-layer model.</p>
                <p id="Par90">After building the RF oracle classifiers, we implement two interpretable classifiers (DT and FRBS) for each of the 11 modalities in each layer. The resulting 22 classifiers play the role of explainers to interpret the oracle decisions at each layer. Thus, we have 11 classifiers as a DT, and 11 classifiers as an FRBS. The FRBS deals naturally with imprecision and uncertainty<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. Moreover, an FRBS plays an important role in the quest for XAI<sup><xref ref-type="bibr" rid="CR76">76</xref></sup>. More precisely, we selected the Fuzzy Unordered Rule Induction Algorithm (FURIA) [51] from among all algorithms available for building an FRBS. FURIA is recognized as one of the most accurate fuzzy classifiers. In addition, FURIA usually yields a compact set of fuzzy IF–THEN rules. FURIA is based on the Repeated Incremental Pruning to Produce Error Reduction (RIPPER) algorithm<sup><xref ref-type="bibr" rid="CR77">77</xref></sup>. FURIA translates RIPPER rule antecedents into trapezoidal fuzzy sets. These antecedents are related by FURIA weighed rules, which do not necessarily include an antecedent for all the input attributes and can have more than one antecedent for the same attribute. Each FURIA rule is associated with a certainty factor, i.e. a rule weight that FURIA computes regarding the relevance of the rule in accordance with the training data. Given a specific data instance, the min–max fuzzy inference mechanism is applied, and the winning rule, i.e. the one with maximum firing degree, determines the output class. If no rules are fired for a given data instance, then FURIA applies the so-called rule-stretching mechanism, which looks for slight modifications in the rule base with the aim of finding a new rule on-the-fly that is able to manage the given instance. Unfortunately, FURIA rules lack linguistic meaning because they have local semantics, i.e. the most suitable fuzzy sets are defined independently for each rule. This fact may jeopardize the interpretability of FURIA rules.</p>
                <p id="Par91">With the aim of paving the way from interpretable to explainable classifiers, we use ExpliClas<sup><xref ref-type="bibr" rid="CR78">78</xref></sup>. This is a web service ready to provide users with multimodal (textual + graphical) explanations related to the DT and FURIA. As a matter of fact, ExpliClas creates a linguistic layer on top of the DT and FURIA. First, global semantics (whether we consider the DT or FURIA) is set up beforehand. By default, three linguistic terms (e.g., low, medium, high) are defined for each attribute. Next, domain experts (if available) can add/remove/refine the given linguistic terms to assure they are meaningful. Then, given a specific data instance, the actual classification carried out by the DT or FURIA is automatically interpreted by ExpliClas with regard to the linguistic terms previously defined. In practice, both the activated branch of the DT and the winner rule of FURIA are translated into sequences of meaningful words (i.e., each numerical interval in the DT or fuzzy set in FURIA is verbalized by the closest linguistic term in ExpliClas). As a result, users are provided with an explanation in natural language of the output class in terms of the involved attributes. It is worth noting that we substituted the default linguistic terms in ExpliClas by meaningful linguistic terms in agreement with a physician in this study.</p>
                <p id="Par92">Figure <xref rid="Fig6" ref-type="fig">6</xref> shows a detailed description of our proposed XAI framework. The first step is preprocessing, which is used to prepare and improve the quality of the datasets. This step has the following four sub-processes.<list list-type="bullet"><list-item><p id="Par93"><italic>Preparing biological modalities:</italic> For the biological MRI modality, we used ready-made extracted and pre-processed features (<ext-link ext-link-type="uri" xlink:href="http://adni.loni.usc.edu/">http://adni.loni.usc.edu/</ext-link>), done by ADNI. We then used these detailed features to create a list of seven volumetric summary features for the most critical brain regions of interest, including the hippocampus, ventricles, entorhinal, fusiform gyrus, MidTemp, whole brain, and ICV. For biological PET modality, we collected only three FDG-PET features from BAI-PET NMRC summaries and UC Berkeley-FDG analysis<sup><xref ref-type="bibr" rid="CR69">69</xref></sup>. For instance, to measure FDG, mean levels of glucose metabolisms are first recorded at different regions of interest. The five most common regions are left and right angular gyri, posterior cingulate cortex, and left and right inferior temporal gyri. Then, the summation of the mean glucose metabolisms is considered FDG<sup><xref ref-type="bibr" rid="CR79">79</xref></sup>. Other PET measures include the HCI to characterize in a single summary metric the extent to which both the magnitude and spatial extent of cerebral glucose hypometabolism in a person’s FDG-PET image corresponds to that in patients with probable AD dementia<sup><xref ref-type="bibr" rid="CR80">80</xref></sup>. Our prepared PET and MRI features are based on their popularity in studies from the literature, their availability, and their level of accuracy in our current medical problem (see Supplementary File [part 2] for further details).</p></list-item><list-item><p id="Par94"><italic>Multimodal fusion:</italic> The AD environment is multimodal in nature, where multiple feature sets are combined. This is called multimodal fusion, where each modality has supplementary information to support the final decision. In this context, two simple strategies are followed: late fusion and early fusion. In late fusion (i.e., decision-level fusion), a different model is trained independently for each modality, and the individual outcomes are merged into a final common decision, as seen in Fig. <xref rid="Fig7" ref-type="fig">7</xref>a. In the early fusion strategy (i.e., feature-level fusion), raw features from the individual modalities are integrated to create a common feature vector. The common feature vector is then used to train a classifier as the final prediction model, as seen in Fig. <xref rid="Fig7" ref-type="fig">7</xref>b. Each strategy has its own advantages and disadvantages. However, late fusion is based mainly on computing weights associated to which classifiers, which is not an easy process to learn and to explain. Therefore, in this study, we apply the early fusion strategy.</p></list-item><list-item><p id="Par95"><italic>Data standardization:</italic> After data splitting, each type of participating data may have a different order of magnitude. These raw data cannot be used directly to train the RF model. To ensure that every feature has the same level of importance, data were standardized using the z-score method (see Eq. <xref rid="Equ1" ref-type="">1</xref>). The standardized data is therefore normally distributed with mean and standard deviation of 0 and 1, respectively.<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$z_{j} = \frac{{x_{j} - \mu_{j} }}{{\sigma_{j} }}$$\end{document}</tex-math><mml:math id="M86" display="block"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="41598_2021_82098_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>
where <inline-formula id="IEq14"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}_{j}$$\end{document}</tex-math><mml:math id="M88"><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq14.gif"/></alternatives></inline-formula> is the old value of feature <inline-formula id="IEq15"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M90"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq15.gif"/></alternatives></inline-formula>, <inline-formula id="IEq16"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${z}_{j}$$\end{document}</tex-math><mml:math id="M92"><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq16.gif"/></alternatives></inline-formula> is the normalized value, <inline-formula id="IEq17"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mu }_{j}$$\end{document}</tex-math><mml:math id="M94"><mml:msub><mml:mi>μ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq17.gif"/></alternatives></inline-formula> is the feature’s mean, and <inline-formula id="IEq18"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sigma }_{j}$$\end{document}</tex-math><mml:math id="M96"><mml:msub><mml:mi>σ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq18.gif"/></alternatives></inline-formula> is the feature’s standard deviation. As a side effect, this method removes outliers.</p></list-item><list-item><p id="Par97"><italic>Handling missing values:</italic> For handling missing values, we first removed any feature with more than 30% of the values missing. Then, we use the k-nearest neighbors (KNN) algorithm to impute missing values, where missing values are replaced using information from neighbor subjects that have the same class. After finding <inline-formula id="IEq19"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M98"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq19.gif"/></alternatives></inline-formula> neighbors, the imputation value is computed by averaging the values of those neighbors. In our study, the mixed Euclidean distance (MED) was used, and <italic>k</italic> was set to 10 empirically via experiments (for numerical values, the Euclidean distance was used; for categorical values, a distance of 0 was taken if both values were the same, otherwise the distance was set to 1). Please note that the data standardization process has been done before the missing values handling.<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MED\left( {x,y} \right) = \sqrt {\mathop \sum \limits_{i = 1}^{N} d_{i} \left( {x_{i} ,y_{i} } \right)^{2} }$$\end{document}</tex-math><mml:math id="M100" display="block"><mml:mrow><mml:mi>M</mml:mi><mml:mi>E</mml:mi><mml:mi>D</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:math><graphic xlink:href="41598_2021_82098_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>
where <inline-formula id="IEq20"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_{i} \left( {x_{i} ,y_{i} } \right) = \left\{ {\begin{array}{*{20}l} {overlab\left( {x_{i} ,y_{i} } \right)} \hfill &amp; {if\;i\;is\;categorical} \hfill \\ {diff\left( {x_{i} ,y_{i} } \right)} \hfill &amp; {if\;i\;is\;numerical} \hfill \\ \end{array} } \right.$$\end{document}</tex-math><mml:math id="M102"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced open="{"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>b</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.277778em"/><mml:mi>i</mml:mi><mml:mspace width="0.277778em"/><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mspace width="0.277778em"/><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.277778em"/><mml:mi>i</mml:mi><mml:mspace width="0.277778em"/><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mspace width="0.277778em"/><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq20.gif"/></alternatives></inline-formula>, <inline-formula id="IEq21"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$overlab\left( {x_{i} ,y_{i} } \right) = \left\{ {\begin{array}{*{20}l} 0 \hfill &amp; {if\;x_{i} = y_{i} } \hfill \\ 1 \hfill &amp; {if\;x_{i} \ne y_{i} } \hfill \\ \end{array} } \right.$$\end{document}</tex-math><mml:math id="M104"><mml:mrow><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>b</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced open="{"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.277778em"/><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mn>1</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.277778em"/><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>≠</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq21.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq22"><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$diff\left({x}_{i},{y}_{i}\right)=\frac{{x}_{i}-{y}_{i}}{{max}_{i}-{min}_{i}}$$\end{document}</tex-math><mml:math id="M106"><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq22.gif"/></alternatives></inline-formula></p></list-item></list><fig id="Fig6"><label>Figure 6</label><caption><p>The proposed XAI framework. A variety of data modalities are used to build the predictive model. In addition, a variety of explanations are built for the entire RF behavior and for each prediction. The FreeSurfer version 6.0 is used (<ext-link ext-link-type="uri" xlink:href="https://surfer.nmr.mgh.harvard.edu/">https://surfer.nmr.mgh.harvard.edu/</ext-link>).</p></caption><graphic xlink:href="41598_2021_82098_Fig6_HTML" id="MO6"/></fig><fig id="Fig7"><label>Figure 7</label><caption><p>Multimodal fusion strategies: (<bold>a</bold>) late fusion, (<bold>b</bold>) early fusion.</p></caption><graphic xlink:href="41598_2021_82098_Fig7_HTML" id="MO7"/></fig></p>
                <p id="Par99">For the automatic feature selection, we used wrapper methods, which obtain subsets of features, and offer better performance than filter methods<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>. The commonly used classifiers in wrapper are naïve Bayes<sup><xref ref-type="bibr" rid="CR81">81</xref></sup>, SVM<sup><xref ref-type="bibr" rid="CR82">82</xref></sup>, RF<sup><xref ref-type="bibr" rid="CR83">83</xref></sup>, and AdaBoost<sup><xref ref-type="bibr" rid="CR84">84</xref></sup>. Along with greedy search algorithms, these methods find the optimal set of features. It is worth noting that the well-known principal component analysis (PCA) technique cannot be used in our experiments because we need to preserve meaningful medical features, and PCA produces synthetic features that are hard to interpret as a combination of the principal components.</p>
                <p id="Par100">Recursive feature elimination (RFE) is famous in the medical domain owing to its efficiency in reducing computational burden<sup><xref ref-type="bibr" rid="CR85">85</xref></sup>. It maximizes its predictor performance through backward feature elimination as well as its ranking criterion. The literature asserts that RF-RFE outperforms SVM-RFE in finding the best subsets of features, and does not need any parameter regulation to offer reasonable outcomes<sup><xref ref-type="bibr" rid="CR86">86</xref></sup>. We applied RFE with the stratified tenfold CV related to the <inline-formula id="IEq23"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S1$$\end{document}</tex-math><mml:math id="M108"><mml:mrow><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq23.gif"/></alternatives></inline-formula> dataset. To prevent the bias introduced by randomly partitioning a dataset in CV, the tenfold CV procedure was repeated five times with different data partitions. To evaluate the robustness of the RF-RFE process in selecting the optimal set of features, we utilized the RFE method with RF, SVM, and gradient boosting (GB) classifiers. The initial fused feature set had 188 features combined from 11 different modalities, including MRI, genetics, and symptoms.</p>
                <p id="Par101">The two RF models are used as the oracle to make the final decisions. Of course, final decisions are made by physicians in light of the provided information (i.e., both oracle decisions, along with related explanations). The 11 modalities are used separately to build classifiers by using two interpretable ML models, i.e. DT and FURIA. In each layer, the resulting 22 interpretable models are used to support the oracle model by providing interpretations of its decisions. The supplementary explanations extracted from different modalities with different classification algorithms are expected to enhance the medical expert’s confidence in the oracle decisions. As a result, it supports the applicability of the resulting system in real medical environments. It is worth noting that we are not interested in explaining the internal behavior of the oracle but providing physicians with post-hoc explanations of the decision output. Our approach is inspired in the way how different experts who look at the same patient may figure out different explanations for a given output in terms of different features (i.e., in accordance with their own knowledge and background). Similarly, our explainers provide physicians with complementary explanations, all of them consistent and reliable.</p>
              </sec>
              <sec id="Sec19">
                <title>Random forest for classification</title>
                <p id="Par102">RF is an ensemble classifier formed by a family of <inline-formula id="IEq24"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$T$$\end{document}</tex-math><mml:math id="M110"><mml:mi>T</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq24.gif"/></alternatives></inline-formula> decision trees,<inline-formula id="IEq25"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h\left({n}_{1}|{\theta }_{1}\right),\dots , h\left({n}_{T}|{\theta }_{T}\right)$$\end{document}</tex-math><mml:math id="M112"><mml:mrow><mml:mi>h</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mfenced><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>n</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq25.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq26"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{i}=({\theta }_{i1},{\theta }_{i2}{,\dots ,\theta }_{ip})$$\end{document}</tex-math><mml:math id="M114"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ip</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq26.gif"/></alternatives></inline-formula> is a list of <inline-formula id="IEq27"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p$$\end{document}</tex-math><mml:math id="M116"><mml:mi>p</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq27.gif"/></alternatives></inline-formula> features for DT <inline-formula id="IEq28"><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M118"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq28.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq29"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${n}_{i}$$\end{document}</tex-math><mml:math id="M120"><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq29.gif"/></alternatives></inline-formula> represents the training instances. Each DT leads to a classifier. Specifically, given data <inline-formula id="IEq30"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D={\{{(\theta }_{i},{y}_{i})\}}_{i=1}^{N}$$\end{document}</tex-math><mml:math id="M122"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq30.gif"/></alternatives></inline-formula>, we train a family of classifiers,<inline-formula id="IEq31"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${h}_{T}$$\end{document}</tex-math><mml:math id="M124"><mml:msub><mml:mi>h</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq31.gif"/></alternatives></inline-formula>. The predictions of all individual trees are combined by using the majority-voting mechanism. A node is partitioned using the best possible binary split. In our case, information gain is used to define the split point at each node, where <inline-formula id="IEq32"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G\left(S,A\right)=E\left(S\right)-\sum_{v\in values\left(A\right)}\frac{\left|{S}_{v}\right|}{\left|S\right|}E\left({S}_{V}\right)$$\end{document}</tex-math><mml:math id="M126"><mml:mrow><mml:mi>G</mml:mi><mml:mfenced close=")" open="("><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>A</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mfenced close=")" open="("><mml:mi>S</mml:mi></mml:mfenced><mml:mo>-</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mfenced close=")" open="("><mml:mi>A</mml:mi></mml:mfenced></mml:mrow></mml:msub><mml:mfrac><mml:mfenced close="|" open="|"><mml:msub><mml:mi>S</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mfenced><mml:mfenced close="|" open="|"><mml:mi>S</mml:mi></mml:mfenced></mml:mfrac><mml:mi>E</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>S</mml:mi><mml:mi>V</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq32.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq33"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$E(X)=-\sum_{i=1}^{c}{p}_{i} {log}_{2}({p}_{i})$$\end{document}</tex-math><mml:math id="M128"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>c</mml:mi></mml:msubsup><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="italic">log</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq33.gif"/></alternatives></inline-formula> is the entropy of set <inline-formula id="IEq34"><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X$$\end{document}</tex-math><mml:math id="M130"><mml:mi>X</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq34.gif"/></alternatives></inline-formula>, in which <inline-formula id="IEq35"><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{i}$$\end{document}</tex-math><mml:math id="M132"><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq35.gif"/></alternatives></inline-formula> is the probability of class <inline-formula id="IEq36"><alternatives><tex-math id="M133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M134"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq36.gif"/></alternatives></inline-formula>; <inline-formula id="IEq37"><alternatives><tex-math id="M135">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left|{S}_{v}\right|$$\end{document}</tex-math><mml:math id="M136"><mml:mfenced close="|" open="|"><mml:msub><mml:mi>S</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mfenced></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq37.gif"/></alternatives></inline-formula> is the number of cases with <inline-formula id="IEq38"><alternatives><tex-math id="M137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A={S}_{v}$$\end{document}</tex-math><mml:math id="M138"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq38.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq39"><alternatives><tex-math id="M139">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$|S|$$\end{document}</tex-math><mml:math id="M140"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>S</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq39.gif"/></alternatives></inline-formula> is the number of cases in <inline-formula id="IEq40"><alternatives><tex-math id="M141">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A$$\end{document}</tex-math><mml:math id="M142"><mml:mi>A</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq40.gif"/></alternatives></inline-formula>. Outliers are likely to be ignored by most trees, which makes RF more stable.</p>
                <p id="Par103">Another important feature of RF is its ability to measure the importance of each feature based on the <italic>Gini impurity index</italic>. <italic>Gini impurity</italic> is the likelihood of an incorrect classification of a randomly selected case if it was randomly labeled according to the class distribution of the data. From intuitive perspective, Gini impurity helps the algorithm to decide the optimal split from a root node, and subsequent splits. It is calculated as <inline-formula id="IEq41"><alternatives><tex-math id="M143">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G(D)=\sum_{i=1}^{c}p\left(i\right)*(1-p(i))$$\end{document}</tex-math><mml:math id="M144"><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>c</mml:mi></mml:msubsup><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:mi>i</mml:mi></mml:mfenced><mml:mrow/><mml:mo>∗</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq41.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq42"><alternatives><tex-math id="M145">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c$$\end{document}</tex-math><mml:math id="M146"><mml:mi>c</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq42.gif"/></alternatives></inline-formula> is the number of classes and <inline-formula id="IEq43"><alternatives><tex-math id="M147">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p(i)$$\end{document}</tex-math><mml:math id="M148"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq43.gif"/></alternatives></inline-formula> is the relative frequency of class <inline-formula id="IEq44"><alternatives><tex-math id="M149">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M150"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq44.gif"/></alternatives></inline-formula> in <inline-formula id="IEq45"><alternatives><tex-math id="M151">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D$$\end{document}</tex-math><mml:math id="M152"><mml:mi>D</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq45.gif"/></alternatives></inline-formula>. For an attribute <inline-formula id="IEq46"><alternatives><tex-math id="M153">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{m}$$\end{document}</tex-math><mml:math id="M154"><mml:msub><mml:mi>θ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq46.gif"/></alternatives></inline-formula>, if it splits <inline-formula id="IEq47"><alternatives><tex-math id="M155">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D$$\end{document}</tex-math><mml:math id="M156"><mml:mi>D</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq47.gif"/></alternatives></inline-formula> in to <inline-formula id="IEq48"><alternatives><tex-math id="M157">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}_{1}$$\end{document}</tex-math><mml:math id="M158"><mml:msub><mml:mi>D</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq48.gif"/></alternatives></inline-formula> and <inline-formula id="IEq49"><alternatives><tex-math id="M159">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}_{2}$$\end{document}</tex-math><mml:math id="M160"><mml:msub><mml:mi>D</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq49.gif"/></alternatives></inline-formula>, then the Gini index for <inline-formula id="IEq50"><alternatives><tex-math id="M161">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{m}$$\end{document}</tex-math><mml:math id="M162"><mml:msub><mml:mi>θ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq50.gif"/></alternatives></inline-formula> is <inline-formula id="IEq51"><alternatives><tex-math id="M163">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${G}_{{\theta }_{m}}\left(D\right)=\frac{\left|{D}_{1}\right|}{\left|D\right|}G\left({D}_{1}\right)+\frac{\left|{D}_{2}\right|}{\left|D\right|}G\left({D}_{2}\right),$$\end{document}</tex-math><mml:math id="M164"><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:msub><mml:mi>θ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:msub><mml:mfenced close=")" open="("><mml:mi>D</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mfenced close="|" open="|"><mml:msub><mml:mi>D</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mfenced><mml:mfenced close="|" open="|"><mml:mi>D</mml:mi></mml:mfenced></mml:mfrac><mml:mi>G</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>D</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mfenced><mml:mo>+</mml:mo><mml:mfrac><mml:mfenced close="|" open="|"><mml:msub><mml:mi>D</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mfenced><mml:mfenced close="|" open="|"><mml:mi>D</mml:mi></mml:mfenced></mml:mfrac><mml:mi>G</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>D</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq51.gif"/></alternatives></inline-formula> and the reduction in impurity is <inline-formula id="IEq52"><alternatives><tex-math id="M165">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta G\left({\theta }_{m}\right)=G\left(D\right)-{G}_{{\theta }_{m}}\left(D\right)$$\end{document}</tex-math><mml:math id="M166"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>G</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>θ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mi>G</mml:mi><mml:mfenced close=")" open="("><mml:mi>D</mml:mi></mml:mfenced><mml:mo>-</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:msub><mml:mi>θ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:msub><mml:mfenced close=")" open="("><mml:mi>D</mml:mi></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq52.gif"/></alternatives></inline-formula>. A binary DT,<inline-formula id="IEq53"><alternatives><tex-math id="M167">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${h}_{T}$$\end{document}</tex-math><mml:math id="M168"><mml:msub><mml:mi>h</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq53.gif"/></alternatives></inline-formula>, is built from a learning sample of size <inline-formula id="IEq54"><alternatives><tex-math id="M169">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${n}_{t}$$\end{document}</tex-math><mml:math id="M170"><mml:msub><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq54.gif"/></alternatives></inline-formula> drawn from <inline-formula id="IEq55"><alternatives><tex-math id="M171">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D$$\end{document}</tex-math><mml:math id="M172"><mml:mi>D</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq55.gif"/></alternatives></inline-formula> using a recursive procedure, which identifies at each node <inline-formula id="IEq56"><alternatives><tex-math id="M173">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t$$\end{document}</tex-math><mml:math id="M174"><mml:mi>t</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq56.gif"/></alternatives></inline-formula> the split condition <inline-formula id="IEq57"><alternatives><tex-math id="M175">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${s}_{t}={\theta }_{m}&lt;c$$\end{document}</tex-math><mml:math id="M176"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>&lt;</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq57.gif"/></alternatives></inline-formula> that splits <inline-formula id="IEq58"><alternatives><tex-math id="M177">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${n}_{t}$$\end{document}</tex-math><mml:math id="M178"><mml:msub><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq58.gif"/></alternatives></inline-formula> node samples into <inline-formula id="IEq59"><alternatives><tex-math id="M179">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${t}_{L}$$\end{document}</tex-math><mml:math id="M180"><mml:msub><mml:mi>t</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq59.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq60"><alternatives><tex-math id="M181">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${t}_{R}$$\end{document}</tex-math><mml:math id="M182"><mml:msub><mml:mi>t</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq60.gif"/></alternatives></inline-formula> maximizes the decrease <inline-formula id="IEq61"><alternatives><tex-math id="M183">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta i\left(s,t\right)=i\left(t\right)-pL*i\left({t}_{L}\right)-pR*i({t}_{R})$$\end{document}</tex-math><mml:math id="M184"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>i</mml:mi><mml:mfenced close=")" open="("><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mfenced close=")" open="("><mml:mi>t</mml:mi></mml:mfenced><mml:mo>-</mml:mo><mml:mi>p</mml:mi><mml:mi>L</mml:mi><mml:mrow/><mml:mo>∗</mml:mo><mml:mi>i</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>t</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mfenced><mml:mo>-</mml:mo><mml:mi>p</mml:mi><mml:mi>R</mml:mi><mml:mrow/><mml:mo>∗</mml:mo><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq61.gif"/></alternatives></inline-formula>; <inline-formula id="IEq62"><alternatives><tex-math id="M185">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta i$$\end{document}</tex-math><mml:math id="M186"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq62.gif"/></alternatives></inline-formula> is the importance of node <inline-formula id="IEq63"><alternatives><tex-math id="M187">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t$$\end{document}</tex-math><mml:math id="M188"><mml:mi>t</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq63.gif"/></alternatives></inline-formula> based on Gini importance; <inline-formula id="IEq64"><alternatives><tex-math id="M189">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$pL={n}_{{t}_{L}}$$\end{document}</tex-math><mml:math id="M190"><mml:mrow><mml:mi>p</mml:mi><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq64.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq65"><alternatives><tex-math id="M191">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$pR={n}_{{t}_{R}}$$\end{document}</tex-math><mml:math id="M192"><mml:mrow><mml:mi>p</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq65.gif"/></alternatives></inline-formula>. For each node split, the Gini impurity index values for the two child nodes are less than the value for the parent node. For each variable, the summation of Gini impurity decreases in a dataset over all trees in the RF model and is the corresponding Gini importance measure for that variable. The global importance of a feature, <inline-formula id="IEq66"><alternatives><tex-math id="M193">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{m}$$\end{document}</tex-math><mml:math id="M194"><mml:msub><mml:mi>θ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq66.gif"/></alternatives></inline-formula>, for predicting <inline-formula id="IEq67"><alternatives><tex-math id="M195">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y$$\end{document}</tex-math><mml:math id="M196"><mml:mi>y</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq67.gif"/></alternatives></inline-formula> is calculated by adding up the weighted impurity decreases, <inline-formula id="IEq68"><alternatives><tex-math id="M197">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p\left(t\right)\Delta i\left({s}_{t},t\right)$$\end{document}</tex-math><mml:math id="M198"><mml:mrow><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:mi>t</mml:mi></mml:mfenced><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>i</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq68.gif"/></alternatives></inline-formula>, for all nodes <inline-formula id="IEq69"><alternatives><tex-math id="M199">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t$$\end{document}</tex-math><mml:math id="M200"><mml:mi>t</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq69.gif"/></alternatives></inline-formula> where <inline-formula id="IEq70"><alternatives><tex-math id="M201">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{m}$$\end{document}</tex-math><mml:math id="M202"><mml:msub><mml:mi>θ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq70.gif"/></alternatives></inline-formula> is used, averaged over all <inline-formula id="IEq71"><alternatives><tex-math id="M203">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$T$$\end{document}</tex-math><mml:math id="M204"><mml:mi>T</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq71.gif"/></alternatives></inline-formula> trees in the forest (see Eq. <xref rid="Equ3" ref-type="">3</xref>).<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M205">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$imp\left( {\theta_{m} } \right) = \frac{1}{T}\mathop \sum \limits_{T} \mathop \sum \limits_{{t \in T:v\left( {s_{t} } \right) = \theta_{m} }} p\left( t \right)\Delta i\left( {s_{t} ,t} \right)$$\end{document}</tex-math><mml:math id="M206" display="block"><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>θ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mi>T</mml:mi></mml:munder><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>T</mml:mi><mml:mo>:</mml:mo><mml:mi>v</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:munder><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:mi>t</mml:mi></mml:mfenced><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>i</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="41598_2021_82098_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula></p>
                <p id="Par104">Interested readers are referred to<sup><xref ref-type="bibr" rid="CR56">56</xref></sup> for further details about the RF algorithm. More details on the Gini variable importance approach in RF can be found in<sup><xref ref-type="bibr" rid="CR87">87</xref></sup>.</p>
                <sec id="Sec20">
                  <title>Explainability capabilities</title>
                  <p id="Par105">As RF is an ensemble classifier, it is difficult to get understandable explanation from this complex model. Therefore, we use a collection of simpler models, see Fig. <xref rid="Fig8" ref-type="fig">8</xref>, to endow RF with explainability. Each of these models is called “<italic>an explainer</italic>.” These models provide complementary views and explanations associated to the original RF model. Because AD is a complex disease and RF is a complex model, in order to have a global comprehensive, consistent, and accurate picture about AD progression, several explanatory techniques are required<sup><xref ref-type="bibr" rid="CR88">88</xref></sup>. Our explainer framework includes SHAP explainer, DT explainer, and fuzzy explainer. Each of these explainers has been carefully designed to exhibit a good balance between accuracy and explainability. All explainers have been tested to verify they provide physicians with consistent and reliable explanations. As a result, medical expert will be more confident regarding the RF decisions.<fig id="Fig8"><label>Figure 8</label><caption><p>Roles of explainers to enhance RF interpretability.</p></caption><graphic xlink:href="41598_2021_82098_Fig8_HTML" id="MO8"/></fig></p>
                  <p id="Par106">For each layer in the proposed model, we provide two types of explanation. <italic>The first type gets explanations from the RF black-box model itself.</italic> For an RF model <inline-formula id="IEq72"><alternatives><tex-math id="M207">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b$$\end{document}</tex-math><mml:math id="M208"><mml:mi>b</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq72.gif"/></alternatives></inline-formula> and a dataset <inline-formula id="IEq73"><alternatives><tex-math id="M209">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D=\left\{\theta ,Y\right\}$$\end{document}</tex-math><mml:math id="M210"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq73.gif"/></alternatives></inline-formula>, function <inline-formula id="IEq74"><alternatives><tex-math id="M211">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f:\left(\theta \to Y\right)\times \left({\theta }^{n}\times {Y}^{n}\right)\to V$$\end{document}</tex-math><mml:math id="M212"><mml:mrow><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:mfenced close=")" open="("><mml:mi>θ</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mi>Y</mml:mi></mml:mfenced><mml:mo>×</mml:mo><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msup><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msup></mml:mfenced><mml:mo stretchy="false">→</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq74.gif"/></alternatives></inline-formula> takes <inline-formula id="IEq75"><alternatives><tex-math id="M213">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b$$\end{document}</tex-math><mml:math id="M214"><mml:mi>b</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq75.gif"/></alternatives></inline-formula> and <inline-formula id="IEq76"><alternatives><tex-math id="M215">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D$$\end{document}</tex-math><mml:math id="M216"><mml:mi>D</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq76.gif"/></alternatives></inline-formula> as input and returns either global or local approximations <inline-formula id="IEq77"><alternatives><tex-math id="M217">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$V$$\end{document}</tex-math><mml:math id="M218"><mml:mi>V</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq77.gif"/></alternatives></inline-formula> of the behavior of <inline-formula id="IEq78"><alternatives><tex-math id="M219">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b$$\end{document}</tex-math><mml:math id="M220"><mml:mi>b</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq78.gif"/></alternatives></inline-formula>,<inline-formula id="IEq79"><alternatives><tex-math id="M221">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f(b,D)=v\in V$$\end{document}</tex-math><mml:math id="M222"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq79.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq80"><alternatives><tex-math id="M223">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$V$$\end{document}</tex-math><mml:math id="M224"><mml:mi>V</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq80.gif"/></alternatives></inline-formula> is the set of all possible explanations from RF. List <inline-formula id="IEq81"><alternatives><tex-math id="M225">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$V$$\end{document}</tex-math><mml:math id="M226"><mml:mi>V</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq81.gif"/></alternatives></inline-formula> includes explanations regarding both global and local issues. We use <italic>Eli5</italic> to calculate global feature importance based on the Gini index<sup><xref ref-type="bibr" rid="CR89">89</xref>,<xref ref-type="bibr" rid="CR90">90</xref></sup>, i.e. we compute the level of importance for all features based on the entire set of training data and the RF structure. Because model <inline-formula id="IEq82"><alternatives><tex-math id="M227">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b$$\end{document}</tex-math><mml:math id="M228"><mml:mi>b</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq82.gif"/></alternatives></inline-formula> is complex, global explanations can sometimes be too approximate to be trustworthy. In addition, medical experts prefer individualized explanations for each specific patient according to his/her own features. Then, we need to take care of local feature contributions too. These explanations, with the contribution directions, are provided for every single patient according to his/her feature vector. We use SHAP tree explainer, which is called the additive feature attribution method<sup><xref ref-type="bibr" rid="CR42">42</xref>,<xref ref-type="bibr" rid="CR91">91</xref></sup>. SHAP is based on the Shapely value concept from game theory<sup><xref ref-type="bibr" rid="CR91">91</xref>,<xref ref-type="bibr" rid="CR92">92</xref></sup>. Shapely values are used to estimate the magnitude as sign of feature contributions or importance. It is a theoretically justified and model-agnostic approach that builds a local explanation model,<inline-formula id="IEq83"><alternatives><tex-math id="M229">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$g$$\end{document}</tex-math><mml:math id="M230"><mml:mi>g</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq83.gif"/></alternatives></inline-formula> for the original model <inline-formula id="IEq84"><alternatives><tex-math id="M231">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f$$\end{document}</tex-math><mml:math id="M232"><mml:mi>f</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq84.gif"/></alternatives></inline-formula>. This model is a linear combination of binary variables <inline-formula id="IEq85"><alternatives><tex-math id="M233">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$g\left({x}^{^{\prime}}\right)={\varnothing }_{0}+\sum_{j=1}^{M}{\varnothing }_{j}{x}_{j}^{^{\prime}}$$\end{document}</tex-math><mml:math id="M234"><mml:mrow><mml:mi>g</mml:mi><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mi>∅</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup><mml:msub><mml:mi>∅</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq85.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq86"><alternatives><tex-math id="M235">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}_{j}^{^{\prime}}$$\end{document}</tex-math><mml:math id="M236"><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq86.gif"/></alternatives></inline-formula> is a simplified input that map to the original input <inline-formula id="IEq87"><alternatives><tex-math id="M237">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x$$\end{document}</tex-math><mml:math id="M238"><mml:mi>x</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq87.gif"/></alternatives></inline-formula> using the mapping function <inline-formula id="IEq88"><alternatives><tex-math id="M239">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x=h}_{x}\left({x}^{^{\prime}}\right)$$\end{document}</tex-math><mml:math id="M240"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mi>x</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq88.gif"/></alternatives></inline-formula>, <inline-formula id="IEq89"><alternatives><tex-math id="M241">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}^{^{\prime}}\in {\left\{0, 1\right\}}^{M}$$\end{document}</tex-math><mml:math id="M242"><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mfenced close="}" open="{"><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mfenced></mml:mrow><mml:mi>M</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq89.gif"/></alternatives></inline-formula> is the coalition vector and the 1 means the features in the new data are the same as those of the original data (the instance <inline-formula id="IEq90"><alternatives><tex-math id="M243">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x$$\end{document}</tex-math><mml:math id="M244"><mml:mi>x</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq90.gif"/></alternatives></inline-formula>), and 0 means the features in the new data are different from those of the original data, <inline-formula id="IEq91"><alternatives><tex-math id="M245">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M$$\end{document}</tex-math><mml:math id="M246"><mml:mi>M</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq91.gif"/></alternatives></inline-formula> is the total number of features, and <inline-formula id="IEq92"><alternatives><tex-math id="M247">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varnothing }_{j}\in {\mathbb{R}}$$\end{document}</tex-math><mml:math id="M248"><mml:mrow><mml:msub><mml:mi>∅</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq92.gif"/></alternatives></inline-formula> is the Shapely value that measures the average feature attribution value for feature <inline-formula id="IEq93"><alternatives><tex-math id="M249">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M250"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq93.gif"/></alternatives></inline-formula> for instance <inline-formula id="IEq94"><alternatives><tex-math id="M251">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x$$\end{document}</tex-math><mml:math id="M252"><mml:mi>x</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq94.gif"/></alternatives></inline-formula>. SHAP try to ensure that <inline-formula id="IEq95"><alternatives><tex-math id="M253">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$g\left({z}^{^{\prime}}\right)\approx f({h}_{x}\left({z}^{^{\prime}}\right))$$\end{document}</tex-math><mml:math id="M254"><mml:mrow><mml:mi>g</mml:mi><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:mfenced><mml:mo>≈</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:mfenced><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq95.gif"/></alternatives></inline-formula> when <inline-formula id="IEq96"><alternatives><tex-math id="M255">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${z}^{^{\prime}}\approx {x}^{^{\prime}}$$\end{document}</tex-math><mml:math id="M256"><mml:mrow><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup><mml:mo>≈</mml:mo><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq96.gif"/></alternatives></inline-formula>. SHAP calculates <inline-formula id="IEq97"><alternatives><tex-math id="M257">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varnothing }_{j}$$\end{document}</tex-math><mml:math id="M258"><mml:msub><mml:mi>∅</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq97.gif"/></alternatives></inline-formula> based on the Shapley value from game theory (see Eq. <xref rid="Equ4" ref-type="">4</xref>)<sup><xref ref-type="bibr" rid="CR93">93</xref></sup>:<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M259">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\emptyset_{j} = \mathop \sum \limits_{{S \in \left\{ {x_{1} , \ldots ,x_{M} } \right\}\backslash \left\{ {x_{j} } \right\}}} \frac{{\left| S \right|!\left( {M - \left| S \right| - 1} \right)!}}{M!}\left( {f\left( {S \cup \left\{ {x_{j} } \right\}} \right) - f\left( S \right)} \right)$$\end{document}</tex-math><mml:math id="M260" display="block"><mml:mrow><mml:msub><mml:mi mathvariant="normal">∅</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mo>∈</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mrow><mml:mo stretchy="true">\</mml:mo></mml:mrow><mml:mfenced close="}" open="{"><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:munder><mml:mfrac><mml:mrow><mml:mfenced close="|" open="|"><mml:mi>S</mml:mi></mml:mfenced><mml:mo>!</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mi>M</mml:mi><mml:mo>-</mml:mo><mml:mfenced close="|" open="|"><mml:mi>S</mml:mi></mml:mfenced><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>!</mml:mo></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>!</mml:mo></mml:mrow></mml:mfrac><mml:mfenced close=")" open="("><mml:mrow><mml:mi>f</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>S</mml:mi><mml:mo>∪</mml:mo><mml:mfenced close="}" open="{"><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:mi>f</mml:mi><mml:mfenced close=")" open="("><mml:mi>S</mml:mi></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="41598_2021_82098_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>
where <inline-formula id="IEq98"><alternatives><tex-math id="M261">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S$$\end{document}</tex-math><mml:math id="M262"><mml:mi>S</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq98.gif"/></alternatives></inline-formula> is the subset of set of the features used in the model which have non-zero indexes in <inline-formula id="IEq99"><alternatives><tex-math id="M263">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}^{^{\prime}}$$\end{document}</tex-math><mml:math id="M264"><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq99.gif"/></alternatives></inline-formula>, <inline-formula id="IEq100"><alternatives><tex-math id="M265">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}^{^{\prime}}$$\end{document}</tex-math><mml:math id="M266"><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq100.gif"/></alternatives></inline-formula> is the vector of feature values for the instance to be explained, <inline-formula id="IEq101"><alternatives><tex-math id="M267">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(\left|S\right|!\left(M-\left|S\right|-1\right)!)/M!$$\end{document}</tex-math><mml:math id="M268"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mfenced close="|" open="|"><mml:mi>S</mml:mi></mml:mfenced><mml:mo>!</mml:mo><mml:mfenced close=")" open="("><mml:mi>M</mml:mi><mml:mo>-</mml:mo><mml:mfenced close="|" open="|"><mml:mi>S</mml:mi></mml:mfenced><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mfenced><mml:mo>!</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">/</mml:mo><mml:mi>M</mml:mi><mml:mo>!</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq101.gif"/></alternatives></inline-formula> is a weighting factor, and <inline-formula id="IEq102"><alternatives><tex-math id="M269">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f\left(S\right)=E[f(x)|{x}_{S}]$$\end{document}</tex-math><mml:math id="M270"><mml:mrow><mml:mi>f</mml:mi><mml:mfenced close=")" open="("><mml:mi>S</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq102.gif"/></alternatives></inline-formula> is the expected value of <inline-formula id="IEq103"><alternatives><tex-math id="M271">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f$$\end{document}</tex-math><mml:math id="M272"><mml:mi>f</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq103.gif"/></alternatives></inline-formula> for features in subset <inline-formula id="IEq104"><alternatives><tex-math id="M273">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S$$\end{document}</tex-math><mml:math id="M274"><mml:mi>S</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq104.gif"/></alternatives></inline-formula> that are marginalized over features not included in subset <inline-formula id="IEq105"><alternatives><tex-math id="M275">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S$$\end{document}</tex-math><mml:math id="M276"><mml:mi>S</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq105.gif"/></alternatives></inline-formula>. SHAP values are consistent and accurate because they are calculated by averaging the differences in predictions over every possible feature ordering. In addition, the mean magnitude of the SHAP values can be used to estimate the global feature importance. We will compare the Gini index and SHAP-based methods using our datasets and trained RF classifiers.</p>
                  <p id="Par108">Because an individual decision explanation is critical in the medical domain, and because confidence is very important in order to create a trustworthy model, we add another type of explainability. <italic>The second type collects explanations from auxiliary or post-hoc models that try to explain RF decisions.</italic> The explainer is a function <inline-formula id="IEq106"><alternatives><tex-math id="M277">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f:\left({\theta }^{m}\to Y\right)\times \left({\theta }^{n\times m}\times {Y}^{n}\right)\to \left({\theta }^{m}\to Y\right)$$\end{document}</tex-math><mml:math id="M278"><mml:mrow><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msup><mml:mo stretchy="false">→</mml:mo><mml:mi>Y</mml:mi></mml:mfenced><mml:mo>×</mml:mo><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msup><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msup></mml:mfenced><mml:mo stretchy="false">→</mml:mo><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msup><mml:mo stretchy="false">→</mml:mo><mml:mi>Y</mml:mi></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq106.gif"/></alternatives></inline-formula>, which takes <inline-formula id="IEq107"><alternatives><tex-math id="M279">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b$$\end{document}</tex-math><mml:math id="M280"><mml:mi>b</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq107.gif"/></alternatives></inline-formula>, <inline-formula id="IEq108"><alternatives><tex-math id="M281">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D$$\end{document}</tex-math><mml:math id="M282"><mml:mi>D</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq108.gif"/></alternatives></inline-formula> as input and returns local predictor <inline-formula id="IEq109"><alternatives><tex-math id="M283">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{i}$$\end{document}</tex-math><mml:math id="M284"><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq109.gif"/></alternatives></inline-formula>, i.e.<inline-formula id="IEq110"><alternatives><tex-math id="M285">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{i}=f(b,D)$$\end{document}</tex-math><mml:math id="M286"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq110.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq111"><alternatives><tex-math id="M287">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{i}$$\end{document}</tex-math><mml:math id="M288"><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq111.gif"/></alternatives></inline-formula> is able to mimic the behavior of <inline-formula id="IEq112"><alternatives><tex-math id="M289">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b$$\end{document}</tex-math><mml:math id="M290"><mml:mi>b</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq112.gif"/></alternatives></inline-formula>; a local explanatory function <inline-formula id="IEq113"><alternatives><tex-math id="M291">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varepsilon }_{i}:\left(\left({\theta }^{m}\to Y\right)\times \left({\theta }^{m}\times Y\right)\times {\theta }^{m}\right)\to \varepsilon$$\end{document}</tex-math><mml:math id="M292"><mml:mrow><mml:msub><mml:mi>ε</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>:</mml:mo><mml:mfenced close=")" open="("><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msup><mml:mo stretchy="false">→</mml:mo><mml:mi>Y</mml:mi></mml:mfenced><mml:mo>×</mml:mo><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msup><mml:mo>×</mml:mo><mml:mi>Y</mml:mi></mml:mfenced><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msup></mml:mfenced><mml:mo stretchy="false">→</mml:mo><mml:mi>ε</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq113.gif"/></alternatives></inline-formula> exists, for <inline-formula id="IEq114"><alternatives><tex-math id="M293">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b$$\end{document}</tex-math><mml:math id="M294"><mml:mi>b</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq114.gif"/></alternatives></inline-formula>,<inline-formula id="IEq115"><alternatives><tex-math id="M295">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{i}$$\end{document}</tex-math><mml:math id="M296"><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq115.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq116"><alternatives><tex-math id="M297">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }^{m}$$\end{document}</tex-math><mml:math id="M298"><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq116.gif"/></alternatives></inline-formula> instances are inputs; and <inline-formula id="IEq117"><alternatives><tex-math id="M299">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varepsilon }_{i}$$\end{document}</tex-math><mml:math id="M300"><mml:msub><mml:mi>ε</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq117.gif"/></alternatives></inline-formula> returns a human interpretable explanation for the patient record <inline-formula id="IEq118"><alternatives><tex-math id="M301">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }^{m}$$\end{document}</tex-math><mml:math id="M302"><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq118.gif"/></alternatives></inline-formula>, i.e.<inline-formula id="IEq119"><alternatives><tex-math id="M303">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${ \varepsilon }_{i}=f\left(b, {p}_{i},{\theta }^{m}\right)=e$$\end{document}</tex-math><mml:math id="M304"><mml:mrow><mml:msub><mml:mi>ε</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mfenced close=")" open="("><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msup></mml:mfenced><mml:mo>=</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_82098_Article_IEq119.gif"/></alternatives></inline-formula>. We implement interpretable classifiers (i.e. DT and FURIA) for each individual modality. These explainers create simple and easy-to-understand explanations from different dimensions (e.g. MRI, cognitive scores, symptoms, etc.), which help to inform domain experts about the oracle’s decision. By using these 22 explainers, we are confident that each oracle’s decision will have a sufficient number of related explanations. The most important thing regarding these 22 explainers is that they are not affected by the feature selection process, which means more features will participate in the explanation. In addition, the extracted formal knowledge from RF and post-hoc models is represented in natural language form by using <italic>ExpliClas</italic><sup><xref ref-type="bibr" rid="CR78">78</xref></sup>. Accordingly, we resolve the accuracy-explainability trade-off by providing a variety of explanations, while retaining the accuracy of a complex ensemble model (i.e. RF).</p>
                </sec>
              </sec>
              <sec id="Sec21">
                <title>Model performance evaluation metrics</title>
                <p id="Par109">To evaluate the proposed method, we used the following performance metrics: The area under the receiver operating characteristic curve (AUC), precision, recall, accuracy (AC), and F1-score (F1). In addition to the performance evaluation, the system maximizes the interpretability of the underlying models, and pays special attention to explainability, which can serve as an indispensable tool in the era of precision medicine. To validate the performance of the models, we report both cross-validation as well as test results. In each layer, we compared the performance of the best RF model with other ML models, including SVM, KNN, and decision tree models. The hyperparameters of these algorithms were tuned in the same way as RF.</p>
                <p id="Par110">We used several libraries in the Python data science ecosystem to execute the experiments. The <italic>scikit-learn</italic> 0.21.2 package was used to perform feature selection and to train and evaluate all classifiers. <italic>Eli5</italic> 0.8.2 and <italic>SHAP</italic> 0.26.0 were used for explainability, and <italic>ExpliClas</italic> was used to provide natural language explanations from the 22 explainers. The naturalness and acceptability of generated explanations was validated by the physicians who collaborated in our study.</p>
              </sec>
            </sec>
            <sec id="Sec22">
              <title>Concluding remarks</title>
              <p id="Par111">In this paper, we proposed a highly accurate and explainable ML model based on a RF classifier. We have shown that multimodal RF classifiers can be successfully applied to AD detection and progression prediction. We proved that predictions based on combined multimodalities are significantly better than any single modality for both binary and multi-class classification tasks. Based on precise selection of the most informative features from 11 multimodalities, the system achieved the highest accuracies. Explainability was achieved using a variety of techniques. <italic>First</italic>, we provided a set of explanation capabilities for the RF models based on SHAP. For each layer’s model, global feature importance for the whole RF model and feature contributions for each specific patient were provided. For the first layer, we found that MMSE was the most important feature for the AD class, and CDRSB was the most important predictor for CN and MCI classes. For the second layer, FAQ was the most important feature for both sMCI and pMCI classes. <italic>Second</italic>, we implemented 22 explainers for each layer based on a decision tree classifier and a fuzzy rule-based system. Each explainer is based on a single modality. As a result, in each layer, each output decision comes up along with several complementary, consistent and reliable explanations. To validate the effectiveness of our model, we conducted experiments using the ADNI dataset. The model achieved high performance in each layer. The first layer had cross-validation accuracy of 93.95% and an F1-score of 93.94%, and second layer had cross-validation accuracy of 87.08% and an F1-Score of 87.09%. Moreover, our model exhibits a good accuracy-interpretability tradeoff because it achieved very accurate results as well as high level of interpretability. The resulting two-layer model provided justifiable, medically accurate, and hence, actionable decisions that can enhance physician confidence.</p>
              <p id="Par112">The proposed ML model is accurate and explainable. However, it is worth noting that even if we achieved promising results from an academic point of view, we are still far from applying the model in a real-world clinical scenario; what we plan to do in the future. This is a long-term ongoing project. Currently, we are reporting results of the first stage. We have already validated our model with the ADNI dataset; what is a crucial contribution to pave the way towards the application of the model to real clinical data in primary care or general medical practice. Although it is the biggest and most popular real dataset for Alzheimer’s disease, the relevance of our work to direct primary care is limited by the ADNI cohort. Therefore, to translate the outcomes of this study into full-scale clinical practice, further investigations are required to determine its performance characteristics by applying the model to other relevant datasets. We plan to enhance our model with the aim of achieving even higher performance by means of deep learning applied to longitudinal data while preserving explainability issues as we already did in the present manuscript.</p>
              <sec id="Sec23">
                <title>Ethics statement</title>
                <p id="Par113">Data used in this study were obtained from the ADNI (<ext-link ext-link-type="uri" xlink:href="http://adni.loni.usc.edu/">http://adni.loni.usc.edu/</ext-link>). The Alzheimer’s Disease Neuroimaging Initiative Data and Publications Committee (ADNI DPC) coordinates patient enrollment and ensures standard practice on the uses and distribution of the data as follows: The ADNI data were previously collected across 50 research sites. To participate in the study, each study subject gave written informed consent at the time of enrollment for imaging and genetic sample collection and completed questionnaires approved by each participating sites’ Institutional Review Board (IRB). All procedures performed in studies involving human participants were in accordance with the ethical standards of the institutional and/or national research committee and with the 1964 Helsinki declaration and its later amendments or comparable ethical standards. A complete description of ADNI and up-to-date information is available at <ext-link ext-link-type="uri" xlink:href="http://adni.loni.usc.edu/">http://adni.loni.usc.edu/</ext-link> and data access requests are to be sent to <ext-link ext-link-type="uri" xlink:href="http://adni.loni.usc.edu/data-samples/access-data/">http://adni.loni.usc.edu/data-samples/access-data/</ext-link>. Detailed inclusion criteria for the diagnostic categories can be found at the ADNI website (<ext-link ext-link-type="uri" xlink:href="http://adni.loni.usc.edu/methods">http://adni.loni.usc.edu/methods</ext-link>). The ethics committees/institutional review board that approved the ADNI study are listed within Supplementary file (part 4).</p>
              </sec>
            </sec>
            <sec sec-type="supplementary-material">
              <title>Supplementary Information</title>
              <sec id="Sec31">
                <p>
                  <supplementary-material content-type="local-data" id="MOESM1">
                    <media xlink:href="41598_2021_82098_MOESM1_ESM.docx">
                      <caption>
                        <p>Supplementary Information.</p>
                      </caption>
                    </media>
                  </supplementary-material>
                </p>
              </sec>
            </sec>
          </body>
          <back>
            <glossary>
              <title>Abbreviations</title>
              <def-list>
                <def-item>
                  <term>AD</term>
                  <def>
                    <p id="Par2">Alzheimer’s disease</p>
                  </def>
                </def-item>
                <def-item>
                  <term>ADAS-Cog</term>
                  <def>
                    <p id="Par3">Features of the Alzheimer’s diseases assessment scale-cognitive</p>
                  </def>
                </def-item>
                <def-item>
                  <term>ADNI</term>
                  <def>
                    <p id="Par4">Alzheimer’s Disease Neuroimaging Initiative</p>
                  </def>
                </def-item>
                <def-item>
                  <term>APOE</term>
                  <def>
                    <p id="Par5">Apolipoprotein E</p>
                  </def>
                </def-item>
                <def-item>
                  <term>AUC</term>
                  <def>
                    <p id="Par6">Area under the ROC curve</p>
                  </def>
                </def-item>
                <def-item>
                  <term>AV45</term>
                  <def>
                    <p id="Par7">Average AV45 SUVR of frontal</p>
                  </def>
                </def-item>
                <def-item>
                  <term>CDSS</term>
                  <def>
                    <p id="Par8">Clinical decision support system</p>
                  </def>
                </def-item>
                <def-item>
                  <term>CNN</term>
                  <def>
                    <p id="Par9">Convolutional neural network</p>
                  </def>
                </def-item>
                <def-item>
                  <term>CFA</term>
                  <def>
                    <p id="Par10">Cognitive and functional assessments</p>
                  </def>
                </def-item>
                <def-item>
                  <term>CS</term>
                  <def>
                    <p id="Par11">Cognitive scores</p>
                  </def>
                </def-item>
                <def-item>
                  <term>CDRSB</term>
                  <def>
                    <p id="Par12">Clinical dementia rating sum of boxes</p>
                  </def>
                </def-item>
                <def-item>
                  <term>CDGLOBAL</term>
                  <def>
                    <p id="Par13">Global CDR</p>
                  </def>
                </def-item>
                <def-item>
                  <term>DL</term>
                  <def>
                    <p id="Par14">Deep learning</p>
                  </def>
                </def-item>
                <def-item>
                  <term>DT</term>
                  <def>
                    <p id="Par15">Decision tree</p>
                  </def>
                </def-item>
                <def-item>
                  <term>DARPA</term>
                  <def>
                    <p id="Par16">Defense Advanced Research Projects Agency</p>
                  </def>
                </def-item>
                <def-item>
                  <term>FRBS</term>
                  <def>
                    <p id="Par17">Fuzzy rule-based system</p>
                  </def>
                </def-item>
                <def-item>
                  <term>FAQ</term>
                  <def>
                    <p id="Par18">Functional assessment questionnaire</p>
                  </def>
                </def-item>
                <def-item>
                  <term>GB</term>
                  <def>
                    <p id="Par19">Gradient boosting</p>
                  </def>
                </def-item>
                <def-item>
                  <term>GDT</term>
                  <def>
                    <p id="Par20">Geriatric depression scale</p>
                  </def>
                </def-item>
                <def-item>
                  <term>GDPR</term>
                  <def>
                    <p id="Par21">General data protection regulation</p>
                  </def>
                </def-item>
                <def-item>
                  <term>HCI</term>
                  <def>
                    <p id="Par22">Hypometabolic convergence index</p>
                  </def>
                </def-item>
                <def-item>
                  <term>ICV</term>
                  <def>
                    <p id="Par23">Intracranial volume</p>
                  </def>
                </def-item>
                <def-item>
                  <term>KNN</term>
                  <def>
                    <p id="Par24">K nearest neighbor</p>
                  </def>
                </def-item>
                <def-item>
                  <term>MRI</term>
                  <def>
                    <p id="Par25">Magnetic resonance imaging</p>
                  </def>
                </def-item>
                <def-item>
                  <term>ML</term>
                  <def>
                    <p id="Par26">Machine learning</p>
                  </def>
                </def-item>
                <def-item>
                  <term>MCI</term>
                  <def>
                    <p id="Par27">Mild cognitive impairment</p>
                  </def>
                </def-item>
                <def-item>
                  <term>MCA</term>
                  <def>
                    <p id="Par28">Multiclass classification accuracy</p>
                  </def>
                </def-item>
                <def-item>
                  <term>MMSE</term>
                  <def>
                    <p id="Par29">Mini-Mental State Examination</p>
                  </def>
                </def-item>
                <def-item>
                  <term>MoCA</term>
                  <def>
                    <p id="Par30">Montreal cognitive assessment</p>
                  </def>
                </def-item>
                <def-item>
                  <term>MH</term>
                  <def>
                    <p id="Par31">Medical history</p>
                  </def>
                </def-item>
                <def-item>
                  <term>NPISCORE</term>
                  <def>
                    <p id="Par32">Neuropsychiatric inventory questionnaire score</p>
                  </def>
                </def-item>
                <def-item>
                  <term>NB</term>
                  <def>
                    <p id="Par33">Neuropsychological battery</p>
                  </def>
                </def-item>
                <def-item>
                  <term>NB</term>
                  <def>
                    <p id="Par34">Naïve Bayes</p>
                  </def>
                </def-item>
                <def-item>
                  <term>pMCI</term>
                  <def>
                    <p id="Par35">Progressive MCI</p>
                  </def>
                </def-item>
                <def-item>
                  <term>PTAU</term>
                  <def>
                    <p id="Par36">Phosphorylated TAU</p>
                  </def>
                </def-item>
                <def-item>
                  <term>PET</term>
                  <def>
                    <p id="Par37">Positron emission tomography</p>
                  </def>
                </def-item>
                <def-item>
                  <term>PCA</term>
                  <def>
                    <p id="Par38">Principal component analysis</p>
                  </def>
                </def-item>
                <def-item>
                  <term>RF</term>
                  <def>
                    <p id="Par39">Random forest</p>
                  </def>
                </def-item>
                <def-item>
                  <term>RFE</term>
                  <def>
                    <p id="Par40">Recursive feature elimination</p>
                  </def>
                </def-item>
                <def-item>
                  <term>RAVLT</term>
                  <def>
                    <p id="Par41">Rey Auditory Verbal Learning Test</p>
                  </def>
                </def-item>
                <def-item>
                  <term>SHAP</term>
                  <def>
                    <p id="Par42">SHapley Additive exPlanations</p>
                  </def>
                </def-item>
                <def-item>
                  <term>sMCI</term>
                  <def>
                    <p id="Par43">Stable MCI</p>
                  </def>
                </def-item>
                <def-item>
                  <term>SVM</term>
                  <def>
                    <p id="Par44">Support vector machine</p>
                  </def>
                </def-item>
                <def-item>
                  <term>SNOMED CT</term>
                  <def>
                    <p id="Par45">Systematized Nomenclature of Medicine-Clinical Terms</p>
                  </def>
                </def-item>
                <def-item>
                  <term>XAI</term>
                  <def>
                    <p id="Par46">Explainable artificial intelligence</p>
                  </def>
                </def-item>
              </def-list>
            </glossary>
            <fn-group>
              <fn>
                <p>
                  <bold>Publisher's note</bold>
                </p>
                <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
              </fn>
            </fn-group>
            <sec>
              <title>Supplementary Information</title>
              <p>The online version contains supplementary material available at 10.1038/s41598-021-82098-3.</p>
            </sec>
            <ack>
              <title>Acknowledgements</title>
              <p>The authors would like to thank <italic>Farid Badria</italic>, a professor of pharmacognosy and head of the Liver Research Lab, Mansoura University, Egypt, and <italic>Hosam Zaghloul</italic>, a professor in the Clinical Pathology Department, Faculty of Medicine, Mansoura University, Egypt, for their efforts to assist this work. for their assistance as medical experts to finish the experimental part of this study. This work was supported by National Research Foundation of Korea-Grant funded by the Korean Government (Ministry of Science and ICT)-NRF-2020R1A2B5B02002478). In addition, Dr. Jose M. Alonso is Ramon y Cajal Researcher (RYC-2016-19802), and its research is supported by the Spanish Ministry of Science, Innovation and Universities (grants RTI2018-099646-B-I00, TIN2017-84796-C2-1-R, TIN2017-90773-REDT, and RED2018-102641-T) and the Galician Ministry of Education, University and Professional Training (grants ED431F 2018/02, ED431C 2018/29, ED431G/08, and ED431G2019/04), with all grants co-funded by the European Regional Development Fund (ERDF/FEDER program). Data collection and sharing for this project was funded by the Alzheimer’s Disease Neuroimaging Initiative (ADNI) (National Institutes of Health Grant U01 AG024904) and DOD ADNI (Department of Defense award number W81XWH-12-2-0012). The ADNI is funded by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, and through generous contributions from the following: AbbVie; Alzheimer’s Association; Alzheimer’s Drug Discovery Foundation; Araclon Biotech; BioClinica, Inc.; Biogen; Bristol-Myers Squibb Company; CereSpir, Inc.; Cogstate; Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli Lilly and Company; EuroImmun; F. Hoffmann-La Roche Ltd and its affiliated company Genentech, Inc.; Fujirebio; GE Healthcare; IXICO Ltd.; Janssen Alzheimer Immunotherapy Research &amp; Development, LLC.; Johnson &amp; Johnson Pharmaceutical Research &amp; Development LLC.; Lumosity; Lundbeck; Merck &amp; Co., Inc.; Meso Scale Diagnostics, LLC.; NeuroRx Research; Neurotrack Technologies; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Piramal Imaging; Servier; Takeda Pharmaceutical Company; and Transition Therapeutics. The Canadian Institutes of Health Research is providing funds to support ADNI clinical sites in Canada. Private sector contributions are facilitated by the Foundation for the National Institutes of Health (<ext-link ext-link-type="uri" xlink:href="http://www.fnih.org">www.fnih.org</ext-link>). The grantee organization is the Northern California Institute for Research and Education, and the study is coordinated by the Alzheimer’s Therapeutic Research Institute at the University of Southern California. ADNI data are disseminated by the Laboratory for Neuro Imaging at the University of Southern California.</p>
            </ack>
            <notes notes-type="author-contribution">
              <title>Author contributions</title>
              <p>Methodology, S.E.S., and S.M.R.I.; conceptualization, J.M.A. and K.S.K.; formal analysis, S.E.S., A.M.S., J.M.A, S.M.R.I., and K.S.K.; validation, S.E.S., A.M.S., and S.M.R.I.; visualization, J.M.A., and A.M.S.; investigation, S.E.S., and J.M.A.; data curation, K.S.K.; writing—original draft preparation, S.E.S. and J.M.A; writing—review and editing, K.S.K.; supervision, K.S.K. and S.E.S.</p>
            </notes>
            <notes notes-type="data-availability">
              <title>Data availability</title>
              <p>The data that support the findings of this study are openly available at the ADNI web site (<ext-link ext-link-type="uri" xlink:href="http://adni.loni.usc.edu/">http://adni.loni.usc.edu/</ext-link>). In addition, the specific patient RIDs used in our study and the full description of used features can be found in the Supplementary Files.</p>
            </notes>
            <notes id="FPar1" notes-type="COI-statement">
              <title>Competing interests</title>
              <p id="Par114">The authors declare no competing interests.</p>
            </notes>
            <ref-list id="Bib1">
              <title>References</title>
              <ref id="CR1">
                <label>1.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Alberdi</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Aztiria</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Basarab</surname>
                      <given-names>A</given-names>
                    </name>
                  </person-group>
                  <article-title>On the early diagnosis of Alzheimer’s disease from multimodal signals: a survey</article-title>
                  <source>Artif. Intell. Med.</source>
                  <year>2016</year>
                  <volume>71</volume>
                  <fpage>1</fpage>
                  <lpage>29</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.artmed.2016.06.003</pub-id>
                  <?supplied-pmid 27506128?>
                  <pub-id pub-id-type="pmid">27506128</pub-id>
                </element-citation>
              </ref>
              <ref id="CR2">
                <label>2.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Masters</surname>
                      <given-names>CL</given-names>
                    </name>
                    <name>
                      <surname>Beyreuther</surname>
                      <given-names>K</given-names>
                    </name>
                  </person-group>
                  <article-title>Alzheimer’s centennial legacy: prospects for rational therapeutic intervention targeting the Aβ amyloid pathway</article-title>
                  <source>Brain</source>
                  <year>2006</year>
                  <volume>129</volume>
                  <fpage>2823</fpage>
                  <lpage>2839</lpage>
                  <pub-id pub-id-type="doi">10.1093/brain/awl251</pub-id>
                  <?supplied-pmid 17012295?>
                  <pub-id pub-id-type="pmid">17012295</pub-id>
                </element-citation>
              </ref>
              <ref id="CR3">
                <label>3.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Zamrini</surname>
                      <given-names>E</given-names>
                    </name>
                    <name>
                      <surname>De Santi</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Tolar</surname>
                      <given-names>M</given-names>
                    </name>
                  </person-group>
                  <article-title>Imaging is superior to cognitive testing for early diagnosis of Alzheimer’s disease</article-title>
                  <source>Neurobiol. Aging</source>
                  <year>2004</year>
                  <volume>25</volume>
                  <fpage>685</fpage>
                  <lpage>691</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.neurobiolaging.2004.02.009</pub-id>
                  <?supplied-pmid 15172748?>
                  <pub-id pub-id-type="pmid">15172748</pub-id>
                </element-citation>
              </ref>
              <ref id="CR4">
                <label>4.</label>
                <mixed-citation publication-type="other">Liu, M., Zhang, J., Adeli, E. &amp; Shen, D. Joint classification and regression via deep multi-task multi-channel learning for Alzheimer’s disease diagnosis. <italic>IEEE Trans. Biomed. Eng.</italic> 1 (2018).</mixed-citation>
              </ref>
              <ref id="CR5">
                <label>5.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Lee</surname>
                      <given-names>G</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Predicting Alzheimer’s disease progression using multi-modal deep learning approach</article-title>
                  <source>Sci. Rep.</source>
                  <year>2019</year>
                  <volume>9</volume>
                  <fpage>1</fpage>
                  <lpage>12</lpage>
                  <pub-id pub-id-type="doi">10.1038/s41598-018-37186-2</pub-id>
                  <pub-id pub-id-type="pmid">30626917</pub-id>
                </element-citation>
              </ref>
              <ref id="CR6">
                <label>6.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Nie</surname>
                      <given-names>L</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Modeling disease progression via multisource multitask learners: a case study with Alzheimer’s disease</article-title>
                  <source>IEEE Trans. Neural Netw. Learn. Syst.</source>
                  <year>2017</year>
                  <volume>28</volume>
                  <fpage>1508</fpage>
                  <lpage>1519</lpage>
                  <pub-id pub-id-type="doi">10.1109/TNNLS.2016.2520964</pub-id>
                  <?supplied-pmid 26929064?>
                  <pub-id pub-id-type="pmid">26929064</pub-id>
                </element-citation>
              </ref>
              <ref id="CR7">
                <label>7.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Wee</surname>
                      <given-names>CY</given-names>
                    </name>
                    <name>
                      <surname>Yap</surname>
                      <given-names>PT</given-names>
                    </name>
                    <name>
                      <surname>Shen</surname>
                      <given-names>D</given-names>
                    </name>
                  </person-group>
                  <article-title>Prediction of Alzheimer’s disease and mild cognitive impairment using cortical morphological patterns</article-title>
                  <source>Hum. Brain Mapp.</source>
                  <year>2013</year>
                  <volume>34</volume>
                  <fpage>3411</fpage>
                  <lpage>3425</lpage>
                  <pub-id pub-id-type="doi">10.1002/hbm.22156</pub-id>
                  <?supplied-pmid 22927119?>
                  <pub-id pub-id-type="pmid">22927119</pub-id>
                </element-citation>
              </ref>
              <ref id="CR8">
                <label>8.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Liao</surname>
                      <given-names>Q</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Multi-task deep convolutional neural network for cancer diagnosis</article-title>
                  <source>Neurocomputing</source>
                  <year>2018</year>
                  <pub-id pub-id-type="doi">10.1016/j.neucom.2018.06.084</pub-id>
                </element-citation>
              </ref>
              <ref id="CR9">
                <label>9.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Lu</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Popuri</surname>
                      <given-names>K</given-names>
                    </name>
                    <name>
                      <surname>Ding</surname>
                      <given-names>W</given-names>
                    </name>
                    <name>
                      <surname>Balachandar</surname>
                      <given-names>R</given-names>
                    </name>
                    <name>
                      <surname>Beg</surname>
                      <given-names>MF</given-names>
                    </name>
                  </person-group>
                  <article-title>Multimodal and multiscale deep neural networks for the early diagnosis of Alzheimer’s disease using structural MR and FDG-PET images</article-title>
                  <source>Sci. Rep.</source>
                  <year>2018</year>
                  <volume>8</volume>
                  <fpage>5697</fpage>
                  <pub-id pub-id-type="doi">10.1038/s41598-018-22871-z</pub-id>
                  <?supplied-pmid 29632364?>
                  <pub-id pub-id-type="pmid">29632364</pub-id>
                </element-citation>
              </ref>
              <ref id="CR10">
                <label>10.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Liu</surname>
                      <given-names>M</given-names>
                    </name>
                    <name>
                      <surname>Cheng</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Wang</surname>
                      <given-names>K</given-names>
                    </name>
                    <name>
                      <surname>Wang</surname>
                      <given-names>Y</given-names>
                    </name>
                  </person-group>
                  <article-title>Multi-modality cascaded convolutional neural networks for Alzheimer’s disease diagnosis</article-title>
                  <source>Neuroinformatics</source>
                  <year>2018</year>
                  <volume>16</volume>
                  <fpage>295</fpage>
                  <lpage>308</lpage>
                  <pub-id pub-id-type="doi">10.1007/s12021-018-9370-4</pub-id>
                  <?supplied-pmid 29572601?>
                  <pub-id pub-id-type="pmid">29572601</pub-id>
                </element-citation>
              </ref>
              <ref id="CR11">
                <label>11.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Qiu</surname>
                      <given-names>S</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Fusion of deep learning models of MRI scans, mini-mental state examination, and logical memory test enhances diagnosis of mild cognitive impairment</article-title>
                  <source>Alzheimer’s Dement. Diagnosis Assess. Dis. Monit.</source>
                  <year>2018</year>
                  <volume>10</volume>
                  <fpage>737</fpage>
                  <lpage>749</lpage>
                </element-citation>
              </ref>
              <ref id="CR12">
                <label>12.</label>
                <mixed-citation publication-type="other">Kim-Han, T., Pew-Thian, Y. &amp; Dinggang, S. Multi-stage diagnosis of Alzheimer’s Disease with incomplete multimodal data via multi-task deep learning. In <italic>Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support</italic> 160–168 (Springer, Cham, 2017).</mixed-citation>
              </ref>
              <ref id="CR13">
                <label>13.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Hinrichs</surname>
                      <given-names>C</given-names>
                    </name>
                    <name>
                      <surname>Singh</surname>
                      <given-names>V</given-names>
                    </name>
                    <name>
                      <surname>Xu</surname>
                      <given-names>G</given-names>
                    </name>
                    <name>
                      <surname>Johnson</surname>
                      <given-names>SC</given-names>
                    </name>
                  </person-group>
                  <article-title>Predictive markers for AD in a multi-modality framework: an analysis of MCI progression in the ADNI population</article-title>
                  <source>Neuroimage</source>
                  <year>2011</year>
                  <volume>55</volume>
                  <fpage>574</fpage>
                  <lpage>589</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.10.081</pub-id>
                  <?supplied-pmid 21146621?>
                  <pub-id pub-id-type="pmid">21146621</pub-id>
                </element-citation>
              </ref>
              <ref id="CR14">
                <label>14.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Zhou</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Liu</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Narayan</surname>
                      <given-names>VA</given-names>
                    </name>
                    <name>
                      <surname>Ye</surname>
                      <given-names>J</given-names>
                    </name>
                  </person-group>
                  <article-title>Modeling disease progression via multi-task learning</article-title>
                  <source>Neuroimage</source>
                  <year>2013</year>
                  <volume>78</volume>
                  <fpage>233</fpage>
                  <lpage>248</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.03.073</pub-id>
                  <?supplied-pmid 23583359?>
                  <pub-id pub-id-type="pmid">23583359</pub-id>
                </element-citation>
              </ref>
              <ref id="CR15">
                <label>15.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Wang</surname>
                      <given-names>T</given-names>
                    </name>
                    <name>
                      <surname>Qiu</surname>
                      <given-names>RG</given-names>
                    </name>
                    <name>
                      <surname>Yu</surname>
                      <given-names>M</given-names>
                    </name>
                  </person-group>
                  <article-title>Predictive modeling of the progression of Alzheimer’ s disease with recurrent neural networks</article-title>
                  <source>Sci. Rep.</source>
                  <year>2018</year>
                  <pub-id pub-id-type="doi">10.1038/s41598-018-27337-w</pub-id>
                  <?supplied-pmid 30591712?>
                  <pub-id pub-id-type="pmid">30591712</pub-id>
                </element-citation>
              </ref>
              <ref id="CR16">
                <label>16.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Ding</surname>
                      <given-names>X</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>A hybrid computational approach for efficient Alzheimer’s disease classification based on heterogeneous data</article-title>
                  <source>Sci. Rep.</source>
                  <year>2018</year>
                  <volume>8</volume>
                  <fpage>1</fpage>
                  <lpage>10</lpage>
                  <pub-id pub-id-type="doi">10.1038/s41598-017-17765-5</pub-id>
                  <pub-id pub-id-type="pmid">29311619</pub-id>
                </element-citation>
              </ref>
              <ref id="CR17">
                <label>17.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Gray</surname>
                      <given-names>KR</given-names>
                    </name>
                    <name>
                      <surname>Aljabar</surname>
                      <given-names>P</given-names>
                    </name>
                    <name>
                      <surname>Heckemann</surname>
                      <given-names>RA</given-names>
                    </name>
                    <name>
                      <surname>Hammers</surname>
                      <given-names>A</given-names>
                    </name>
                  </person-group>
                  <article-title>Random forest-based similarity measures for multi-modal classification of Alzheimer’ s disease</article-title>
                  <source>Neuroimage</source>
                  <year>2013</year>
                  <volume>65</volume>
                  <fpage>167</fpage>
                  <lpage>175</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.09.065</pub-id>
                  <?supplied-pmid 23041336?>
                  <pub-id pub-id-type="pmid">23041336</pub-id>
                </element-citation>
              </ref>
              <ref id="CR18">
                <label>18.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Das</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Ito</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Kadowaki</surname>
                      <given-names>T</given-names>
                    </name>
                    <name>
                      <surname>Tsuda</surname>
                      <given-names>K</given-names>
                    </name>
                  </person-group>
                  <article-title>An interpretable machine learning model for diagnosis of Alzheimer’s disease</article-title>
                  <source>PeerJ</source>
                  <year>2019</year>
                  <volume>7</volume>
                  <fpage>e6543</fpage>
                  <pub-id pub-id-type="doi">10.7717/peerj.6543</pub-id>
                  <?supplied-pmid 30842909?>
                  <pub-id pub-id-type="pmid">30842909</pub-id>
                </element-citation>
              </ref>
              <ref id="CR19">
                <label>19.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Mattila</surname>
                      <given-names>J</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>A disease state fingerprint for evaluation of Alzheimer’s disease</article-title>
                  <source>J. Alzheimer’s Dis.</source>
                  <year>2011</year>
                  <volume>27</volume>
                  <fpage>163</fpage>
                  <lpage>176</lpage>
                  <pub-id pub-id-type="doi">10.3233/JAD-2011-110365</pub-id>
                  <pub-id pub-id-type="pmid">21799247</pub-id>
                </element-citation>
              </ref>
              <ref id="CR20">
                <label>20.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Bucholc</surname>
                      <given-names>M</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>A practical computerized decision support system for predicting the severity of Alzheimer’s disease of an individual</article-title>
                  <source>Expert Syst. Appl.</source>
                  <year>2019</year>
                  <volume>130</volume>
                  <fpage>157</fpage>
                  <lpage>171</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.eswa.2019.04.022</pub-id>
                  <?supplied-pmid 31402810?>
                  <pub-id pub-id-type="pmid">31402810</pub-id>
                </element-citation>
              </ref>
              <ref id="CR21">
                <label>21.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Travers</surname>
                      <given-names>C</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Opportunities and obstacles for deep learning in biology and medicine</article-title>
                  <source>bioRxiv</source>
                  <year>2017</year>
                  <pub-id pub-id-type="doi">10.1101/142760</pub-id>
                </element-citation>
              </ref>
              <ref id="CR22">
                <label>22.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Choi</surname>
                      <given-names>H</given-names>
                    </name>
                    <name>
                      <surname>Jin</surname>
                      <given-names>KH</given-names>
                    </name>
                  </person-group>
                  <article-title>Predicting cognitive decline with deep learning of brain metabolism and amyloid imaging</article-title>
                  <source>Behav. Brain Res.</source>
                  <year>2018</year>
                  <volume>344</volume>
                  <fpage>103</fpage>
                  <lpage>109</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.bbr.2018.02.017</pub-id>
                  <?supplied-pmid 29454006?>
                  <pub-id pub-id-type="pmid">29454006</pub-id>
                </element-citation>
              </ref>
              <ref id="CR23">
                <label>23.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Spasov</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Passamonti</surname>
                      <given-names>L</given-names>
                    </name>
                    <name>
                      <surname>Duggento</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Lio</surname>
                      <given-names>P</given-names>
                    </name>
                    <name>
                      <surname>Toschi</surname>
                      <given-names>N</given-names>
                    </name>
                  </person-group>
                  <article-title>A parameter-efficient deep learning approach to predict conversion from mild cognitive impairment to Alzheimer’s disease</article-title>
                  <source>Neuroimage</source>
                  <year>2019</year>
                  <volume>189</volume>
                  <fpage>276</fpage>
                  <lpage>287</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.01.031</pub-id>
                  <?supplied-pmid 30654174?>
                  <pub-id pub-id-type="pmid">30654174</pub-id>
                </element-citation>
              </ref>
              <ref id="CR24">
                <label>24.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Zhang</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Shen</surname>
                      <given-names>D</given-names>
                    </name>
                  </person-group>
                  <article-title>Multi-modal multi-task learning for joint prediction of multiple regression and classification variables in Alzheimer’s disease</article-title>
                  <source>Neuroimage</source>
                  <year>2012</year>
                  <volume>59</volume>
                  <fpage>895</fpage>
                  <lpage>907</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.09.069</pub-id>
                  <?supplied-pmid 21992749?>
                  <pub-id pub-id-type="pmid">21992749</pub-id>
                </element-citation>
              </ref>
              <ref id="CR25">
                <label>25.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Cheng</surname>
                      <given-names>B</given-names>
                    </name>
                    <name>
                      <surname>Liu</surname>
                      <given-names>M</given-names>
                    </name>
                    <name>
                      <surname>Zhang</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Munsell</surname>
                      <given-names>BC</given-names>
                    </name>
                    <name>
                      <surname>Shen</surname>
                      <given-names>D</given-names>
                    </name>
                  </person-group>
                  <article-title>Domain transfer learning for MCI conversion prediction</article-title>
                  <source>IEEE Trans. Biomed. Eng.</source>
                  <year>2015</year>
                  <volume>62</volume>
                  <fpage>1805</fpage>
                  <lpage>1817</lpage>
                  <pub-id pub-id-type="doi">10.1109/TBME.2015.2404809</pub-id>
                  <?supplied-pmid 25751861?>
                  <pub-id pub-id-type="pmid">25751861</pub-id>
                </element-citation>
              </ref>
              <ref id="CR26">
                <label>26.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Moore</surname>
                      <given-names>PJ</given-names>
                    </name>
                    <name>
                      <surname>Lyons</surname>
                      <given-names>TJ</given-names>
                    </name>
                    <name>
                      <surname>Gallacher</surname>
                      <given-names>J</given-names>
                    </name>
                  </person-group>
                  <article-title>Random forest prediction of Alzheimer’s disease using pairwise selection from time series data</article-title>
                  <source>PLoS ONE</source>
                  <year>2019</year>
                  <volume>14</volume>
                  <fpage>1</fpage>
                  <lpage>14</lpage>
                </element-citation>
              </ref>
              <ref id="CR27">
                <label>27.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Moradi</surname>
                      <given-names>E</given-names>
                    </name>
                    <name>
                      <surname>Pepe</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Gaser</surname>
                      <given-names>C</given-names>
                    </name>
                    <name>
                      <surname>Huttunen</surname>
                      <given-names>H</given-names>
                    </name>
                    <name>
                      <surname>Tohka</surname>
                      <given-names>J</given-names>
                    </name>
                  </person-group>
                  <article-title>Machine learning framework for early MRI-based Alzheimer’s conversion prediction in MCI subjects</article-title>
                  <source>Neuroimage</source>
                  <year>2015</year>
                  <volume>104</volume>
                  <fpage>398</fpage>
                  <lpage>412</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.10.002</pub-id>
                  <?supplied-pmid 25312773?>
                  <pub-id pub-id-type="pmid">25312773</pub-id>
                </element-citation>
              </ref>
              <ref id="CR28">
                <label>28.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Fisher</surname>
                      <given-names>CK</given-names>
                    </name>
                    <name>
                      <surname>Smith</surname>
                      <given-names>AM</given-names>
                    </name>
                    <name>
                      <surname>Walsh</surname>
                      <given-names>JR</given-names>
                    </name>
                  </person-group>
                  <article-title>Machine learning for comprehensive forecasting of Alzheimer’s disease progression</article-title>
                  <source>Sci. Rep.</source>
                  <year>2019</year>
                  <volume>9</volume>
                  <fpage>1</fpage>
                  <lpage>14</lpage>
                  <pub-id pub-id-type="doi">10.1038/s41598-019-49656-2</pub-id>
                  <pub-id pub-id-type="pmid">30626917</pub-id>
                </element-citation>
              </ref>
              <ref id="CR29">
                <label>29.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Oxtoby</surname>
                      <given-names>NP</given-names>
                    </name>
                    <name>
                      <surname>Alexander</surname>
                      <given-names>DC</given-names>
                    </name>
                  </person-group>
                  <article-title>Imaging plus X: Multimodal models of neurodegenerative disease</article-title>
                  <source>Curr. Opin. Neurol.</source>
                  <year>2017</year>
                  <volume>30</volume>
                  <fpage>371</fpage>
                  <lpage>379</lpage>
                  <pub-id pub-id-type="doi">10.1097/WCO.0000000000000460</pub-id>
                  <?supplied-pmid 28520598?>
                  <pub-id pub-id-type="pmid">28520598</pub-id>
                </element-citation>
              </ref>
              <ref id="CR30">
                <label>30.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Burrell</surname>
                      <given-names>J</given-names>
                    </name>
                  </person-group>
                  <article-title>How the machine ‘Thinks:’ understanding opacity in machine learning algorithms</article-title>
                  <source>Ssrn</source>
                  <year>2015</year>
                  <pub-id pub-id-type="doi">10.2139/ssrn.2660674</pub-id>
                </element-citation>
              </ref>
              <ref id="CR31">
                <label>31.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Adadi</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Berrada</surname>
                      <given-names>M</given-names>
                    </name>
                  </person-group>
                  <article-title>Peeking Inside the black-box: a survey on explainable artificial intelligence (XAI)</article-title>
                  <source>IEEE Access</source>
                  <year>2018</year>
                  <volume>6</volume>
                  <fpage>52138</fpage>
                  <lpage>52160</lpage>
                  <pub-id pub-id-type="doi">10.1109/ACCESS.2018.2870052</pub-id>
                </element-citation>
              </ref>
              <ref id="CR32">
                <label>32.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Lundberg</surname>
                      <given-names>SM</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Explainable machine-learning predictions for the prevention of hypoxaemia during surgery</article-title>
                  <source>Nat. Biomed. Eng.</source>
                  <year>2018</year>
                  <volume>2</volume>
                  <fpage>749</fpage>
                  <lpage>760</lpage>
                  <pub-id pub-id-type="doi">10.1038/s41551-018-0304-0</pub-id>
                  <?supplied-pmid 31001455?>
                  <pub-id pub-id-type="pmid">31001455</pub-id>
                </element-citation>
              </ref>
              <ref id="CR33">
                <label>33.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Guidotti</surname>
                      <given-names>R</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>A survey of methods for explaining black box models</article-title>
                  <source>ACM Comput. Surv.</source>
                  <year>2018</year>
                  <volume>51</volume>
                  <fpage>93:1</fpage>
                  <lpage>93:42</lpage>
                </element-citation>
              </ref>
              <ref id="CR34">
                <label>34.</label>
                <element-citation publication-type="book">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Quinlan</surname>
                      <given-names>JR</given-names>
                    </name>
                  </person-group>
                  <source>C4.5: Programs for Machine Learning</source>
                  <year>1993</year>
                  <publisher-loc>San Mateo</publisher-loc>
                  <publisher-name>Morgan Kaufmann Publishers</publisher-name>
                </element-citation>
              </ref>
              <ref id="CR35">
                <label>35.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>El-Sappagh</surname>
                      <given-names>S</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>An ontology-based interpretable fuzzy decision support system for diabetes diagnosis</article-title>
                  <source>IEEE Access</source>
                  <year>2018</year>
                  <volume>6</volume>
                  <fpage>37371</fpage>
                  <lpage>37394</lpage>
                  <pub-id pub-id-type="doi">10.1109/ACCESS.2018.2852004</pub-id>
                </element-citation>
              </ref>
              <ref id="CR36">
                <label>36.</label>
                <element-citation publication-type="book">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Trillas</surname>
                      <given-names>E</given-names>
                    </name>
                    <name>
                      <surname>Eciolaza</surname>
                      <given-names>L</given-names>
                    </name>
                  </person-group>
                  <source>Fuzzy Logic: An Introductory Course for Engineering Students</source>
                  <year>2015</year>
                  <publisher-loc>New York</publisher-loc>
                  <publisher-name>Springer</publisher-name>
                </element-citation>
              </ref>
              <ref id="CR37">
                <label>37.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Huysmans</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Dejaeger</surname>
                      <given-names>K</given-names>
                    </name>
                    <name>
                      <surname>Mues</surname>
                      <given-names>C</given-names>
                    </name>
                    <name>
                      <surname>Vanthienen</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Baesens</surname>
                      <given-names>B</given-names>
                    </name>
                  </person-group>
                  <article-title>An empirical evaluation of the comprehensibility of decision table, tree and rule based predictive models</article-title>
                  <source>Decis. Support Syst.</source>
                  <year>2011</year>
                  <volume>51</volume>
                  <fpage>141</fpage>
                  <lpage>154</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.dss.2010.12.003</pub-id>
                </element-citation>
              </ref>
              <ref id="CR38">
                <label>38.</label>
                <mixed-citation publication-type="other">Alonso, J. M., Castiello, C., Lucarelli, M. &amp; Mencar, C. Modeling interpretable fuzzy rule-based classifiers for medical decision support. In <italic>Medical Applications of Intelligent Data Analysis: Research Advancements.</italic> 1064–1081 (Hershey, PA, USA: IGI Global, 2013).</mixed-citation>
              </ref>
              <ref id="CR39">
                <label>39.</label>
                <mixed-citation publication-type="other">Alonso, J. M., Castiello, C. &amp; Mencar, C. Interpretability of fuzzy systems: current research trends and prospects. In <italic>Springer Handbook of Computational Intelligence</italic> 219–237 (Springer, Berlin, 2015).</mixed-citation>
              </ref>
              <ref id="CR40">
                <label>40.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Fernandez-Delgado</surname>
                      <given-names>M</given-names>
                    </name>
                    <name>
                      <surname>Cernadas</surname>
                      <given-names>E</given-names>
                    </name>
                    <name>
                      <surname>Barro</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Amorim</surname>
                      <given-names>D</given-names>
                    </name>
                  </person-group>
                  <article-title>Do we need hundreds of classifiers to solve real world classification problems</article-title>
                  <source>J. Mach. Learn. Res.</source>
                  <year>2014</year>
                  <volume>15</volume>
                  <fpage>3133</fpage>
                  <lpage>3181</lpage>
                </element-citation>
              </ref>
              <ref id="CR41">
                <label>41.</label>
                <mixed-citation publication-type="other">Alonso, J. M., Ramos-Soto, A., Castiello, C. &amp; Mencar, C. Hybrid data-expert explainable beer style classifier. In <italic>IJCAI/ECAI Workshop on Explainable Artificial Intelligence</italic> 1–5 (2018).</mixed-citation>
              </ref>
              <ref id="CR42">
                <label>42.</label>
                <mixed-citation publication-type="other">Ribeiro, M. T., Singh, S. &amp; Guestrin, C. ‘Why Should I Trust You?’: Explaining the Predictions of Any Classifier (2016).</mixed-citation>
              </ref>
              <ref id="CR43">
                <label>43.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Zhou</surname>
                      <given-names>Z-H</given-names>
                    </name>
                    <name>
                      <surname>Jiang</surname>
                      <given-names>Y</given-names>
                    </name>
                    <name>
                      <surname>Chen</surname>
                      <given-names>S-F</given-names>
                    </name>
                  </person-group>
                  <article-title>Extracting symbolic rules from trained neural network ensembles</article-title>
                  <source>AI Commun.</source>
                  <year>2003</year>
                  <volume>16</volume>
                  <fpage>3</fpage>
                  <lpage>15</lpage>
                </element-citation>
              </ref>
              <ref id="CR44">
                <label>44.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Breiman</surname>
                      <given-names>L</given-names>
                    </name>
                  </person-group>
                  <article-title>Statistical modeling: the two cultures</article-title>
                  <source>Stat. Sci.</source>
                  <year>2001</year>
                  <volume>16</volume>
                  <fpage>199</fpage>
                  <lpage>231</lpage>
                  <pub-id pub-id-type="doi">10.1214/ss/1009213726</pub-id>
                </element-citation>
              </ref>
              <ref id="CR45">
                <label>45.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Zhao</surname>
                      <given-names>X</given-names>
                    </name>
                    <name>
                      <surname>Wu</surname>
                      <given-names>Y</given-names>
                    </name>
                    <name>
                      <surname>Lee</surname>
                      <given-names>DL</given-names>
                    </name>
                    <name>
                      <surname>Cui</surname>
                      <given-names>W</given-names>
                    </name>
                  </person-group>
                  <article-title>IForest: interpreting random forests via visual analytics</article-title>
                  <source>IEEE Trans. Vis. Comput. Graph.</source>
                  <year>2019</year>
                  <volume>25</volume>
                  <fpage>407</fpage>
                  <lpage>416</lpage>
                  <pub-id pub-id-type="doi">10.1109/TVCG.2018.2864475</pub-id>
                </element-citation>
              </ref>
              <ref id="CR46">
                <label>46.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Matthews</surname>
                      <given-names>K</given-names>
                    </name>
                  </person-group>
                  <article-title>Tau protein abnormalities correlate with the severity of dementia in Alzheimer’s disease</article-title>
                  <source>Nat. Clin. Pract. Neurol.</source>
                  <year>2006</year>
                  <volume>2</volume>
                  <fpage>178</fpage>
                  <pub-id pub-id-type="doi">10.1038/ncpneuro0139</pub-id>
                </element-citation>
              </ref>
              <ref id="CR47">
                <label>47.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Murphy</surname>
                      <given-names>MP</given-names>
                    </name>
                    <name>
                      <surname>Levine</surname>
                      <given-names>H</given-names>
                    </name>
                  </person-group>
                  <article-title>Alzheimer’s disease and the amyloid-β peptide</article-title>
                  <source>J. Alzheimer’s Dis.</source>
                  <year>2010</year>
                  <volume>19</volume>
                  <fpage>311</fpage>
                  <lpage>323</lpage>
                  <pub-id pub-id-type="doi">10.3233/JAD-2010-1221</pub-id>
                  <pub-id pub-id-type="pmid">20061647</pub-id>
                </element-citation>
              </ref>
              <ref id="CR48">
                <label>48.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Sadigh-Eteghad</surname>
                      <given-names>S</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Amyloid-beta: a crucial factor in Alzheimer’s disease</article-title>
                  <source>Med. Princ. Pract.</source>
                  <year>2015</year>
                  <volume>24</volume>
                  <fpage>1</fpage>
                  <lpage>10</lpage>
                  <pub-id pub-id-type="doi">10.1159/000369101</pub-id>
                  <?supplied-pmid 25471398?>
                  <pub-id pub-id-type="pmid">25471398</pub-id>
                </element-citation>
              </ref>
              <ref id="CR49">
                <label>49.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Verdile</surname>
                      <given-names>G</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>The role of beta amyloid in Alzheimer’ s disease: still a cause of everything or the only one who got caught?</article-title>
                  <source>Pharmacol. Res.</source>
                  <year>2004</year>
                  <volume>50</volume>
                  <fpage>397</fpage>
                  <lpage>409</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.phrs.2003.12.028</pub-id>
                  <?supplied-pmid 15304237?>
                  <pub-id pub-id-type="pmid">15304237</pub-id>
                </element-citation>
              </ref>
              <ref id="CR50">
                <label>50.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Thaweepoksomboon</surname>
                      <given-names>J</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Assessment of cerebrospinal fluid (CSF) beta-amyloid (1–42), phosphorylated tau (ptau-181) and total Tau protein in patients with Alzheimer’s disease (AD) and other dementia at Siriraj Hospital Thailand</article-title>
                  <source>J. Med. Assoc. Thai.</source>
                  <year>2011</year>
                  <volume>94</volume>
                  <issue>Suppl 1</issue>
                  <fpage>S77</fpage>
                  <lpage>83</lpage>
                  <?supplied-pmid 21721431?>
                  <pub-id pub-id-type="pmid">21721431</pub-id>
                </element-citation>
              </ref>
              <ref id="CR51">
                <label>51.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Zetterberg</surname>
                      <given-names>H</given-names>
                    </name>
                  </person-group>
                  <article-title>Biomarkers for Alzheimer’ s disease: current status and prospects for the future</article-title>
                  <source>J. Intern. Med.</source>
                  <year>2018</year>
                  <volume>6</volume>
                  <fpage>643</fpage>
                  <lpage>663</lpage>
                </element-citation>
              </ref>
              <ref id="CR52">
                <label>52.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Weiner</surname>
                      <given-names>MW</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Recent publications from the Alzheimer’s disease neuroimaging initiative: reviewing progress toward improved AD clinical trials</article-title>
                  <source>Alzheimer’s Dement.</source>
                  <year>2017</year>
                  <volume>13</volume>
                  <fpage>e1</fpage>
                  <lpage>e85</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.jalz.2016.11.007</pub-id>
                  <pub-id pub-id-type="pmid">28342697</pub-id>
                </element-citation>
              </ref>
              <ref id="CR53">
                <label>53.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Tong</surname>
                      <given-names>T</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>A novel grading biomarker for the prediction of conversion from mild cognitive impairment to Alzheimer’s disease</article-title>
                  <source>IEEE Trans. Biomed. Eng.</source>
                  <year>2017</year>
                  <volume>64</volume>
                  <fpage>155</fpage>
                  <lpage>165</lpage>
                  <pub-id pub-id-type="doi">10.1109/TBME.2016.2549363</pub-id>
                  <?supplied-pmid 27046891?>
                  <pub-id pub-id-type="pmid">27046891</pub-id>
                </element-citation>
              </ref>
              <ref id="CR54">
                <label>54.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Li</surname>
                      <given-names>K</given-names>
                    </name>
                    <name>
                      <surname>O’Brien</surname>
                      <given-names>R</given-names>
                    </name>
                    <name>
                      <surname>Lutz</surname>
                      <given-names>M</given-names>
                    </name>
                    <name>
                      <surname>Luo</surname>
                      <given-names>S</given-names>
                    </name>
                  </person-group>
                  <article-title>A prognostic model of Alzheimer’s disease relying on multiple longitudinal measures and time-to-event data</article-title>
                  <source>Alzheimer’s Dement.</source>
                  <year>2018</year>
                  <volume>14</volume>
                  <fpage>644</fpage>
                  <lpage>651</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.jalz.2017.11.004</pub-id>
                  <pub-id pub-id-type="pmid">29306668</pub-id>
                </element-citation>
              </ref>
              <ref id="CR55">
                <label>55.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Jin</surname>
                      <given-names>Y</given-names>
                    </name>
                    <name>
                      <surname>Su</surname>
                      <given-names>Y</given-names>
                    </name>
                    <name>
                      <surname>Zhou</surname>
                      <given-names>XH</given-names>
                    </name>
                    <name>
                      <surname>Huang</surname>
                      <given-names>S</given-names>
                    </name>
                  </person-group>
                  <article-title>Heterogeneous multimodal biomarkers analysis for Alzheimer’s disease via Bayesian network</article-title>
                  <source>Eurasip J. Bioinform. Syst. Biol.</source>
                  <year>2016</year>
                  <volume>2016</volume>
                  <fpage>4</fpage>
                  <lpage>11</lpage>
                  <pub-id pub-id-type="doi">10.1186/s13637-016-0046-9</pub-id>
                  <pub-id pub-id-type="pmid">26877724</pub-id>
                </element-citation>
              </ref>
              <ref id="CR56">
                <label>56.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Breiman</surname>
                      <given-names>LEO</given-names>
                    </name>
                  </person-group>
                  <article-title>Random forests</article-title>
                  <source>Mach. Learn.</source>
                  <year>2001</year>
                  <volume>45</volume>
                  <fpage>5</fpage>
                  <lpage>32</lpage>
                  <pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id>
                </element-citation>
              </ref>
              <ref id="CR57">
                <label>57.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Lebedev</surname>
                      <given-names>AV</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Random forest ensembles for detection and prediction of Alzheimer’s disease with a good between-cohort robustness</article-title>
                  <source>NeuroImage Clin.</source>
                  <year>2014</year>
                  <volume>6</volume>
                  <fpage>115</fpage>
                  <lpage>125</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.nicl.2014.08.023</pub-id>
                  <?supplied-pmid 25379423?>
                  <pub-id pub-id-type="pmid">25379423</pub-id>
                </element-citation>
              </ref>
              <ref id="CR58">
                <label>58.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Ramírez</surname>
                      <given-names>J</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Ensemble of random forests one vs. rest classifiers for MCI and AD prediction using ANOVA cortical and subcortical feature selection and partial least squares</article-title>
                  <source>J. Neurosci. Methods</source>
                  <year>2018</year>
                  <volume>302</volume>
                  <fpage>47</fpage>
                  <lpage>57</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.jneumeth.2017.12.005</pub-id>
                  <?supplied-pmid 29242123?>
                  <pub-id pub-id-type="pmid">29242123</pub-id>
                </element-citation>
              </ref>
              <ref id="CR59">
                <label>59.</label>
                <mixed-citation publication-type="other">Cheng, M., Nazarian, S. &amp; Bogdan, P. There is hope after all: quantifying opinion and trustworthiness in neural networks. <italic>Front. Artif. Intell.</italic><bold>3</bold> (2020).</mixed-citation>
              </ref>
              <ref id="CR60">
                <label>60.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Dodd</surname>
                      <given-names>E</given-names>
                    </name>
                    <name>
                      <surname>Cheston</surname>
                      <given-names>R</given-names>
                    </name>
                    <name>
                      <surname>Ivanecka</surname>
                      <given-names>A</given-names>
                    </name>
                  </person-group>
                  <article-title>The assessment of dementia in primary care</article-title>
                  <source>J. Psychiatr. Ment. Health Nurs.</source>
                  <year>2015</year>
                  <volume>22</volume>
                  <fpage>731</fpage>
                  <lpage>737</lpage>
                  <pub-id pub-id-type="doi">10.1111/jpm.12250</pub-id>
                  <?supplied-pmid 26459923?>
                  <pub-id pub-id-type="pmid">26459923</pub-id>
                </element-citation>
              </ref>
              <ref id="CR61">
                <label>61.</label>
                <mixed-citation publication-type="other">Onoda, K. &amp; Yamaguchi, S. Revision of the cognitive assessment for dementia, iPad version (CADi2). <italic>PLoS One</italic><bold>9</bold> (2014).</mixed-citation>
              </ref>
              <ref id="CR62">
                <label>62.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>El-Sappagh</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Abuhmed</surname>
                      <given-names>T</given-names>
                    </name>
                    <name>
                      <surname>Riazul Islam</surname>
                      <given-names>SM</given-names>
                    </name>
                    <name>
                      <surname>Kwak</surname>
                      <given-names>KS</given-names>
                    </name>
                  </person-group>
                  <article-title>Multimodal multitask deep learning model for Alzheimer’s disease progression detection based on time series data</article-title>
                  <source>Neurocomputing</source>
                  <year>2020</year>
                  <volume>412</volume>
                  <fpage>197</fpage>
                  <lpage>215</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.neucom.2020.05.087</pub-id>
                </element-citation>
              </ref>
              <ref id="CR63">
                <label>63.</label>
                <mixed-citation publication-type="other">El-Sappagh, S. <italic>et al.</italic> Alzheimer’s disease progression detection model based on an early fusion of cost-effective multimodal data. <italic>Futur. Gener. Comput. Syst.</italic><bold>115</bold> (2021).</mixed-citation>
              </ref>
              <ref id="CR64">
                <label>64.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Chen</surname>
                      <given-names>G</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Classification of Alzheimer disease, mild cognitive impairment, and normal cognitive status with large-scale network analysis based on resting-state functional MR imaging</article-title>
                  <source>Radiology</source>
                  <year>2011</year>
                  <volume>259</volume>
                  <fpage>213</fpage>
                  <lpage>221</lpage>
                  <pub-id pub-id-type="doi">10.1148/radiol.10100734</pub-id>
                  <?supplied-pmid 21248238?>
                  <pub-id pub-id-type="pmid">21248238</pub-id>
                </element-citation>
              </ref>
              <ref id="CR65">
                <label>65.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Wang</surname>
                      <given-names>P</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Aberrant intra-and inter-network connectivity architectures in Alzheimer’s disease and mild cognitive impairment</article-title>
                  <source>Sci. Rep.</source>
                  <year>2015</year>
                  <volume>5</volume>
                  <fpage>1</fpage>
                  <lpage>12</lpage>
                </element-citation>
              </ref>
              <ref id="CR66">
                <label>66.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Yang</surname>
                      <given-names>R</given-names>
                    </name>
                    <name>
                      <surname>Bogdan</surname>
                      <given-names>P</given-names>
                    </name>
                  </person-group>
                  <article-title>Controlling the multifractal generating measures of complex networks</article-title>
                  <source>Sci. Rep.</source>
                  <year>2020</year>
                  <volume>10</volume>
                  <fpage>1</fpage>
                  <lpage>13</lpage>
                  <pub-id pub-id-type="doi">10.1038/s41598-019-56847-4</pub-id>
                  <pub-id pub-id-type="pmid">31913322</pub-id>
                </element-citation>
              </ref>
              <ref id="CR67">
                <label>67.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Zhang</surname>
                      <given-names>Y</given-names>
                    </name>
                    <name>
                      <surname>Zhang</surname>
                      <given-names>H</given-names>
                    </name>
                    <name>
                      <surname>Chen</surname>
                      <given-names>X</given-names>
                    </name>
                    <name>
                      <surname>Lee</surname>
                      <given-names>SW</given-names>
                    </name>
                    <name>
                      <surname>Shen</surname>
                      <given-names>D</given-names>
                    </name>
                  </person-group>
                  <article-title>Hybrid high-order functional connectivity networks using resting-state functional MRI for mild cognitive impairment diagnosis</article-title>
                  <source>Sci. Rep.</source>
                  <year>2017</year>
                  <volume>7</volume>
                  <fpage>1</fpage>
                  <lpage>15</lpage>
                  <pub-id pub-id-type="doi">10.1038/s41598-016-0028-x</pub-id>
                  <pub-id pub-id-type="pmid">28127051</pub-id>
                </element-citation>
              </ref>
              <ref id="CR68">
                <label>68.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>McKhann</surname>
                      <given-names>G</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Clinical diagnosis of Alzheimer’s disease: report of the NINCDS-ADRDA Work Group under the auspices of Department of Health and Human Services Task Force on Alzheimer’s Disease</article-title>
                  <source>Neurology</source>
                  <year>2012</year>
                  <volume>34</volume>
                  <fpage>939</fpage>
                  <lpage>939</lpage>
                  <pub-id pub-id-type="doi">10.1212/WNL.34.7.939</pub-id>
                </element-citation>
              </ref>
              <ref id="CR69">
                <label>69.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Jagust</surname>
                      <given-names>WJ</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>The Alzheimer’s disease neuroimaging initiative 2 PET core: 2015</article-title>
                  <source>Alzheimer’s Dement.</source>
                  <year>2015</year>
                  <volume>11</volume>
                  <fpage>757</fpage>
                  <lpage>771</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.jalz.2015.05.001</pub-id>
                  <pub-id pub-id-type="pmid">26194311</pub-id>
                </element-citation>
              </ref>
              <ref id="CR70">
                <label>70.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Desikan</surname>
                      <given-names>RS</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest</article-title>
                  <source>Neuroimage</source>
                  <year>2006</year>
                  <volume>31</volume>
                  <fpage>968</fpage>
                  <lpage>980</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.01.021</pub-id>
                  <?supplied-pmid 16530430?>
                  <pub-id pub-id-type="pmid">16530430</pub-id>
                </element-citation>
              </ref>
              <ref id="CR71">
                <label>71.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Chawla</surname>
                      <given-names>NV</given-names>
                    </name>
                    <name>
                      <surname>Bowyer</surname>
                      <given-names>KW</given-names>
                    </name>
                    <name>
                      <surname>Hall</surname>
                      <given-names>LO</given-names>
                    </name>
                    <name>
                      <surname>Kegelmeyer</surname>
                      <given-names>WP</given-names>
                    </name>
                  </person-group>
                  <article-title>SMOTE: Synthetic minority over-sampling technique</article-title>
                  <source>J. Artif. Intell. Res.</source>
                  <year>2002</year>
                  <volume>16</volume>
                  <fpage>321</fpage>
                  <lpage>357</lpage>
                  <pub-id pub-id-type="doi">10.1613/jair.953</pub-id>
                </element-citation>
              </ref>
              <ref id="CR72">
                <label>72.</label>
                <mixed-citation publication-type="other">Elisseeff, A. &amp; Pontil, M. Leave-one-out error and stability of learning algorithms with applications. In <italic>NATO science series sub series iii computer and systems sciences</italic> 111–130 (ISO Press, 2003).</mixed-citation>
              </ref>
              <ref id="CR73">
                <label>73.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Krstajic</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Buturovic</surname>
                      <given-names>LJ</given-names>
                    </name>
                    <name>
                      <surname>Leahy</surname>
                      <given-names>DE</given-names>
                    </name>
                    <name>
                      <surname>Thomas</surname>
                      <given-names>S</given-names>
                    </name>
                  </person-group>
                  <article-title>Cross-validation pitfalls when selecting and assessing regression and classification models</article-title>
                  <source>J. Cheminform.</source>
                  <year>2014</year>
                  <volume>6</volume>
                  <fpage>1</fpage>
                  <lpage>15</lpage>
                  <pub-id pub-id-type="doi">10.1186/1758-2946-6-10</pub-id>
                  <pub-id pub-id-type="pmid">24397863</pub-id>
                </element-citation>
              </ref>
              <ref id="CR74">
                <label>74.</label>
                <mixed-citation publication-type="other">Raschka, S. Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning. (2018).</mixed-citation>
              </ref>
              <ref id="CR75">
                <label>75.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Kohavi</surname>
                      <given-names>R</given-names>
                    </name>
                  </person-group>
                  <article-title>A study of cross-validation and bootstrap for accuracy estimation and model selection</article-title>
                  <source>Ijcai</source>
                  <year>1995</year>
                  <volume>14</volume>
                  <fpage>1137</fpage>
                  <lpage>1145</lpage>
                </element-citation>
              </ref>
              <ref id="CR76">
                <label>76.</label>
                <mixed-citation publication-type="other">Alonso, J. M., Castiello, C. &amp; Mencar, C. A bibliometric analysis of the explainable artificial intelligence research field. In <italic>Information Processing and Management of Uncertainty in Knowledge-Based Systems-Theory and Foundations, CCIS853, </italic>1–13 (Springer, 2018).</mixed-citation>
              </ref>
              <ref id="CR77">
                <label>77.</label>
                <mixed-citation publication-type="other">Cohen, W. Fast effective rule induction. In <italic>International Conference on Machine Learning (ICML)</italic> 115–123 (1995).</mixed-citation>
              </ref>
              <ref id="CR78">
                <label>78.</label>
                <mixed-citation publication-type="other">Alonso, J. M. &amp; Bugar, A. ExpliClas: automatic generation of explanations in natural language for weka classifiers. In <italic>IEEE International Conference on Fuzzy Systems</italic> 1–6 (2019).</mixed-citation>
              </ref>
              <ref id="CR79">
                <label>79.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Landau</surname>
                      <given-names>SM</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Associations between cognitive, functional, and FDG-PET measures of decline in AD and MCI</article-title>
                  <source>Neurobiol. Aging</source>
                  <year>2011</year>
                  <volume>32</volume>
                  <fpage>1207</fpage>
                  <lpage>1218</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.neurobiolaging.2009.07.002</pub-id>
                  <?supplied-pmid 19660834?>
                  <pub-id pub-id-type="pmid">19660834</pub-id>
                </element-citation>
              </ref>
              <ref id="CR80">
                <label>80.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Chen</surname>
                      <given-names>K</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Characterizing Alzheimer’s disease using a hypometabolic convergence index</article-title>
                  <source>Neuroimage</source>
                  <year>2011</year>
                  <volume>56</volume>
                  <fpage>52</fpage>
                  <lpage>60</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.01.049</pub-id>
                  <?supplied-pmid 21276856?>
                  <pub-id pub-id-type="pmid">21276856</pub-id>
                </element-citation>
              </ref>
              <ref id="CR81">
                <label>81.</label>
                <mixed-citation publication-type="other">Cortizo, J. C. &amp; Giraldez, I. Multi criteria wrapper improvements to Naive Bayes learning. In <italic>International Conference on Intelligent Data Engineering and Automated Learning</italic> 419–427 (Springer, Berlin, Heidelberg, 2006). 10.1007/11875581_51.</mixed-citation>
              </ref>
              <ref id="CR82">
                <label>82.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Maldonado</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Weber</surname>
                      <given-names>R</given-names>
                    </name>
                    <name>
                      <surname>Famili</surname>
                      <given-names>F</given-names>
                    </name>
                  </person-group>
                  <article-title>Feature selection for high-dimensional class-imbalanced data sets using support vector machines</article-title>
                  <source>Inf. Sci. (Ny)</source>
                  <year>2014</year>
                  <volume>286</volume>
                  <fpage>228</fpage>
                  <lpage>246</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.ins.2014.07.015</pub-id>
                </element-citation>
              </ref>
              <ref id="CR83">
                <label>83.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Rodin</surname>
                      <given-names>AS</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Use of wrapper algorithms coupled with a random forests classifier for variable selection in large-scale genomic association studies</article-title>
                  <source>J. Comput. Biol.</source>
                  <year>2010</year>
                  <volume>16</volume>
                  <fpage>1705</fpage>
                  <lpage>1718</lpage>
                  <pub-id pub-id-type="doi">10.1089/cmb.2008.0037</pub-id>
                </element-citation>
              </ref>
              <ref id="CR84">
                <label>84.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Panthong</surname>
                      <given-names>R</given-names>
                    </name>
                    <name>
                      <surname>Srivihok</surname>
                      <given-names>A</given-names>
                    </name>
                  </person-group>
                  <article-title>Wrapper feature subset selection for dimension reduction based on ensemble learning algorithm</article-title>
                  <source>Procedia Comput. Sci.</source>
                  <year>2015</year>
                  <volume>72</volume>
                  <fpage>162</fpage>
                  <lpage>169</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.procs.2015.12.117</pub-id>
                </element-citation>
              </ref>
              <ref id="CR85">
                <label>85.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Li</surname>
                      <given-names>Z</given-names>
                    </name>
                    <name>
                      <surname>Xie</surname>
                      <given-names>W</given-names>
                    </name>
                    <name>
                      <surname>Liu</surname>
                      <given-names>T</given-names>
                    </name>
                  </person-group>
                  <article-title>Efficient feature selection and classification for microarray data</article-title>
                  <source>PLoS ONE</source>
                  <year>2018</year>
                  <volume>13</volume>
                  <fpage>1</fpage>
                  <lpage>21</lpage>
                </element-citation>
              </ref>
              <ref id="CR86">
                <label>86.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Granitto</surname>
                      <given-names>PM</given-names>
                    </name>
                    <name>
                      <surname>Furlanello</surname>
                      <given-names>C</given-names>
                    </name>
                    <name>
                      <surname>Biasioli</surname>
                      <given-names>F</given-names>
                    </name>
                    <name>
                      <surname>Gasperi</surname>
                      <given-names>F</given-names>
                    </name>
                  </person-group>
                  <article-title>Recursive feature elimination with random forest for PTR-MS analysis of agroindustrial products</article-title>
                  <source>Chemom. Intell. Lab. Syst.</source>
                  <year>2006</year>
                  <volume>83</volume>
                  <fpage>83</fpage>
                  <lpage>90</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.chemolab.2006.01.007</pub-id>
                </element-citation>
              </ref>
              <ref id="CR87">
                <label>87.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Menze</surname>
                      <given-names>BH</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>A comparison of random forest and its Gini importance with standard chemometric methods for the feature selection and classification of spectral data</article-title>
                  <source>BMC Bioinformatics</source>
                  <year>2009</year>
                  <volume>10</volume>
                  <fpage>1</fpage>
                  <lpage>16</lpage>
                  <pub-id pub-id-type="doi">10.1186/1471-2105-10-213</pub-id>
                  <pub-id pub-id-type="pmid">19118496</pub-id>
                </element-citation>
              </ref>
              <ref id="CR88">
                <label>88.</label>
                <mixed-citation publication-type="other">Hall, P. On the Art and Science of Machine Learning Explanations. arXiv Prepr. arXiv 1810.02909 (2018).</mixed-citation>
              </ref>
              <ref id="CR89">
                <label>89.</label>
                <mixed-citation publication-type="other">Ando Saabas. Interpreting Random Forests, treeinterpreter. (2019).</mixed-citation>
              </ref>
              <ref id="CR90">
                <label>90.</label>
                <mixed-citation publication-type="other">Korobov, M. &amp; Lopuhin, K. ELI5 Documentation. (2019).</mixed-citation>
              </ref>
              <ref id="CR91">
                <label>91.</label>
                <mixed-citation publication-type="other">Lundberg, S. &amp; Lee, S.-I. A Unified approach to interpreting model predictions. In <italic>Advances in Neural Information Processing Systems</italic> 4765–4774 (2017).</mixed-citation>
              </ref>
              <ref id="CR92">
                <label>92.</label>
                <mixed-citation publication-type="other">Molnar, C. <italic>Interpretable Machine Learning A Guide for Making Black Box Models Explainable</italic>. (2020).</mixed-citation>
              </ref>
              <ref id="CR93">
                <label>93.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Štrumbelj</surname>
                      <given-names>E</given-names>
                    </name>
                    <name>
                      <surname>Kononenko</surname>
                      <given-names>I</given-names>
                    </name>
                  </person-group>
                  <article-title>Explaining prediction models and individual predictions with feature contributions</article-title>
                  <source>Knowl. Inf. Syst.</source>
                  <year>2014</year>
                  <volume>41</volume>
                  <fpage>647</fpage>
                  <lpage>665</lpage>
                  <pub-id pub-id-type="doi">10.1007/s10115-013-0679-x</pub-id>
                </element-citation>
              </ref>
            </ref-list>
          </back>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
