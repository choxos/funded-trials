<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2024-05-03T02:01:45Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:9365219" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:9365219</identifier>
        <datestamp>2022-08-11</datestamp>
        <setSpec>jaro</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" article-type="research-article" dtd-version="1.3">
          <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
            <restricted-by>pmc</restricted-by>
          </processing-meta>
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">J Assoc Res Otolaryngol</journal-id>
              <journal-id journal-id-type="iso-abbrev">J Assoc Res Otolaryngol</journal-id>
              <journal-title-group>
                <journal-title>JARO: Journal of the Association for Research in Otolaryngology</journal-title>
              </journal-title-group>
              <issn pub-type="ppub">1525-3961</issn>
              <issn pub-type="epub">1438-7573</issn>
              <publisher>
                <publisher-name>Springer US</publisher-name>
                <publisher-loc>New York</publisher-loc>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC9365219</article-id>
              <article-id pub-id-type="pmcid">PMC9365219</article-id>
              <article-id pub-id-type="pmc-uid">9365219</article-id>
              <article-id pub-id-type="pmid">35948694</article-id>
              <article-id pub-id-type="pmid">35948694</article-id>
              <article-id pub-id-type="publisher-id">859</article-id>
              <article-id pub-id-type="doi">10.1007/s10162-022-00859-x</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Research Article</subject>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>Rate Discrimination Training May Partially Restore Temporal Processing Abilities from Age-Related Deficits</article-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author" corresp="yes">
                  <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0731-4574</contrib-id>
                  <name>
                    <surname>Anderson</surname>
                    <given-names>Samira</given-names>
                  </name>
                  <address>
                    <email>sander22@umd.edu</email>
                  </address>
                  <xref ref-type="aff" rid="Aff1"/>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>DeVries</surname>
                    <given-names>Lindsay</given-names>
                  </name>
                  <address>
                    <email>ldevries@umd.edu</email>
                  </address>
                  <xref ref-type="aff" rid="Aff1"/>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Smith</surname>
                    <given-names>Edward</given-names>
                  </name>
                  <address>
                    <email>esmith6@umd.edu</email>
                  </address>
                  <xref ref-type="aff" rid="Aff1"/>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Goupell</surname>
                    <given-names>Matthew J.</given-names>
                  </name>
                  <address>
                    <email>goupell@umd.edu</email>
                  </address>
                  <xref ref-type="aff" rid="Aff1"/>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Gordon-Salant</surname>
                    <given-names>Sandra</given-names>
                  </name>
                  <address>
                    <email>sgsalant@umd.edu</email>
                  </address>
                  <xref ref-type="aff" rid="Aff1"/>
                </contrib>
                <aff id="Aff1"><institution-wrap><institution-id institution-id-type="GRID">grid.164295.d</institution-id><institution-id institution-id-type="ISNI">0000 0001 0941 7177</institution-id><institution>Department of Hearing and Speech Sciences, </institution><institution>University of Maryland, </institution></institution-wrap>College Park, 20742 USA </aff>
              </contrib-group>
              <pub-date pub-type="epub">
                <day>10</day>
                <month>8</month>
                <year>2022</year>
              </pub-date>
              <pub-date pub-type="ppub">
                <month>12</month>
                <year>2022</year>
              </pub-date>
              <volume>23</volume>
              <issue>6</issue>
              <fpage>771</fpage>
              <lpage>786</lpage>
              <history>
                <date date-type="received">
                  <day>29</day>
                  <month>11</month>
                  <year>2021</year>
                </date>
                <date date-type="accepted">
                  <day>30</day>
                  <month>6</month>
                  <year>2022</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>© The Author(s) under exclusive licence to Association for Research in Otolaryngology 2022</copyright-statement>
              </permissions>
              <abstract id="Abs1">
                <p id="Par1">The ability to understand speech in complex environments depends on the brain’s ability to preserve the precise timing characteristics of the speech signal. Age-related declines in temporal processing may contribute to the older adult’s experience of communication difficulty in challenging listening conditions. This study’s purpose was to evaluate the effects of rate discrimination training on auditory temporal processing. A double-blind, randomized control design assigned 77 young normal-hearing, older normal-hearing, and older hearing-impaired listeners to one of two treatment groups: experimental (rate discrimination for 100- and 300-Hz pulse trains) and active control (tone detection in noise). All listeners were evaluated during pre- and post-training sessions using perceptual rate discrimination of 100-, 200-, 300-, and 400-Hz band-limited pulse trains and auditory steady-state responses (ASSRs) to the same stimuli. Training generalization was evaluated using several temporal processing measures and sentence recognition tests that included time-compressed and reverberant speech stimuli. Results demonstrated a session × training group interaction for perceptual and ASSR testing to the trained frequencies (100 and 300 Hz), driven by greater improvements in the training group than in the active control group. Further, post-test rate discrimination of the older listeners reached levels that were equivalent to those of the younger listeners at pre-test. Generalization was observed in significant improvement in rate discrimination of untrained frequencies (200 and 400 Hz) and in correlations between performance changes in rate discrimination and sentence recognition of reverberant speech. Further, non-auditory inhibition/attention performance predicted training-related improvement in rate discrimination. Overall, the results demonstrate the potential for auditory training to partially restore temporal processing in older listeners and highlight the role of cognitive function in these gains.
</p>
              </abstract>
              <kwd-group xml:lang="en">
                <title>Keywords</title>
                <kwd>Auditory Training</kwd>
                <kwd>Aging</kwd>
                <kwd>Temporal processing</kwd>
                <kwd>Speech perception</kwd>
                <kwd>Auditory steady-state response</kwd>
              </kwd-group>
              <funding-group>
                <award-group>
                  <funding-source>
                    <institution-wrap>
                      <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000049</institution-id>
                      <institution>National Institute on Aging</institution>
                    </institution-wrap>
                  </funding-source>
                  <award-id>P01AG055365</award-id>
                  <principal-award-recipient>
                    <name>
                      <surname>Gordon-Salant</surname>
                      <given-names>Sandra</given-names>
                    </name>
                  </principal-award-recipient>
                </award-group>
              </funding-group>
              <custom-meta-group>
                <custom-meta>
                  <meta-name>issue-copyright-statement</meta-name>
                  <meta-value>© The Author(s) under exclusive licence to Association for Research in Otolaryngology 2022</meta-value>
                </custom-meta>
              </custom-meta-group>
            </article-meta>
          </front>
          <body>
            <sec id="Sec1">
              <title>INTRODUCTION</title>
              <p id="Par2">The brain’s ability to process the temporal characteristics of auditory stimuli is an integral component of speech understanding, particularly in complex environments that reduce the redundancy of the speech signal. For example, the ability to discriminate between changes in temporal rate contributes to the listener’s ability to discriminate fundamental frequency, which serves as a cue to speaker and gender identification. Thus, temporal processing is an important factor that supports speech segregation and speech understanding in noise (Zaltz and Kishon-Rabin <xref ref-type="bibr" rid="CR52">2022</xref>). In addition, non-speech measures of temporal processing such as gap detection can predict speech recognition in reverberation in normal-hearing listeners (Dreschler and Leeuw <xref ref-type="bibr" rid="CR13">1990</xref>; Gordon-Salant and Fitzgibbons <xref ref-type="bibr" rid="CR22">1993</xref>; Irwin and McAuley <xref ref-type="bibr" rid="CR28">1987</xref>), and pulse-rate discrimination can predict speech recognition in noise in cochlear-implant listeners (Zhou et al. <xref ref-type="bibr" rid="CR53">2019</xref>).</p>
              <p id="Par3">Listeners can discriminate small changes in the amplitude modulation rate of complex signals (e.g., pulse trains). Abilities are as good as 3 to 7% for rates of ~ 100 Hz, but performance declines rapidly for rates &gt; 200–300 Hz (e.g., Carlyon and Deeks <xref ref-type="bibr" rid="CR8">2002</xref>; Carlyon et al. <xref ref-type="bibr" rid="CR9">2008</xref>; Kong et al. <xref ref-type="bibr" rid="CR33">2009</xref>; Macherey and Carlyon <xref ref-type="bibr" rid="CR38">2014</xref>). The physiological basis for this limitation on rate discrimination may arise from both peripheral and central sources (e.g., Ihlefeld et al. <xref ref-type="bibr" rid="CR27">2015</xref>; Johnson et al. <xref ref-type="bibr" rid="CR31">2021</xref>). Previous studies have demonstrated age-related declines in rate discrimination (DeVries et al. <xref ref-type="bibr" rid="CR12">2022</xref>; Gaskins et al. <xref ref-type="bibr" rid="CR20">2019</xref>) and in other temporal processing tasks, including gap detection (Snell <xref ref-type="bibr" rid="CR46">1997</xref>), duration discrimination (Fitzgibbons and Gordon‐Salant <xref ref-type="bibr" rid="CR18">1995</xref>), and tempo discrimination (Fitzgibbons and Gordon-Salant <xref ref-type="bibr" rid="CR17">2001</xref>). Moreover, links between basic measures of auditory temporal processing and age-related deficits in speech recognition have been observed. Therefore, temporal processing deficits may underlie older adults’ reported difficulties when understanding speech characterized by altered timing cues (i.e., time-compressed speech and reverberant speech), and the question remains whether these age-related deficits can be improved through targeted auditory training.</p>
              <p id="Par4">Previous studies have demonstrated the efficacy of training in improving temporal processing abilities. For example, training improves temporal rate discrimination thresholds in cochlear-implant listeners across a wide range of ages (Bissmeyer et al. <xref ref-type="bibr" rid="CR6">2020</xref>; Goldsworthy and Shannon <xref ref-type="bibr" rid="CR21">2014</xref>), and pitch discrimination can be improved through musical training in normal-hearing listeners (Bianchi et al. <xref ref-type="bibr" rid="CR5">2019</xref>; Micheyl et al. <xref ref-type="bibr" rid="CR39">2006</xref>). Furthermore, animal and human studies suggest that the brain retains some plasticity into older age. Age-related decreases in rat temporal coding and cortical firing synchrony can largely be reversed by training on a frequency discrimination auditory training paradigm (de Villers-Sidani et al. <xref ref-type="bibr" rid="CR10">2010</xref>). A cross-species study including mice and humans found that adaptive training on signal-in-noise detection in a closed-loop paradigm led to improvements in signal detection in both species and generalization to speech-in-noise performance in human listeners (Whitton et al. <xref ref-type="bibr" rid="CR51">2017</xref>). Older normal-hearing and hearing-impaired human listeners experience reductions in frequency-following response latencies, an indication of improved temporal precision, from training that adaptively increased or decreased both consonant-transition durations and auditory memory load (Anderson et al. <xref ref-type="bibr" rid="CR1">2013</xref>). Overall, these studies demonstrate the potential for training-related neuroplasticity in older listeners. It is, however, currently unknown whether auditory training targeted at auditory temporal processing can improve temporal rate discrimination ability in older normal-hearing listeners or hearing-impaired listeners and whether improvement in temporal rate discrimination generalizes to performance on speech-understanding measures.</p>
              <p id="Par5">Therefore, the current study was designed to (1) determine whether rate discrimination training can improve auditory temporal processing in older and younger listeners in both perceptual and neural responses; (2) determine the extent to which perceptual learning on rate discrimination generalizes to other temporal processing tasks and measures of speech understanding; and (3) investigate the neural and cognitive variables that are associated with training-related improvements in perception. Based on previous animal and human studies, we hypothesized that perceptual training would partially restore temporal processing abilities in older listeners. In addition, we hypothesized that neural responses to the trained pulse trains (auditory steady-state responses, ASSR) and cognitive ability would relate to changes in perception. Finally, given that previous studies have not shown significant effects of hearing loss on temporal processing tasks (Fitzgibbons and Gordon-Salant <xref ref-type="bibr" rid="CR16">1996</xref>; Roque et al. <xref ref-type="bibr" rid="CR41">2019a</xref>), we hypothesized a similar training benefit regardless of hearing status.</p>
            </sec>
            <sec id="Sec2">
              <title>MATERIALS AND METHODS</title>
              <sec id="Sec3">
                <title>Listeners</title>
                <p id="Par6">We recruited 301 listeners for a double-blind randomized controlled clinical trial and determined if they met the following age and audiometric criteria for these groups: young normal hearing (YNH, age 18–30 years), older normal hearing (ONH, age 65–85 years), and older hearing impaired (OHI, age 68–85 years). Normal hearing was defined as pure-tone thresholds ≤ 25 dB HL (re: ANSI <xref ref-type="bibr" rid="CR2">2018</xref>) from 125 to 4000 Hz in the right ear. Impaired hearing was defined by a high-frequency pure-tone average (average thresholds at 1, 2, and 4 kHz) &gt; 30 dB HL and thresholds at 2 and 4 kHz &lt; 70 dB HL (to ensure signal audibility). Hearing thresholds were required to be symmetrical (no interaural differences &gt; 10 dB at any frequency) for all listeners, and there were no air-bone gaps &gt; 10 dB at any frequency. Word recognition scores were &gt; 70% for a single 25-word lists of the NU-6 test (Tillman and Carhart <xref ref-type="bibr" rid="CR49">1966</xref>) presented bilaterally at 75 dB HL in quiet. Middle ear function was normal bilaterally based on average values for tympanometric peak pressure, peak admittance, tympanometric width, and equivalent volume. Acoustic reflexes were present from 500 to 2000 Hz, elicited ipsilaterally and contralaterally. Finally, auditory brainstem responses (ABRs) were recorded, and Wave V latencies were &lt; 6.8 ms with no interaural asymmetries &gt; 0.2 ms. Additional criteria included the following: A passing score of ≥ 26 on the Montreal Cognitive Assessment (MoCA; Nasreddine et al. <xref ref-type="bibr" rid="CR40">2005</xref>), a negative history of neurological disease, a passing score on the Snellen vision screening chart ≤ 20/50 (Hetherington <xref ref-type="bibr" rid="CR25">1954</xref>), being a native English speaker, and earning a high school diploma. All procedures were reviewed and approved by the Institutional Review Board (IRB) at the University of Maryland, College Park. Listeners provided informed consent and were monetarily compensated for their time.</p>
                <p id="Par7">The 125 listeners who met the study criteria were randomly assigned to one of two training groups: experimental and active control. Of these, 48 listeners did not complete the study. Seventeen listeners were dismissed due to: non-compliance with training (3), poor quality data (7), an adverse event (1), and excessive time delay associated with COVID-19 (6). Twenty-six listeners withdrew from the study due to medical or transportation issues. Eleven listeners were lost to follow-up. The final numbers of listeners in each training group were 40 experimental (14 YNH, 16 ONH, and 10 OHI; 30 females) and 37 active control (15 YNH, 14 ONH, and 8 OHI; 28 females). See Table <xref rid="Tab1" ref-type="table">1</xref> for additional demographic characteristics. Note that 1% of listener data (31 of 2618 measurements) are missing because of isolated issues during data collection or because of anomalous data that did not converge.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Demographic characteristics of experimental and active control groups including sex, age, and pure-tone average (PTA). <italic>YNH</italic> young normal hearing, <italic>ONH</italic> older normal hearing, <italic>OHI</italic> older hearing impaired, <italic>F</italic> female, <italic>M</italic> mean, and <italic>S.D.</italic> standard deviation</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Group</th><th align="left" colspan="3">Experimental</th><th align="left" colspan="3">Active Control</th></tr><tr><th align="left">YNH (<italic>n</italic> = 14)</th><th align="left">ONH (<italic>n</italic> = 16)</th><th align="left">OHI (<italic>n</italic> = 10)</th><th align="left">YNH (<italic>n</italic> = 15)</th><th align="left">ONH (<italic>n</italic> = 14)</th><th align="left">OHI<break/>(<italic>n</italic> = 8)</th></tr></thead><tbody><tr><td align="left">Sex</td><td char="." align="char">7 F</td><td align="left">15 F</td><td align="left">8 F</td><td char="." align="char">9 F</td><td align="left">12 F</td><td align="left">7 F</td></tr><tr><td align="left">Age</td><td char="." align="char"><p>21.1 (M)</p><p>  2.2 (S.D)</p></td><td align="left"><p>69.9 (M)</p><p>  4.0 (S.D)</p></td><td align="left"><p>74.0(M)</p><p>  6.4 (S.D)</p></td><td char="." align="char"><p>21.0 (M)</p><p>  2.0 (S.D)</p></td><td align="left"><p>70.0 (M)</p><p>  4.5 (S.D)</p></td><td align="left"><p>74.4(M)</p><p>  6.4 (S.D)</p></td></tr><tr><td align="left">HF PTA</td><td char="." align="char"><p>  5.5 (M)</p><p>  2.6 (S.D)</p></td><td align="left"><p>14.1 (M)</p><p>  3.0 (S.D.)</p></td><td align="left"><p>38.2 (M)</p><p>  4.4 (S.D.)</p></td><td char="." align="char"><p>  6.2 (M)</p><p>  2.9 (S.D)</p></td><td align="left"><p>13.9 (M)</p><p>  4.3 (S.D.)</p></td><td align="left"><p>36.8 (M)</p><p>  7.1 (S.D.)</p></td></tr></tbody></table></table-wrap></p>
              </sec>
              <sec id="Sec4">
                <title>Pre- and Post-Testing</title>
                <p id="Par8">Both training groups were tested using the same battery of electrophysiological and behavioral measures prior to the onset and after completion of training. ASSRs were recorded to 100-, 200-, 300- and 400-Hz bandpass-filtered click trains, and behavioral pulse-rate discrimination was measured to the same stimuli. The behavioral test battery also included generalization measures: gap detection, gap duration discrimination, tempo discrimination, and several speech recognition measures. These measures will be described in more detail below. The duration of pre- and post-testing was approximately 1½ h for ASSR recording and 2 ½ h for behavioral testing.</p>
                <sec id="Sec5">
                  <title>Procedure</title>
                  <p id="Par9">Listeners were seated in a double-walled sound-attenuating booth. The stimuli were presented to listeners through a single insert earphone (ER-2, Etymotic, Elk Grove Village, IL). Stimulus presentation and event timing were controlled from a laptop computer and a custom MATLAB script.</p>
                </sec>
              </sec>
              <sec id="Sec6">
                <title>Perceptual and Neural Responses to Pulse Trains</title>
                <sec id="Sec7">
                  <title>Stimuli.</title>
                  <p id="Par10">The stimuli were band-limited pulse trains (300-ms duration) having rates of 100, 200, 300, and 400 Hz. The pulses had a 1-kHz bandwidth arithmetically centered around 4 kHz, created using forward–backward Butterworth filters (5th order) (DeVries et al. <xref ref-type="bibr" rid="CR12">2022</xref>). Raised cosine Hanning windows with a 10-ms rise-fall time were applied to the stimuli to avoid filter-related onset and offset transients. The stimuli were presented monaurally to the right ear at 75 dBA for all electrophysiological and non-speech behavioral measures described below. For perceptual testing only, a low-frequency masking noise was mixed with the pulse train stimuli to eliminate the use of low-frequency distortion products to perform the task. Wideband masking noise was low-pass filtered using a 200-Hz cutoff with a − 3 dB/octave filter and presented at an overall level of 61 dB SPL.</p>
                </sec>
              </sec>
              <sec id="Sec8">
                <title>Perceptual Rate Discrimination</title>
                <p id="Par11">Rate discrimination for each reference pulse rate was assessed by measuring pulse-rate difference limens (DLs) using a three-interval, two-alternative forced choice (3I-2AFC) procedure. Each rate (100, 200, 300, and 400 Hz) was tested with three blocks of 60 trials for a total of 720 trials across blocks. The order of reference pulse rate was randomized.</p>
                <p id="Par12">Stimulus presentation was self-paced throughout the experiment. The listeners viewed a monitor that displayed four boxes. They were asked to click the box containing “Begin Trial” and then heard a sequence of three stimuli, with the presentation of each stimulus synchronized to a flash in the corresponding visual block in the sequence. The first stimulus was always the reference stimulus. The target stimulus with the higher rate was in the second or third interval, randomly chosen with a 50% <italic>a priori</italic> probability.</p>
                <p id="Par13">The listeners received the following instructions: “You will hear three brief sounds that sound like a buzz. The first one is the ‘standard.’ One of the other sounds has a slightly higher pitch that sounds different from the standard sound. Please select the sound, 2 or 3, that contains the higher pitch (or sounds different from the standard sound). If you are not sure, take a guess.”</p>
                <p id="Par14">After each listener response, correct answer feedback was provided by flashing a green light at the box corresponding to the correct interval. A two-down-one-up adaptive procedure was employed to target 70.7% correct on the psychometric function (Levitt <xref ref-type="bibr" rid="CR37">1971</xref>). The initial rate difference between the reference and target stimulus was set at 40%. The maximum allowable rate difference was 40%. The rate difference after two correct responses or one incorrect response was changed by a factor of 2 (e.g., for a 100-Hz reference pulse rate, the 140-Hz target rate was changed to 120 Hz after correct answers on the first two trials). After three reversals of the adaptive procedure, the changes in step size were decreased by a factor of √2. The tracking ended after reaching the fixed number of 60 trials.</p>
                <sec id="Sec9">
                  <title>Analysis.</title>
                  <p id="Par15">Perceptual responses were recorded in MATLAB. The pulse rate difference limen (DL) in percent for an individual adaptive track was found by calculating the geometric mean over all of the reversals in the adaptive procedure except the first two. The arithmetic mean of the second and third tracks was used to calculate the final DL for each listener and condition. The first track was omitted to decrease the possible impact of learning effects from the first track. The DLs were log-transformed due to a negative skew in the data prior to conducting the statistical analysis.</p>
                </sec>
              </sec>
              <sec id="Sec10">
                <title>ASSR</title>
                <sec id="Sec11">
                  <title>Recording</title>
                  <p id="Par16">The 300-ms pulse trains were presented at a rate of 1.66 Hz using the Intelligent Hearing Systems Continuous Acquisition Model (IHS SEPCAM, Miami, FL) through electromagnetically shielded insert ER-3 earphones (IHS) in an electrically shielded double-walled sound-attenuating booth. A three-electrode vertical montage was used (Cz active, right ear lobe reference, low forehead ground). Responses were recorded with a 10-kHz sampling rate and were filtered from 1 to 5 kHz on-line. A minimum of 1024 artifact-free sweeps (≤ 30 µV) were obtained for each condition. The listeners watched their movie of choice, muted with subtitles, to facilitate a relaxed but awake state.</p>
                </sec>
                <sec id="Sec12">
                  <title>Data Analysis</title>
                  <p id="Par17">Responses were imported into MATLAB format using custom scripts and filtered from 50 to 500 Hz. An individual average response was created with the first 1000 artifact-free sweeps. Phase-locking factor (PLF) was assessed in a manner similar to that employed in previous studies (Jenkins et al. <xref ref-type="bibr" rid="CR30">2018</xref>; Roque et al. <xref ref-type="bibr" rid="CR42">2019b</xref>), using Morlet wavelets to decompose the signal from 50 to 500 Hz (Tallon-Baudry et al. <xref ref-type="bibr" rid="CR48">1996</xref>). The PLF value was then calculated for the response time region of 10–310 ms and around a 20-Hz frequency bin corresponding to the pulse rate of each condition. The PLFs were log-transformed due to a negative skew in the data.</p>
                </sec>
              </sec>
              <sec id="Sec13">
                <title>Mid Generalization Measures</title>
                <p id="Par18">It was hypothesized that training to improve temporal processing on one measure (pulse-rate discrimination) would generalize to improvement on other non-speech auditory tasks that rely on accurate temporal processing. Gap detection, gap duration discrimination, and temporal interval discrimination measures were chosen because previous studies have demonstrated age-related deficits on these tasks (Fitzgibbons and Gordon-Salant <xref ref-type="bibr" rid="CR17">2001</xref>; Harris et al. <xref ref-type="bibr" rid="CR23">2010</xref>; Kumar <xref ref-type="bibr" rid="CR35">2011</xref>; Ross et al. <xref ref-type="bibr" rid="CR43">2010</xref>; Snell <xref ref-type="bibr" rid="CR46">1997</xref>).</p>
              </sec>
              <sec id="Sec14">
                <title>Gap Detection</title>
                <p id="Par19">Gap detection thresholds were measured using target stimuli that were 250-ms wideband Gaussian noise bursts that had a silent gap temporally centered in the stimulus. Cosine squared windows with a 1-ms rise-fall time were applied to the stimuli to avoid transients.</p>
                <p id="Par20">A 3I-2AFC procedure was used. The first interval was the standard, with no gap. The target stimulus with the silent gap was in the second or third interval, randomly chosen with a 50 % <italic>a priori</italic> probability.</p>
                <p id="Par21">The listeners received the following instructions, “This is the ‘standard’ and is a continuous noise. One of the other noise bursts, 2 or 3, has a very brief pause or interruption that sounds different from the standard noise burst. Please select the noise burst, 2 or 3, that contains the brief pause (or sounds different from the standard noise burst). If you are not sure, take a guess.”</p>
                <p id="Par22">After each listener response, correct answer feedback was provided. Then the gap duration was adapted according to the two-down-one-up adaptive rule, targeting 70.7% correct discrimination. The initial gap duration was 25 ms. The maximum gap duration was 100 ms, and the minimum gap duration was 1 ms. The initial step size in the adaptive procedure was 5 ms. After two reversals, the step size was changed to 1 ms. The adaptive track continued until there were eight reversals. Threshold was defined as the arithmetic mean of the last six reversals. Three adaptive tracks were conducted. The arithmetic mean of the second and third tracks was used to calculate the gap detection threshold for each listener.</p>
              </sec>
              <sec id="Sec15">
                <title>Gap Duration Discrimination</title>
                <p id="Par23">Gap duration discrimination was measured using 250-ms 1000-Hz tone pairs separated by a silent interval (Fitzgibbons and Gordon-Salant <xref ref-type="bibr" rid="CR15">1994</xref>). Cosine squared windows with a 5-ms rise-fall time were applied to the stimuli to avoid transients.</p>
                <p id="Par24">The listener received the following instruction: “Please select the tone pair, 2 or 3, that contains the longer silent interval (or sounds different from the standard tone pair). If you are not sure, take a guess.”</p>
                <p id="Par25">After each listener response, correct answer feedback was provided. Then the gap duration was adapted according to the two-down-one-up adaptive rule. The initial gap duration for the target was 350 ms (i.e., 40% larger than the reference gap of 250 ms). The maximum gap duration was 450 ms, and the minimum gap duration was 252 ms. The initial step size in the adaptive procedure was 10 ms. After two reversals, the step size was reduced to 2 ms. The adaptive track continued until there were eight reversals. The relative gap duration discrimination DL in percent (based on the 250-ms reference) was calculated from the arithmetic mean of the last six reversals. Three adaptive tracks were measured. The arithmetic mean of the second and third tracks was used to calculate the gap duration discrimination DL for each listener.</p>
              </sec>
              <sec id="Sec16">
                <title>Tempo (Rhythm) Discrimination</title>
                <p id="Par26">Discrimination DLs were measured for inter-onset intervals (IOIs) in isochronous sequences of five brief 50-ms 1000-Hz tones (see Fitzgibbons and Gordon-Salant <xref ref-type="bibr" rid="CR17">2001</xref>). The IOI is defined as the duration between the onset of one tone in the sequence and the onset of the subsequent tone. Cosine squared windows with a 5-ms rise-fall time were applied to the stimuli to avoid transients.</p>
                <p id="Par27">A 3I-2AFC procedure was used. The reference intervals had a fixed IOI, either 100 ms (fast reference) or 600 ms (slow reference). The target stimulus with the relatively slower tone sequence was in the second or third interval, randomly chosen with a 50% <italic>a priori</italic> probability.</p>
                <p id="Par28">The listeners received the following instructions: “You will hear three sequences of 5 brief tones. The first sequence is the ‘standard.’ One of the other sequences, 2 or 3, sounds slower than the standard sequence. Please select the tone sequence, 2 or 3, that is a slower sequence (or sounds different from the standard sequence). If you are not sure, take a guess.”</p>
                <p id="Par29">After each listener response, correct answer feedback was provided. Then, the IOI was adapted according to the two-down-one-up adaptive rule. The starting target IOI was 150 ms for the 100-ms reference IOI and 700 ms for the 600-ms reference IOI. The maximum target IOI was 200 ms, and the minimum target IOI was 101 ms for the 100-ms reference IOI; the maximum target IOI was 800 ms, and the minimum target IOI was 601 ms for the 600-ms reference IOI. The initial step size in the adaptive procedure was 10 ms. After two reversals, the step size decreased to 2 ms. The adaptive track continued until there were eight reversals. The DL for each IOI was calculated from the arithmetic mean of the last six reversals of each track. Three adaptive tracks were conducted for each reference IOI (i.e., there were six separate adaptive tracks). The arithmetic mean of the second and third tracks was used to calculate the relative IOI DL in percent (based on either the 100-ms or 600-ms IOI reference) for each listener.</p>
              </sec>
              <sec id="Sec17">
                <title>Sentence Recognition</title>
                <p id="Par30">Sentence recognition in quiet was measured for sentences from the IEEE corpus (IEEE <xref ref-type="bibr" rid="CR26">1969</xref>) in five conditions: normal rate with no reverberation (i.e., clean speech), two levels of time compression (TC; 40% and 60%), and two levels of reverberation (REV; 0.6 s and 1.2 s). There were 10 sentences presented in each condition. Each sentence was preceded by a carrier phrase, “Number 1,” “Number 2,” etc. Listeners were instructed to repeat the sentence they heard. The experimenter scored which of the five keywords in each sentence were repeated correctly, and the percent correct keywords words out of 50 was calculated for each condition.</p>
              </sec>
              <sec id="Sec18">
                <title>Training</title>
                <sec id="Sec19">
                  <title>Experimental</title>
                  <p id="Par31">Listeners received in-lab perceptual rate discrimination training for two rates, 100 and 300 Hz, using a procedure similar to that described above for rate discrimination assessment. The training was blocked by rate, with four blocks of 60 trials for each rate, for a total of 480 trials. Correct-answer feedback was provided after each trial throughout the training sessions. Nine sessions of this training took place in the sound-attenuating booth over the course of 2 to 3 weeks. The duration of training per session was 45 to 60 min, depending on the participant’s speed of response.</p>
                </sec>
                <sec id="Sec20">
                  <title>Active Control</title>
                  <p id="Par32">Listeners received in-lab training on tone-in-noise detection, using a 3I-2AFC procedure. A notched-noise paradigm and simultaneous masking were used to measure filter bandwidths (Desloge et al. <xref ref-type="bibr" rid="CR11">2012</xref>), using a 300-ms 1-kHz stimulus tone and a 500-ms white Gaussian noise (0.25–6 kHz). The target tone was temporally centered in the noise. Cosine squared windows with a 10-ms rise-fall time were applied to the noise and target tones to avoid transients. The noise level was fixed at 75 dBA, and the tone level varied adaptively to determine threshold in three notch bandwidths: 90, 120, and 150 Hz.</p>
                  <p id="Par33">After each listener response, correct answer feedback was provided. Then, the tone level was adapted according to the two-down-one-up adaptive rule. The initial and maximum target tone level was 75 dBA, and the minimum target tone level was − 20 dBA. The initial step size in the adaptive procedure was 3 dB. After three reversals, the step size decreased to 0.5 dB. Each of the three notch bandwidth conditions was presented in four blocks, with 40 trials per block, for a total of 480 trials; therefore, the procedure had the same number of trials when compared to the pulse-rate discrimination training, except that the task was different. Nine sessions of this training took place in the sound-attenuating booth over the course of 2 to 3 weeks. The masked threshold in dB for an individual adaptive track was found by calculating the arithmetic mean over the last four reversals in the adaptive track. The arithmetic mean of the second and third tracks was used to calculate the final masked threshold for each listener and condition. The duration of training per session was 45 to 60 min, depending on the participant’s speed of response.</p>
                </sec>
              </sec>
              <sec id="Sec21">
                <title>Cognitive Testing</title>
                <p id="Par34">Assessments from the National Institutes of Health (NIH) Cognition Toolbox (Weintraub et al. <xref ref-type="bibr" rid="CR50">2013</xref>) were used to determine if particular cognitive skills predicted perceptual training benefits. These tests included the List Sorting Working Memory Test, the Flanker Inhibitory Control and Attention Test, the Pattern Comparison Processing Speed Test, and the Dimensional Card Sort Test. The tests were administered using the NIH toolbox application on an Apple iPad (Apple, Inc., Cupertino, CA). The Uncorrected Standard scores (not age-corrected, mean = 100, SD = 15) were downloaded from the application.</p>
              </sec>
              <sec id="Sec22">
                <title>Statistical Analysis</title>
                <p id="Par35">The data were analyzed by JASP (v.14.1, <xref ref-type="bibr" rid="CR29">2020</xref>) statistical software.</p>
              </sec>
              <sec id="Sec23">
                <title>Pulse Rate Discrimination Improvement and Near Generalization</title>
                <p id="Par36">Separate four-way mixed analyses of variance (ANOVA) were conducted to evaluate the effects of training on perception and neural representation of the pulse trains, comparing pre-test and post-test measures. There were two between-subjects factors (listener group: YNH, ONH, OHI; training group: experimental, active control) and two within-subjects factors (rate: 100, 200, 300, 400 Hz; session: pre-test, post-test). For perceptual measurements, the dependent variable was pulse-rate DL. For the electrophysiological measurements, the dependent variable was the ASSR PLF. In addition, multivariate ANOVAs (MANOVAs) were conducted to assess differences between post-test rate discrimination in the older listeners with pre-testing rate discrimination in the YNH listeners to determine if training restores temporal processing deficits in the older listeners across rates. Bonferroni-corrected two-way ANOVAs, independent-samples <italic>t</italic> tests (assuming equal variance), and paired-samples <italic>t</italic> tests were used to perform <italic>post hoc</italic> analyses when significant main effects or interactions were observed.</p>
              </sec>
              <sec id="Sec24">
                <title>Mid Generalization</title>
                <p id="Par37">Separate mixed ANOVAs were conducted to evaluate mid generalization to the other temporal processing measures using the same two between-subjects factors (listener group and training group) as for the pulse trains and the same within-subjects factor (session). For gap detection, the gap detection threshold was submitted to a three-way mixed ANOVA. For gap duration discrimination, the gap duration discrimination DL was submitted to a three-way mixed ANOVA. For tempo discrimination, the IOI discrimination DL was submitted to a four-way mixed ANOVA, because there was an additional within-subjects factor (reference IOI: 100, 600 ms).</p>
              </sec>
              <sec id="Sec25">
                <title>Far Generalization</title>
                <p id="Par38">A mixed ANOVA was conducted to evaluate generalization to sentence recognition measures using the same between-subjects factors. The within-subjects factors were condition [clean speech, two levels of time compression (TC40, TC60), and two levels of reverberation (0.6-s RV, 1.2-s RV)] and session (pre-test, post-test). The dependent variable was the sentence recognition score. The percent correct scores were transformed using the rationalized arcsine unit (RAU) transform (Studebaker <xref ref-type="bibr" rid="CR47">1985</xref>) to avoid violation of the homogeneity of variance assumption required for an ANOVA.</p>
              </sec>
              <sec id="Sec26">
                <title>Relationships Among Perceptual Temporal Processing Measures</title>
                <p id="Par39">To test our hypothesis that the behavioral measures share a common temporal processing mechanism, correlations were conducted to evaluate relationships among the pulse-rate discrimination DLs, gap detection thresholds, gap duration discrimination DLs, temporal interval discrimination DLs, and RAU-transformed sentence recognition scores for temporally altered stimuli. Spearman’s rho was calculated because not all of the data were normally distributed. The False Discovery Rate was used to correct for multiple comparisons (Benjamini and Hochberg <xref ref-type="bibr" rid="CR4">1995</xref>).</p>
              </sec>
              <sec id="Sec27">
                <title>Performance Predictors</title>
                <p id="Par40">A step-wise multiple linear regression was conducted to identify the potential factors that contributed to changes in pulse-rate discrimination performance for 100- and 300-Hz rates in the experimental group. The dependent variable was the average change in rate DL (post-test–pre-test) for 100- and 300-Hz reference rates. The Pattern Comparison Processing Speed Test scores were included as an independent variable due to its relationship to pre-test DLs (Gaskins et al. <xref ref-type="bibr" rid="CR20">2019</xref>). Additional cognitive measures included in the analyses were the List Sorting Working Memory Test, the Flanker Inhibitory Control and Attention Test, the Pattern Comparison Processing Speed Test, and the Dimensional Card Sort. The PTA in the right ear (500 to 4000 Hz) was also included to determine the contribution of audibility to performance. A log transform was applied to the skewed PTA distribution. Finally, to determine the contributions of subcortical neural processing to performance changes, the pre-test PLF and change in PLF averaged for 100- and 300-Hz rates were included.</p>
              </sec>
            </sec>
            <sec id="Sec28">
              <title>RESULTS</title>
              <sec id="Sec29">
                <title>Rate Discrimination</title>
                <p id="Par41">Figure <xref rid="Fig1" ref-type="fig">1</xref> displays pre- and post-test performance for the 100- to 400-Hz reference rates in YNH, ONH, and OHI listeners. The mixed ANOVA showed a main effect of session (<italic>F</italic><sub>(1, 69)</sub> = 52.62, <italic>P</italic> &lt; 0.001, <italic>η</italic><sup><italic>2</italic></sup> = 0.43), such that DLs were lower (better) at the post-test compared to the pre-test. There was a significant training group × session interaction (<italic>F</italic><sub>(1, 69)</sub> = 5.48, <italic>P</italic> = 0.005, <italic>η</italic><sup><italic>2</italic></sup> = 0.15), which was driven by the larger decrease in DL from post- to pre-test sessions in the experimental compared to the active control group (<italic>T</italic><sub>(73)</sub> = 2.96, <italic>P</italic> = 0.004). Furthermore, improvement occurred for the untrained rates in the experimental group but not in the active control group. Post hoc testing revealed that the experimental group exhibited significant effects of session for both the trained rates [two-way mixed ANOVA with factors session and rate (100 and 300 Hz); <italic>F</italic><sub>(1, 39)</sub> = 41.96, <italic>P</italic> &lt; 0.001, <italic>η</italic><sup><italic>2</italic></sup> = 0.53] and the untrained rates (200 and 400 Hz; <italic>F</italic><sub>(1, 39)</sub> = 21.39, <italic>P</italic> &lt; 0.001, <italic>η</italic><sup><italic>2</italic></sup> = 0.35), but the active control group showed a significant effect of session for only the trained rates (100 and 300 Hz; <italic>F</italic><sub>(1, 35)</sub> = 17.89, <italic>P</italic> &lt; 0.001, <italic>η</italic><sup><italic>2</italic></sup> = 0.34) and not the untrained rates (200 and 400 Hz; <italic>F</italic><sub>(1, 35)</sub> = 3.41, <italic>P</italic> = 0.073, <italic>η</italic><sup><italic>2</italic></sup> = 0.09).<fig id="Fig1"><label>Fig. 1</label><caption><p>Average rate discrimination difference limens (DLs) are displayed for 100 and 300 Hz (left panels) and 200 and 400 Hz (right panels) in young normal-hearing (YNH), older normal-hearing (ONH), and older hearing-impaired (OHI) listeners who completed nine sessions of rate discrimination training (experimental group, EXP) or tone-in-noise detection training (active control group, AC). There were significant improvements in performance (smaller DLs) in the EXP group that were not observed in the AC group. *<italic>P</italic> &lt; 0.05, **<italic>P</italic> &lt; 0.01, ***<italic>P</italic> &lt; 0.001. Error bars = ± 1 S.E</p></caption><graphic xlink:href="10162_2022_859_Fig1_HTML" id="MO1"/></fig></p>
                <p id="Par42">The training group × listener group × session interaction was not significant (<italic>F</italic><sub>(2, 69)</sub> = 0.53, <italic>P</italic> = 0.592, <italic>η</italic><sup><italic>2</italic></sup> = 0.02), suggesting that training effects on rate discrimination did not differ significantly by listener group (YNH, ONH, OHI). In addition, there was no listener group × session interaction in either training group (all <italic>P</italic> values &gt; 0.05).</p>
                <p id="Par43">A MANOVA was then used to compare the post-test DLs in the ONH and OHI listeners to the pre-test DLs in the YNH listeners in the experimental training group for the four different rates. At the pre-test, there was a main effect of listener group (<italic>F</italic><sub>(2, 36)</sub> = 14.28, <italic>P</italic> &lt; 0.001, <italic>η</italic><sup><italic>2</italic></sup> = 0.44); post hoc <italic>t</italic> tests showed that both groups of older listeners had higher (poorer) DLs than the YNH listeners (<italic>P</italic> &lt; 0.001), but the older groups did not differ from each other (<italic>P</italic> = 1). A comparison of the pre-test DLs in the YNH listeners with the post-test DLs in ONH and OHI listeners showed a main effect of listener group (<italic>F</italic><sub>(2, 37)</sub> = 8.29, <italic>P</italic> = 0.001, <italic>η</italic><sup><italic>2</italic></sup> = 0.31); post hoc <italic>t</italic> tests showed that the DLs of ONH listeners at post-test did not differ from those of YNH listeners at pre-test (<italic>P</italic> = 0.426). However, the OHI listeners had higher DLs than both the ONH listeners at post-test (<italic>P</italic> = 0.025) and the YNH listeners at pre-test (<italic>P</italic> &lt; .001). There was also a rate × listener group interaction (<italic>F</italic><sub>(6, 111)</sub> = 4.68, <italic>P</italic> &lt; 0.001, <italic>η</italic><sup><italic>2</italic></sup> = 0.13). At the 100-Hz rate, there was no main effect of listener group (<italic>P</italic> = 0.18). At the 200-, 300-, and 400-Hz rates, there was no significant difference between the YNH and ONH listeners (<italic>P</italic> &gt; 0.05 for all three comparisons), but the OHI listeners had higher DLs than the YNH listeners (<italic>P</italic> &lt; 0.05 for all three comparisons). Given that pre-test DL differences existed between the ONH and YNH listeners (<italic>P</italic> &lt; 0.001), these results demonstrate that training on rate discrimination at least partially restored temporal processing abilities on this measure in ONH listeners.</p>
              </sec>
              <sec id="Sec30">
                <title>ASSR</title>
                <p id="Par44">Figure <xref rid="Fig2" ref-type="fig">2</xref> displays pre- and post-training PLF values for all four rates, and Fig. <xref rid="Fig3" ref-type="fig">3</xref> displays pre- and post-training phase-locking spectra for the 100- and 300-Hz rates. The mixed ANOVA showed no main effect of session (<italic>F</italic><sub>(1, 69)</sub> = 0.31, <italic>P</italic> = 0.582, <italic>η</italic><sup><italic>2</italic></sup> = 0.00), but there was a training group × session interaction (<italic>F</italic><sub>(1, 69)</sub> = 4.61, <italic>P</italic> = 0.035, <italic>η</italic><sup><italic>2</italic></sup> = 0.06), driven by a significant increase in PLF in the experimental group (post hoc two-way repeated-measures ANOVA with factors rate and session; <italic>F</italic><sub>(1, 37)</sub> = 4.99, <italic>P</italic> = 0.032, <italic>η</italic><sup><italic>2</italic></sup> = 0.12) that was not observed in the active control group (<italic>F</italic><sub>(1, 36)</sub> = 0.87, <italic>P</italic> = 0.357, <italic>η</italic><sup><italic>2</italic></sup> = 0.02). The training group × listener group × session interaction was not significant (<italic>F</italic><sub>(2, 69)</sub> = 0.08, <italic>P</italic> = 0.927, <italic>η</italic><sup><italic>2</italic></sup> = 0.00), suggesting that training effects on PLF did not differ by listener group.<fig id="Fig2"><label>Fig. 2</label><caption><p>Average pre- and post-training phase-locking factor (PLF) are displayed for 100 and 300 Hz (left panels) and 200 and 400 Hz (right panels) in young normal-hearing (YNH), older normal-hearing (ONH), and older hearing-impaired (OHI) listeners in the experimental (EXP) and active control (AC) groups. There were significant increases in PLF in the training group, especially in the YNH listeners that were not observed in the active control group. *<italic>P</italic> &lt; 0.05, **<italic>P</italic> &lt; 0.01. Error bars = ± S.E</p></caption><graphic xlink:href="10162_2022_859_Fig2_HTML" id="MO2"/></fig><fig id="Fig3"><label>Fig. 3</label><caption><p>Pre- and post-training phase-locking factor (PLF) for 100- and 300-Hz rates is displayed in the time–frequency domain for young normal-hearing (YNH), older normal-hearing (ONH), and older hearing-impaired (OHI) listeners in the experimental (top three panels) and active control (bottom three panels) groups</p></caption><graphic xlink:href="10162_2022_859_Fig3_HTML" id="MO3"/></fig></p>
                <p id="Par45">Post hoc testing in the experimental group showed significant effects of session for the trained rates (two-way mixed ANOVA with factors session and rate (100 and 300 Hz); <italic>F</italic><sub>(1, 37)</sub> = 5.44, <italic>P</italic> = 0.025, <italic>η</italic><sup><italic>2</italic></sup> = 0.13), but not the untrained rates (200 and 400 Hz; <italic>F</italic><sub>(1, 37)</sub> = 2.88, <italic>P</italic> = 0.098, <italic>η</italic><sup><italic>2</italic></sup> = 0.07). The active control group did not show significant effects of session for either the trained rates (100 and 300 Hz; <italic>F</italic><sub>(1, 36)</sub> = 1.66, <italic>P</italic> = 0.21, <italic>η</italic><sup><italic>2</italic></sup> = 0.04) or the untrained rates (200 and 400 Hz; <italic>F</italic><sub>(1, 36)</sub> = 0.29, <italic>P</italic> = 0.594, <italic>η</italic><sup><italic>2</italic></sup> = 0.01).</p>
                <p id="Par46">The mixed ANOVA showed a significant effect of rate (<italic>F</italic><sub>(3, 216)</sub> = 48.85, <italic>P</italic> &lt; 0.001, <italic>η</italic><sup><italic>2</italic></sup> = 0.40) because there were higher PLFs for the lower rates compared to the higher rates. There was a main effect of listener group (<italic>F</italic><sub>(2, 72)</sub> = 8.24, <italic>P</italic> &lt; 0.001, <italic>η</italic><sup><italic>2</italic></sup> = 0.19). Post hoc <italic>t</italic> tests showed that the YNH group had higher PLFs than the ONH group (<italic>P</italic> = 0.002) and the OHI group (<italic>P</italic> = 0.005), but the group difference was not significant between the ONH and OHI groups (<italic>P</italic> = 1.00). There was a significant listener group × rate interaction (<italic>F</italic><sub>(6, 216)</sub> = 6.42, <italic>P</italic> &lt; 0.001, <italic>η</italic><sup><italic>2</italic></sup> = 0.15). In separate <italic>post hoc</italic> mixed ANOVAs with factors listener group and training group, there was no significant listener group difference for the 100-Hz PLF (<italic>F</italic><sub>(2, 73)</sub> = 0.85, <italic>P</italic> = 0.431, <italic>η</italic><sup><italic>2</italic></sup> = 0.02), but there were significant group differences for the 200-Hz PLF (<italic>F</italic><sub>(2, 73)</sub> = 13.65, <italic>P</italic> &lt; 0.001, <italic>η</italic><sup><italic>2</italic></sup> = 0.27), 300-Hz PLF (<italic>F</italic><sub>(2, 72)</sub> = 6.86, <italic>P</italic> = 0.002, <italic>η</italic><sup><italic>2</italic></sup> = 0.16), and 400-Hz PLF (<italic>F</italic><sub>(2, 72)</sub> = 11.11, <italic>P</italic> &lt; 0.001, <italic>η</italic><sup><italic>2</italic></sup> = 0.24). At the 200-, 300-, and 400-Hz rates, there was no significant difference between the ONH and OHI listeners (<italic>P</italic> &gt; 0.05 for all three comparisons), but the YNH listeners had higher PLF than the either group of older listeners (<italic>P</italic> &lt; 0.05 for all six comparisons).</p>
              </sec>
              <sec id="Sec31">
                <title>Mid Generalization–Temporal Processing</title>
                <p id="Par47">Gap detection</p>
                <p id="Par48">Figure <xref rid="Fig4" ref-type="fig">4</xref>A displays pre- and post-training data for the gap detection tasks. The mixed ANOVA showed that there was a main effect of session (<italic>F</italic><sub>(1, 70)</sub> = 5.41, <italic>P</italic> = 0.023, <italic>η</italic><sup><italic>2</italic></sup> = 0.01), but there was no training group × session interaction (<italic>F</italic><sub>(1, 70)</sub> = 0.09, <italic>P</italic> = 0.77, <italic>η</italic><sup><italic>2</italic></sup> = 0.00). There was no main effect of listener group (<italic>F</italic><sub>(2, 70)</sub> = 1.51, <italic>P</italic> = 0.29, <italic>η</italic><sup><italic>2</italic></sup> = 0.03).<fig id="Fig4"><label>Fig. 4</label><caption><p>Average pre- and post-training gap detection thresholds (<bold>A</bold>) and gap duration DLs (<bold>B</bold>) are displayed for young normal-hearing (YNH), older normal-hearing (ONH), and older hearing-impaired (OHI) listeners in the experimental (EXP) and active control (AC) groups. No changes in performance were noted from pre-test to post-test in any group. Error bars = ± S.E</p></caption><graphic xlink:href="10162_2022_859_Fig4_HTML" id="MO4"/></fig></p>
                <sec id="Sec32">
                  <title>Gap Duration Discrimination</title>
                  <p id="Par49">Figure <xref rid="Fig4" ref-type="fig">4</xref>B displays pre- and post-training data for the gap duration discrimination tasks. The mixed ANOVA showed a main effect of session (<italic>F</italic><sub>(1, 69)</sub> = 7.00, <italic>P</italic> = 0.01, <italic>η</italic><sup><italic>2</italic></sup> = 0.01), but there was no training group × session interaction (<italic>F</italic><sub>(1, 69)</sub> = 0.75, <italic>P</italic> = 0.56, <italic>η</italic><sup><italic>2</italic></sup> = 0.00). The was no main effect of listener group (<italic>F</italic><sub>(2, 69)</sub> = 0.53, <italic>P</italic> = 0.59, <italic>η</italic><sup><italic>2</italic></sup> = 0.01).</p>
                </sec>
                <sec id="Sec33">
                  <title>Tempo Discrimination</title>
                  <p id="Par50">Figure <xref rid="Fig5" ref-type="fig">5</xref> displays pre- and post-training data for relative DLs as a function of 100- and 600-ms IOIs. The mixed ANOVA showed neither a main effect of session (<italic>F</italic><sub>(1, 66)</sub> = 1.10, <italic>P</italic> = 0.301, <italic>η</italic><sup><italic>2</italic></sup> = 0.02) nor a training group × session interaction (<italic>F</italic><sub>(1, 66)</sub> = 0.02, <italic>P</italic> = 0.893, <italic>η</italic><sup><italic>2</italic></sup> = 0.00). The was no main effect of listener group (<italic>F</italic><sub>(2, 66)</sub> = 0.36, <italic>P</italic> = 0.696, <italic>η</italic><sup><italic>2</italic></sup> = 0.01). There was a main effect of IOI (<italic>F</italic><sub>(1, 66)</sub> = 23.66, <italic>P</italic> &lt; 0.001, <italic>η</italic><sup><italic>2</italic></sup> = 0.23); the relative DLs were smaller for the 600-ms IOI than for the 100-ms IOI. No other interactions were significant.<fig id="Fig5"><label>Fig. 5</label><caption><p>Average relative difference limens (DL) are displayed as a function of 100- and 600-ms inter-onset intervals (IOIs) obtained in young normal-hearing (YNH), older normal-hearing (ONH), and older hearing-impaired (OHI) listeners in the experimental (EXP) and active control (AC) groups. No changes in performance were noted in any group. Error bars = ± S.E</p></caption><graphic xlink:href="10162_2022_859_Fig5_HTML" id="MO5"/></fig></p>
                </sec>
              </sec>
              <sec id="Sec34">
                <title>Far Generalization–Speech Recognition</title>
                <p id="Par51">Figure <xref rid="Fig6" ref-type="fig">6</xref> displays pre- and post-training speech recognition data in experimental and active control groups, respectively. The mixed ANOVA showed neither a main effect of session (<italic>F</italic><sub>(1, 72)</sub> = 1.10, <italic>P</italic> = 0.299, <italic>η</italic><sup><italic>2</italic></sup> = 0.00) nor a training group × session interaction (<italic>F</italic><sub>(1, 71)</sub> = 0.77, <italic>P</italic> = 0.381, <italic>η</italic><sup><italic>2</italic></sup> = 0.00), suggesting that sentence recognition did not improve across groups. There was a main effect of listener group (<italic>F</italic><sub>(2, 71)</sub> = 60.03, <italic>P</italic> &lt; 0.001, <italic>η</italic><sup><italic>2</italic></sup> = 0.29). Post hoc testing showed that the OHI listeners had poorer overall performance than the YNH and ONH listeners (<italic>P</italic> &lt; 0.001 for both), and ONH listeners had poorer overall performance than the YNH listeners (<italic>P</italic> = 0.008). There was a significant measure × listener group interaction (<italic>F</italic><sub>(8, 284)</sub> = 44.82, <italic>P</italic> &lt; 0.001, <italic>η</italic><sup><italic>2</italic></sup> = 0.08). The OHI listeners had lower scores than the YNH and ONH listeners on all scores (all <italic>P</italic> &lt; 0.001) except clean speech (<italic>P</italic> &gt; 0.05). The ONH listeners had lower scores than the YNH listeners for the TC60 condition (<italic>P</italic> &lt; 0.001) but not for any other measure. Removal of the outlier in the OHI experimental group did not change these results.<fig id="Fig6"><label>Fig. 6</label><caption><p>Average percent correct sentence recognition scores are displayed for pre- and post-training for clean (undistorted) speech, 40 % time-compressed speech (40 % TC), 60 % time-compressed speech (60 % TC), and 0.6-s and 1.2-s reverberation time (0.6s REV, 1.2s REV, respectively) in young normal-hearing (YNH), older normal-hearing (ONH), and older hearing-impaired (OHI) listeners in the experimental (EXP) and active control (AC) groups. No changes in performance were noted in any listener group. Error bars = ± S.E</p></caption><graphic xlink:href="10162_2022_859_Fig6_HTML" id="MO6"/></fig></p>
              </sec>
              <sec id="Sec35">
                <title>Correlations Among Perceptual Measures</title>
                <p id="Par52">Correlations were calculated among the pre-test pulse-rate discrimination DLs and the other non-speech and speech temporal processing measures. Table <xref rid="Tab2" ref-type="table">2</xref> displays the <italic>R</italic> values for these correlations. Correlations were generally high and significant within the groups of measures (near, mid, or far generalization). There were also significant correlations across groups of measures. The pulse-rate discrimination DLs were significantly correlated with most of these measures, including gap detection thresholds, temporal interval discrimination thresholds, and all temporally altered sentence recognition measures. The correlations between pulse-rate discrimination DLs and the mid generalization measures, as well as temporally altered sentence recognition measures and the mid generalization measures tended to be the smallest, often lacking significant correlations.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Correlations among pulse-rate discrimination difference limens and other non-speech and speech temporal processing measures. Spearman correlation <italic>ρ</italic> values are displayed for the following variables: difference limens (DLs) for discrimination of 100-, 200-, 300-, and 400-Hz pulse trains, gap detection thresholds (GAP DET), gap duration detection thresholds (GAP DUR), temporal interval discrimination thresholds for 100 and 600 ms (TEMPO 100 and TEMPO 600), and sentence recognition presented in 40% and 60% time compression ratio conditions (40% TC and 60% TC) and in 0.6-s reverberation time and 1.2-s reverberation time conditions (0.6-s REV and 1.2-s REV). Boldface font indicates values that are significant at an alpha level of 0.05 or better. *<italic>P</italic> &lt; 0.05, **<italic>P</italic> &lt; 0.01, ***<italic>P</italic> &lt; 0.001</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">DL 100</th><th align="left">DL 200</th><th align="left">DL 300</th><th align="left">DL 400</th><th align="left">GAP DET</th><th align="left">GAP DUR</th><th align="left">TEMPO 100</th><th align="left">TEMPO 600</th><th align="left">40% TC</th><th align="left">60% TC</th><th align="left">0.6-s RV</th><th align="left">1.2-s RV</th></tr></thead><tbody><tr><td align="left" colspan="13">Pulse rate DLs (Near Generalization)</td></tr><tr><td align="left">DL 100</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">DL 200</td><td align="left"><bold>.671***</bold></td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">DL 300</td><td align="left"><bold>.607***</bold></td><td align="left">.<bold>592***</bold></td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">DL 400</td><td align="left"><bold>.588***</bold></td><td align="left"><bold>.616***</bold></td><td align="left"><bold>.799***</bold></td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left" colspan="13">Temporal Processing (Mid Generalization)</td></tr><tr><td align="left">GAP DET</td><td align="left"><bold>.425***</bold></td><td align="left"><bold>.433*</bold></td><td align="left"><bold>.522***</bold></td><td align="left"><bold>.463***</bold></td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">GAP DUR</td><td align="left">.196</td><td align="left">.137</td><td align="left"><bold>.233*</bold></td><td align="left"><bold>.231*</bold></td><td align="left"><bold>.313**</bold></td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">TEMPO 100</td><td align="left"><bold>.373**</bold></td><td align="left"><bold>.343**</bold></td><td align="left"><bold>.289*</bold></td><td align="left"><bold>.358**</bold></td><td align="left">.<bold>258*</bold></td><td align="left"><bold>.341**</bold></td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">TEMPO 600</td><td align="left"><bold>.274*</bold></td><td align="left"><bold>.456***</bold></td><td align="left"><bold>.250*</bold></td><td align="left"><bold>.289*</bold></td><td align="left"><bold>.271*</bold></td><td align="left"><bold>.297*</bold></td><td align="left"><bold>.487***</bold></td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left" colspan="13">Sentence Recognition (Far Generalization)</td></tr><tr><td align="left">40% TC</td><td align="left"><bold>-.331**</bold></td><td align="left"><bold>-.361**</bold></td><td align="left"><bold>-.587***</bold></td><td align="left"><bold>-.509***</bold></td><td align="left"><bold>-.458***</bold></td><td align="left">-.214</td><td align="left">-.141</td><td align="left">-.201</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">60% TC</td><td align="left"><bold>-.392***</bold></td><td align="left"><bold>-.411***</bold></td><td align="left"><bold>-.729***</bold></td><td align="left"><bold>-.611***</bold></td><td align="left"><bold>-.433**</bold></td><td align="left"><bold>-.276*</bold></td><td align="left">-.163</td><td align="left">-.171</td><td align="left"><bold>.613***</bold></td><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">0.6-s RV</td><td align="left"><bold>-.363**</bold></td><td align="left"><bold>-.363**</bold></td><td align="left"><bold>-.610***</bold></td><td align="left"><bold>-.532***</bold></td><td align="left"><bold>-.298**</bold></td><td align="left"><bold>-.251*</bold></td><td align="left">-.100</td><td align="left">-.165</td><td align="left"><bold>.717***</bold></td><td align="left"><bold>.662***</bold></td><td align="left"/><td align="left"/></tr><tr><td align="left">1.2-s RV</td><td align="left"><bold>-.346**</bold></td><td align="left"><bold>-.433***</bold></td><td align="left"><bold>-.581***</bold></td><td align="left"><bold>-.496***</bold></td><td align="left"><bold>-.267*</bold></td><td align="left">-.332</td><td align="left">-.174</td><td align="left">-.221</td><td align="left"><bold>.573***</bold></td><td align="left"><bold>.681***</bold></td><td align="left"><bold>.656***</bold></td><td align="left"/></tr></tbody></table></table-wrap></p>
                <p id="Par53">Correlations were also calculated for the improvements in measures (post-test minus pre-test change) for the 300-Hz DL and the PLF (the rate at which the greatest changes were observed across groups) and measures that were related to pre-test 300-Hz DLs in Table <xref rid="Tab2" ref-type="table">2</xref> (non-speech measures: gap detection and 100-ms tempo discrimination; speech measures: 60 % TC, 0.6-s RV, and 1.2-s RV). The analysis was restricted to the training group listeners who had scores less than 100 % on the pre-test measures (<italic>N</italic> = 39), in other words, the listeners that had the potential to improve. The sentence recognition score in the 0.6-s RV condition was negatively correlated with the 300-Hz DL (<italic>ρ</italic> = − 0.434, <italic>P</italic> = 0.008) and was positively correlated with the 300-Hz PLF (<italic>ρ</italic> = 0.394, <italic>P</italic> = 0.018) after correcting for multiple comparisons using the False Discovery Rate procedure (Benjamini and Hochberg <xref ref-type="bibr" rid="CR4">1995</xref>). Figure <xref rid="Fig7" ref-type="fig">7</xref> displays scatter plots for these relationships. No other correlations were significant.<fig id="Fig7"><label>Fig. 7</label><caption><p>Scatter plots demonstrating relationships among training-related changes in relative phase-locking factor (PLF) (left two panels) and differences limens (DLs right two panels) to the 300-Hz rate and sentence recognition in young normal-hearing (YNH, cyan squares), older normal-hearing (ONH, red triangles), and older hearing-impaired (OHI, black circles) listeners. Improvement in 300-Hz PLF and 300-Hz DLs was related to improvement in sentence recognition in the 0.6-s reverberation condition. *<italic>P</italic> &lt; 0.05, **<italic>P</italic> &lt; 0.01</p></caption><graphic xlink:href="10162_2022_859_Fig7_HTML" id="MO7"/></fig></p>
              </sec>
              <sec id="Sec36">
                <title>Factors Contributing to Training-Induced Changes in Pulse Rate Discrimination</title>
                <p id="Par54">To identify the potential factors that contributed to changes in pulse-rate discrimination performance for 100- and 300-Hz rates in the experimental group, a step-wise multiple linear regression was conducted. The multiple linear regression collinearity diagnostics showed satisfactory tolerance (lowest 0.30) and variance inflation factor (highest 2.61) values, suggesting that the predictor variables were not highly correlated. One significant regression equation was returned; the Flanker score (attention) significantly predicted change in rate discrimination (<italic>F</italic><sub>(1, 35)</sub> = 13.53, <italic>P</italic> &lt; 0.001) with <italic>R</italic><sup><italic>2</italic></sup> = 0.29. None of the other variables contributed significantly to the change in rate discrimination. This model is summarized in Table <xref rid="Tab3" ref-type="table">3</xref>.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Summary of “stepwise” regression analysis for variables contributing to change in rate discrimination. Unstandardized (B) and standard error (S.E.) coefficients and standardized (β) coefficients in a model were automatically generated by evaluating the significance of each variable’s contribution to the average change in 100- and 300-Hz rate discrimination. Only one model was generated, in which the Flanker score predicts significant variance in rate discrimination change. All other variables were excluded from the model (working memory, speed of processing, dimension card sort, pure-tone average, pre-training phase-locking factor, and change in phase-locking factor)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Variable</th><th align="left"><italic>R</italic><sup>2</sup></th><th align="left"><italic>B</italic></th><th align="left"><italic>S.E</italic></th><th align="left"><italic>β</italic></th><th align="left">95% C.I. for <italic>B</italic></th><th align="left"><italic>p</italic> value</th></tr></thead><tbody><tr><td align="left">Model 1</td><td char="." align="char">0.35</td><td char="." align="char"/><td char="." align="char"/><td char="." align="char"/><td char="." align="char"/><td char="." align="char"> &lt; 0.001</td></tr><tr><td align="left">Flanker</td><td char="." align="char"/><td char="." align="char">0.26</td><td char="." align="char">0.06</td><td char="." align="char">0.59</td><td char="–" align="char">0.14–0.39</td><td char="." align="char"> &lt; 0.001</td></tr></tbody></table></table-wrap></p>
              </sec>
            </sec>
            <sec id="Sec37">
              <title>DISCUSSION</title>
              <p id="Par55">The overarching goal of this investigation was to determine the effect of rate discrimination training on temporal processing in older and younger listeners. The results showed training-related improvements in temporal rate discrimination DLs and phase locking. A larger degree of improvement in temporal rate discrimination DLs occurred for the experimental group compared to the active control group, suggesting perceptual learning for the experimental group and some procedural learning for both groups (Koziol and Budding <xref ref-type="bibr" rid="CR34">2012</xref>). The training × listening group interactions were not significant; therefore, training effects were not limited to a specific listener group (YNH, ONH, and OHI). Improved rate discrimination and phase locking related to higher sentence recognition scores in the condition with the shorter reverberation time (0.6 s), suggesting that generalization of training effects may potentially extend to real-world listening situations.</p>
              <sec id="Sec38">
                <title>Effects of Aging and Hearing Loss on Training Benefits</title>
                <p id="Par56">Results showed training benefits across listener groups for both rate discrimination and phase locking. There was no significant listener × training group interaction, suggesting that training effects did not differ by age or hearing status (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). These results appear to contrast with those of Sabin et al. (<xref ref-type="bibr" rid="CR44">2013</xref>), who found improvement in spectrotemporal modulation thresholds in young listeners but not in older listeners. The older listeners in the Sabin et al. study had mild to moderate hearing loss (thresholds ranging from 15 to 70 dB HL from 0.5 to 4 kHz), which may have affected their ability to benefit from training on spectrotemporal modulation due to decreased spectral resolution associated with hearing loss. Our study focused on a measure of temporal processing, an acoustic dimension that is less affected by hearing loss (Fitzgibbons and Gordon-Salant <xref ref-type="bibr" rid="CR16">1996</xref>), and we did not find effects of hearing loss on pre-training rate discrimination. Bianchi et al. (<xref ref-type="bibr" rid="CR5">2019</xref>) found that the extent of musical training benefit on F<sub>0</sub> discrimination was limited by the extent of hearing loss. Therefore, we examined the relationship between high-frequency PTA and change in the 100-Hz DL, and found a modest correlation among the older listeners (<italic>ρ</italic> = 4.20, <italic>P</italic> = 0.03), suggesting that the training benefit decreased with increased hearing threshold.</p>
                <p id="Par57">The improvement in behavioral temporal processing with training partially reduced age-related deficits. The ONH listeners’ post-training DLs decreased to levels that approached those of the YNH listeners’ pre-training DLs. These results are consistent with animal models of neuroplasticity in auditory aging that have shown that perceptual training can reduce or eliminate age-related deficits in temporal processing (de Villers-Sidani et al. <xref ref-type="bibr" rid="CR10">2010</xref>). Although there was a modest decrease in DLs in the OHI listeners, their post-training DLs remained significantly different from the pre-training DLs of the YNH listeners.</p>
                <p id="Par58">We did not find a similar reduction of the age-related deficit in neural temporal processing. Significant group differences in the PLF (at rates &gt; 100 Hz) at the pre-test session persisted at the post-test session. Our selection of rates was motivated to match testing between rate discrimination and the ASSR, and rates of 100–400 Hz arise from low to high brainstem sources (Herdman et al. <xref ref-type="bibr" rid="CR24">2002</xref>). The de Villers-Sidani et al. (<xref ref-type="bibr" rid="CR10">2010</xref>) study found changes in temporal precision in the rat auditory cortex, and therefore, it is possible that a selection of a lower frequency rate (40 Hz or lower) that represents cortical sources would have shown an improvement in temporal precision.</p>
              </sec>
              <sec id="Sec39">
                <title>Generalization</title>
                <p id="Par59">Generalization was evaluated by comparing pre- and post-test performance on untrained measures and by determining the extent to which changes in rate discrimination and phase locking correlated with changes in untrained measures. We found that relative DLs were lower for the untrained rates (200 and 400 Hz), but we did not find significant training-related changes in any of the other measures. We also found that improvements in rate discrimination and phase locking were related to improvement in recognition of reverberant sentences.</p>
                <sec id="Sec40">
                  <title>Rate Discrimination</title>
                  <p id="Par60">The improvement in pulse-rate discrimination and the specificity of training effects for trained and untrained rates are consistent with previous studies that have demonstrated near generalization effects that were specific to the training task. For example, Fitzgerald and Wright (<xref ref-type="bibr" rid="CR14">2011</xref>) trained YNH listeners to detect sinusoidal amplitude modulations and found that training generalized to untrained modulation rates but not to untrained carrier spectra or to rate discrimination using the trained rate and carrier spectrum. Similarly, YNH listeners trained to detect depth of either spectral, temporal, or spectrotemporal modulations did not show generalization of training effects to untrained modulations (Sabin et al. <xref ref-type="bibr" rid="CR45">2012</xref>).</p>
                  <p id="Par61">The Fitzgerald and Wright (<xref ref-type="bibr" rid="CR14">2011</xref>) and Sabin et al. (<xref ref-type="bibr" rid="CR45">2012</xref>) studies only trained YNH listeners, but different learning patterns might be found in older listeners. For example, Sabin et al. (<xref ref-type="bibr" rid="CR44">2013</xref>) found that training to detect spectral modulations generalized to an untrained spectral modulation frequency in ONH listeners but not YNH listeners. In the current study, there were significant improvements in rate discrimination for the untrained frequencies (200 and 400 Hz) in the ONH and OHI listeners but not in the YNH listeners (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>). The reason for the lack of generalization in YNH listeners is currently unknown but may be due to the fact that performance in the YNH listener group was excellent at the pre-test across rates, thus limiting capacity for improvement.</p>
                </sec>
                <sec id="Sec41">
                  <title>ASSR</title>
                  <p id="Par62">No near generalization was found for untrained rates (200 and 400 Hz). The absence of generalization suggests two points: (1) the lack of increased PLF to 200- and 400-Hz rates suggests that the increase to 100- and 300-Hz rates is due to effects of training rather than to the effects of repeated testing and (2) cortical neural processes may underlie generalization in perceptual performance, but the ASSR recordings in the current study targeted subcortical processing.</p>
                </sec>
                <sec id="Sec42">
                  <title>Generalization to other temporal processing and sentence recognition measures</title>
                  <p id="Par63">When comparing pre- and post-test performance, no mid or far generalization was observed for any of the other temporal processing (non-rate discrimination) or sentence recognition measures. This is in contrast to other training studies employing temporally based training that have observed generalization to speech stimuli. For example, Lakshminarayanan and Tallal (<xref ref-type="bibr" rid="CR36">2007</xref>) trained YNH listeners’ perception of frequency-modulated (FM) sweeps that varied in direction of change, duration of FM sweep, and inter-stimulus interval between sweeps. They found that this training led to enhanced discrimination between syllables that differed in the onset of the second formant (/ba/ vs /da/), transition duration (/ba/ vs /wa/), and silence duration (/sa/ vs /sta/). The transfer of temporally based training has also been observed in older listeners. Fostick et al. (<xref ref-type="bibr" rid="CR19">2020</xref>) trained older listeners with normal to mild hearing loss levels on a spatial temporal order judgment task and found that improvement on this task generalized to recognition of word stimuli presented in quiet, narrowband noise, and wideband noise. They did not observe similar generalization for training on an intensity discrimination task.</p>
                  <p id="Par64">In the current study, significant relationships among the pre-test measurements DLs and all of the temporally distorted sentence recognition measures, consistent with previous studies that have found that performance on non-speech temporal processing measures predicts sentence recognition in challenging listening environments (Gordon-Salant and Fitzgibbons <xref ref-type="bibr" rid="CR22">1993</xref>; Zhou et al. <xref ref-type="bibr" rid="CR53">2019</xref>). Although there was no significant effect of training on sentence recognition overall, there were relationships between training-related changes on the key measures of rate discrimination and phase locking and improvements in speech recognition performance from pre- to post-testing, specifically the 0.6-s REV condition (Fig. <xref rid="Fig7" ref-type="fig">7</xref>). These results and those of Fostick et al. (<xref ref-type="bibr" rid="CR19">2020</xref>) support the hypothesis that improvements in temporal processing ability may lead better speech recognition in some situations. The strength of this result needs further investigation because a similar relationship was not also seen for the 1.2-s RT condition.</p>
                  <p id="Par65">Other training studies employing speech stimuli have observed generalization, and these effects vary depending on training parameters (Banai and Lavner <xref ref-type="bibr" rid="CR3">2019</xref>; Burk and Humes <xref ref-type="bibr" rid="CR7">2008</xref>; Karawani et al. <xref ref-type="bibr" rid="CR32">2015</xref>). Banai and Lavner (<xref ref-type="bibr" rid="CR3">2019</xref>) trained young listeners to recognize time-compressed sentences under several different listening protocols that varied by stimulus set size, training schedule (trials presented in one training session vs. several sessions), and training duration. They found that all protocols led to improvement on the trained task and generalization to untrained tasks (new talker or sentences), but training over several sessions was the only protocol that led to generalization to new untrained sentences. Banai and Lavner concluded that distributed training provides multiple opportunities to consolidate learning. The current study also implemented distributed training during ten sessions over the course of 2 to 3 weeks and found that training with non-speech stimuli may lead to improvements in recognition of reverberant speech stimuli.</p>
                </sec>
              </sec>
              <sec id="Sec43">
                <title>Factors That Contribute to Perceptual Learning</title>
                <p id="Par66">The Flanker score was the only variable that contributed significantly to change in rate discrimination from pre-test to post-test. Individuals with better response inhibition/attention experienced greater decreases in relative DLs following training. We had hypothesized that both cognitive and ASSR measures would relate to changes in rate discrimination. This hypothesis was based in part on the results of Gaskins et al. (<xref ref-type="bibr" rid="CR20">2019</xref>), who found that both processing speed and ASSR spectral energy predicted 400-Hz rate discrimination. The current study found relationships among all of the cognitive variables and the pre-test relative DLs (<italic>R</italic><sup><italic>2</italic></sup> values ranging from 0.14 to 0.37), but not among the pre-test ASSR PLFs and relative DLs (no <italic>R</italic><sup><italic>2</italic></sup> value higher than 0.10). Overall, the current results suggest that cognitive function could potentially be important factor in the potential for improvement in temporal processing ability, at least with respect to rate discrimination. We note that the relatively high rates used in the current study arise from brainstem sources (Herdman et al. <xref ref-type="bibr" rid="CR24">2002</xref>). Perhaps the inclusion of a lower rate emanating from the cortex (e.g., ≤ 40 Hz) would reveal a relationship between ASSR PLF and perceptual change due to the likelihood that cortical sources may be more highly influenced by top-down cognitive influences.</p>
              </sec>
            </sec>
            <sec id="Sec44">
              <title>CONCLUSION</title>
              <p id="Par67">The current results suggest that perceptual training improves rate discrimination across listeners and can partially restore behavioral auditory temporal processing deficits in older listeners. Neural phase locking also improves with training, but there was no relationship among behavioral and neural measurements with the tested rates. At least one measure of cognitive function, response inhibition/attention, accounts for significant variance in improvement in rate discrimination. Therefore, the paradigm used in the study protocol may be efficacious for individuals with average attention ability, but individuals with impaired attention or cognitive function may benefit from a different paradigm.</p>
            </sec>
          </body>
          <back>
            <fn-group>
              <fn>
                <p>
                  <bold>Publisher's Note</bold>
                </p>
                <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
              </fn>
            </fn-group>
            <ack>
              <title>Acknowledgements</title>
              <p>We would like to acknowledge the P01 Project 2 team (Graduate assistants: Jennifer Borja, Amarachukwa Ezenwa, Logan Fraser, Sydney Hancock, Andrew Morris, Alexandra Papanicolau, Abigail Poe, Alyson Schapira, Mary Zhou, and Rachel Zimmerman; Human Subject Research Coordinator: Carol Gorham; Research audiologist: Katie Brow) for their dedication and hard work, and we thank Beverly Wright for her suggestions regarding the training and testing protocols.</p>
            </ack>
            <notes notes-type="funding-information">
              <title>Funding</title>
              <p>We would also like to thank the NIH National Institute on Aging for funding this project (P01 5P01AG055365).</p>
            </notes>
            <ref-list id="Bib1">
              <title>References</title>
              <ref id="CR1">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Anderson</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>White-Schwoch</surname>
                      <given-names>T</given-names>
                    </name>
                    <name>
                      <surname>Parbery-Clark</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Kraus</surname>
                      <given-names>N</given-names>
                    </name>
                  </person-group>
                  <article-title>Reversal of age-related neural timing delays with training</article-title>
                  <source>Proc Natl Acad Sci U S A</source>
                  <year>2013</year>
                  <volume>110</volume>
                  <fpage>4357</fpage>
                  <lpage>4362</lpage>
                  <pub-id pub-id-type="doi">10.1073/pnas.1213555110</pub-id>
                  <pub-id pub-id-type="pmid">23401541</pub-id>
                </element-citation>
              </ref>
              <ref id="CR2">
                <mixed-citation publication-type="other">ANSI (2018) ANSI/ASA S3.6-2018 Specification for audiometers. American National Standards Institute, New York</mixed-citation>
              </ref>
              <ref id="CR3">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Banai</surname>
                      <given-names>K</given-names>
                    </name>
                    <name>
                      <surname>Lavner</surname>
                      <given-names>Y</given-names>
                    </name>
                  </person-group>
                  <article-title>Effects of stimulus repetition and training schedule on the perceptual learning of time-compressed speech and its transfer</article-title>
                  <source>Atten Percept Psychophys</source>
                  <year>2019</year>
                  <volume>81</volume>
                  <fpage>2944</fpage>
                  <lpage>2955</lpage>
                  <pub-id pub-id-type="doi">10.3758/s13414-019-01714-7</pub-id>
                  <pub-id pub-id-type="pmid">31161493</pub-id>
                </element-citation>
              </ref>
              <ref id="CR4">
                <mixed-citation publication-type="other">Benjamini Y, Hochberg Y (1995) Controlling the false discovery rate: a practical and powerful approach to multiple testing J R Stat Soc Series B Stat Methodol 289–300. <ext-link ext-link-type="uri" xlink:href="https://www.jstor.org/stable/2346101">https://www.jstor.org/stable/2346101</ext-link></mixed-citation>
              </ref>
              <ref id="CR5">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Bianchi</surname>
                      <given-names>F</given-names>
                    </name>
                    <name>
                      <surname>Carney</surname>
                      <given-names>LH</given-names>
                    </name>
                    <name>
                      <surname>Dau</surname>
                      <given-names>T</given-names>
                    </name>
                    <name>
                      <surname>Santurette</surname>
                      <given-names>S</given-names>
                    </name>
                  </person-group>
                  <article-title>Effects of musical training and hearing loss on fundamental frequency discrimination and temporal fine structure processing: psychophysics and modeling</article-title>
                  <source>J Assoc Res Otolaryngol</source>
                  <year>2019</year>
                  <volume>20</volume>
                  <fpage>263</fpage>
                  <lpage>277</lpage>
                  <pub-id pub-id-type="doi">10.1007/s10162-018-00710-2</pub-id>
                  <pub-id pub-id-type="pmid">30693416</pub-id>
                </element-citation>
              </ref>
              <ref id="CR6">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Bissmeyer</surname>
                      <given-names>SRS</given-names>
                    </name>
                    <name>
                      <surname>Hossain</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Goldsworthy</surname>
                      <given-names>RL</given-names>
                    </name>
                  </person-group>
                  <article-title>Perceptual learning of pitch provided by cochlear implant stimulation rate</article-title>
                  <source>PLoS ONE</source>
                  <year>2020</year>
                  <volume>15</volume>
                  <fpage>e0242842</fpage>
                  <pub-id pub-id-type="doi">10.1371/journal.pone.0242842</pub-id>
                  <pub-id pub-id-type="pmid">33270735</pub-id>
                </element-citation>
              </ref>
              <ref id="CR7">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Burk</surname>
                      <given-names>MH</given-names>
                    </name>
                    <name>
                      <surname>Humes</surname>
                      <given-names>LE</given-names>
                    </name>
                  </person-group>
                  <article-title>Effects of long-term training on aided speech-recognition performance in noise in older adults</article-title>
                  <source>J Speech Lang Hear Res</source>
                  <year>2008</year>
                  <volume>51</volume>
                  <fpage>759</fpage>
                  <lpage>771</lpage>
                  <pub-id pub-id-type="doi">10.1044/1092-4388(2008/054)</pub-id>
                  <pub-id pub-id-type="pmid">18506049</pub-id>
                </element-citation>
              </ref>
              <ref id="CR8">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Carlyon</surname>
                      <given-names>RP</given-names>
                    </name>
                    <name>
                      <surname>Deeks</surname>
                      <given-names>JM</given-names>
                    </name>
                  </person-group>
                  <article-title>Limitations on rate discrimination</article-title>
                  <source>J Acoust Soc Am</source>
                  <year>2002</year>
                  <volume>112</volume>
                  <fpage>1009</fpage>
                  <lpage>1025</lpage>
                  <pub-id pub-id-type="doi">10.1121/1.1496766</pub-id>
                  <pub-id pub-id-type="pmid">12243150</pub-id>
                </element-citation>
              </ref>
              <ref id="CR9">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Carlyon</surname>
                      <given-names>RP</given-names>
                    </name>
                    <name>
                      <surname>Long</surname>
                      <given-names>CJ</given-names>
                    </name>
                    <name>
                      <surname>Deeks</surname>
                      <given-names>JM</given-names>
                    </name>
                  </person-group>
                  <article-title>Pulse-rate discrimination by cochlear-implant and normal-hearing listeners with and without binaural cues</article-title>
                  <source>J Acoust Soc Am</source>
                  <year>2008</year>
                  <volume>123</volume>
                  <fpage>2276</fpage>
                  <lpage>2286</lpage>
                  <pub-id pub-id-type="doi">10.1121/1.2874796</pub-id>
                  <pub-id pub-id-type="pmid">18397032</pub-id>
                </element-citation>
              </ref>
              <ref id="CR10">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>de Villers-Sidani</surname>
                      <given-names>E</given-names>
                    </name>
                    <name>
                      <surname>Alzghoul</surname>
                      <given-names>L</given-names>
                    </name>
                    <name>
                      <surname>Zhou</surname>
                      <given-names>X</given-names>
                    </name>
                    <name>
                      <surname>Simpson</surname>
                      <given-names>KL</given-names>
                    </name>
                    <name>
                      <surname>Lin</surname>
                      <given-names>RCS</given-names>
                    </name>
                    <name>
                      <surname>Merzenich</surname>
                      <given-names>MM</given-names>
                    </name>
                  </person-group>
                  <source>Recovery of Functional and Structural Age-Related Changes in the Rat Primary Auditory Cortex with Operant Training Proceedings of the National Academuy of Sciences - USA</source>
                  <year>2010</year>
                  <volume>107</volume>
                  <fpage>13900</fpage>
                  <lpage>13905</lpage>
                  <pub-id pub-id-type="doi">10.1073/pnas.1007885107</pub-id>
                </element-citation>
              </ref>
              <ref id="CR11">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Desloge</surname>
                      <given-names>JG</given-names>
                    </name>
                    <name>
                      <surname>Reed</surname>
                      <given-names>CM</given-names>
                    </name>
                    <name>
                      <surname>Braida</surname>
                      <given-names>LD</given-names>
                    </name>
                    <name>
                      <surname>Perez</surname>
                      <given-names>ZD</given-names>
                    </name>
                    <name>
                      <surname>Delhorne</surname>
                      <given-names>LA</given-names>
                    </name>
                  </person-group>
                  <source>Auditory-Filter Characteristics for Listeners with Real and Simulated Hearing Impairment Trends Amplif</source>
                  <year>2012</year>
                  <volume>16</volume>
                  <fpage>19</fpage>
                  <lpage>39</lpage>
                  <pub-id pub-id-type="doi">10.1177/1084713812445510</pub-id>
                  <pub-id pub-id-type="pmid">22593204</pub-id>
                </element-citation>
              </ref>
              <ref id="CR12">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>DeVries</surname>
                      <given-names>L</given-names>
                    </name>
                    <name>
                      <surname>Anderson</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Goupell</surname>
                      <given-names>MJ</given-names>
                    </name>
                    <name>
                      <surname>Smith</surname>
                      <given-names>E</given-names>
                    </name>
                    <name>
                      <surname>Gordon-Salant</surname>
                      <given-names>S</given-names>
                    </name>
                  </person-group>
                  <article-title>Effects of aging and hearing loss on perceptual and electrophysiological measures of pulse-rate discrimination</article-title>
                  <source>J Acoust Soc Am</source>
                  <year>2022</year>
                  <volume>151</volume>
                  <fpage>1639</fpage>
                  <pub-id pub-id-type="doi">10.1121/10.0009399</pub-id>
                  <pub-id pub-id-type="pmid">35364956</pub-id>
                </element-citation>
              </ref>
              <ref id="CR13">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Dreschler</surname>
                      <given-names>WA</given-names>
                    </name>
                    <name>
                      <surname>Leeuw</surname>
                      <given-names>AR</given-names>
                    </name>
                  </person-group>
                  <article-title>Speech reception in reverberation related to temporal resolution</article-title>
                  <source>J Speech Hear Res</source>
                  <year>1990</year>
                  <volume>33</volume>
                  <fpage>181</fpage>
                  <lpage>187</lpage>
                  <pub-id pub-id-type="doi">10.1044/jshr.3301.181</pub-id>
                  <pub-id pub-id-type="pmid">2314078</pub-id>
                </element-citation>
              </ref>
              <ref id="CR14">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Fitzgerald</surname>
                      <given-names>MB</given-names>
                    </name>
                    <name>
                      <surname>Wright</surname>
                      <given-names>BA</given-names>
                    </name>
                  </person-group>
                  <article-title>Perceptual learning and generalization resulting from training on an auditory amplitude-modulation detection task</article-title>
                  <source>J Acoust Soc Am</source>
                  <year>2011</year>
                  <volume>129</volume>
                  <fpage>898</fpage>
                  <lpage>906</lpage>
                  <pub-id pub-id-type="doi">10.1121/1.3531841</pub-id>
                  <pub-id pub-id-type="pmid">21361447</pub-id>
                </element-citation>
              </ref>
              <ref id="CR15">
                <mixed-citation publication-type="other">Fitzgibbons PJ, Gordon-Salant S (1994) Age effects on measures of auditory duration discrimination J Speech Hear Res 37:662. 10.1044/jshr.3703.662</mixed-citation>
              </ref>
              <ref id="CR16">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Fitzgibbons</surname>
                      <given-names>PJ</given-names>
                    </name>
                    <name>
                      <surname>Gordon-Salant</surname>
                      <given-names>S</given-names>
                    </name>
                  </person-group>
                  <article-title>Auditory temporal processing in elderly listeners</article-title>
                  <source>J Am Acad Audiol</source>
                  <year>1996</year>
                  <volume>7</volume>
                  <fpage>183</fpage>
                  <lpage>189</lpage>
                  <pub-id pub-id-type="pmid">8780991</pub-id>
                </element-citation>
              </ref>
              <ref id="CR17">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Fitzgibbons</surname>
                      <given-names>PJ</given-names>
                    </name>
                    <name>
                      <surname>Gordon-Salant</surname>
                      <given-names>S</given-names>
                    </name>
                  </person-group>
                  <article-title>Aging and temporal discrimination in auditory sequences</article-title>
                  <source>J Acoust Soc Am</source>
                  <year>2001</year>
                  <volume>109</volume>
                  <fpage>2955</fpage>
                  <lpage>2963</lpage>
                  <pub-id pub-id-type="doi">10.1121/1.1371760</pub-id>
                  <pub-id pub-id-type="pmid">11425137</pub-id>
                </element-citation>
              </ref>
              <ref id="CR18">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Fitzgibbons</surname>
                      <given-names>PJ</given-names>
                    </name>
                    <name>
                      <surname>Gordon-Salant</surname>
                      <given-names>S</given-names>
                    </name>
                  </person-group>
                  <article-title>Age effects on duration discrimination with simple and complex stimuli</article-title>
                  <source>J Acoust Soc Am</source>
                  <year>1995</year>
                  <volume>98</volume>
                  <fpage>3140</fpage>
                  <lpage>3145</lpage>
                  <pub-id pub-id-type="doi">10.1121/1.413803</pub-id>
                  <pub-id pub-id-type="pmid">8550939</pub-id>
                </element-citation>
              </ref>
              <ref id="CR19">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Fostick</surname>
                      <given-names>L</given-names>
                    </name>
                    <name>
                      <surname>Taitelbaum-Swead</surname>
                      <given-names>R</given-names>
                    </name>
                    <name>
                      <surname>Kreitler</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Zokraut</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Billig</surname>
                      <given-names>M</given-names>
                    </name>
                  </person-group>
                  <article-title>Auditory training to improve speech perception and self-efficacy in aging adults</article-title>
                  <source>J Speech Lang Hear Res</source>
                  <year>2020</year>
                  <volume>63</volume>
                  <fpage>1270</fpage>
                  <lpage>1281</lpage>
                  <pub-id pub-id-type="doi">10.1044/2019_jslhr-19-00355</pub-id>
                  <pub-id pub-id-type="pmid">32182434</pub-id>
                </element-citation>
              </ref>
              <ref id="CR20">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Gaskins</surname>
                      <given-names>C</given-names>
                    </name>
                    <name>
                      <surname>Jaekel</surname>
                      <given-names>BN</given-names>
                    </name>
                    <name>
                      <surname>Gordon-Salant</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Goupell</surname>
                      <given-names>MJ</given-names>
                    </name>
                    <name>
                      <surname>Anderson</surname>
                      <given-names>S</given-names>
                    </name>
                  </person-group>
                  <article-title>Effects of aging on perceptual and electrophysiological responses to acoustic pulse trains as a function of rate</article-title>
                  <source>J Speech Lang Hear Res</source>
                  <year>2019</year>
                  <volume>62</volume>
                  <fpage>1087</fpage>
                  <lpage>1098</lpage>
                  <pub-id pub-id-type="doi">10.1044/2018_jslhr-h-ascc7-18-0133</pub-id>
                  <pub-id pub-id-type="pmid">31026191</pub-id>
                </element-citation>
              </ref>
              <ref id="CR21">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Goldsworthy</surname>
                      <given-names>RL</given-names>
                    </name>
                    <name>
                      <surname>Shannon</surname>
                      <given-names>RV</given-names>
                    </name>
                  </person-group>
                  <article-title>Training improves cochlear implant rate discrimination on a psychophysical task</article-title>
                  <source>J Acoust Soc Am</source>
                  <year>2014</year>
                  <volume>135</volume>
                  <fpage>334</fpage>
                  <lpage>341</lpage>
                  <pub-id pub-id-type="doi">10.1121/1.4835735</pub-id>
                  <pub-id pub-id-type="pmid">24437773</pub-id>
                </element-citation>
              </ref>
              <ref id="CR22">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Gordon-Salant</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Fitzgibbons</surname>
                      <given-names>PJ</given-names>
                    </name>
                  </person-group>
                  <article-title>Temporal factors and speech recognition performance in young and elderly listeners</article-title>
                  <source>J Speech Hear Res</source>
                  <year>1993</year>
                  <volume>36</volume>
                  <fpage>1276</fpage>
                  <lpage>1285</lpage>
                  <pub-id pub-id-type="doi">10.1044/jshr.3606.1276</pub-id>
                  <pub-id pub-id-type="pmid">8114494</pub-id>
                </element-citation>
              </ref>
              <ref id="CR23">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Harris</surname>
                      <given-names>KC</given-names>
                    </name>
                    <name>
                      <surname>Eckert</surname>
                      <given-names>MA</given-names>
                    </name>
                    <name>
                      <surname>Ahlstrom</surname>
                      <given-names>JB</given-names>
                    </name>
                    <name>
                      <surname>Dubno</surname>
                      <given-names>JR</given-names>
                    </name>
                  </person-group>
                  <article-title>Age-related differences in gap detection: effects of task difficulty and cognitive ability</article-title>
                  <source>Hear Res</source>
                  <year>2010</year>
                  <volume>264</volume>
                  <fpage>21</fpage>
                  <lpage>29</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.heares.2009.09.017</pub-id>
                  <pub-id pub-id-type="pmid">19800958</pub-id>
                </element-citation>
              </ref>
              <ref id="CR24">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Herdman</surname>
                      <given-names>AT</given-names>
                    </name>
                    <name>
                      <surname>Picton</surname>
                      <given-names>TW</given-names>
                    </name>
                    <name>
                      <surname>Stapells</surname>
                      <given-names>DR</given-names>
                    </name>
                  </person-group>
                  <article-title>Place specificity of multiple auditory steady-state responses</article-title>
                  <source>J Acoust Soc Am</source>
                  <year>2002</year>
                  <volume>112</volume>
                  <fpage>1569</fpage>
                  <lpage>1582</lpage>
                  <pub-id pub-id-type="doi">10.1121/1.1506367</pub-id>
                  <pub-id pub-id-type="pmid">12398463</pub-id>
                </element-citation>
              </ref>
              <ref id="CR25">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Hetherington</surname>
                      <given-names>R</given-names>
                    </name>
                  </person-group>
                  <source>The Snellen Chart as a Test of Visual Acuity Psychol Forsch</source>
                  <year>1954</year>
                  <volume>24</volume>
                  <fpage>349</fpage>
                  <lpage>357</lpage>
                  <pub-id pub-id-type="doi">10.1007/BF00422033</pub-id>
                  <pub-id pub-id-type="pmid">13204500</pub-id>
                </element-citation>
              </ref>
              <ref id="CR26">
                <mixed-citation publication-type="other">IEEE (1969) IEEE recommended practice for speech quality measurements. 10.1109/IEEESTD.1969.7405210</mixed-citation>
              </ref>
              <ref id="CR27">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Ihlefeld</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Carlyon</surname>
                      <given-names>RP</given-names>
                    </name>
                    <name>
                      <surname>Kan</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Churchill</surname>
                      <given-names>TH</given-names>
                    </name>
                    <name>
                      <surname>Litovsky</surname>
                      <given-names>RY</given-names>
                    </name>
                  </person-group>
                  <article-title>Limitations on monaural and binaural temporal processing in bilateral cochlear implant listeners</article-title>
                  <source>J Assoc Res Otolaryngol</source>
                  <year>2015</year>
                  <volume>16</volume>
                  <fpage>641</fpage>
                  <lpage>652</lpage>
                  <pub-id pub-id-type="doi">10.1007/s10162-015-0527-7</pub-id>
                  <pub-id pub-id-type="pmid">26105749</pub-id>
                </element-citation>
              </ref>
              <ref id="CR28">
                <mixed-citation publication-type="other">Irwin RJ, McAuley SF (1987) Relations among temporal acuity, hearing loss, and the perception of speech distorted by noise and reverberation J Acoust Soc Am 81:1557–1565. 10.1121/1.394508</mixed-citation>
              </ref>
              <ref id="CR29">
                <mixed-citation publication-type="other">JASP Team (2020) JASP (Version 0.14.1[Computer software])</mixed-citation>
              </ref>
              <ref id="CR30">
                <mixed-citation publication-type="other">Jenkins KA, Fodor C, Presacco A, Anderson S (2018) Effects of amplification on neural phase locking, amplitude, and latency to a speech syllable. Ear Hear 39:810–824. 10.1097/aud.0000000000000538</mixed-citation>
              </ref>
              <ref id="CR31">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Johnson</surname>
                      <given-names>KC</given-names>
                    </name>
                    <name>
                      <surname>Xie</surname>
                      <given-names>Z</given-names>
                    </name>
                    <name>
                      <surname>Shader</surname>
                      <given-names>MJ</given-names>
                    </name>
                    <name>
                      <surname>Mayo</surname>
                      <given-names>PG</given-names>
                    </name>
                    <name>
                      <surname>Goupell</surname>
                      <given-names>MJ</given-names>
                    </name>
                  </person-group>
                  <source>Effect of Chronological Age on Pulse Rate Discrimination in Adult Cochlear-Implant Users Trends Hear</source>
                  <year>2021</year>
                  <volume>25</volume>
                  <fpage>23312165211007367</fpage>
                  <pub-id pub-id-type="doi">10.1177/23312165211007367</pub-id>
                  <pub-id pub-id-type="pmid">34028313</pub-id>
                </element-citation>
              </ref>
              <ref id="CR32">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Karawani</surname>
                      <given-names>H</given-names>
                    </name>
                    <name>
                      <surname>Bitan</surname>
                      <given-names>T</given-names>
                    </name>
                    <name>
                      <surname>Attias</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Banai</surname>
                      <given-names>K</given-names>
                    </name>
                  </person-group>
                  <source>Auditory Perceptual Learning in Adults with and without Age-Related Hearing Loss Front Psychol</source>
                  <year>2015</year>
                  <volume>6</volume>
                  <fpage>2066</fpage>
                  <pub-id pub-id-type="doi">10.3389/fpsyg.2015.02066</pub-id>
                  <pub-id pub-id-type="pmid">26869944</pub-id>
                </element-citation>
              </ref>
              <ref id="CR33">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Kong</surname>
                      <given-names>YY</given-names>
                    </name>
                    <name>
                      <surname>Deeks</surname>
                      <given-names>JM</given-names>
                    </name>
                    <name>
                      <surname>Axon</surname>
                      <given-names>PR</given-names>
                    </name>
                    <name>
                      <surname>Carlyon</surname>
                      <given-names>RP</given-names>
                    </name>
                  </person-group>
                  <article-title>Limits of temporal pitch in cochlear implants</article-title>
                  <source>J Acoust Soc Am</source>
                  <year>2009</year>
                  <volume>125</volume>
                  <fpage>1649</fpage>
                  <lpage>1657</lpage>
                  <pub-id pub-id-type="doi">10.1121/1.3068457</pub-id>
                  <pub-id pub-id-type="pmid">19275322</pub-id>
                </element-citation>
              </ref>
              <ref id="CR34">
                <mixed-citation publication-type="other">Koziol LF, Budding DE (2012) Procedural Learning. In: Seel NM (ed) Encyclopedia of the Sciences of Learning. Springer US, Boston, MA, pp 2694–2696. 10.1007/978-1-4419-1428-6_670</mixed-citation>
              </ref>
              <ref id="CR35">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Kumar</surname>
                      <given-names>U</given-names>
                    </name>
                  </person-group>
                  <article-title>Temporal processing abilities across different age groups</article-title>
                  <source>J Am Acad Audiol</source>
                  <year>2011</year>
                  <volume>22</volume>
                  <fpage>5</fpage>
                  <lpage>12</lpage>
                  <pub-id pub-id-type="doi">10.3766/jaaa.22.1.2</pub-id>
                  <pub-id pub-id-type="pmid">21419065</pub-id>
                </element-citation>
              </ref>
              <ref id="CR36">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Lakshminarayanan</surname>
                      <given-names>K</given-names>
                    </name>
                    <name>
                      <surname>Tallal</surname>
                      <given-names>P</given-names>
                    </name>
                  </person-group>
                  <article-title>Generalization of non-linguistic auditory perceptual training to syllable discrimination</article-title>
                  <source>Restor Neurol Neurosci</source>
                  <year>2007</year>
                  <volume>25</volume>
                  <fpage>263</fpage>
                  <lpage>272</lpage>
                  <pub-id pub-id-type="pmid">17943004</pub-id>
                </element-citation>
              </ref>
              <ref id="CR37">
                <mixed-citation publication-type="other">Levitt H (1971) Transformed up-down methods in psychoacoustics J Acoust Soc Am 49:Suppl 2:467</mixed-citation>
              </ref>
              <ref id="CR38">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Macherey</surname>
                      <given-names>O</given-names>
                    </name>
                    <name>
                      <surname>Carlyon</surname>
                      <given-names>RP</given-names>
                    </name>
                  </person-group>
                  <article-title>Re-examining the upper limit of temporal pitch</article-title>
                  <source>J Acoust Soc Am</source>
                  <year>2014</year>
                  <volume>136</volume>
                  <fpage>3186</fpage>
                  <pub-id pub-id-type="doi">10.1121/1.4900917</pub-id>
                  <pub-id pub-id-type="pmid">25480066</pub-id>
                </element-citation>
              </ref>
              <ref id="CR39">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Micheyl</surname>
                      <given-names>C</given-names>
                    </name>
                    <name>
                      <surname>Delhommeau</surname>
                      <given-names>K</given-names>
                    </name>
                    <name>
                      <surname>Perrot</surname>
                      <given-names>X</given-names>
                    </name>
                    <name>
                      <surname>Oxenham</surname>
                      <given-names>AJ</given-names>
                    </name>
                  </person-group>
                  <article-title>Influence of musical and psychoacoustical training on pitch discrimination</article-title>
                  <source>Hear Res</source>
                  <year>2006</year>
                  <volume>219</volume>
                  <fpage>36</fpage>
                  <lpage>47</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.heares.2006.05.004</pub-id>
                  <pub-id pub-id-type="pmid">16839723</pub-id>
                </element-citation>
              </ref>
              <ref id="CR40">
                <mixed-citation publication-type="other">Nasreddine ZS et al (2005) The Montreal cognitive assessment, MoCA: a brief screening tool for mild cognitive impairment. J Am Geriatr Soc 53:695–699. 10.1111/j.1532-5415.2005.53221.x</mixed-citation>
              </ref>
              <ref id="CR41">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Roque</surname>
                      <given-names>L</given-names>
                    </name>
                    <name>
                      <surname>Gaskins</surname>
                      <given-names>C</given-names>
                    </name>
                    <name>
                      <surname>Gordon-Salant</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Goupell</surname>
                      <given-names>MJ</given-names>
                    </name>
                    <name>
                      <surname>Anderson</surname>
                      <given-names>S</given-names>
                    </name>
                  </person-group>
                  <article-title>Age effects on neural representation and perception of silence duration cues in speech</article-title>
                  <source>J Speech Lang Hear Res</source>
                  <year>2019</year>
                  <volume>62</volume>
                  <fpage>1099</fpage>
                  <lpage>1116</lpage>
                  <pub-id pub-id-type="doi">10.1044/2018_jslhr-h-ascc7-18-0076</pub-id>
                  <pub-id pub-id-type="pmid">31026197</pub-id>
                </element-citation>
              </ref>
              <ref id="CR42">
                <mixed-citation publication-type="other">Roque L, Karawani H, Gordon-Salant S, Anderson S (2019b) Effects of age, cognition, and neural encoding on the perception of temporal speech cues. Front Neurosci 13:749. 10.3389/fnins.2019b.00749</mixed-citation>
              </ref>
              <ref id="CR43">
                <mixed-citation publication-type="other">Ross B, Schneider B, Snyder JS, Alain C (2010) Biological markers of auditory gap detection in young, middle-aged, and older adults. Plos ONE 5:e10101</mixed-citation>
              </ref>
              <ref id="CR44">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Sabin</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Clark</surname>
                      <given-names>C</given-names>
                    </name>
                    <name>
                      <surname>Eddins</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Wright</surname>
                      <given-names>B</given-names>
                    </name>
                  </person-group>
                  <article-title>Different patterns of perceptual learning on spectral modulation detection between older hearing-impaired and younger normal-hearing adults</article-title>
                  <source>J Assoc Res Otolaryngol</source>
                  <year>2013</year>
                  <volume>14</volume>
                  <fpage>283</fpage>
                  <lpage>294</lpage>
                  <pub-id pub-id-type="doi">10.1007/s10162-012-0363-y</pub-id>
                  <pub-id pub-id-type="pmid">23229719</pub-id>
                </element-citation>
              </ref>
              <ref id="CR45">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Sabin</surname>
                      <given-names>AT</given-names>
                    </name>
                    <name>
                      <surname>Eddins</surname>
                      <given-names>DA</given-names>
                    </name>
                    <name>
                      <surname>Wright</surname>
                      <given-names>BA</given-names>
                    </name>
                  </person-group>
                  <article-title>Perceptual learning evidence for tuning to spectrotemporal modulation in the human auditory system</article-title>
                  <source>J Neurosci</source>
                  <year>2012</year>
                  <volume>32</volume>
                  <fpage>6542</fpage>
                  <lpage>6549</lpage>
                  <pub-id pub-id-type="doi">10.1523/jneurosci.5732-11.2012</pub-id>
                  <pub-id pub-id-type="pmid">22573676</pub-id>
                </element-citation>
              </ref>
              <ref id="CR46">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Snell</surname>
                      <given-names>KB</given-names>
                    </name>
                  </person-group>
                  <article-title>Age-related changes in temporal gap detection</article-title>
                  <source>J Acoust Soc Am</source>
                  <year>1997</year>
                  <volume>101</volume>
                  <fpage>2214</fpage>
                  <lpage>2220</lpage>
                  <pub-id pub-id-type="doi">10.1121/1.418205</pub-id>
                  <pub-id pub-id-type="pmid">9104023</pub-id>
                </element-citation>
              </ref>
              <ref id="CR47">
                <mixed-citation publication-type="other">Studebaker GA (1985) A “rationalized” arcsine transform. J Speech Hear Res 28:455–462. 10.1044/jshr.2803.455</mixed-citation>
              </ref>
              <ref id="CR48">
                <mixed-citation publication-type="other">Tallon-Baudry C, Bertrand O, Delpuech C, Pernier J (1996) Stimulus specificity of phase-locked and non-phase-locked 40 hz visual responses in human. J Neurosci 16:4240–4249. 10.1523/JNEUROSCI.16-13-04240.1996</mixed-citation>
              </ref>
              <ref id="CR49">
                <mixed-citation publication-type="other">Tillman TW, Carhart R (1966) An expanded test for speech discrimination utilizing CNC monosyllabic words. Northwestern University Auditory Test No. 6. SAM-TR-66–55 Tech Rep SAM-TR:1–12. 10.21236/ad0639638</mixed-citation>
              </ref>
              <ref id="CR50">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Weintraub</surname>
                      <given-names>S</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <source>Cognition Assessment Using the NIH Toolbox Neurology</source>
                  <year>2013</year>
                  <volume>80</volume>
                  <fpage>S54</fpage>
                  <lpage>S64</lpage>
                  <pub-id pub-id-type="doi">10.1212/WNL.0b013e3182872ded</pub-id>
                  <pub-id pub-id-type="pmid">23479546</pub-id>
                </element-citation>
              </ref>
              <ref id="CR51">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Whitton</surname>
                      <given-names>JP</given-names>
                    </name>
                    <name>
                      <surname>Hancock</surname>
                      <given-names>KE</given-names>
                    </name>
                    <name>
                      <surname>Shannon</surname>
                      <given-names>JM</given-names>
                    </name>
                    <name>
                      <surname>Polley</surname>
                      <given-names>DB</given-names>
                    </name>
                  </person-group>
                  <article-title>Audiomotor perceptual training enhances speech intelligibility in background noise</article-title>
                  <source>Curr Biol</source>
                  <year>2017</year>
                  <volume>27</volume>
                  <fpage>3237</fpage>
                  <lpage>3247.e3236</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.cub.2017.09.014</pub-id>
                  <pub-id pub-id-type="pmid">29056453</pub-id>
                </element-citation>
              </ref>
              <ref id="CR52">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Zaltz</surname>
                      <given-names>Y</given-names>
                    </name>
                    <name>
                      <surname>Kishon-Rabin</surname>
                      <given-names>L</given-names>
                    </name>
                  </person-group>
                  <source>Difficulties Experienced by Older Listeners in Utilizing Voice Cues for Speaker Discrimination Front Psychol</source>
                  <year>2022</year>
                  <volume>13</volume>
                  <fpage>797422</fpage>
                  <pub-id pub-id-type="doi">10.3389/fpsyg.2022.797422</pub-id>
                  <pub-id pub-id-type="pmid">35310278</pub-id>
                </element-citation>
              </ref>
              <ref id="CR53">
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Zhou</surname>
                      <given-names>N</given-names>
                    </name>
                    <name>
                      <surname>Mathews</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Dong</surname>
                      <given-names>L</given-names>
                    </name>
                  </person-group>
                  <article-title>Pulse-rate discrimination deficit in cochlear implant users: is the upper limit of pitch peripheral or central?</article-title>
                  <source>Hear Res</source>
                  <year>2019</year>
                  <volume>371</volume>
                  <fpage>1</fpage>
                  <lpage>10</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.heares.2018.10.018</pub-id>
                  <pub-id pub-id-type="pmid">30423498</pub-id>
                </element-citation>
              </ref>
            </ref-list>
          </back>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
