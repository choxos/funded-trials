<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2024-05-03T02:20:21Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:8646178" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:8646178</identifier>
        <datestamp>2021-12-15</datestamp>
        <setSpec>nic</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" article-type="research-article" dtd-version="1.3">
          <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
            <restricted-by>pmc</restricted-by>
          </processing-meta>
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">Neuroimage Clin</journal-id>
              <journal-id journal-id-type="iso-abbrev">Neuroimage Clin</journal-id>
              <journal-title-group>
                <journal-title>NeuroImage : Clinical</journal-title>
              </journal-title-group>
              <issn pub-type="epub">2213-1582</issn>
              <publisher>
                <publisher-name>Elsevier</publisher-name>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC8646178</article-id>
              <article-id pub-id-type="pmcid">PMC8646178</article-id>
              <article-id pub-id-type="pmc-uid">8646178</article-id>
              <article-id pub-id-type="pmid">34911199</article-id>
              <article-id pub-id-type="pii">S2213-1582(21)00340-5</article-id>
              <article-id pub-id-type="doi">10.1016/j.nicl.2021.102896</article-id>
              <article-id pub-id-type="publisher-id">102896</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Regular Article</subject>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>Assessing the utility of low resolution brain imaging: treatment of infant hydrocephalus</article-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author" id="au005">
                  <name>
                    <surname>Harper</surname>
                    <given-names>Joshua R.</given-names>
                  </name>
                  <xref rid="af005" ref-type="aff">a</xref>
                </contrib>
                <contrib contrib-type="author" id="au010">
                  <name>
                    <surname>Cherukuri</surname>
                    <given-names>Venkateswararao</given-names>
                  </name>
                  <xref rid="af010" ref-type="aff">b</xref>
                </contrib>
                <contrib contrib-type="author" id="au015">
                  <name>
                    <surname>O’Reilly</surname>
                    <given-names>Tom</given-names>
                  </name>
                  <xref rid="af015" ref-type="aff">c</xref>
                </contrib>
                <contrib contrib-type="author" id="au020">
                  <name>
                    <surname>Yu</surname>
                    <given-names>Mingzhao</given-names>
                  </name>
                  <xref rid="af010" ref-type="aff">b</xref>
                </contrib>
                <contrib contrib-type="author" id="au025">
                  <name>
                    <surname>Mbabazi-Kabachelor</surname>
                    <given-names>Edith</given-names>
                  </name>
                  <xref rid="af020" ref-type="aff">d</xref>
                </contrib>
                <contrib contrib-type="author" id="au030">
                  <name>
                    <surname>Mulando</surname>
                    <given-names>Ronald</given-names>
                  </name>
                  <xref rid="af020" ref-type="aff">d</xref>
                </contrib>
                <contrib contrib-type="author" id="au035">
                  <name>
                    <surname>Sheth</surname>
                    <given-names>Kevin N.</given-names>
                  </name>
                  <xref rid="af025" ref-type="aff">e</xref>
                </contrib>
                <contrib contrib-type="author" id="au040">
                  <name>
                    <surname>Webb</surname>
                    <given-names>Andrew G.</given-names>
                  </name>
                  <xref rid="af015" ref-type="aff">c</xref>
                </contrib>
                <contrib contrib-type="author" id="au045">
                  <name>
                    <surname>Warf</surname>
                    <given-names>Benjamin C.</given-names>
                  </name>
                  <xref rid="af030" ref-type="aff">f</xref>
                </contrib>
                <contrib contrib-type="author" id="au050">
                  <name>
                    <surname>Kulkarni</surname>
                    <given-names>Abhaya V.</given-names>
                  </name>
                  <xref rid="af035" ref-type="aff">g</xref>
                </contrib>
                <contrib contrib-type="author" id="au055">
                  <name>
                    <surname>Monga</surname>
                    <given-names>Vishal</given-names>
                  </name>
                  <xref rid="af010" ref-type="aff">b</xref>
                </contrib>
                <contrib contrib-type="author" id="au060">
                  <name>
                    <surname>Schiff</surname>
                    <given-names>Steven J.</given-names>
                  </name>
                  <email>steven.j.schiff@gmail.com</email>
                  <xref rid="af005" ref-type="aff">a</xref>
                  <xref rid="af040" ref-type="aff">h</xref>
                  <xref rid="cor1" ref-type="corresp">⁎</xref>
                </contrib>
                <aff id="af005"><label>a</label>Center for Neural Engineering, Department of Engineering Science and Mechanics, The Pennsylvania State University, University Park, PA, USA</aff>
                <aff id="af010"><label>b</label>School of Electrical Engineering and Computer Science, The Pennsylvania State University, University Park, PA, USA</aff>
                <aff id="af015"><label>c</label>Gorter Center for High Field MRI, Leiden University Medical Center, Leiden, NL, the Netherlands</aff>
                <aff id="af020"><label>d</label>The CURE Children’s Hospital of Uganda, Uganda</aff>
                <aff id="af025"><label>e</label>Department of Neurology, Yale University School of Medicine, New Haven, CT, USA</aff>
                <aff id="af030"><label>f</label>Department of Neurosurgery, Boston Children’s Hospital, Harvard Medical School, Boston, USA</aff>
                <aff id="af035"><label>g</label>Department of Surgery, Hospital for Sick Children, University of Toronto, CA, USA</aff>
                <aff id="af040"><label>h</label>Departments of Neurosurgery, and Physics, The Pennsylvania State University, University Park, PA, USA</aff>
              </contrib-group>
              <author-notes>
                <corresp id="cor1"><label>⁎</label>Corresponding author at: W311 Millennium Science Complex, University Park, PA 16802, USA. <email>steven.j.schiff@gmail.com</email></corresp>
              </author-notes>
              <pub-date pub-type="pmc-release">
                <day>23</day>
                <month>11</month>
                <year>2021</year>
              </pub-date>
              <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
              <pub-date pub-type="collection">
                <year>2021</year>
              </pub-date>
              <pub-date pub-type="epub">
                <day>23</day>
                <month>11</month>
                <year>2021</year>
              </pub-date>
              <volume>32</volume>
              <elocation-id>102896</elocation-id>
              <history>
                <date date-type="received">
                  <day>21</day>
                  <month>7</month>
                  <year>2021</year>
                </date>
                <date date-type="rev-recd">
                  <day>27</day>
                  <month>10</month>
                  <year>2021</year>
                </date>
                <date date-type="accepted">
                  <day>22</day>
                  <month>11</month>
                  <year>2021</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>© 2021 Published by Elsevier Inc.</copyright-statement>
                <copyright-year>2021</copyright-year>
                <copyright-holder/>
                <license>
                  <ali:license_ref specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
                  <license-p>This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).</license-p>
                </license>
              </permissions>
              <abstract id="ab005">
                <p>As low-field MRI technology is being disseminated into clinical settings around the world, it is important to assess the image quality required to properly diagnose and treat a given disease and evaluate the role of machine learning algorithms, such as deep learning, in the enhancement of lower quality images. In this post hoc analysis of an ongoing randomized clinical trial, we assessed the diagnostic utility of reduced-quality and deep learning enhanced images for hydrocephalus treatment planning. CT images of post-infectious infant hydrocephalus were degraded in terms of spatial resolution, noise, and contrast between brain and CSF and enhanced using deep learning algorithms. Both degraded and enhanced images were presented to three experienced pediatric neurosurgeons accustomed to working in low- to middle-income countries (LMIC) for assessment of clinical utility in treatment planning for hydrocephalus. In addition, enhanced images were presented alongside their ground-truth CT counterparts in order to assess whether reconstruction errors caused by the deep learning enhancement routine were acceptable to the evaluators. Results indicate that image resolution and contrast-to-noise ratio between brain and CSF predict the likelihood of an image being characterized as useful for hydrocephalus treatment planning. Deep learning enhancement substantially increases contrast-to-noise ratio improving the apparent likelihood of the image being useful; however, deep learning enhancement introduces structural errors which create a substantial risk of misleading clinical interpretation. We find that images with lower quality than is customarily acceptable can be useful for hydrocephalus treatment planning. Moreover, low quality images may be preferable to images enhanced with deep learning, since they do not introduce the risk of misleading information which could misguide treatment decisions. These findings advocate for new standards in assessing acceptable image quality for clinical use.</p>
              </abstract>
              <kwd-group id="kg005">
                <title>Keywords</title>
                <kwd>Low field MRI</kwd>
                <kwd>Image quality</kwd>
                <kwd>Deep learning</kwd>
                <kwd>Risk assessment</kwd>
                <kwd>Hydrocephalus treatment planning</kwd>
              </kwd-group>
            </article-meta>
          </front>
          <body>
            <sec id="s0005">
              <label>1</label>
              <title>Introduction</title>
              <p id="p0005">With an estimated 400,000 new cases worldwide each year, childhood hydrocephalus is the most common pediatric condition requiring neurosurgery globally (<xref rid="b0040" ref-type="bibr">Dewan et al., 2018</xref>). Over 90% of cases occur in low- and middle-income countries (LMIC) (<xref rid="b0040" ref-type="bibr">Dewan et al., 2018</xref>). In sub-Saharan Africa, approximately 180,000 infants per year are affected (<xref rid="b0200" ref-type="bibr">Warf, 2013</xref>). Hydrocephalus is characterized by a build up of intracranial cerebrospinal fluid (CSF) that, in infants, causes the head to enlarge. These infants need surgical treatment to survive requiring intracranial imaging for planning. In planning surgery it is important to know where the CSF is in relation to brain, and how many compartments are loculated where fluid is trapped. An imaging technology capable of showing contrast between brain and CSF at an appropriate resolution is required. We have previously suggested that a voxel size approaching 100 <inline-formula><mml:math id="M1" altimg="si1.svg"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="italic">mm</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> (e.g 3 × 3 × 10 mm<sup>3</sup>) could be sufficient for planning treatment (<xref rid="b0135" ref-type="bibr">Obungoloch et al., 2018</xref>).</p>
              <p id="p0010">The brain is an organ where the soft tissue and fluid encased within the skull have limited alternatives for imaging. Ultrasound is only effective within the first year of life before skull fusion closes the acoustical windows of the fontanels. The ionizing radiation associated with CT poses exceptional risks to infants (<xref rid="b0055" ref-type="bibr">Frush et al., 2003</xref>, <xref rid="b0010" ref-type="bibr">Brenner and Eric, 2007</xref>); however, in sub-Saharan Africa CT is more prevalent than MRI (<xref rid="b0145" ref-type="bibr">World Health Organization, 2011</xref>) due to its lower cost. Although MRI is the gold standard for pediatric neuro-imaging, the high cost, strict siting requirements, and demanding maintenance schedule render high-field cryogenic systems infeasible for most of the developing world (<xref rid="b0060" ref-type="bibr">Gatrad et al., 2007</xref>, <xref rid="b0100" ref-type="bibr">Klein, 2015</xref>, <xref rid="b0120" ref-type="bibr">Malkin, 2007</xref>, <xref rid="b0145" ref-type="bibr">World Health Organization, 2011</xref>).</p>
              <p id="p0015">According to a 2014 baseline country survey on medical devices conducted by the World Health Organization, Uganda has 0.45 CT machines per million people and only 0.08 MRI machines per million people. By comparison, a high income country such as the Netherlands, has 12 CT and 12 MRI machines per million people (roughly 27 times more CT/million and 150 times more MRI/million people) (<xref rid="b0145" ref-type="bibr">World Health Organization, 2011</xref>). Placed in the context of new hydrocephalus cases per year, with rates at least 10 times more per year in Africa than in Europe (<xref rid="b0040" ref-type="bibr">Dewan et al., 2018</xref>), the clinical need for globally sustainable diagnostic imaging devices is clear. Low-field MRI devices have been recently developed that are feasible for the developing world and show diagnostic promise for the treatment and management of illnesses such as hydrocephalus (<xref rid="b0135" ref-type="bibr">Obungoloch et al., 2018</xref>, <xref rid="b0140" ref-type="bibr">O’Reilly et al., 2020</xref>, <xref rid="b0180" ref-type="bibr">Sheth et al., 2020</xref>, <xref rid="b0035" ref-type="bibr">Cooley et al., 2021</xref>).</p>
              <p id="p0020">The quality of an MRI image ultimately depends on the signal-to-noise ratio (SNR) per voxel. Higher field strength systems (&gt;1.5 Tesla) can produce increased signal-to-noise and pushing voxel size as low as hundreds of micrometers (<xref rid="b0170" ref-type="bibr">Rutland et al., 2020</xref>). Low-field systems (&lt;0.1 Tesla) inherently suffer from low signal-to-noise placing limits on achievable voxel size and including more baseline noise than most clinicians are accustomed to. <xref rid="f0005" ref-type="fig">Fig. 1</xref> demonstrates the difference in brain image quality between a high-field (<xref rid="f0005" ref-type="fig">Fig. 1</xref>A) and a low-field (<xref rid="f0005" ref-type="fig">Fig. 1</xref>B) MRI system.<fig id="f0005"><label>Fig. 1</label><caption><p>A comparison of the image quality between a high-field (3T) and a low-field (0.05 T) image of the brain of the same volunteer taken at the Leiden University Medical Center. A) A 256 × 256 3D T1 weighted TFE with Field of View: 200 × 175 × 156 mm, Resolution: 1.15 × 1.15 × 1.2 mm, TR/TE/TI  = 9.8 ms/4.6 ms/1050 ms, ETL  = 166, scan duration: 3 min 13 s; B) A 128 × 128 image at 0.05 T with Field of view: 256 × 256 × 200mm, Resolution: 2 × 2 × 4 mm, TR/TE  = 400 ms/15 ms, echo train length  = 6, scan duration: 7 min 7 s.</p></caption><graphic xlink:href="gr1"/></fig></p>
              <p id="p0025">The adoption of low-field MRI into clinical practice depends largely on a longstanding and recently growing body of evidence that higher image quality does not always lead to better diagnostic accuracy or better patient outcome (<xref rid="b0085" ref-type="bibr">Jhaveri, 2015</xref>). In clinical practice there exists a threshold of image quality for specific pathologies, above which no further outcome-based value can be observed (<xref rid="b0050" ref-type="bibr">Durand et al., 2013</xref>). It has been demonstrated that 0.5 Tesla MRI can be as diagnostically accurate as 1.5 Tesla MRI for a variety of diseases including central nervous system pathologies (<xref rid="b0080" ref-type="bibr">Jack et al., 1990</xref>), hepatic lesions (<xref rid="b0190" ref-type="bibr">Steinberg et al., 1990</xref>), and multiple-sclerosis (<xref rid="b0110" ref-type="bibr">Lee et al., 1995</xref>). It has also been shown that a 0.064 Tesla MRI can have comparable diagnostic accuracy to a 1.5 Tesla MRI for neoplasms and white matter disease (<xref rid="b0150" ref-type="bibr">Orrison et al., 1991</xref>). Although the threshold of image quality required to plan effective hydrocephalus treatment has not been previously explored, we hypothesized that the level of resolution, tissue contrast, and SNR provided by CT or high-field MRI substantially exceeds this threshold.</p>
              <p id="p0030">Various machine learning-based methods have previously been used to perform super-resolution enhancement of low-quality MRI images. Interpolation based methods (<xref rid="b0115" ref-type="bibr">Lehmann et al., 1999</xref>) are simple to implement but lack prior information often resulting in blurring. Model-based methods (<xref rid="b0125" ref-type="bibr">Manjón et al., 2010</xref>, <xref rid="b0130" ref-type="bibr">Manjón et al., 2010</xref>, <xref rid="b0185" ref-type="bibr">Shi et al., 2015</xref>) explore the stochastic mechanism in the MRI generating process and model it with prior information; nevertheless, the design of a suitable regularization for the model can be difficult. Learning-based methods have the advantage of modeling and learning the mapping of low-quality images to high-quality images from data alone (<xref rid="b0005" ref-type="bibr">Alexander et al., 2014</xref>, <xref rid="b0205" ref-type="bibr">Yang et al., 2010</xref>, <xref rid="b0195" ref-type="bibr">Wang et al., 2014</xref>, <xref rid="b0090" ref-type="bibr">Jia et al., 2017</xref>). Recently, deep learning has shown impressive performance in the field of super-resolution of MRI (<xref rid="b0020" ref-type="bibr">Chen et al., 2018</xref>, <xref rid="b0160" ref-type="bibr">Pham et al., 2017</xref>, <xref rid="b0210" ref-type="bibr">Zhu et al., 2018</xref>, <xref rid="b0030" ref-type="bibr">Cherukuri et al., 2019</xref>, <xref rid="b0025" ref-type="bibr">Cherukuri et al., 2017</xref>).</p>
              <p id="p0035">In the present work, we assess the diagnostic utility of reduced-quality and deep learning enhanced images for hydrocephalus treatment planning. We focus on the most common form of infant hydrocephalus in sub-Saharan Africa – postinfectious (<xref rid="b0155" ref-type="bibr">Paulson et al., 2020</xref>). This form of hydrocephalus is uncommon outside of LMIC (<xref rid="b0040" ref-type="bibr">Dewan et al., 2018</xref>), and the only abundant high-resolution comparative images are from CT. We developed an image utility assessment which was completed by three senior neurosurgeons with extensive experience in the treatment and management of hydrocephalus in low-resource settings (<xref rid="b0105" ref-type="bibr">Kulkarni et al., 2017</xref>, <xref rid="b0155" ref-type="bibr">Paulson et al., 2020</xref>, <xref rid="b0175" ref-type="bibr">Schiff et al., 2021</xref>). Qualitative and quantitative measures of image utility are used to classify images revealing the quality threshold for treatment planning of hydrocephalus in terms of resolution, noise, and contrast between brain and CSF. We further evaluate how machine learning can lead to misleading modifications during the enhancement of low-resolution imagery.</p>
            </sec>
            <sec id="s0010">
              <label>2</label>
              <title>Methods</title>
              <p id="p0040">Three experienced pediatric neurosurgeons accustomed to working in LMIC, with particular experience in interpretation of postinfectious hydrocephalus imagery of African infants, were chosen as participants in the image utility assessment. CT images were acquired from a repository of 90 patients enrolled in an ongoing randomized clinical trial (median age of 3.1 months, 39% female <xref rid="b0105" ref-type="bibr">Kulkarni et al., 2017</xref>) and treated at the CURE Children’s Hospital of Uganda for post-infectious hydrocephalus. The center-most image slice from each patient was chosen for the assessment as either a test image (10 randomly selected, <xref rid="s0060" ref-type="sec">Fig. S5</xref>) or a learning library image (remaining 80). The images are 512 × 512 with 0.4 mm resolution (20.48 cm field of view). Each slice is 5 mm thick.</p>
              <p id="p0045">The 10 test images were degraded in terms of resolution, noise, and contrast between brain and CSF. Since the field of view remained constant for all images, resolution was adjusted by reducing the matrix size of the image. Because of this relationship, we adopt the term ”resolution” to describe changes in image matrix size for the present work. An image parameter space, as shown in <xref rid="f0010" ref-type="fig">Fig. 2A-B</xref>, was constructed consisting of the variables: 1) resolution (32 × 32, 64 × 64, 128 × 128, 512 × 512); 2) contrast reduction (20 levels between 0 and 1), 3) and noise added (20 levels between 0 and 1) resulting in 1,600 possible parameter combinations.<fig id="f0010"><label>Fig. 2</label><caption><p>Schematic of study. In A) the image parameter space describing all possible combinations of noise, contrast between brain and CSF, and image resolution are visualized. There is likely to be a region of parameter combinations yielding images which are useful for hydrocephalus treatment planning (green volume), a region of parameter combinations that are not useful (red volume), and a region of uncertainty in between (orange volume). In B) we show a single plane from image parameter space in which all images have 512 × 512 resolution. The lower right corner has maximum contrast between brain and CSF and least noise considered in this study and the upper left corner has the lowest contrast and most noise. In C) the starred image from panel B) is chosen to be enhanced with a single encoder dual decoder (SEDD) architecture following the DenseNet network described in (<xref rid="b0065" ref-type="bibr">Guo et al., 2019</xref>, <xref rid="b0030" ref-type="bibr">Cherukuri et al., 2019</xref>). The output of such enhancement is seen in the upper panel of D) with corresponding segmentation in the lower panel of D). The ground truth version of the enhancement and segmentation from the original image without degradation or enhancement is shown in E) and called “ground truth”.</p></caption><graphic xlink:href="gr2"/></fig></p>
              <p id="p0050">Resolution was down-sampled from the 512 × 512 image using bi-linear interpolation. The averaging between pixels in bi-linear interpolation can be considered an approximation of a partial volume effect.</p>
              <p id="p0055">Contrast between brain and CSF was reduced using histogram compression (<xref rid="s0060" ref-type="sec">Fig. S6</xref>), an algorithm developed specifically for this purpose. In histogram compression the histogram of gray-scale values for brain and CSF are iteratively compressed into a smaller gray-scale bandwidth to simulate loss in tissue contrast.</p>
              <p id="p0060">Gaussian noise with mean equal to variance was added according to known noise characteristics of CT images (<xref rid="b0045" ref-type="bibr">Diwakar and Kumar, 2018</xref>). Since lower resolution images are more sensitive to noise, the noise added was scaled by clinical inspection for each resolution so that both useful and not useful images would be represented. The noise variance added was scaled by resolution as follows and normalized to the maximum value: from 0 to 0.001 (32 × 32), 0 to 0.01 (64 × 64), 0 to 0.05 (128 × 128, and 0 to 0.13 (512 × 512).</p>
              <p id="p0065">In <xref rid="b0030" ref-type="bibr">Cherukuri et al., 2019</xref>, <xref rid="b0025" ref-type="bibr">Cherukuri et al., 2017</xref>, deep learning networks took advantage of low-rank structural prior information to enhance low quality images. Building on this work, we developed a deep learning network capable of simultaneously enhancing and segmenting CT images of infant hydrocephalus that have been artificially degraded. Following the DenseNet network described in <xref rid="b0070" ref-type="bibr">Guo et al. (2019)</xref>, a single encoder dual decoder (SEDD) architecture was used to enhance CT images that have reduced quality. Deep learning networks, as shown in <xref rid="f0010" ref-type="fig">Fig. 2C-E</xref>, were trained for two resolutions (64 × 64 and 128 × 128) at seven locations in parameter space using library images. With noise added as the x-coordinate and contrast reduction as the y-coordinate, networks were trained for both resolutions at: 1) (0.3,0.3), 2) (0.6,0.3), 3) (0.3,0.6), 4) (0.6,0.6), 5) (0.9,0.6), 6) (0.6,0.9), 7) (0.9,0.9) (<xref rid="s0060" ref-type="sec">Fig. S7</xref>). The least degraded network is network 1. The networks were built by degrading the 80 library images at each of the 14 network locations and training with the original non-degraded image as ground truth. After training, the 10 test images were degraded at the network locations and enhanced generating 140 deep learning enhanced images.</p>
              <p id="p0070">From the 1,600 parameter combinations applied to the 10 test images, 420 cases were randomly presented to the panel of experts along with all 140 deep learning enhanced images. The image utility assessment was divided into two parts. In Part 1, the images were shown in 140 panels of 4 images each, as shown in <xref rid="f0015" ref-type="fig">Fig. 3</xref>A. In each of the 140 panels, one image location was randomly selected for an enhanced image and the other three were degraded images. The expert was not told that there would be enhanced images. In each panel, the expert was asked to select which, if any, of the 4 images are clinically useful for planning hydrocephalus treatment (see Supplementary Methods for full instructions). The data from the three experts were combined by addition of scores for each image in order to be classified as useful, uncertain, or not useful. If all three experts agreed that an image was useful, this image received a 3 (i.e. Useful). If all experts agreed that an image was not useful this image received a 0 (i.e. Not Useful). Uncertain images received a score of either 1 or 2.<fig id="f0015"><label>Fig. 3</label><caption><p>The figure shows results from Part 1 of the Assessment. In A) we show an example panel from Part 1 of the assessment. The lower left image is an enhanced image and all other images are degraded. The experts must indicate which (if any) is useful. The left panel of B) shows raw classification data from Part 1 for 64 × 64 images. Solid lines are lines of constant contrast-to-noise ratio (CNR). Dashed lines show lines of constant usefulness likelihood from the multivariate logistic regression. The right panel of B) shows the receiver operating characteristic curves. In C) we show the univariate logistic regression models for each resolution with CNR as the predictor. The diamond and circle datapoints show the calculated CNR values for the low-field and high-field MRI images shown in <xref rid="f0005" ref-type="fig">Fig. 1</xref>, respectively. Resolution for these images lie between the 128 × 128 and 512 × 512 curves, which overlap for the CNR values reported. The bottom four panels of C) show the raw classification data for each resolution.</p></caption><graphic xlink:href="gr3"/></fig></p>
              <p id="p0075">In Part 2, the experts were shown enhanced images in a side-by-side comparison with their corresponding 512 × 512 non-degraded versions as seen in <xref rid="f0020" ref-type="fig">Fig. 4</xref>A. The experts were asked to assess whether the spatial errors in the enhanced version were acceptable or would alter treatment decisions (see Supplementary Methods for full instructions). The data from Part 2 were also combined by addition of scores. Part 2 enhanced images receiving a 3 were classified as useful (i.e. useful in both Part1 and Part2), those receiving a 1 or 2 were classified as uncertain, and those receiving a 0 were classified as misleading (i.e. useful in Part 1, but shown to have unacceptable error in Part 2).<fig id="f0020"><label>Fig. 4</label><caption><p>The figure shows results from Part 2 of the assessment. A) An example panel from Part 2 of the assessment. The left column of images are ground truth and the right column are the enhanced versions. B) shows the usefulness likelihood curves based on image CNR. The triangles show the average CNR for each network location before enhancement and the circles show the average CNR for each network after enhancement. C) shows the predicted usefulness likelihood of the enhanced images based on CNR after enhancement, the actual Part 1 classification of the enhanced images, and the Part 2 re-classification of the enhanced images after comparison with ground truth. In D) we compare the usefulness likelihood of the degraded images with the risk of a misleading result if the image is enhanced for 128 × 128 images. The left vertical axis shows the usefulness likelihood of the degraded image and the right vertical axis shows the risk of a misleading result if the corresponding degraded image were enhanced. In D) we also show an example degraded image on the left with CNR  = 1, the enhanced version of this image on the right with CNR` = 8 after enhancement and corresponding high likelihood of misleading results after enhancement. Finally, E) shows the ground truth version of the example image in D) for comparison.</p></caption><graphic xlink:href="gr4"/></fig></p>
              <p id="p0080">In addition, an analysis of inter-rater reliability was performed using a variation of Cohen’s Kappa, as described in <xref rid="b0015" ref-type="bibr">Byrt et al. (1993)</xref>, which accounts for the existence of prevalence in the data and bias between evaluators (see Supplementary Methods). For this analysis, the data was divided into three parts: 1) classification of Part1 degraded images, 2) classification of Part 1 enhanced images, and 3) classification of Part 2 enhanced images. The Kappa statistic of <xref rid="b0015" ref-type="bibr">Byrt et al. (1993)</xref> was calculated for all possible pairings of evaluators and conclusions regarding agreement were drawn based on the interpretation of Kappa values as suggested in <xref rid="b0015" ref-type="bibr">Byrt et al., 1993</xref>, <xref rid="b0075" ref-type="bibr">Hallgren, 2012</xref>.</p>
              <p id="p0085">Univariate and multivariate logistic regression was used to investigate the ability of contrast, noise, and contrast-to-noise ratio to predict image classification. A deviance statistic was used to assess goodness of fit of the logistic regression models. The deviance of the model is a chi-squared statistic which assesses the difference between the maximum log likelihood of the chosen model and that of the null model (i.e. the average probability of a classification at a given resolution being useful).</p>
            </sec>
            <sec id="s0015">
              <label>3</label>
              <title>Results</title>
              <sec id="s0020">
                <label>3.1</label>
                <title>Part 1: What makes an image useful?</title>
                <p id="p0090">We first characterize the relationship between resolution, contrast, noise and usefulness. The inter-rater reliability for the classification of degraded images shows fair agreement between evaluators 1 and 2 (K  = 0.33), substantial agreement between evaluators 2 and 3 (K  = 0.94), and fair agreement between evaluators 1 and 3 (K  = 0.36). For all three evaluators, there was a high prevalence for classifying Part 1 enhanced images as being useful (see Supplementary results). As such, inter-rater reliability calculations for this data are not informative and all evaluators are in near perfect agreement. In <xref rid="f0015" ref-type="fig">Fig. 3</xref>A we show several degraded images, of which the lower left is enhanced by deep learning. The left panel of <xref rid="f0015" ref-type="fig">Fig. 3</xref>B shows how the contrast and noise of each image relates to the image classification determinations at 64 × 64 resolution (see <xref rid="s0060" ref-type="sec">Fig. S10</xref> for full dataset results). The solid contour lines in <xref rid="f0015" ref-type="fig">Fig. 3</xref>B show lines of constant contrast-to-noise ratio between brain and CSF averaged from the full dataset of images. In comparison, the dotted lines show constant usefulness likelihood based upon a multivariate logistic regression model with contrast and noise as predictors. For images with each of the four resolutions considered, the multivariate logistic regression model provided a significant fit with p-values less than 0.01 (p<sub>32 × 32</sub> = 7e-6, p<sub>64 × 64</sub> = 4e-27, p<sub>128 × 128</sub> = 2e-17, p<sub>512 × 512</sub> = 8e-32). Note that there is qualitative agreement between the average contrast-to-noise contours and the lines of constant likelihood that the image is useful. On the right of <xref rid="f0015" ref-type="fig">Fig. 3</xref>B receiver operating characteristic curves demonstrate that average contrast-to-noise and likelihood are both comparably effective classifiers of image utility with areas under their curves  &gt; 0.85 (curves for full dataset in <xref rid="s0060" ref-type="sec">Fig. S11</xref>).</p>
                <p id="p0095">Since average contrast-to-noise appeared to be an effective classifier, <xref rid="f0015" ref-type="fig">Fig. 3</xref>C shows that individual image contrast-to-noise alone is a significant predictor of usefullness likelihood, stratified by resolution. The grey circle shows the usefullness likelihood of the 256 × 256 brain image from the 3 Tesla system in <xref rid="f0005" ref-type="fig">Fig. 1</xref>A based on its contrast-to-noise ratio (CNR = 13). The grey diamond shows the same for the 128 × 128 brain image from the 0.05 Tesla system in <xref rid="f0005" ref-type="fig">Fig. 1</xref>B (CNR = 4). Though the image generated by the 3T system has twice the resolution and 3 times the CNR, both share a predicted usefulness likelihood of 1. For each resolution, the raw classification data from Part 1 can be seen in the four inset panels of <xref rid="f0015" ref-type="fig">Fig. 3</xref>C. The solid lines show the logistic regression model and the dashed lines show the 95% confidence intervals around the fit.</p>
              </sec>
              <sec id="s0025">
                <label>3.2</label>
                <title>Part 2: Is reconstruction error acceptable?</title>
                <p id="p0100">Next we investigate the effect of deep learning enhancement on image classification. The inter-rater reliability for the classification of enhanced images in Part 2 shows slight agreement between evaluators 1 and 2 (K  = 0.15), fair agreement between evaluators 2 and 3 (K  = 0.24), and moderate agreement between evaluators 1 and 3 (K  = 0.48). <xref rid="f0020" ref-type="fig">Fig. 4</xref>A shows a side by side comparison of ground truth (left column) with corresponding enhanced images (right column). Note the subtle errors in brain and CSF locations in the top right image and the more substantial errors in the lower right image. Regardless of these spatial errors, CNR is significantly increased by the enhancement network, as shown in the plot in <xref rid="f0020" ref-type="fig">Fig. 4</xref>B where average CNR of test images at each network location are shown before and after enhancement using the logistic models developed in Part 1. These data predict very high usefulness likelihood for enhanced images based on increased CNR. The table in <xref rid="f0020" ref-type="fig">Fig. 4</xref>C shows that while the Part 1 classification of enhanced images does closely follow the prediction of high usefulness likelihood, re-classification of enhanced images in Part 2 reveals that many enhanced images contain errors that are not clinically acceptable. We use an additional classification of Misleading for these images (i.e. images that were deemed Useful in Part 1, but had unacceptable errors in Part 2).</p>
                <p id="p0105">Since the logistic models developed in Part 1 do not describe the Part 2 classification, a new logistic regression model was constructed for Part 2 with pre-enhancement noise and contrast of images as predictors. Only contrast showed significance (<xref rid="s0060" ref-type="sec">Figs. S13 and S14</xref>) so noise was removed from the model. In order to compare the usefulness likelihood of a degraded image (Part 1) with the risk of misleading errors in an enhanced image (Part 2), an additional logistic regression model with CNR as the predictor was computed based on Part 2 classification (<xref rid="f0020" ref-type="fig">Fig. 4</xref>D). Risk of misleading results is calculated to be 1 minus the usefulness likelihood of the enhanced images based on a univariate logistic regression with CNR prior to enhancement as the predictor. As CNR increases, a 128 × 128 image is more likely to be useful in its degraded state (left vertical axis) and less likely to be misleading if enhanced (right vertical axis). Note that there exists no CNR value for which there is low usefulness likelihood of the degraded image <italic>and</italic> low risk of generating a misleading image through enhancement.</p>
              </sec>
            </sec>
            <sec id="s0030">
              <label>4</label>
              <title>Discussion</title>
              <sec id="s0035">
                <label>4.1</label>
                <title>Utility of Low CNR Images</title>
                <p id="p0110">The image quality threshold required for treatment planning of hydrocephalus is significantly lower than the quality typically provided by CT or high-field MRI imaging systems. The results in <xref rid="f0015" ref-type="fig">Fig. 3</xref>B-C can be viewed in several different ways. CNR is a comparison between the signal-to-noise ratio of two regions of interest. This implies that the true limiting factor of image quality is per voxel signal-to-noise, for which high-field MRI has an inherent advantage over low-field MRI. However, <xref rid="f0015" ref-type="fig">Fig. 3</xref>B-C suggests that there are options for using low CNR or low resolution images that may be advantageous. For a high-field system imaging infant hydrocephalus, a short scan time is desirable, in which case resolution and signal-to-noise can be traded for a faster scan. Alternatively, in the resource limited setting of an LMIC, a low-field MRI system has the potential to provide equivalent diagnostic information at a significant reduction in cost and complexity. The trade-off for this low cost and complexity is lower signal-to-noise and interpretability. It is the interpretability that sets the threshold for the lower bound of signal-to-noise.</p>
                <p id="p0115">The usefulness likelihood for the 3T (CNR  = 13) and 0.05 T (CNR  = 4) MRI images without deep learning enhancement featured in <xref rid="f0005" ref-type="fig">Fig. 1</xref> are indicated in <xref rid="f0015" ref-type="fig">Fig. 3</xref>C. Although the visual quality of the two images is strikingly different, they are predicted to have the same utility for hydrocephalus treatment planning.</p>
                <p id="p0120">To put this in the context of global sustainability, the acquisition cost of the 0.05 T system used for producing the image in <xref rid="f0005" ref-type="fig">Fig. 1</xref>B is less than $20,000 USD. A 3T system costs at least an additional $2.8 million USD (excluding siting, maintenance, and consumables) and it can provide over three times the CNR (<xref rid="f0005" ref-type="fig">Fig. 1</xref>A). However, for the cost of a single 3T system, 150 low-field MRI systems could be placed throughout the region, providing increased access to the hydrocephalus patient population without compromise in diagnostic utility.</p>
                <p id="p0125">In addition to being a substantial global health need for children’s medicine, hydrocephalus is also an exceptionally straightforward technical challenge for low-field MRI systems. In the vast majority of hydrocephalic children, there is no need to differentiate contrast within the brain parenchyma for diagnosis, triage, monitoring, or treatment planning. For MRI the signal strength from the water-based CSF is the strongest signal within the head. Although our results support substantial utility from images with reduced quality in hydrocephalus management, more complex diagnostic and treatment decision-making in other diseases will pose additional challenges to such technologies.</p>
              </sec>
              <sec id="s0040">
                <label>4.2</label>
                <title>Enhanced Images: Benefit or risk?</title>
                <p id="p0130">Image enhancement appears to perform exceptionally well based on Part 1 data, as shown in <xref rid="f0020" ref-type="fig">Fig. 4</xref>A where even the worst network locations are more than 85% likely to be rendered useful. However, data from Part 2 reveals that enhancement yields images that appear useful, but in fact would mislead treatment decisions due to unacceptable errors in brain and CSF location. Subtle features in the configuration of the CSF spaces, such as increased rounding of brain ventricles, are important signs of increased intracranial pressure suggesting that surgery might be required to improve CSF diversion through a shunt or endoscopic fenestration. If features such as these are a product of the enhancement network and not indicative of the true condition of the disease, clinicians may be led to make poor treatment decisions.</p>
                <p id="p0135">The key difference in using a degraded image versus its enhanced counterpart in a clinical setting is the source of risk. A degraded image is either useful or it is not - the risk of using it to diagnose or treat disease rests with the judgement of the clinician. Enhanced images in this study yield useful looking images 99% of the time, however 75% of these images are shown to have uncertain utility or to be misleading after comparison with ground truth. The risk of enhancement arises from the black box of the deep learning network. Furthermore, as shown in <xref rid="f0020" ref-type="fig">Fig. 4</xref>D, there is never a CNR for which there is low risk of producing a misleading image and low usefulness likelihood of the degraded image without enhancement. For example, a 128 × 128 degraded image with modest CNR yielding 75% usefulness likelihood still has a 14% chance of producing a misleading image through enhancement. Enhancing highly degraded images can improve the usefulness likelihood, but with substantially increased risk of misleading results. We find no scenario in which enhancement is safely beneficial. Note also that the CNR of the 0.05 T system studied had a very high useful likelihood and would not have required enhancement. Yet acceptance of such unenhanced images as shown in <xref rid="f0005" ref-type="fig">Fig. 1</xref>B would constitute a cultural shift in current standards of diagnostic acceptability.</p>
                <p id="p0140">Machine learning can generate attractive images from patterns with highly degraded information content. Philosophically, a learning library of other patient images enables utilization of information not present in the individual case undergoing enhancement. Such learned information brought to a new case image can be clinically misleading. This is a very different situation from machine learning faces or objects, or diagnosis classification from images, where there is only one correct match and the information required is already in the learning library. Hydrocephalus, as in so many other pathological conditions, tends to produce a unique structural pattern for each patient. For machine learning, automating the choice of a diagnosis is therefore very different from reconstructing an unknown unique architecture. This fundamental issue implies that while this study only employed one learning network architecture, this risk likely exists in other machine learning strategies and great care should be taken when employing these methods for anatomic reconstruction. A challenge for the machine learning community working with low-resolution and low-contrast images is to improve interpretation while minimizing risk of clinical errors.</p>
              </sec>
              <sec id="s0045">
                <label>4.3</label>
                <title>Limitations</title>
                <p id="p0145">This study has limitations. Only three experts participated in the assessment. The single central slice from the image stack was chosen to demonstrate image quality and enhancement. Only image quality concerns inherent to low-field systems such as noise and contrast were considered, while distortions in the low-field image were not. Only one deep learning network architecture was employed and the number of training samples was relatively low (80). However, the size of available image archives is typically not large for diseases unique to LMIC such as post-infectious hydrocephalus in sub-Saharan Africa. A more complex machine learning strategy could incorporate a 3D array of connected slices for enhancement and clinical review.</p>
                <p id="p0150">Although motivation for this study stems from the advent of clinical low-field MRI as a tool for hydrocephalus treatment planning, the work was conducted with CT images. In high-resource settings where low-field MRI is being deployed (such as intensive care units), CT remains the high-resolution alternative of choice (<xref rid="bib211" ref-type="bibr">Mazurek et al., 2021</xref>, <xref rid="b0180" ref-type="bibr">Sheth et al., 2020</xref>). CT is the high-resolution modality most available in LMIC, and currently the only available repository of postinfectious hydrocephalus images where low-field MRI will soon be deployed. Note that we argue the potential benefits of low-field MRI using only one example image in <xref rid="f0005" ref-type="fig">Fig. 1</xref>B. This can be extended in the future as reliable low-field MR image repositories become available such as the new comparative repository in Adult stroke reported in (<xref rid="bib211" ref-type="bibr">Mazurek et al., 2021</xref>). We anticipate that this quantifiable measure of CNR between brain and CSF will be generalizable to MRI at various field strengths as well as other CT studies of infant hydrocephalus treatment planning. Further evaluation will be necessary to determine whether CNR proves an important classifier for other conditions that may have more stringent image quality requirements.</p>
              </sec>
            </sec>
            <sec id="s0050">
              <label>5</label>
              <title>Conclusion</title>
              <p id="p0155">The true value of a clinical medical image is in the treatment guiding information that it conveys to those providing care and in the patient outcomes that result, rather than its visual appeal. We have shown that lower quality images that are not customarily considered acceptable can be useful in planning hydrocephalus treatment. In addition, image resolution and contrast-to-noise ratio of brain and CSF predict the likelihood of a useful image for hydrocephalus treatment planning. Although deep learning can dramatically improve the visual quality of a highly degraded image, there is a substantial risk of misleading results, and algorithmic guidelines should be developed to avoid structural alterations which are potentially hazardous to clinical interpretation. At present, the most valuable low-resolution images may be less enhanced versions that maintain the structural details undistorted by excessive deep learning processing; indeed, emerging low-field MRI technologies are capable of producing useful images for hydrocephalus treatment planning without enhancement. Our findings advocate for new standards in assessing the cost-effectiveness of sustainable imaging technologies that can broaden global access to diagnostic imaging, and a reconsideration of acceptable image quality for clinical use.</p>
            </sec>
            <sec id="s0070">
              <title>CRediT authorship contribution statement</title>
              <p id="p0165"><bold>Joshua R. Harper:</bold> Conceptualization, Methodology, Software, Validation, Formal analysis, Investigation, Writing - original draft, Writing - review &amp; editing, Visualization. <bold>Venkateswararao Cherukuri:</bold> Conceptualization, Methodology, Software, Validation, Formal analysis, Investigation, Writing - original draft, Writing - review &amp; editing, Visualization. <bold>Tom O’Reilly:</bold> Conceptualization, Resources, Writing - review &amp; editing, Visualization. <bold>Mingzhao Yu:</bold> Writing - original draft, Writing - review &amp; editing. <bold>Edith Mbabazi-Kabachelor:</bold> Resources, Writing - review &amp; editing. <bold>Ronald Mulando:</bold> Resources, Writing - review &amp; editing. <bold>Kevin N. Sheth:</bold> Writing - review &amp; editing, Conceptualization. <bold>Andrew G. Webb:</bold> Writing - review &amp; editing, Conceptualization. <bold>Benjamin C. Warf:</bold> Writing - review &amp; editing, Conceptualization, Resources. <bold>Abhaya V. Kulkarni:</bold> Writing - review &amp; editing, Conceptualization, Resources. <bold>Vishal Monga:</bold> Writing - review &amp; editing, Conceptualization, Methodology, Supervision. <bold>Steven J. Schiff:</bold> Writing - review &amp; editing, Writing - original draft, Conceptualization, Supervision, Project administration, Funding acquisition.</p>
            </sec>
            <sec sec-type="COI-statement">
              <title>Declaration of Competing Interest</title>
              <p id="p0170">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p>
            </sec>
          </body>
          <back>
            <ref-list id="bi005">
              <title>References</title>
              <ref id="b0005">
                <element-citation publication-type="book" id="h0005">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Alexander</surname>
                      <given-names>D.C.</given-names>
                    </name>
                    <name>
                      <surname>Zikic</surname>
                      <given-names>D.</given-names>
                    </name>
                    <name>
                      <surname>Zhang</surname>
                      <given-names>J.</given-names>
                    </name>
                    <name>
                      <surname>Zhang</surname>
                      <given-names>H.</given-names>
                    </name>
                    <name>
                      <surname>Criminisi</surname>
                      <given-names>A.</given-names>
                    </name>
                  </person-group>
                  <part-title>Image quality transfer via random forest regression: applications in diffusion MRI</part-title>
                  <source>International Conference on Medical Image Computing and Computer-Assisted Intervention</source>
                  <year>2014</year>
                  <publisher-name>Springer</publisher-name>
                  <fpage>225</fpage>
                  <lpage>232</lpage>
                </element-citation>
              </ref>
              <ref id="b0010">
                <element-citation publication-type="journal" id="h0010">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Brenner</surname>
                      <given-names>D.J.</given-names>
                    </name>
                    <name>
                      <surname>Eric</surname>
                      <given-names>J.</given-names>
                    </name>
                  </person-group>
                  <article-title>Hall. Computed tomography–an increasing source of radiation exposure</article-title>
                  <source>N. Engl. J. Med.</source>
                  <volume>357</volume>
                  <issue>22</issue>
                  <year>2007</year>
                  <fpage>2277</fpage>
                  <lpage>2284</lpage>
                  <pub-id pub-id-type="pmid">18046031</pub-id>
                </element-citation>
              </ref>
              <ref id="b0015">
                <element-citation publication-type="journal" id="h0015">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Byrt</surname>
                      <given-names>T.</given-names>
                    </name>
                    <name>
                      <surname>Bishop</surname>
                      <given-names>J.</given-names>
                    </name>
                    <name>
                      <surname>Carlin</surname>
                      <given-names>J.B.</given-names>
                    </name>
                  </person-group>
                  <article-title>Bias, prevalence and kappa</article-title>
                  <source>J. Clinical Epidemiol.</source>
                  <volume>46</volume>
                  <issue>5</issue>
                  <year>1993</year>
                  <fpage>423</fpage>
                  <lpage>429</lpage>
                  <pub-id pub-id-type="pmid">8501467</pub-id>
                </element-citation>
              </ref>
              <ref id="b0020">
                <mixed-citation publication-type="other" id="h0020">Chen, Y., Y. Xie, Z. Zhou, F. Shi, A.G. Christodoulou, and D. Li (2018) ”Brain MRI super resolution using 3D deep densely connected neural networks,” in 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018), IEEE, pp. 739–742.</mixed-citation>
              </ref>
              <ref id="b0025">
                <element-citation publication-type="journal" id="h0025">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Cherukuri</surname>
                      <given-names>V.</given-names>
                    </name>
                    <name>
                      <surname>Ssenyonga</surname>
                      <given-names>P.</given-names>
                    </name>
                    <name>
                      <surname>Warf</surname>
                      <given-names>B.C.</given-names>
                    </name>
                    <name>
                      <surname>Kulkarni</surname>
                      <given-names>A.V.</given-names>
                    </name>
                    <name>
                      <surname>Monga</surname>
                      <given-names>V.</given-names>
                    </name>
                    <name>
                      <surname>Schiff</surname>
                      <given-names>S.J.</given-names>
                    </name>
                  </person-group>
                  <article-title>Learning based segmentation of CT brain images: application to postoperative hydrocephalic scans</article-title>
                  <source>IEEE Trans. Biomed. Eng.</source>
                  <volume>65</volume>
                  <issue>8</issue>
                  <year>2017</year>
                  <fpage>1871</fpage>
                  <lpage>1884</lpage>
                  <pub-id pub-id-type="pmid">29989926</pub-id>
                </element-citation>
              </ref>
              <ref id="b0030">
                <element-citation publication-type="journal" id="h0030">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Cherukuri</surname>
                      <given-names>V.</given-names>
                    </name>
                    <name>
                      <surname>Guo</surname>
                      <given-names>T.</given-names>
                    </name>
                    <name>
                      <surname>Schiff</surname>
                      <given-names>S.J.</given-names>
                    </name>
                    <name>
                      <surname>Monga</surname>
                      <given-names>V.</given-names>
                    </name>
                  </person-group>
                  <article-title>Deep MR Brain Image Super-Resolution Using Spatio-Structural Priors</article-title>
                  <source>IEEE Trans. Image Process.</source>
                  <volume>29</volume>
                  <year>2019</year>
                  <fpage>1368</fpage>
                  <lpage>1383</lpage>
                </element-citation>
              </ref>
              <ref id="b0035">
                <element-citation publication-type="journal" id="h0035">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Cooley</surname>
                      <given-names>C.Z.</given-names>
                    </name>
                    <name>
                      <surname>McDaniel</surname>
                      <given-names>P.C.</given-names>
                    </name>
                    <name>
                      <surname>Stockmann</surname>
                      <given-names>J.P.</given-names>
                    </name>
                    <name>
                      <surname>Srinivas</surname>
                      <given-names>S.A.</given-names>
                    </name>
                    <name>
                      <surname>Cauley</surname>
                      <given-names>S.F.</given-names>
                    </name>
                    <name>
                      <surname>Śliwiak</surname>
                      <given-names>M.</given-names>
                    </name>
                    <name>
                      <surname>Sappo</surname>
                      <given-names>C.R.</given-names>
                    </name>
                    <name>
                      <surname>Vaughn</surname>
                      <given-names>C.F.</given-names>
                    </name>
                    <name>
                      <surname>Guerin</surname>
                      <given-names>B.</given-names>
                    </name>
                    <name>
                      <surname>Rosen</surname>
                      <given-names>M.S.</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>A portable scanner for magnetic resonance imaging of the brain</article-title>
                  <source>Nature Biomed. Eng.</source>
                  <volume>5</volume>
                  <issue>3</issue>
                  <year>2021</year>
                  <fpage>229</fpage>
                  <lpage>239</lpage>
                  <pub-id pub-id-type="pmid">33230306</pub-id>
                </element-citation>
              </ref>
              <ref id="b0040">
                <element-citation publication-type="journal" id="h0040">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Dewan</surname>
                      <given-names>M.C.</given-names>
                    </name>
                    <name>
                      <surname>Rattani</surname>
                      <given-names>A.</given-names>
                    </name>
                    <name>
                      <surname>Mekary</surname>
                      <given-names>R.</given-names>
                    </name>
                    <name>
                      <surname>Glancz</surname>
                      <given-names>L.J.</given-names>
                    </name>
                    <name>
                      <surname>Yunusa</surname>
                      <given-names>I.</given-names>
                    </name>
                    <name>
                      <surname>Baticulon</surname>
                      <given-names>R.E.</given-names>
                    </name>
                    <name>
                      <surname>Fieggen</surname>
                      <given-names>G.</given-names>
                    </name>
                    <name>
                      <surname>Wellons</surname>
                      <given-names>J.C.</given-names>
                    </name>
                    <name>
                      <surname>Park</surname>
                      <given-names>K.B.</given-names>
                    </name>
                    <name>
                      <surname>Warf</surname>
                      <given-names>B.C.</given-names>
                    </name>
                  </person-group>
                  <article-title>Global hydrocephalus epidemiology and incidence: systematic review and meta-analysis</article-title>
                  <source>J. Neurosurg.</source>
                  <volume>130</volume>
                  <issue>4</issue>
                  <year>2018</year>
                  <fpage>1065</fpage>
                  <lpage>1079</lpage>
                </element-citation>
              </ref>
              <ref id="b0045">
                <element-citation publication-type="journal" id="h0045">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Diwakar</surname>
                      <given-names>M.</given-names>
                    </name>
                    <name>
                      <surname>Kumar</surname>
                      <given-names>M.</given-names>
                    </name>
                  </person-group>
                  <article-title>A review on CT image noise and its denoising</article-title>
                  <source>Biomed. Signal Process. Control</source>
                  <volume>42</volume>
                  <year>2018</year>
                  <fpage>73</fpage>
                  <lpage>88</lpage>
                </element-citation>
              </ref>
              <ref id="b0050">
                <element-citation publication-type="journal" id="h0050">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Durand</surname>
                      <given-names>D.J.</given-names>
                    </name>
                    <name>
                      <surname>Carrino</surname>
                      <given-names>J.A.</given-names>
                    </name>
                    <name>
                      <surname>Fayad</surname>
                      <given-names>L.M.</given-names>
                    </name>
                    <name>
                      <surname>Huisman</surname>
                      <given-names>T.A.</given-names>
                    </name>
                    <name>
                      <surname>El-Sharkawy</surname>
                      <given-names>A.-M.M.</given-names>
                    </name>
                    <name>
                      <surname>Edelstein</surname>
                      <given-names>W.A.</given-names>
                    </name>
                  </person-group>
                  <article-title>MRI pyschophysics: An experimental framework relating image quality to diagnostic performance metrics</article-title>
                  <source>J. Magn. Reson. Imaging</source>
                  <volume>37</volume>
                  <issue>6</issue>
                  <year>2013</year>
                  <fpage>1402</fpage>
                  <lpage>1408</lpage>
                  <pub-id pub-id-type="pmid">23172743</pub-id>
                </element-citation>
              </ref>
              <ref id="b0055">
                <element-citation publication-type="journal" id="h0055">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Frush</surname>
                      <given-names>D.P.</given-names>
                    </name>
                    <name>
                      <surname>Donnelly</surname>
                      <given-names>L.F.</given-names>
                    </name>
                    <name>
                      <surname>Rosen</surname>
                      <given-names>N.S.</given-names>
                    </name>
                  </person-group>
                  <article-title>Computed tomography and radiation risks: what pediatric health care providers should know</article-title>
                  <source>Pediatrics</source>
                  <volume>112</volume>
                  <issue>4</issue>
                  <year>2003</year>
                  <fpage>951</fpage>
                  <lpage>957</lpage>
                  <pub-id pub-id-type="pmid">14523191</pub-id>
                </element-citation>
              </ref>
              <ref id="b0060">
                <element-citation publication-type="journal" id="h0060">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Gatrad</surname>
                      <given-names>A.</given-names>
                    </name>
                    <name>
                      <surname>Gatrad</surname>
                      <given-names>S.</given-names>
                    </name>
                    <name>
                      <surname>Gatrad</surname>
                      <given-names>A.</given-names>
                    </name>
                  </person-group>
                  <article-title>Equipment donation to developing countries</article-title>
                  <source>Anaesthesia</source>
                  <volume>62</volume>
                  <year>2007</year>
                  <fpage>90</fpage>
                  <lpage>95</lpage>
                </element-citation>
              </ref>
              <ref id="b0065">
                <element-citation publication-type="book" id="h0065">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Guo</surname>
                      <given-names>T.</given-names>
                    </name>
                    <name>
                      <surname>Cherukuri</surname>
                      <given-names>V.</given-names>
                    </name>
                    <name>
                      <surname>Monga</surname>
                      <given-names>V.</given-names>
                    </name>
                  </person-group>
                  <part-title>Dense123’color enhancement dehazing network</part-title>
                  <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</source>
                  <year>2019</year>
                </element-citation>
              </ref>
              <ref id="b0070">
                <element-citation publication-type="book" id="h0070">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Guo</surname>
                      <given-names>T.</given-names>
                    </name>
                    <name>
                      <surname>Li</surname>
                      <given-names>X.</given-names>
                    </name>
                    <name>
                      <surname>Cherukuri</surname>
                      <given-names>V.</given-names>
                    </name>
                    <name>
                      <surname>Monga</surname>
                      <given-names>V.</given-names>
                    </name>
                  </person-group>
                  <part-title>Dense scene information estimation network for dehazing</part-title>
                  <source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</source>
                  <year>2019</year>
                </element-citation>
              </ref>
              <ref id="b0075">
                <element-citation publication-type="journal" id="h0075">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Hallgren</surname>
                      <given-names>K.A.</given-names>
                    </name>
                  </person-group>
                  <article-title>Computing inter-rater reliability for observational data: an overview and tutorial</article-title>
                  <source>Tutorials Quantitative Methods Psychol.</source>
                  <volume>8</volume>
                  <issue>1</issue>
                  <year>2012</year>
                  <fpage>23</fpage>
                </element-citation>
              </ref>
              <ref id="b0080">
                <element-citation publication-type="journal" id="h0080">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Jack</surname>
                      <given-names>J.C.</given-names>
                    </name>
                    <name>
                      <surname>Berquist</surname>
                      <given-names>T.H.</given-names>
                    </name>
                    <name>
                      <surname>Miller</surname>
                      <given-names>G.M.</given-names>
                    </name>
                    <name>
                      <surname>Forbes</surname>
                      <given-names>G.S.</given-names>
                    </name>
                    <name>
                      <surname>Gray</surname>
                      <given-names>J.E.</given-names>
                    </name>
                    <name>
                      <surname>Morin</surname>
                      <given-names>R.L.</given-names>
                    </name>
                    <name>
                      <surname>Ilstrup</surname>
                      <given-names>D.M.</given-names>
                    </name>
                  </person-group>
                  <article-title>Field strength in neuro-MR imaging: a comparison of 0.5 T and 1.5 T</article-title>
                  <source>J. Computer Assisted Tomography</source>
                  <volume>14</volume>
                  <issue>4</issue>
                  <year>1990</year>
                  <fpage>505</fpage>
                  <lpage>513</lpage>
                </element-citation>
              </ref>
              <ref id="b0085">
                <element-citation publication-type="journal" id="h0085">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Jhaveri</surname>
                      <given-names>K.</given-names>
                    </name>
                  </person-group>
                  <article-title>Image quality versus outcomes</article-title>
                  <source>J. Magn. Reson. Imaging</source>
                  <volume>41</volume>
                  <issue>4</issue>
                  <year>2015</year>
                  <fpage>866</fpage>
                  <lpage>869</lpage>
                  <pub-id pub-id-type="pmid">24677391</pub-id>
                </element-citation>
              </ref>
              <ref id="b0090">
                <element-citation publication-type="journal" id="h0090">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Jia</surname>
                      <given-names>Y.</given-names>
                    </name>
                    <name>
                      <surname>Gholipour</surname>
                      <given-names>A.</given-names>
                    </name>
                    <name>
                      <surname>He</surname>
                      <given-names>Z.</given-names>
                    </name>
                    <name>
                      <surname>Warfield</surname>
                      <given-names>S.K.</given-names>
                    </name>
                  </person-group>
                  <article-title>A new sparse representation framework for reconstruction of an isotropic high spatial resolution MR volume from orthogonal anisotropic resolution scans</article-title>
                  <source>IEEE Trans. Med. Imaging</source>
                  <volume>36</volume>
                  <issue>5</issue>
                  <year>2017</year>
                  <fpage>1182</fpage>
                  <lpage>1193</lpage>
                  <pub-id pub-id-type="pmid">28129152</pub-id>
                </element-citation>
              </ref>
              <ref id="b0100">
                <element-citation publication-type="book" id="h0100">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Klein</surname>
                      <given-names>H.-M.</given-names>
                    </name>
                  </person-group>
                  <part-title>clinical low field strength magnetic resonance imaging: a practical guide to accessible MRI</part-title>
                  <year>2015</year>
                  <publisher-name>Springer</publisher-name>
                </element-citation>
              </ref>
              <ref id="b0105">
                <element-citation publication-type="journal" id="h0105">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Kulkarni</surname>
                      <given-names>A.V.</given-names>
                    </name>
                    <name>
                      <surname>Schiff</surname>
                      <given-names>S.J.</given-names>
                    </name>
                    <name>
                      <surname>Mbabazi-Kabachelor</surname>
                      <given-names>E.</given-names>
                    </name>
                    <name>
                      <surname>Mugamba</surname>
                      <given-names>J.</given-names>
                    </name>
                    <name>
                      <surname>Ssenyonga</surname>
                      <given-names>P.</given-names>
                    </name>
                    <name>
                      <surname>Donnelly</surname>
                      <given-names>R.</given-names>
                    </name>
                    <name>
                      <surname>Levenbach</surname>
                      <given-names>J.</given-names>
                    </name>
                    <name>
                      <surname>Monga</surname>
                      <given-names>V.</given-names>
                    </name>
                    <name>
                      <surname>Peterson</surname>
                      <given-names>M.</given-names>
                    </name>
                    <name>
                      <surname>MacDonald</surname>
                      <given-names>M.</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Endoscopic treatment versus shunting for infant hydrocephalus in Uganda</article-title>
                  <source>N. Engl. J. Med.</source>
                  <volume>377</volume>
                  <issue>25</issue>
                  <year>2017</year>
                  <fpage>2456</fpage>
                  <lpage>2464</lpage>
                  <pub-id pub-id-type="pmid">29262276</pub-id>
                </element-citation>
              </ref>
              <ref id="b0110">
                <element-citation publication-type="journal" id="h0110">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Lee</surname>
                      <given-names>D.H.</given-names>
                    </name>
                    <name>
                      <surname>Vellet</surname>
                      <given-names>A.D.</given-names>
                    </name>
                    <name>
                      <surname>Eliasziw</surname>
                      <given-names>M.</given-names>
                    </name>
                    <name>
                      <surname>Vidito</surname>
                      <given-names>L.</given-names>
                    </name>
                    <name>
                      <surname>Ebers</surname>
                      <given-names>G.C.</given-names>
                    </name>
                    <name>
                      <surname>Rice</surname>
                      <given-names>G.P.</given-names>
                    </name>
                    <name>
                      <surname>Hewett</surname>
                      <given-names>L.</given-names>
                    </name>
                    <name>
                      <surname>Dunlavy</surname>
                      <given-names>S.</given-names>
                    </name>
                  </person-group>
                  <article-title>MR imaging field strength: prospective evaluation of the diagnostic accuracy of MR for diagnosis of multiple sclerosis at 0.5 and 1.5 T</article-title>
                  <source>Radiology</source>
                  <volume>194</volume>
                  <issue>1</issue>
                  <year>1995</year>
                  <fpage>257</fpage>
                  <lpage>262</lpage>
                  <pub-id pub-id-type="pmid">7997564</pub-id>
                </element-citation>
              </ref>
              <ref id="b0115">
                <element-citation publication-type="journal" id="h0115">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Lehmann</surname>
                      <given-names>T.M.</given-names>
                    </name>
                    <name>
                      <surname>Gonner</surname>
                      <given-names>C.</given-names>
                    </name>
                    <name>
                      <surname>Spitzer</surname>
                      <given-names>K.</given-names>
                    </name>
                  </person-group>
                  <article-title>Survey: Interpolation methods in medical image processing</article-title>
                  <source>IEEE Trans. Med. Imaging</source>
                  <volume>18</volume>
                  <issue>11</issue>
                  <year>1999</year>
                  <fpage>1049</fpage>
                  <lpage>1075</lpage>
                  <pub-id pub-id-type="pmid">10661324</pub-id>
                </element-citation>
              </ref>
              <ref id="b0120">
                <element-citation publication-type="journal" id="h0120">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Malkin</surname>
                      <given-names>R.A.</given-names>
                    </name>
                  </person-group>
                  <article-title>“Design of health care technologies for the developing world, “ Annu</article-title>
                  <source>Rev. Biomed. Eng.</source>
                  <volume>9</volume>
                  <year>2007</year>
                  <fpage>567</fpage>
                  <lpage>587</lpage>
                </element-citation>
              </ref>
              <ref id="b0125">
                <element-citation publication-type="journal" id="h0125">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Manjón</surname>
                      <given-names>J.V.</given-names>
                    </name>
                    <name>
                      <surname>Coupé</surname>
                      <given-names>P.</given-names>
                    </name>
                    <name>
                      <surname>Buades</surname>
                      <given-names>A.</given-names>
                    </name>
                    <name>
                      <surname>Fonov</surname>
                      <given-names>V.</given-names>
                    </name>
                    <name>
                      <surname>Collins</surname>
                      <given-names>D.L.</given-names>
                    </name>
                    <name>
                      <surname>Robles</surname>
                      <given-names>M.</given-names>
                    </name>
                  </person-group>
                  <article-title>Non-local MRI upsampling</article-title>
                  <source>Med. Image Anal.</source>
                  <volume>14</volume>
                  <issue>6</issue>
                  <year>2010</year>
                  <fpage>784</fpage>
                  <lpage>792</lpage>
                  <pub-id pub-id-type="pmid">20566298</pub-id>
                </element-citation>
              </ref>
              <ref id="b0130">
                <mixed-citation publication-type="other" id="h0130">Manjón, J.V., P. Coupé, A. Buades, D.L. Collins, and M. Robles (2010) ”MRI superresolution using self-similarity and image priors,” International journal of biomedical imaging, 2010.</mixed-citation>
              </ref>
              <ref id="bib211">
                <element-citation publication-type="journal" id="optxVpVzSb0pM">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Mazurek</surname>
                      <given-names>M.</given-names>
                    </name>
                    <name>
                      <surname>Cahn</surname>
                      <given-names>B.</given-names>
                    </name>
                    <name>
                      <surname>Yuen</surname>
                      <given-names>Mercy</given-names>
                    </name>
                    <name>
                      <surname>Cahn</surname>
                      <given-names>Bradley</given-names>
                    </name>
                    <name>
                      <surname>Yuen</surname>
                      <given-names>Matthew</given-names>
                    </name>
                    <name>
                      <surname>Prabhat</surname>
                      <given-names>Anjali</given-names>
                    </name>
                    <name>
                      <surname>Chavva</surname>
                      <given-names>Isha</given-names>
                    </name>
                    <name>
                      <surname>Shah</surname>
                      <given-names>Jill</given-names>
                    </name>
                    <name>
                      <surname>Crawford</surname>
                      <given-names>Anna</given-names>
                    </name>
                    <name>
                      <surname>Welch</surname>
                      <given-names>E.</given-names>
                    </name>
                    <name>
                      <surname>Rothburg</surname>
                      <given-names>Jonathan</given-names>
                    </name>
                    <name>
                      <surname>Sacolick</surname>
                      <given-names>Laura</given-names>
                    </name>
                    <name>
                      <surname>Poole</surname>
                      <given-names>Michael</given-names>
                    </name>
                    <name>
                      <surname>Wira</surname>
                      <given-names>Charles</given-names>
                    </name>
                    <name>
                      <surname>Matouk</surname>
                      <given-names>Charles</given-names>
                    </name>
                    <name>
                      <surname>Ward</surname>
                      <given-names>Adrienne</given-names>
                    </name>
                    <name>
                      <surname>Timario</surname>
                      <given-names>Nona</given-names>
                    </name>
                    <name>
                      <surname>Leasure</surname>
                      <given-names>Audrey</given-names>
                    </name>
                    <name>
                      <surname>Beekman</surname>
                      <given-names>Rachel</given-names>
                    </name>
                    <name>
                      <surname>Peng</surname>
                      <given-names>Teng</given-names>
                    </name>
                    <name>
                      <surname>Witsch</surname>
                      <given-names>Jens</given-names>
                    </name>
                    <name>
                      <surname>Antonios</surname>
                      <given-names>Joseph</given-names>
                    </name>
                    <name>
                      <surname>Falcone</surname>
                      <given-names>Guido</given-names>
                    </name>
                    <name>
                      <surname>Gobeske</surname>
                      <given-names>Kevin</given-names>
                    </name>
                    <name>
                      <surname>Petersen</surname>
                      <given-names>Nils</given-names>
                    </name>
                    <name>
                      <surname>Schindler</surname>
                      <given-names>Joseph</given-names>
                    </name>
                    <name>
                      <surname>Sansing</surname>
                      <given-names>Lauren</given-names>
                    </name>
                    <name>
                      <surname>Gilmore</surname>
                      <given-names>Emily</given-names>
                    </name>
                    <name>
                      <surname>Hwang</surname>
                      <given-names>David</given-names>
                    </name>
                    <name>
                      <surname>Kim</surname>
                      <given-names>Jennifer</given-names>
                    </name>
                    <name>
                      <surname>Malhotra</surname>
                      <given-names>Ajay</given-names>
                    </name>
                    <name>
                      <surname>Sze</surname>
                      <given-names>Gordon</given-names>
                    </name>
                    <name>
                      <surname>Rosen</surname>
                      <given-names>Matthew</given-names>
                    </name>
                    <name>
                      <surname>Kimberly</surname>
                      <given-names>Taylor</given-names>
                    </name>
                    <name>
                      <surname>Sheth</surname>
                      <given-names>Kevin</given-names>
                    </name>
                  </person-group>
                  <article-title>Portable, bedside, low-field magnetic resonance imaging for evaluation of intracerebral hemorrhage</article-title>
                  <source>Nat. Commun.</source>
                  <year>2021</year>
                  <pub-id pub-id-type="doi">10.1038/s41467-021-25441-6</pub-id>
                </element-citation>
              </ref>
              <ref id="b0135">
                <element-citation publication-type="journal" id="h0135">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Obungoloch</surname>
                      <given-names>J.</given-names>
                    </name>
                    <name>
                      <surname>Harper</surname>
                      <given-names>J.R.</given-names>
                    </name>
                    <name>
                      <surname>Consevage</surname>
                      <given-names>S.</given-names>
                    </name>
                    <name>
                      <surname>Savukov</surname>
                      <given-names>I.M.</given-names>
                    </name>
                    <name>
                      <surname>Neuberger</surname>
                      <given-names>T.</given-names>
                    </name>
                    <name>
                      <surname>Tadigadapa</surname>
                      <given-names>S.</given-names>
                    </name>
                    <name>
                      <surname>Schiff</surname>
                      <given-names>S.J.</given-names>
                    </name>
                  </person-group>
                  <article-title>Design of a sustainable prepolarizing magnetic resonance imaging system for infant hydrocephalus</article-title>
                  <source>Magn. Reson. Mater. Phys., Biol. Med.</source>
                  <volume>31</volume>
                  <issue>5</issue>
                  <year>2018</year>
                  <fpage>665</fpage>
                  <lpage>676</lpage>
                </element-citation>
              </ref>
              <ref id="b0140">
                <element-citation publication-type="journal" id="h0140">
                  <person-group person-group-type="author">
                    <name>
                      <surname>O’Reilly</surname>
                      <given-names>T.</given-names>
                    </name>
                    <name>
                      <surname>Teeuwisse</surname>
                      <given-names>W.M.</given-names>
                    </name>
                    <name>
                      <surname>de Gans</surname>
                      <given-names>D.</given-names>
                    </name>
                    <name>
                      <surname>Koolstra</surname>
                      <given-names>K.</given-names>
                    </name>
                    <name>
                      <surname>Webb</surname>
                      <given-names>A.G.</given-names>
                    </name>
                  </person-group>
                  <article-title>In vivo 3D brain and extremity MRI at 50 mT using a permanent magnet Halbach array</article-title>
                  <source>Magn. Reson. Med.</source>
                  <year>2020</year>
                </element-citation>
              </ref>
              <ref id="b0150">
                <element-citation publication-type="journal" id="h0150">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Orrison</surname>
                      <given-names>W.</given-names>
                      <suffix>Jr</suffix>
                    </name>
                    <name>
                      <surname>Stimac</surname>
                      <given-names>G.</given-names>
                    </name>
                    <name>
                      <surname>Stevens</surname>
                      <given-names>E.</given-names>
                    </name>
                    <name>
                      <surname>LaMasters</surname>
                      <given-names>D.</given-names>
                    </name>
                    <name>
                      <surname>Espinosa</surname>
                      <given-names>M.</given-names>
                    </name>
                    <name>
                      <surname>Cobb</surname>
                      <given-names>L.</given-names>
                    </name>
                    <name>
                      <surname>Mettler</surname>
                      <given-names>F.</given-names>
                      <suffix>Jr</suffix>
                    </name>
                  </person-group>
                  <article-title>Comparison of CT, low-field-strength MR imaging, and high-field-strength MR imaging. Work in progress</article-title>
                  <source>Radiology</source>
                  <volume>181</volume>
                  <issue>1</issue>
                  <year>1991</year>
                  <fpage>121</fpage>
                  <lpage>127</lpage>
                  <pub-id pub-id-type="pmid">1887020</pub-id>
                </element-citation>
              </ref>
              <ref id="b0155">
                <element-citation publication-type="journal" id="h0155">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Paulson</surname>
                      <given-names>J.N.</given-names>
                    </name>
                    <name>
                      <surname>Williams</surname>
                      <given-names>B.L.</given-names>
                    </name>
                    <name>
                      <surname>Hehnly</surname>
                      <given-names>C.</given-names>
                    </name>
                    <name>
                      <surname>Mishra</surname>
                      <given-names>N.</given-names>
                    </name>
                    <name>
                      <surname>Sinnar</surname>
                      <given-names>S.A.</given-names>
                    </name>
                    <name>
                      <surname>Zhang</surname>
                      <given-names>L.</given-names>
                    </name>
                    <name>
                      <surname>Ssentongo</surname>
                      <given-names>P.</given-names>
                    </name>
                    <name>
                      <surname>Mbabazi-Kabachelor</surname>
                      <given-names>E.</given-names>
                    </name>
                    <name>
                      <surname>Wijetunge</surname>
                      <given-names>D.S.</given-names>
                    </name>
                    <name>
                      <surname>von Bredow</surname>
                      <given-names>B.</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>The Bacterial and Viral Complexity of Postinfectious Hydrocephalus in Uganda</article-title>
                  <source>Sci. Transl. Med.</source>
                  <volume>12</volume>
                  <issue>563</issue>
                  <year>2020</year>
                </element-citation>
              </ref>
              <ref id="b0160">
                <mixed-citation publication-type="other" id="h0160">Pham, C.-H., A. Ducournau, R. Fablet, and F. Rousseau (2017) ”Brain MRI super-resolution using deep 3D convolutional networks,” in 2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017), IEEE, pp. 197–200.</mixed-citation>
              </ref>
              <ref id="b0170">
                <element-citation publication-type="journal" id="h0170">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Rutland</surname>
                      <given-names>J.</given-names>
                    </name>
                    <name>
                      <surname>Delman</surname>
                      <given-names>B.</given-names>
                    </name>
                    <name>
                      <surname>Gill</surname>
                      <given-names>C.</given-names>
                    </name>
                    <name>
                      <surname>Zhu</surname>
                      <given-names>C.</given-names>
                    </name>
                    <name>
                      <surname>Shrivastava</surname>
                      <given-names>R.</given-names>
                    </name>
                    <name>
                      <surname>Balchandani</surname>
                      <given-names>P.</given-names>
                    </name>
                  </person-group>
                  <article-title>Emerging Use of Ultra-High-Field 7T MRI in the Study of Intracranial Vascularity: State of the Field and Future Directions</article-title>
                  <source>Am. J. Neuroradiol.</source>
                  <volume>41</volume>
                  <issue>1</issue>
                  <year>2020</year>
                  <fpage>2</fpage>
                  <lpage>9</lpage>
                  <pub-id pub-id-type="pmid">31879330</pub-id>
                </element-citation>
              </ref>
              <ref id="b0175">
                <mixed-citation publication-type="other" id="h0175">Schiff, S., A. Kulkarni, K.E. Mbabazi, J. Mugamba, P. Ssenyonga, R. Donnelly, J. Levenbach, V. Monga, M. Peterson, V. Cherukuri, and B. Warf (2021) ”Brain growth after surgical treatment of infant post-infectious hydrocephalus in sub-Saharan Africa: two-year results of a randomized trial.” Journal of Neurosurgery Pediatrics.</mixed-citation>
              </ref>
              <ref id="b0180">
                <mixed-citation publication-type="other" id="h0180">Sheth, K.N., M.H. Mazurek, M.M. Yuen, B.A. Cahn, J.T. Shah, A. Ward, J.A. Kim, E.J. Gilmore, G.J. Falcone, N. Petersen, et al. (2020) ”Assessment of Brain Injury Using Portable, Low-Field Magnetic Resonance Imaging at the Bedside of Critically Ill Patients,” JAMA neurology.</mixed-citation>
              </ref>
              <ref id="b0185">
                <element-citation publication-type="journal" id="h0185">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Shi</surname>
                      <given-names>F.</given-names>
                    </name>
                    <name>
                      <surname>Cheng</surname>
                      <given-names>J.</given-names>
                    </name>
                    <name>
                      <surname>Wang</surname>
                      <given-names>L.</given-names>
                    </name>
                    <name>
                      <surname>Yap</surname>
                      <given-names>P.-T.</given-names>
                    </name>
                    <name>
                      <surname>Shen</surname>
                      <given-names>D.</given-names>
                    </name>
                  </person-group>
                  <article-title>LRTV: MR image super-resolution with low-rank and total variation regularizations</article-title>
                  <source>IEEE Trans. Med. Imaging</source>
                  <volume>34</volume>
                  <issue>12</issue>
                  <year>2015</year>
                  <fpage>2459</fpage>
                  <lpage>2466</lpage>
                  <pub-id pub-id-type="pmid">26641727</pub-id>
                </element-citation>
              </ref>
              <ref id="b0190">
                <element-citation publication-type="journal" id="h0190">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Steinberg</surname>
                      <given-names>H.</given-names>
                    </name>
                    <name>
                      <surname>Alarcon</surname>
                      <given-names>J.</given-names>
                    </name>
                    <name>
                      <surname>Bernardino</surname>
                      <given-names>M.</given-names>
                    </name>
                  </person-group>
                  <article-title>Focal hepatic lesions: comparative MR imaging at 0.5 and 1.5 T</article-title>
                  <source>Radiology</source>
                  <volume>174</volume>
                  <issue>1</issue>
                  <year>1990</year>
                  <fpage>153</fpage>
                  <lpage>156</lpage>
                  <pub-id pub-id-type="pmid">2152980</pub-id>
                </element-citation>
              </ref>
              <ref id="b0195">
                <element-citation publication-type="journal" id="h0195">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Wang</surname>
                      <given-names>Y.-H.</given-names>
                    </name>
                    <name>
                      <surname>Qiao</surname>
                      <given-names>J.</given-names>
                    </name>
                    <name>
                      <surname>Li</surname>
                      <given-names>J.-B.</given-names>
                    </name>
                    <name>
                      <surname>Fu</surname>
                      <given-names>P.</given-names>
                    </name>
                    <name>
                      <surname>Chu</surname>
                      <given-names>S.-C.</given-names>
                    </name>
                    <name>
                      <surname>Roddick</surname>
                      <given-names>J.F.</given-names>
                    </name>
                  </person-group>
                  <article-title>Sparse representation-based MRI super-resolution reconstruction</article-title>
                  <source>Measurement</source>
                  <volume>47</volume>
                  <year>2014</year>
                  <fpage>946</fpage>
                  <lpage>953</lpage>
                </element-citation>
              </ref>
              <ref id="b0200">
                <element-citation publication-type="journal" id="h0200">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Warf</surname>
                      <given-names>B.C.</given-names>
                    </name>
                  </person-group>
                  <article-title>Educate one to save a few. Educate a few to save many</article-title>
                  <source>World Neurosurg.</source>
                  <volume>79</volume>
                  <issue>2</issue>
                  <year>2013</year>
                  <fpage>S15</fpage>
                  <lpage>e15</lpage>
                </element-citation>
              </ref>
              <ref id="b0145">
                <element-citation publication-type="journal" id="h0145">
                  <person-group person-group-type="author">
                    <name>
                      <surname>World Health Organization</surname>
                    </name>
                  </person-group>
                  <article-title>Baseline country survey on medical devices 2010</article-title>
                  <source>Tech. rep., World Health Organization.</source>
                  <year>2011</year>
                </element-citation>
              </ref>
              <ref id="b0205">
                <element-citation publication-type="journal" id="h0205">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Yang</surname>
                      <given-names>J.</given-names>
                    </name>
                    <name>
                      <surname>Wright</surname>
                      <given-names>J.</given-names>
                    </name>
                    <name>
                      <surname>Huang</surname>
                      <given-names>T.S.</given-names>
                    </name>
                    <name>
                      <surname>Ma</surname>
                      <given-names>Y.</given-names>
                    </name>
                  </person-group>
                  <article-title>Image super-resolution via sparse representation</article-title>
                  <source>IEEE Trans. Image Process.</source>
                  <volume>19</volume>
                  <issue>11</issue>
                  <year>2010</year>
                  <fpage>2861</fpage>
                  <lpage>2873</lpage>
                  <pub-id pub-id-type="pmid">20483687</pub-id>
                </element-citation>
              </ref>
              <ref id="b0210">
                <element-citation publication-type="journal" id="h0210">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Zhu</surname>
                      <given-names>B.</given-names>
                    </name>
                    <name>
                      <surname>Liu</surname>
                      <given-names>J.Z.</given-names>
                    </name>
                    <name>
                      <surname>Cauley</surname>
                      <given-names>S.F.</given-names>
                    </name>
                    <name>
                      <surname>Rosen</surname>
                      <given-names>B.R.</given-names>
                    </name>
                    <name>
                      <surname>Rosen</surname>
                      <given-names>M.S.</given-names>
                    </name>
                  </person-group>
                  <article-title>Image reconstruction by domain-transform manifold learning</article-title>
                  <source>Nature</source>
                  <volume>555</volume>
                  <issue>7697</issue>
                  <year>2018</year>
                  <fpage>487</fpage>
                  <lpage>492</lpage>
                  <pub-id pub-id-type="pmid">29565357</pub-id>
                </element-citation>
              </ref>
            </ref-list>
            <sec id="s0060" sec-type="supplementary-material">
              <label>Appendix A</label>
              <title>Supplementary data</title>
              <p id="p0180">The following are the Supplementary data to this article:</p>
              <p id="p0185">
                <supplementary-material content-type="local-data" id="m0005">
                  <caption>
                    <title>Supplementary data 1</title>
                  </caption>
                  <media xlink:href="mmc1.pdf"/>
                </supplementary-material>
              </p>
            </sec>
            <ack id="ak005">
              <title>Acknowledgements</title>
              <p id="p0190">Supported by US National Institutes of Health grant R01HD085853. ClinicalTrials.gov registration number NCT01936272.</p>
            </ack>
            <fn-group>
              <fn id="s0055" fn-type="supplementary-material">
                <label>Appendix A</label>
                <p id="p0175">Supplementary data associated with this article can be found, in the online version, at <ext-link ext-link-type="doi" xlink:href="10.1016/j.nicl.2021.102896" id="ir005">https://doi.org/10.1016/j.nicl.2021.102896</ext-link>.</p>
              </fn>
            </fn-group>
          </back>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
