<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2024-05-03T03:33:23Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:8593763" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:8593763</identifier>
        <datestamp>2021-11-24</datestamp>
        <setSpec>jamasd</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" dtd-version="1.3" xml:lang="en" article-type="research-article">
          <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
            <restricted-by>pmc</restricted-by>
          </processing-meta>
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">JAMA Netw Open</journal-id>
              <journal-id journal-id-type="iso-abbrev">JAMA Netw Open</journal-id>
              <journal-title-group>
                <journal-title>JAMA Network Open</journal-title>
              </journal-title-group>
              <issn pub-type="epub">2574-3805</issn>
              <publisher>
                <publisher-name>American Medical Association</publisher-name>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC8593763</article-id>
              <article-id pub-id-type="pmcid">PMC8593763</article-id>
              <article-id pub-id-type="pmc-uid">8593763</article-id>
              <article-id pub-id-type="pmid">34779843</article-id>
              <article-id pub-id-type="pmid">34779843</article-id>
              <article-id pub-id-type="doi">10.1001/jamanetworkopen.2021.34254</article-id>
              <article-id pub-id-type="publisher-id">zoi210963</article-id>
              <article-categories>
                <subj-group subj-group-type="category" specific-use="electronic">
                  <subject>Research</subject>
                </subj-group>
                <subj-group subj-group-type="heading">
                  <subject>Original Investigation</subject>
                </subj-group>
                <subj-group subj-group-type="online-only">
                  <subject>Online Only</subject>
                </subj-group>
                <subj-group subj-group-type="subject-area">
                  <subject>Diabetes and Endocrinology</subject>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>Pivotal Evaluation of an Artificial Intelligence System for Autonomous Detection of Referrable and Vision-Threatening Diabetic Retinopathy</article-title>
                <alt-title alt-title-type="headline">Pivotal Evaluation of an Artificial Intelligence System for Detection of Diabetic Retinopathy</alt-title>
                <alt-title alt-title-type="running-head">Pivotal Evaluation of an Artificial Intelligence System for Detection of Diabetic Retinopathy</alt-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author" corresp="yes">
                  <name>
                    <surname>Ipp</surname>
                    <given-names>Eli</given-names>
                  </name>
                  <degrees>MB</degrees>
                  <xref rid="zoi210963aff1" ref-type="aff">
                    <sup>1</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Liljenquist</surname>
                    <given-names>David</given-names>
                  </name>
                  <degrees>MD</degrees>
                  <xref rid="zoi210963aff2" ref-type="aff">
                    <sup>2</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Bode</surname>
                    <given-names>Bruce</given-names>
                  </name>
                  <degrees>MD</degrees>
                  <xref rid="zoi210963aff3" ref-type="aff">
                    <sup>3</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Shah</surname>
                    <given-names>Viral N.</given-names>
                  </name>
                  <degrees>MD</degrees>
                  <xref rid="zoi210963aff4" ref-type="aff">
                    <sup>4</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Silverstein</surname>
                    <given-names>Steven</given-names>
                  </name>
                  <degrees>MD</degrees>
                  <xref rid="zoi210963aff5" ref-type="aff">
                    <sup>5</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Regillo</surname>
                    <given-names>Carl D.</given-names>
                  </name>
                  <degrees>MD</degrees>
                  <xref rid="zoi210963aff6" ref-type="aff">
                    <sup>6</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Lim</surname>
                    <given-names>Jennifer I.</given-names>
                  </name>
                  <degrees>MD</degrees>
                  <xref rid="zoi210963aff7" ref-type="aff">
                    <sup>7</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Sadda</surname>
                    <given-names>SriniVas</given-names>
                  </name>
                  <degrees>MD</degrees>
                  <xref rid="zoi210963aff8" ref-type="aff">
                    <sup>8</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Domalpally</surname>
                    <given-names>Amitha</given-names>
                  </name>
                  <degrees>MD</degrees>
                  <degrees>PhD</degrees>
                  <xref rid="zoi210963aff9" ref-type="aff">
                    <sup>9</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Gray</surname>
                    <given-names>Gerry</given-names>
                  </name>
                  <degrees>PhD</degrees>
                  <xref rid="zoi210963aff10" ref-type="aff">
                    <sup>10</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Bhaskaranand</surname>
                    <given-names>Malavika</given-names>
                  </name>
                  <degrees>PhD</degrees>
                  <xref rid="zoi210963aff11" ref-type="aff">
                    <sup>11</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Ramachandra</surname>
                    <given-names>Chaithanya</given-names>
                  </name>
                  <degrees>PhD</degrees>
                  <xref rid="zoi210963aff11" ref-type="aff">
                    <sup>11</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Solanki</surname>
                    <given-names>Kaushal</given-names>
                  </name>
                  <degrees>PhD</degrees>
                  <xref rid="zoi210963aff11" ref-type="aff">
                    <sup>11</sup>
                  </xref>
                </contrib>
                <on-behalf-of>for the EyeArt Study Group</on-behalf-of>
              </contrib-group>
              <aff id="zoi210963aff1"><label>1</label>The Lundquist Institute, Harbor-UCLA Medical Center, Torrance, California</aff>
              <aff id="zoi210963aff2"><label>2</label>Rocky Mountain Diabetes Center, Idaho Falls, Idaho</aff>
              <aff id="zoi210963aff3"><label>3</label>Atlanta Diabetes Associates, Atlanta, Georgia</aff>
              <aff id="zoi210963aff4"><label>4</label>Barbara Davis Center for Diabetes, University of Colorado Anschutz Medical Campus, Aurora, Colorado</aff>
              <aff id="zoi210963aff5"><label>5</label>Silverstein Eye Centers, Kansas City, Missouri</aff>
              <aff id="zoi210963aff6"><label>6</label>Wills Eye Hospital, Thomas Jefferson University, Philadelphia, Pennsylvania</aff>
              <aff id="zoi210963aff7"><label>7</label>Department of Ophthalmology, Illinois Eye and Ear Infirmary, University of Illinois University of Illinois at Chicago, Chicago, Illinois</aff>
              <aff id="zoi210963aff8"><label>8</label>Doheny Eye Center, Arcadia, California</aff>
              <aff id="zoi210963aff9"><label>9</label>Fundus Photograph Reading Center, University of Wisconsin-Madison, Madison, Wisconsin</aff>
              <aff id="zoi210963aff10"><label>10</label>Data-Fi, LLC, Silver Spring, Maryland</aff>
              <aff id="zoi210963aff11"><label>11</label>Eyenuk Inc, Los Angeles, California</aff>
              <author-notes>
                <title>Article Information</title>
                <p><bold>Accepted for Publication:</bold> September 19, 2021.</p>
                <p content-type="published-online"><bold>Published:</bold> November 15, 2021. <?xpp bx;1?>doi:<uri content-type="doi">10.1001/jamanetworkopen.2021.34254</uri></p>
                <p content-type="open-access-note"><bold>Open Access:</bold> This is an open access article distributed under the terms of the <ext-link xlink:href="https://jamanetwork.com/pages/cc-by-nc-nd-license-permissions" ext-link-type="uri">CC-BY-NC-ND License</ext-link>. © 2021 Ipp E et al. <italic toggle="yes">JAMA Network Open</italic>.</p>
                <corresp id="zoi210963cor1"><bold>Corresponding Author:</bold> Eli Ipp, MD, The Lundquist Institute, Harbor-UCLA Medical Center, 1124 W Carson St, Torrance, CA 90502 (<email xlink:href="ipp@lundquist.org">ipp@lundquist.org</email>).</corresp>
                <p content-type="author-contributions"><bold>Author Contributions:</bold> Drs Bhaskaranand and Ramachandra had full access to all of the data in the study and take responsibility for the integrity of the data and the accuracy of the data analysis.</p>
                <p><italic toggle="yes">Concept and design:</italic> Bhaskaranand, Ramachandra, Solanki.</p>
                <p><italic toggle="yes">Acquisition, analysis, or interpretation of data:</italic> All authors.</p>
                <p><italic toggle="yes">Drafting of the manuscript:</italic> Ipp, Silverstein, Regillo, Lim, Domalpally, Bhaskaranand, Ramachandra, Solanki.</p>
                <p><italic toggle="yes">Critical revision of the manuscript for important intellectual content:</italic> Ipp, Liljenquist, Bode, Shah, Silverstein, Regillo, Lim, Sadda, Gray, Bhaskaranand, Ramachandra, Solanki.</p>
                <p><italic toggle="yes">Statistical analysis:</italic> Gray, Bhaskaranand, Ramachandra, Solanki.</p>
                <p><italic toggle="yes">Obtained funding:</italic> Bhaskaranand, Solanki.</p>
                <p><italic toggle="yes">Administrative, technical, or material support:</italic> Silverstein, Bhaskaranand, Ramachandra.</p>
                <p><italic toggle="yes">Supervision:</italic> Shah, Regillo, Lim, Domalpally, Bhaskaranand, Solanki.</p>
                <p content-type="COI-statement"><bold>Conflict of Interest Disclosures:</bold> Dr Ipp reported receiving grants from Eyenuk Inc for the conduct of the study and grants from Genentech and Norris foundations outside the submitted work. Dr Bode reported receiving grants from Atlanta Diabetes Associates during the conduct of the study. Dr Shah reported receiving grants from Eyenuk Inc for the conduct of the study; grants from Sanofi US, Dexcom, Insulet, NovoNordisk, Eli Lilly, vTv Therapeutics, and Abbott; speaker’s fee from Insulet; and honoraria for serving on the advisory boards of Sanofi US and Medscape outside the submitted work. Dr Silverstein reported buying financial interest in Eyenuk Inc after the study was complete and after the study data were submitted to the US Food and Drug Administration (FDA). Dr Regillo reported receiving grants from Mid Atlantic Retina for the conduct of the study. Dr Lim reported receiving personal fees from Eyenuk Inc as a consultant after the study was completed and after the study data were submitted to the FDA; personal fees from Genentech/Roche, Novartis, Kodiak, Iveric, Cognition, Opthea DMC, Luxa DMC, Unity, Santen DMC, Quark DMC, Aura Biosciences DMC, and Alcon outside the submitted work; and grants from Regeneron, Chengdu, Stealth, Graybug, Aldeyra, NGM, and Clearside outside the submitted work. Dr Sadda reported receiving personal fees from Optos, Centervue, Heidelberg, Topcon, Carl Zeiss Meditec, Nidek, Amgen, Allergan, Apellis, Iveric, Oxurion, Roche/Genentech, Novartis, and 4dMT outside the submitted work. Dr Gray reported receiving personal fees from Eyenuk Inc for supporting design and analysis of the study; Zeiss Inc, and Optovue Inc, and personal payment from Jeffrey Luttrull, MD, outside the submitted work. Dr Bhaskaranand reported being an employee of and has a financial interest in Eyenuk Inc; in addition, Dr Bhaskaranand had patents 9008391, 9002085, 8885901, 8879813, and 11051693 issued to Eyenuk Inc. Dr Ramachandra is an employee of and has a financial interest in Eyenuk Inc; in addition, Dr Ramachandra had patents for 9008391, 9002085, 8885901, 8879813, and 11051693 issued to Eyenuk Inc. Dr Solanki is an employee of and has a financial interest in Eyenuk Inc; in addition, Dr Solanki had patents 9008391, 9002085, 8885901, 8879813, and 11051693 issued to Eyenuk Inc. No other disclosures were reported.</p>
                <p content-type="funding-statement"><bold>Funding/Support:</bold> The study was funded in part by grants 9SB1EY027241 and 2R44EY026864 from the National Institutes of Health and in part by Eyenuk Inc. Dr Domalpally was supported in part by an unrestricted grant from Research to Prevent Blindness Inc to the University of Wisconsin Madison Department of Ophthalmology.</p>
                <p><bold>Role of the Funder/Sponsor:</bold> The National Institutes of Health was not involved in design and conduct of the study; collection, management, analysis, and interpretation of the data; preparation, review, or approval of the manuscript; and decision to submit the manuscript for publication. Eyenuk Inc was involved in design and conduct of the study; collection, management, analysis, and interpretation of the data; preparation, review, or approval of the manuscript; and decision to submit the manuscript for publication.</p>
                <p><bold>Group Information:</bold> The EyeArt Study Group members appear in <xref rid="note-ZOI210963-1-s" ref-type="supplementary-material">Supplement 2</xref>.</p>
                <p><bold>Meeting Presentations:</bold> Portions of these data were presented at the Association for Research in Vision and Ophthalmology Imaging Conference; Vancouver, British Columbia, Canada, April 27, 2019; American Diabetes Association 29th Scientific Sessions, San Francisco, California; June 9, 2019; 19th EURETINA Congress; Paris, France; September 5, 2019; the European Association for the Study of Diabetes; September 17, 2019; and the American Academy of Ophthalmology Annual Meeting; San Francisco, California, October 14, 2019.</p>
                <p><bold>Additional Information:</bold> Writing assistance was provided by Jack Pike, PhD, CMPP (Envision Pharma) funded by Eyenuk Inc.</p>
              </author-notes>
              <pub-date pub-type="epub" iso-8601-date="2021-11-15T10:00">
                <day>15</day>
                <month>11</month>
                <year>2021</year>
              </pub-date>
              <pub-date pub-type="collection">
                <month>11</month>
                <year>2021</year>
              </pub-date>
              <pub-date pub-type="pmc-release">
                <day>15</day>
                <month>11</month>
                <year>2021</year>
              </pub-date>
              <!--PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>.-->
              <volume>4</volume>
              <issue>11</issue>
              <elocation-id>e2134254</elocation-id>
              <history>
                <date date-type="received">
                  <day>7</day>
                  <month>6</month>
                  <year>2021</year>
                </date>
                <date date-type="accepted">
                  <day>19</day>
                  <month>9</month>
                  <year>2021</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>Copyright 2021 Ipp E et al. <italic toggle="yes">JAMA Network Open</italic>.</copyright-statement>
                <license>
                  <ali:license_ref specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
                  <license-p>This is an open access article distributed under the terms of the CC-BY-NC-ND License.</license-p>
                </license>
              </permissions>
              <self-uri content-type="pdf-version" xlink:href="jamanetwopen-e2134254.pdf">jamanetwopen-e2134254.pdf</self-uri>
              <self-uri content-type="silverchair" xlink:href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/10.1001/jamanetworkopen.2021.34254"/>
              <abstract abstract-type="key-points">
                <title>Key Points</title>
                <sec id="ab-zoi210963-1">
                  <title>Question</title>
                  <p>How does an artificial intelligence (AI) system for autonomous detection of vision-threatening diabetic retinopathy (vtDR) and more than mild diabetic retinopathy (mtmDR) compare with the reading center clinical reference standard?</p>
                </sec>
                <sec id="ab-zoi210963-2">
                  <title>Findings</title>
                  <p>In this multicenter cross-sectional diagnostic study including 942 individuals with diabetes, the accuracy of the EyeArt autonomous AI system vs the reference standard was high (mtmDR sensitivity: 96%, specificity: 88% and vtDR sensitivity: 97%, specificity: 90%). The AI system successfully graded more than 97% of the eyes scored manually, with most not requiring dilation.</p>
                </sec>
                <sec id="ab-zoi210963-3">
                  <title>Meaning</title>
                  <p>An autonomous AI system can accurately detect vtDR and mtmDR without physician oversight or need for dilation in most individuals, facilitating diabetic eye examinations at nonspecialist facilities and enabling accelerated referral of vtDR.</p>
                </sec>
              </abstract>
              <abstract>
                <sec id="ab-zoi210963-4">
                  <title>Importance</title>
                  <p>Diabetic retinopathy (DR) is a leading cause of blindness in adults worldwide. Early detection and intervention can prevent blindness; however, many patients do not receive their recommended annual diabetic eye examinations, primarily owing to limited access.</p>
                </sec>
                <sec id="ab-zoi210963-5">
                  <title>Objective</title>
                  <p>To evaluate the safety and accuracy of an artificial intelligence (AI) system (the EyeArt Automated DR Detection System, version 2.1.0) in detecting both more-than-mild diabetic retinopathy (mtmDR) and vision-threatening diabetic retinopathy (vtDR).</p>
                </sec>
                <sec id="ab-zoi210963-6">
                  <title>Design, Setting, and Participants</title>
                  <p>A prospective multicenter cross-sectional diagnostic study was preregistered (NCT03112005) and conducted from April 17, 2017, to May 30, 2018. A total of 942 individuals aged 18 years or older who had diabetes gave consent to participate at 15 primary care and eye care facilities. Data analysis was performed from February 14 to July 10, 2019.</p>
                </sec>
                <sec id="ab-zoi210963-7">
                  <title>Interventions</title>
                  <p>Retinal imaging for the autonomous AI system and Early Treatment Diabetic Retinopathy Study (ETDRS) reference standard determination.</p>
                </sec>
                <sec id="ab-zoi210963-8">
                  <title>Main Outcomes and Measures</title>
                  <p>Primary outcome measures included the sensitivity and specificity of the AI system in identifying participants’ eyes with mtmDR and/or vtDR by 2-field undilated fundus photography vs a rigorous clinical reference standard comprising reading center grading of 4 wide-field dilated images using the ETDRS severity scale. Secondary outcome measures included the evaluation of imageability, dilated-if-needed analysis, enrichment correction analysis, worst-case imputation, and safety outcomes.</p>
                </sec>
                <sec id="ab-zoi210963-9">
                  <title>Results</title>
                  <p>Of 942 consenting individuals, 893 patients (1786 eyes) met the inclusion criteria and completed the study protocol. The population included 449 men (50.3%). Mean (SD) participant age was 53.9 (15.2) years (median, 56; range, 18-88 years), 655 were White (73.3%), and 206 had type 1 diabetes (23.1%). Sensitivity and specificity of the AI system were high in detecting mtmDR (sensitivity: 95.5%; 95% CI, 92.4%-98.5% and specificity: 85.0%; 95% CI, 82.6%-87.4%) and vtDR (sensitivity: 95.1%; 95% CI, 90.1%-100% and specificity: 89.0%; 95% CI, 87.0%-91.1%) without dilation. Imageability was high without dilation, with the AI system able to grade 87.4% (95% CI, 85.2%-89.6%) of the eyes with reading center grades. When eyes with ungradable results were dilated per the protocol, the imageability improved to 97.4% (95% CI, 96.4%-98.5%), with the sensitivity and specificity being similar. After correcting for enrichment, the mtmDR specificity increased to 87.8% (95% CI, 86.3%-89.5%) and the sensitivity remained similar; for vtDR, both sensitivity (97.0%; 95% CI, 91.2%-100%) and specificity (90.1%; 95% CI, 89.4%-91.5%) improved.</p>
                </sec>
                <sec id="ab-zoi210963-10">
                  <title>Conclusions and Relevance</title>
                  <p>This prospective multicenter cross-sectional diagnostic study noted safety and accuracy with use of the EyeArt Automated DR Detection System in detecting both mtmDR and, for the first time, vtDR, without physician assistance. These findings suggest that improved access to accurate, reliable diabetic eye examinations may increase adherence to recommended annual screenings and allow for accelerated referral of patients identified as having vtDR.</p>
                </sec>
              </abstract>
              <abstract abstract-type="teaser" specific-use="electronic">
                <p>This diagnostic study compares the accuracy of an automated diabetic retinopathy detection system with the Early Treatment Diabetic Retinopathy Study reference standard in adults with diabetic retinopathy.</p>
              </abstract>
            </article-meta>
          </front>
          <body>
            <sec id="H1-1-ZOI210963">
              <title>Introduction</title>
              <p>Worldwide, the prevalence of type 1 and type 2 diabetes in adults is expected to increase from approximately 415 million in 2015 to 642 million by 2040.<sup><xref rid="zoi210963r1" ref-type="bibr">1</xref></sup> Approximately 35% of patients are at risk of developing diabetic retinopathy (DR), with more than 10% at risk of more severe vision-threatening DR (vtDR).<sup><xref rid="zoi210963r2" ref-type="bibr">2</xref></sup> Vision loss from DR may occur asymptomatically, with patients unaware of progressive damage.<sup><xref rid="zoi210963r3" ref-type="bibr">3</xref></sup> Despite twice as many patients with diabetes reporting fear of vision loss being the most prevalent disease-related concern over any other complication, recommended annual vision screening is rarely completed.<sup><xref rid="zoi210963r4" ref-type="bibr">4</xref></sup> Indeed, 21% of patients with diabetes worldwide have never undergone DR screening,<sup><xref rid="zoi210963r4" ref-type="bibr">4</xref></sup> and in the US, only 60% of the patients receive annual dilated examinations—even lower among low-income patients of minority race and ethnicity.<sup><xref rid="zoi210963r5" ref-type="bibr">5</xref>,<xref rid="zoi210963r6" ref-type="bibr">6</xref></sup> These levels may be even lower in low-income countries where patients experience waiting lists or long-distance referrals owing to the scarcity of specialists.<sup><xref rid="zoi210963r7" ref-type="bibr">7</xref></sup> Patients commonly report barriers to regular DR screening consisting of limited access to eye care specialists, including long wait times for appointments and high costs.<sup><xref rid="zoi210963r4" ref-type="bibr">4</xref></sup> In low-income communities, this difficulty is compounded by failure to attend existing appointments for DR screening.<sup><xref rid="zoi210963r8" ref-type="bibr">8</xref></sup> Limited access to eye care specialists highlights a need for efficient and convenient DR screening at easily accessible sites in primary care,<sup><xref rid="zoi210963r9" ref-type="bibr">9</xref></sup> facilitating early diagnosis and prioritization for treatment of vtDR before vision loss occurs.<sup><xref rid="zoi210963r10" ref-type="bibr">10</xref></sup></p>
              <p>Recent advances in automated DR detection using artificial intelligence (AI) algorithms provide patients with increased opportunities for care, improving patient access to diabetic eye examinations and identifying patients requiring specialist referrals.<sup><xref rid="zoi210963r11" ref-type="bibr">11</xref>,<xref rid="zoi210963r12" ref-type="bibr">12</xref>,<xref rid="zoi210963r13" ref-type="bibr">13</xref>,<xref rid="zoi210963r14" ref-type="bibr">14</xref>,<xref rid="zoi210963r15" ref-type="bibr">15</xref>,<xref rid="zoi210963r16" ref-type="bibr">16</xref>,<xref rid="zoi210963r17" ref-type="bibr">17</xref></sup> Artificial intelligence facilitates safe detection of DR in local primary care offices.<sup><xref rid="zoi210963r18" ref-type="bibr">18</xref></sup> Consequently, adherence to regular eye examinations may improve, particularly in individuals with limited access to specialists.</p>
              <p>Beyond providing regular examinations to patients with diabetes, AI-based automated DR detection allows consistent interpretation and real-time reporting of results.<sup><xref rid="zoi210963r16" ref-type="bibr">16</xref></sup> Automated systems are cost-effective alternatives to human grading<sup><xref rid="zoi210963r17" ref-type="bibr">17</xref></sup> and can increase access to screening for patients.<sup><xref rid="zoi210963r10" ref-type="bibr">10</xref></sup> In addition, automated DR screening systems reduce physician workload associated with manual grading of images.<sup><xref rid="zoi210963r15" ref-type="bibr">15</xref></sup> Several automated DR image assessment systems have been reported (eg, EyeArt, Eyenuk Inc; IDx-DR, Digital Diagnostics Inc; SELENA, Singapore Eye Research Institute; Retmarker, Retmarker Ltd; and Automated Retinal Disease Assessment, Google LLC).<sup><xref rid="zoi210963r12" ref-type="bibr">12</xref>,<xref rid="zoi210963r14" ref-type="bibr">14</xref>,<xref rid="zoi210963r16" ref-type="bibr">16</xref>,<xref rid="zoi210963r17" ref-type="bibr">17</xref>,<xref rid="zoi210963r19" ref-type="bibr">19</xref>,<xref rid="zoi210963r20" ref-type="bibr">20</xref>,<xref rid="zoi210963r21" ref-type="bibr">21</xref></sup> Diagnostic study has shown IDx-DR to be sensitive and specific for DR screening, and the AI system has been cleared by the US Food and Drug Administration (FDA) for the detection of more-than-mild DR (mtmDR) only (ie, not for vtDR).<sup><xref rid="zoi210963r12" ref-type="bibr">12</xref></sup></p>
              <p>Many patients with mtmDR need to be referred for eye specialist care (hence, mtmDR is typically considered referable), but vtDR may need more urgent intervention. This need is particularly important in medical systems in which retinal screening and specialty care are limited<sup><xref rid="zoi210963r7" ref-type="bibr">7</xref>,<xref rid="zoi210963r8" ref-type="bibr">8</xref>,<xref rid="zoi210963r9" ref-type="bibr">9</xref>,<xref rid="zoi210963r10" ref-type="bibr">10</xref></sup> An AI approach that specifically detects vtDR allows for prioritized appointment schedules for vtDR that conform with recommended referral time guidelines for urgent treatment.<sup><xref rid="zoi210963r9" ref-type="bibr">9</xref>,<xref rid="zoi210963r22" ref-type="bibr">22</xref></sup></p>
              <p>The EyeArt AI Automated DR Detection System is an FDA-cleared cloud-based retinal diagnostic software device that analyzes digital color fundus photographs (CFPs) of patient eyes for signs of DR.<sup><xref rid="zoi210963r14" ref-type="bibr">14</xref>,<xref rid="zoi210963r19" ref-type="bibr">19</xref></sup> The system is designed to detect both mtmDR and vtDR in each eye of patients with diabetes. A recent retrospective real-world study assessed the diagnostic outcomes of EyeArt, version 2.0, in 101 710 consecutive patient visits from more than 400 primary care centers in previously obtained CFPs.<sup><xref rid="zoi210963r14" ref-type="bibr">14</xref></sup> The system achieved a 91.3% sensitivity and 91.1% specificity compared with a clinical reference. Moreover, the AI system achieved a 98.5% sensitivity for a positive referral output in patients with vtDR (potentially treatable DR).<sup><xref rid="zoi210963r14" ref-type="bibr">14</xref></sup> The present prospective multicenter cross-sectional diagnostic study evaluated the use of EyeArt, version 2.1.0, in detecting mtmDR and vtDR in eyes of patients with diabetes.</p>
            </sec>
            <sec id="H1-2-ZOI210963">
              <title>Methods</title>
              <p>The prospective multicenter cross-sectional diagnostic study was preregistered (<ext-link xlink:href="https://clinicaltrials.gov/ct2/show/NCT03112005" ext-link-type="uri">NCT03112005</ext-link>) and conducted from April 17, 2017, to May 30, 2018. Data analysis was performed from February 14 to July 10, 2019. The overall study design is depicted in <xref rid="zoi210963f1" ref-type="fig">Figure 1</xref> and described herein. The protocol was approved by the Alpha Institutional Review Board and site-specific institutional review boards, where required. All participants provided written informed consent and received nominal compensation that was reviewed and approved by the institutional review boards. The study was conducted in accordance with International Conference on Harmonization Good Clinical Practice,<sup><xref rid="zoi210963r23" ref-type="bibr">23</xref></sup> Declaration of Helsinki,<sup><xref rid="zoi210963r24" ref-type="bibr">24</xref></sup> and all applicable laws and regulations. This study followed the Standards for Reporting of Diagnostic Accuracy (<ext-link xlink:href="https://www.equator-network.org/reporting-guidelines/stard/" ext-link-type="uri">STARD</ext-link>) reporting guideline.</p>
              <fig position="float" id="zoi210963f1" fig-type="figure">
                <label>Figure 1. </label>
                <caption>
                  <title>Study Procedures in the Prospective Multicenter Cross-Sectional Diagnostic Study of the EyeArt Automated Diabetic Retinopathy Detection System</title>
                  <p>The clinical reference standard was determined using 4-wide field stereoscopic dilated fundus photographs. The retinal coverage of the four 45-degree field of view images is equivalent to that of 7-field Early Treatment Diabetic Retinopathy Study images (30-degree field of view). Only 1 photograph from each stereo pair for the 4 retinal fields and anterior view is shown. R indicates right eye; L, left eye; ANT, anterior. 1W, 2W, 4W, and 5W are the nasal, central, superior, and inferior fields of the 4-wide field photography protocol, respectively. EyeArt is an artificial intelligence system for autonomous detection of more-than-mild diabetic retinopathy and vision-threatening diabetic retinopathy.</p>
                </caption>
                <graphic xlink:href="jamanetwopen-e2134254-g001" position="float"/>
              </fig>
              <sec id="H2-1-ZOI210963">
                <title>Study Population</title>
                <p>Fifteen US study centers participated, including primary care (6), general ophthalmology (6), and retina specialty (3) centers. After a prespecified check for poolability, data from study centers were pooled for analysis.</p>
                <p>Participants were aged 18 years or older and had diabetes. Exclusion criteria were persistent visual impairment in 1 or both eyes; history of macular edema or retinal vascular occlusion, ocular injections, retinal laser treatment, or intraocular surgery other than uncomplicated cataract surgery; and contraindication for fundus photography. Data on age, sex, and self-reported race and ethnicity were collected per requirements of the FDA and to show possible generalizability of the findings.</p>
                <p>Patients with scheduled study center visits were sequentially assessed for eligibility by medical records review before being invited to participate during the sequential recruitment period. A subsequent enrichment-permitted period was performed to increase the likelihood of enrolling individuals with a more advanced level of disease. During this period, sites could invite patients who met eligibility requirements and 1 or more enrichment criterion by medical records review or a prescreening questionnaire including diagnosis of diabetes for 10 or more years, type 2 diabetes diagnosis with insulin dependence for 3 or more years, diagnosis of diabetes for 5 or more years with no prior diabetic eye examination, or diagnosis of diabetes for 5 or more years with hemoglobin A<sub>1c</sub> level 9% or higher (to convert to proportion of total hemoglobin, multiply by 0.01) within the past 6 months. During this period, enrichment was permitted but not required. To eliminate potential spectrum bias caused by enrichment, the study analysis plan included enrichment correction analyses by evaluating performance using disease prevalence statistics of the study population enrolled sequentially.</p>
              </sec>
              <sec id="H2-2-ZOI210963">
                <title>Image Acquisition and Reference Standard</title>
                <p>Two-field retinal CFP images (1 disc-centered and 1 macula-centered) were taken for each eye (Canon CR-2 AF or Canon CR-2 Plus AF; Canon USA Inc). The images were submitted to the cloud for analysis.</p>
                <p>After 2-field CFP images were captured, participants underwent dilation followed by 4-wide-field stereoscopic CFP imaging in accordance with the Wisconsin Reading Center (FPRC)<sup><xref rid="zoi210963r25" ref-type="bibr">25</xref></sup> imaging protocol by FPRC-certified staff at all sites. Instances in which a participant’s pupil did not dilate or media opacities resulted in poor-quality images or narrow field of view (&lt;45°) were noted by imaging staff. The dilate-if-needed imaging protocol allowed the inclusion of disc and macula-centered images obtained following dilation.</p>
                <p>The AI system results were compared with the clinical reference standard of Early Treatment Diabetic Retinopathy Study (ETDRS) grading of 4-wide-field stereoscopic dilated fundus photographs (equivalent to 7-field 30° ETDRS photographs) by the FPRC.<sup><xref rid="zoi210963r26" ref-type="bibr">26</xref>,<xref rid="zoi210963r27" ref-type="bibr">27</xref></sup> Two independent certified graders masked to the AI system’s results examined the images using standardized procedures to establish the reference standards and provide the ETDRS level, which was translated to mtmDR and vtDR. Between-grader differences exceeding prespecified criteria were adjudicated by a third more senior grader.</p>
                <p>Per the FPRC, the reference standard mtmDR was considered positive if the reading center determined an ETDRS level greater than or equal to 35 (but not equal to 90) and/or the presence of clinically significant macular edema (CSME) was detected. The reference standard mtmDR was considered negative if an ETDRS level less than or equal to 20 was given and CSME was absent. The reference standard vtDR was considered to be positive if the reading center determined an ETDRS level greater than or equal to 53 (but not equal to 90) and/or presence of CSME was determined. The reference standard vtDR was considered negative if the reading center determined an ETDRS level less than or equal to 47 and CSME was determined to be absent.</p>
              </sec>
              <sec id="H2-3-ZOI210963">
                <title>Outcome Measures</title>
                <p>Primary outcome measures included the sensitivity and specificity of the AI system in identifying eyes with mtmDR or vtDR by 2-field undilated CFP vs the FPRC reference standard. Secondary outcome measures included the evaluation of imageability, sensitivity, and specificity of the AI system vs the reference standard using the dilate-if-needed protocol, comparison of sequential vs enriched enrollment populations, worst-case imputation, and safety outcomes. Additional prespecified analyses (eAppendix in <xref rid="note-ZOI210963-1-s" ref-type="supplementary-material">Supplement 1</xref>) were performed on a subset of participants determined using FDA-specified criteria (eFigure 1 in <xref rid="note-ZOI210963-1-s" ref-type="supplementary-material">Supplement 1</xref>) to support FDA clearance. Participant baseline characteristics per FDA-specified analysis are presented in eTable 1 in the <xref rid="note-ZOI210963-1-s" ref-type="supplementary-material">Supplement 1</xref>, the performance of the AI system in eTable 2 and eTable 3 in <xref rid="note-ZOI210963-1-s" ref-type="supplementary-material">Supplement 1</xref>, and imageability in eTable 4 and eTable 5 in <xref rid="note-ZOI210963-1-s" ref-type="supplementary-material">Supplement 1</xref>.</p>
              </sec>
              <sec id="H2-4-ZOI210963">
                <title>Statistical Analysis</title>
                <p>Results for mtmDR and vtDR were examined independently. Sensitivity was defined as the accuracy among positive findings per the clinical reference standard, calculated as the proportion of eyes with positive findings per the reference standard that also test positive with the AI system. Specificity was defined as the accuracy among negative findings per the clinical reference standard, calculated as the proportion of eyes with negative findings per the reference standard that also test negative with the AI system. Imageability was defined as the percentage of eyes that received a disease detection result from the AI system (positive or negative) among all images determined gradable by the FPRC.</p>
                <p>A prespecified enrichment correction analysis to adjust for any potential spectrum bias introduced by transitioning from sequential enrollment to the enrichment-permitted period evaluated performance using disease prevalence statistics of the study population enrolled sequentially. Enrichment-corrected accuracies were computed as prevalence-weighted sum of accuracies at each DR severity level.</p>
                <p>Hypothesis tests with 1-sided 2.5% type I error for the null hypotheses (sensitivity ≤80% and specificity ≤77.5%) were designed per prespecified regulatory requirements and assessed using methods for correlated binary data.<sup><xref rid="zoi210963r28" ref-type="bibr">28</xref></sup> Alternative hypotheses of 90.0% for sensitivity and 82.5% for specificity were established. Statistical analyses in this study were conducted using Python, version 2.7 (Python Software Foundation) and NumPy, version, 1.11.3 (NumPy). Significance threshold was P=.025.</p>
              </sec>
            </sec>
            <sec id="H1-3-ZOI210963">
              <title>Results</title>
              <p>Of 942 consenting individuals, 915 participants (1830 eyes) met eligibility criteria and 893 participants (1786 eyes) (intent-to-screen) completed the study according to protocol (<xref rid="zoi210963f2" ref-type="fig">Figure 2</xref>). A total of 22 participants did not complete 2-field imaging for the AI system analysis and/or 4-wide field imaging and hence were excluded. Of the intent-to-screen eyes, 1701 were analyzable for mtmDR and 1677 were analyzable for vtDR under the dilate-if-needed protocol. Mean (SD) participant age was 53.9 (15.2) years (median, 56; range, 18-88 years). Of 1786 individuals in the overall cohort, 206 (23.1%) had type 1 diabetes. Race and ethnicity groups represented in the analyzable cohort were American Indian or Alaska Native (3 [0.3%]), Asian (22 [2.5%]), Black or African American (159 [17.8%]), Native Hawaiian or other Pacific Islander (4 [0.4%]), White (655 [73.3%]), and Other (50 [5.6%]) (eTable 1 in <xref rid="note-ZOI210963-1-s" ref-type="supplementary-material">Supplement 1</xref>). A total of 444 participants were women (49.7%) and 449 were men (50.3%). No notable differences in age, ethnicity, and race were identified within the analyzable and nonanalyzable cohorts (<xref rid="zoi210963t1" ref-type="table">Table 1</xref>). Complete characteristics are included in eTable 1 in <xref rid="note-ZOI210963-1-s" ref-type="supplementary-material">Supplement 1</xref>.</p>
              <fig position="float" id="zoi210963f2" fig-type="figure">
                <label>Figure 2. </label>
                <caption>
                  <title>Flow Diagram for Participant Disposition in the Prospective Multicenter Cross-Sectional Diagnostic Study of the EyeArt Automated Diabetic Retinopathy Detection System</title>
                  <p>Final disposition of participants included in more-than-mild diabetic retinopathy (mtmDR) (A) and vision-threatening diabetic retinopathy (vtDR) (B) analyses.AI indicates artificial intelligence.</p>
                </caption>
                <graphic xlink:href="jamanetwopen-e2134254-g002" position="float"/>
              </fig>
              <table-wrap position="float" id="zoi210963t1">
                <label>Table 1. </label>
                <caption>
                  <title>Demographic Characteristics for Analyzable (N = 1701) and Nonanalyzable (N = 85) Intent-to-Screen Eyes</title>
                </caption>
                <table frame="hsides" rules="groups">
                  <col width="46.16%" span="1"/>
                  <col width="26.21%" span="1"/>
                  <col width="27.63%" span="1"/>
                  <thead>
                    <tr>
                      <th rowspan="2" valign="top" align="left" scope="col" colspan="1">Subgroup</th>
                      <th colspan="2" valign="top" align="left" scope="colgroup" rowspan="1">Eyes, No. (%)</th>
                    </tr>
                    <tr>
                      <th valign="top" colspan="1" align="left" scope="colgroup" rowspan="1">Analyzable (n = 1701)</th>
                      <th valign="top" align="left" scope="col" rowspan="1" colspan="1">Nonanalyzable (n = 85)</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td valign="top" align="left" scope="col" rowspan="1" colspan="1">Age, y</td>
                      <td valign="top" align="left" rowspan="1" colspan="1"/>
                      <td valign="top" align="left" rowspan="1" colspan="1"/>
                    </tr>
                    <tr>
                      <td valign="top" align="left" scope="row" rowspan="1" colspan="1"> &lt;65</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">1278 (75.1)</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">42 (49.4)</td>
                    </tr>
                    <tr>
                      <td valign="top" align="left" scope="row" rowspan="1" colspan="1"> ≥65</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">423 (24.9)</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">43 (50.6)</td>
                    </tr>
                    <tr>
                      <td valign="top" align="left" scope="col" rowspan="1" colspan="1">Sex</td>
                      <td valign="top" align="left" rowspan="1" colspan="1"/>
                      <td valign="top" align="left" rowspan="1" colspan="1"/>
                    </tr>
                    <tr>
                      <td valign="top" align="left" scope="row" rowspan="1" colspan="1"> Men</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">853 (50.1)</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">45 (52.9)</td>
                    </tr>
                    <tr>
                      <td valign="top" align="left" scope="row" rowspan="1" colspan="1"> Women</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">848 (49.9)</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">40 (47.1)</td>
                    </tr>
                    <tr>
                      <td valign="top" align="left" scope="col" rowspan="1" colspan="1">Ethnicity<xref rid="zoi210963t1n1" ref-type="table-fn"><sup>a</sup></xref></td>
                      <td valign="top" align="left" rowspan="1" colspan="1"/>
                      <td valign="top" align="left" rowspan="1" colspan="1"/>
                    </tr>
                    <tr>
                      <td valign="top" align="left" scope="row" rowspan="1" colspan="1"> Hispanic/Latino</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">374 (22.0)</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">22 (25.9)</td>
                    </tr>
                    <tr>
                      <td valign="top" align="left" scope="row" rowspan="1" colspan="1"> Non-Hispanic/Latino</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">1327 (78.0)</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">63 (74.1)</td>
                    </tr>
                    <tr>
                      <td valign="top" align="left" scope="col" rowspan="1" colspan="1">Race<xref rid="zoi210963t1n1" ref-type="table-fn"><sup>a</sup></xref></td>
                      <td valign="top" align="left" rowspan="1" colspan="1"/>
                      <td valign="top" align="left" rowspan="1" colspan="1"/>
                    </tr>
                    <tr>
                      <td valign="top" align="left" scope="row" rowspan="1" colspan="1"> American Indian or Alaska Native</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">6/ (0.4)</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">0</td>
                    </tr>
                    <tr>
                      <td valign="top" align="left" scope="row" rowspan="1" colspan="1"> Asian</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">38 (2.2)</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">6 (7.1)</td>
                    </tr>
                    <tr>
                      <td valign="top" align="left" scope="row" rowspan="1" colspan="1"> Black or African American</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">301 (17.7)</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">17 (20.0)</td>
                    </tr>
                    <tr>
                      <td valign="top" align="left" scope="row" rowspan="1" colspan="1"> Native Hawaiian or other Pacific Islander</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">8 (0.5)</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">0</td>
                    </tr>
                    <tr>
                      <td valign="top" align="left" scope="row" rowspan="1" colspan="1"> White</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">1251 (73.5)</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">59 (69.4)</td>
                    </tr>
                    <tr>
                      <td valign="top" align="left" scope="row" rowspan="1" colspan="1"> Other</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">97 (5.7)</td>
                      <td valign="top" align="left" rowspan="1" colspan="1">3 (3.5)</td>
                    </tr>
                  </tbody>
                </table>
                <table-wrap-foot>
                  <fn id="zoi210963t1n1">
                    <label>
                      <sup>a</sup>
                    </label>
                    <p>Race and ethnicity were self-reported; Other category did not specify groups.</p>
                  </fn>
                </table-wrap-foot>
              </table-wrap>
              <sec id="H2-5-ZOI210963">
                <title>Undilated and Dilate-if-Needed Imaging Protocols</title>
                <p>With the undilated imaging protocol, the AI system exceeded the prespecified superiority end points for both sensitivity (&gt;90.0%) and specificity (&gt;82.5%) in detecting both mtmDR and vtDR. For mtmDR, the AI system detected 273 of 286 eyes identified as positive by the FPRC, for a sensitivity of 95.5% (95% CI, 92.4%-98.5%), and 1054 of 1240 eyes were identified as negative by the FPRC, for a specificity of 85.0% (95% CI, 82.6%-87.4%) (<xref rid="zoi210963t2" ref-type="table">Table 2</xref>). For vtDR, the AI system detected 58 of 61 eyes identified as positive by the FPRC, for a sensitivity of 95.1% (95% CI, 90.1%-100%), and 1288 of 1447 eyes were identified as negative for vtDR, for a specificity of 89.0% (95% CI, 87.0%-91.1%) (<xref rid="zoi210963t3" ref-type="table">Table 3</xref>).</p>
                <table-wrap position="float" id="zoi210963t2">
                  <?xpp 2col?>
                  <label>Table 2. </label>
                  <caption>
                    <title>EyeArt Performance for Detecting mtmDR Using Undilated and Dilate-if-Needed Protocols<xref rid="zoi210963t2n1" ref-type="table-fn"><sup>a</sup></xref><sup>,</sup><xref rid="zoi210963t2n2" ref-type="table-fn"><sup>b</sup></xref></title>
                  </caption>
                  <table frame="hsides" rules="groups">
                    <col width="15.4%" span="1"/>
                    <col width="20.09%" span="1"/>
                    <col width="22.21%" span="1"/>
                    <col width="20.09%" span="1"/>
                    <col width="22.21%" span="1"/>
                    <thead>
                      <tr>
                        <th rowspan="3" valign="top" align="left" scope="col" colspan="1">Variable</th>
                        <th colspan="4" valign="top" align="left" scope="colgroup" rowspan="1">mtmDR<xref rid="zoi210963t2n3" ref-type="table-fn"><sup>c</sup></xref><sup>,</sup><xref rid="zoi210963t2n4" ref-type="table-fn"><sup>d</sup></xref></th>
                      </tr>
                      <tr>
                        <th colspan="2" valign="top" align="left" scope="colgroup" rowspan="1">Undilated protocol</th>
                        <th colspan="2" valign="top" align="left" scope="colgroup" rowspan="1">Dilate-if-needed protocol</th>
                      </tr>
                      <tr>
                        <th valign="top" colspan="1" align="left" scope="colgroup" rowspan="1">Observed (95% CI) [No./total No.]</th>
                        <th valign="top" align="left" scope="col" rowspan="1" colspan="1">Enrichment corrected (95% CI)</th>
                        <th valign="top" align="left" scope="col" rowspan="1" colspan="1">Observed (95% CI) [No./total No.]</th>
                        <th valign="top" align="left" scope="col" rowspan="1" colspan="1">Enrichment corrected (95% CI)</th>
                      </tr>
                    </thead>
                    <tbody>
                      <tr>
                        <td valign="top" align="left" scope="row" rowspan="1" colspan="1">Sensitivity</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">95.5 (92.4-98.5) [273/286]</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">95.5 (92.6-97.7)</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">95.5 (92.6-98.4) [296/310]</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">95.5 (92.9-97.7)</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" scope="row" rowspan="1" colspan="1">Specificity</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">85.0 (82.6-87.4) [1054/1240]</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">87.7 (86.0-89.5)</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">85.3 (83.0-87.5) [1186/1391]</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">87.8 (86.3-89.5)</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" scope="row" rowspan="1" colspan="1">Imageability</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">87.4 (85.2-89.6) [1526/1746]</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">87.6 (85.0-89.3)</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">97.4 (96.4-98.5) [1701/1746]</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">97.7 (96.4-98.3)</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" scope="row" rowspan="1" colspan="1">PPV</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">59.5 (53.9-63.9) [273/459]</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">62.7 (57.8-64.7)</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">59.1 (53.8-64.4) [296/501]</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">62.8 (58.1-64.7)</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" scope="row" rowspan="1" colspan="1">NPV</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">98.8 (98.2-99.4) [1054/1067]</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">98.9 (98.3-99.5)</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">98.8 (98.2-99.5) [1186/1200]</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">98.9 (98.4-99.5)</td>
                      </tr>
                    </tbody>
                  </table>
                  <table-wrap-foot>
                    <p>Abbreviations: mtmDR, more-than-mild diabetic retinopathy; NPV, negative predictive value; PPV, positive predictive value; vtDR, vision-threatening diabetic retinopathy.</p>
                    <fn id="zoi210963t2n1">
                      <label>
                        <sup>a</sup>
                      </label>
                      <p>EyeArt is an artificial intelligence system for autonomous detection of mtmDR and vtDR.</p>
                    </fn>
                    <fn id="zoi210963t2n2">
                      <label>
                        <sup>b</sup>
                      </label>
                      <p>Enrichment-corrected estimates are adjusted for prevalence.</p>
                    </fn>
                    <fn id="zoi210963t2n3">
                      <label>
                        <sup>c</sup>
                      </label>
                      <p>The 95% CIs were estimated using clustered bootstrap to account for the correlation between eyes.</p>
                    </fn>
                    <fn id="zoi210963t2n4">
                      <label>
                        <sup>d</sup>
                      </label>
                      <p>The undilated protocol included only undilated images and the dilate-if-needed protocol included images obtained following dilation for a small fraction of cases.</p>
                    </fn>
                  </table-wrap-foot>
                </table-wrap>
                <table-wrap position="float" id="zoi210963t3">
                  <?xpp 2col?>
                  <label>Table 3. </label>
                  <caption>
                    <title>EyeArt Performance for Detecting vtDR Using Undilated and Dilate-if-Needed Protocols<xref rid="zoi210963t3n1" ref-type="table-fn"><sup>a</sup></xref><sup>,</sup><xref rid="zoi210963t3n2" ref-type="table-fn"><sup>b</sup></xref></title>
                  </caption>
                  <table frame="hsides" rules="groups">
                    <col width="15.4%" span="1"/>
                    <col width="21.32%" span="1"/>
                    <col width="20.98%" span="1"/>
                    <col width="21.32%" span="1"/>
                    <col width="20.98%" span="1"/>
                    <thead>
                      <tr>
                        <th rowspan="3" valign="top" align="left" scope="col" colspan="1">Variable</th>
                        <th colspan="4" valign="top" align="left" scope="colgroup" rowspan="1">vtDR<xref rid="zoi210963t3n3" ref-type="table-fn"><sup><sup>c</sup></sup></xref><sup>,</sup><xref rid="zoi210963t3n4" ref-type="table-fn"><sup><sup>d</sup></sup></xref></th>
                      </tr>
                      <tr>
                        <th colspan="2" valign="top" align="left" scope="colgroup" rowspan="1">Undilated protocol</th>
                        <th colspan="2" valign="top" align="left" scope="colgroup" rowspan="1">Dilate-if-needed protocol</th>
                      </tr>
                      <tr>
                        <th valign="top" colspan="1" align="left" scope="colgroup" rowspan="1">Observed (95% CI) [No./total No.]</th>
                        <th valign="top" align="left" scope="col" rowspan="1" colspan="1">Enrichment corrected (95% CI)</th>
                        <th valign="top" align="left" scope="col" rowspan="1" colspan="1">Observed (95% CI) [No./total No.]</th>
                        <th valign="top" align="left" scope="col" rowspan="1" colspan="1">Enrichment corrected (95% CI)</th>
                      </tr>
                    </thead>
                    <tbody>
                      <tr>
                        <td valign="top" align="left" scope="row" rowspan="1" colspan="1">Sensitivity</td>
                        <td valign="middle" align="left" rowspan="1" colspan="1">95.1 (90.1-100) [58/61]</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">96.9 (91.2-100)</td>
                        <td valign="middle" align="left" rowspan="1" colspan="1">95.2 (90.4-100) [60/63]</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">97.0 (91.2-100)</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" scope="row" rowspan="1" colspan="1">Specificity</td>
                        <td valign="middle" align="left" rowspan="1" colspan="1">89.0 (87.0-91.1) [1288/1447]</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">90.0 (89.2-91.5)</td>
                        <td valign="middle" align="left" rowspan="1" colspan="1">89.5 (87.6-91.4) [1444/1614]</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">90.1 (89.4-91.5)</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" scope="row" rowspan="1" colspan="1">Imageability</td>
                        <td valign="middle" align="left" rowspan="1" colspan="1">87.6 (85.4-89.8) [1508/1721]</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">87.8 (85.0-89.3)</td>
                        <td valign="middle" align="left" rowspan="1" colspan="1">97.4 (96.4-98.5) [1677/1721]</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">97 .7 (96.4-98.3)</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" scope="row" rowspan="1" colspan="1">PPV</td>
                        <td valign="middle" align="left" rowspan="1" colspan="1">26.7 (19.5-33.0) [58/217]</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">29.6 (24.4-29.9)</td>
                        <td valign="middle" align="left" rowspan="1" colspan="1">26.1 (19.6-32.6) [60/230]</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">29.9 (24.7-30.1)</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" scope="row" rowspan="1" colspan="1">NPV</td>
                        <td valign="middle" align="left" rowspan="1" colspan="1">99.8 (99.5-100) [1288/1291]</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">99.8 (99.6-100)</td>
                        <td valign="middle" align="left" rowspan="1" colspan="1">99.8 [99.5-100) [1444/1447]</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">99.9 (99.6-100)</td>
                      </tr>
                    </tbody>
                  </table>
                  <table-wrap-foot>
                    <p>Abbreviations: mtmDR, more-than-mild diabetic retinopathy; NPV, negative predictive value; PPV, positive predictive value; vtDR, vision-threatening diabetic retinopathy.</p>
                    <fn id="zoi210963t3n1">
                      <label>
                        <sup>a</sup>
                      </label>
                      <p>EyeArt is an artificial intelligence system for autonomous detection of mtmDR and vtDR.</p>
                    </fn>
                    <fn id="zoi210963t3n2">
                      <label>
                        <sup>b</sup>
                      </label>
                      <p>Enrichment-corrected estimates are adjusted for prevalence.</p>
                    </fn>
                    <fn id="zoi210963t3n3">
                      <label>
                        <sup>c</sup>
                      </label>
                      <p>The 95% CIs were estimated using clustered bootstrap to account for the correlation between eyes.</p>
                    </fn>
                    <fn id="zoi210963t3n4">
                      <label>
                        <sup>d</sup>
                      </label>
                      <p>The undilated protocol included only undilated images and the dilate-if-needed protocol included images obtained following dilation for a small fraction of cases.</p>
                    </fn>
                  </table-wrap-foot>
                </table-wrap>
                <p>Of participants with gradable images under the dilate-if-needed protocol, mtmDR was detected by the AI system in 296 of 310 eyes identified by the FPRC, for a sensitivity of 95.5% (95% CI, 92.6%-98.4%), indicating only 14 false-negative results (all of which had mild nonproliferative DR). The AI system correctly identified 1186 of 1391 eyes found to be negative for mtmDR by the FPRC, for a specificity of 85.3% (95% CI, 83.0%-87.5%) (<xref rid="zoi210963t2" ref-type="table">Table 2</xref>). Of the 205 eyes with false-positive results, 141 eyes (68.8%) were graded by the FPRC as having mild nonproliferative DR or other non-DR conditions; 31.3% (546 of 1746) of the eyes were referred if ungradable eyes were put together with the disease-positive eyes.</p>
                <p>Sensitivity and specificity of the AI system vs the FPRC were similar for vtDR. The AI system detected vtDR in 60 of 63 eyes positively identified by the FPRC, for a sensitivity of 95.2% (95% CI, 90.4%-100%), and correctly identified 1444 of 1614 eyes graded as negative for vtDR by the FPRC, for a specificity of 89.5% (95% CI, 87.6%-91.4%) (<xref rid="zoi210963t3" ref-type="table">Table 3</xref>). Of the 3 false-negative vtDR identifications, 2 were identified as positive for mtmDR by the AI system and would have received a referral per protocol regardless. Of 170 false-positive eyes, 131 eyes (77.1%) were graded by the FPRC as having mild nonproliferative DR or other non-DR conditions.</p>
                <p>Enrichment correction analysis was conducted to correct for enrichment that was allowed during the enrichment-permitted period. After this enrichment correction, for mtmDR detection the sensitivity was 95.5% (95% CI, 92.9%-97.7%) and specificity was 87.8% (95% CI,86.3%-89.5%), and for vtDR detection the sensitivity was 97.0% (95% CI, 91.2%-100%) and specificity was 90.1% (95% CI, 89.4%-91.5%). Enrichment-corrected imageability outcomes were similar for mtmDR (97.7%; 95% CI, 96.4%-98.3%) and vtDR (97.7%; 95% CI, 96.4%-98.3%) (<xref rid="zoi210963t2" ref-type="table">Table 2</xref>).</p>
                <p>Positive predictive values, indicating the percentage of eyes with true mtmDR or vtDR per FPRC among those with a positive AI result, were 62.8% (95% CI, 58.1%-64.7%) for mtmDR and 29.9% (95% CI, 24.7%-30.1%) for vtDR in the enrichment-corrected population. Negative predictive values, indicating the percentage of eyes without FPRC mtmDR or vtDR among those with a negative AI result, were 98.9% (95% CI, 98.4%-99.5%) for mtmDR and 99.9% (95% CI, 99.6%-100%) for vtDR (<xref rid="zoi210963t3" ref-type="table">Table 3</xref>).</p>
              </sec>
              <sec id="H2-6-ZOI210963">
                <title>Imageability</title>
                <p>Of the 1746 eyes whose images were rated as gradable for mtmDR by the FPRC, the AI system successfully graded 1701 for an imageability of 97.4% (95% CI, 96.4%-98.5%) (<xref rid="zoi210963t2" ref-type="table">Table 2</xref>) under the dilate-if-needed protocol. A total of 1526 of 1746 eyes (87.4%; 95% CI, 85.2%-89.6%) received an mtmDR detection result for the AI system using 2-field CFP without dilation (<xref rid="zoi210963t2" ref-type="table">Table 2</xref>). All eyes with an ETDRS level greater than or equal to 43 were correctly identified as having mtmDR by the AI system.</p>
                <p>Similarly, imageability was high in the analysis of vtDR under the dilate-if-needed protocol. Of 1721 eyes rated as gradable by the FPRC, 1677 were gradable by the AI system for an imageability of 97.4% (95% CI, 96.4%-98.5%). Of eyes that received 2-field retinal imaging for AI analysis, 1508 of 1721 (87.6%; 95% CI, 85.4%-89.8%) did not require dilation to obtain a vtDR detection result (<xref rid="zoi210963t3" ref-type="table">Table 3</xref>).</p>
              </sec>
              <sec id="H2-7-ZOI210963">
                <title>Further Analyses</title>
                <p>No notable differences were observed between disease prevalence (eTables 2 and 3 in <xref rid="note-ZOI210963-1-s" ref-type="supplementary-material">Supplement 1</xref>) and the AI system performance when comparing primary care with eye care sites. Both site types demonstrated similar sensitivity, specificity, and imageability for mtmDR and vtDR (eTable 6 in <xref rid="note-ZOI210963-1-s" ref-type="supplementary-material">Supplement 1</xref>).</p>
                <p>Imputation analysis classified all eyes with images ungradable by the AI system as the opposite of the reference standard (worse-case imputation) or the same as the reference standard (best-case imputation). Outcomes for both mtmDR and vtDR are included in eTable 7 in <xref rid="note-ZOI210963-1-s" ref-type="supplementary-material">Supplement 1</xref>. In brief, the worst-case imputation of sensitivity was 90.8% (95% CI, 86.7%-94.9%) and, of specificity, 83.5% (95% CI, 81.2%-85.9%) for mtmDR and 84.5% (95% CI, 74.7%-94.3%) of sensitivity and 87.5% (95% CI, 85.5%-89.6%) of specificity for vtDR. No notable differences were observed between the imputed outcomes and those of the per-protocol analysis. No adverse events were reported during this study.</p>
                <p>Baseline characteristics of the FDA-specified analysis subgroup of 655 participants (eFigure 1 in <xref rid="note-ZOI210963-1-s" ref-type="supplementary-material">Supplement 1</xref>) are included in eTable 1 in <xref rid="note-ZOI210963-1-s" ref-type="supplementary-material">Supplement 1</xref>. Full results from the FDA-specified analyses of the subgroup population are included in eTables 2-5 in <xref rid="note-ZOI210963-1-s" ref-type="supplementary-material">Supplement 1</xref>.</p>
                <p>Briefly, in participants from the FDA-specified analysis (eAppendix in <xref rid="note-ZOI210963-1-s" ref-type="supplementary-material">Supplement 1</xref>), the sensitivity of the AI system in detecting mtmDR was 96.0% (95% CI, 89.4%-100%) and the specificity was 87.7% (95% CI, 83.9%-91.2%). Similarly, sensitivity of the AI system in detecting vtDR was 92.3% (95% CI, 70.0%-100%) and the specificity was 94.4% (95% CI, 91.7%-97.0%). At primary care sites, the sensitivity of the AI system for mtmDR was 100% (95% CI, 74.1%-100%) and the specificity was 92.0% (95% CI, 85.1%-97.5%). Comparable results were observed for vtDR, with a sensitivity of 100% (95% CI, 51.0%-100%) and specificity of 97.5% (95% CI, 93.4%-100%) (eTables 2 and 3 in <xref rid="note-ZOI210963-1-s" ref-type="supplementary-material">Supplement 1</xref>). Imageability using the AI system at primary care sites where most operators had no prior ophthalmic imaging experience was 97% under the dilate-if-needed protocol and 90% in the first attempt without dilation. For comparison, the AI system’s imageability at eye care sites was 98% (eTables 4 and 5 in <xref rid="note-ZOI210963-1-s" ref-type="supplementary-material">Supplement 1</xref>).</p>
              </sec>
            </sec>
            <sec id="H1-4-ZOI210963">
              <title>Discussion</title>
              <p>In this prospective multicenter cross-sectional diagnostic study, use of the EyeArt Automated DR Detection System in both primary care and eye care centers compared favorably with the reference standard of 4-wide field stereoscopic images and reading center assessment in detecting both mtmDR and vtDR in patients older than 18 years with diabetes. The AI system consistently met the predetermined sensitivity and specificity end points for detection of mtmDR and vtDR using 2-field CFP imaging.</p>
              <p>Overall imageability of the AI system was high under the dilate-if-needed protocol, yet also high without dilation. The rate of cases classified as ungradable by the AI system was 12.5% without dilation and 2.7% under the dilate-if-needed protocol, which is consistent with the rates of human graders (10%-15%).<sup><xref rid="zoi210963r15" ref-type="bibr">15</xref>,<xref rid="zoi210963r29" ref-type="bibr">29</xref></sup> When the AI system’s images are considered ungradable, physician referral is indicated for further examination to minimize missed diagnoses, reducing any risk of undiagnosed retinal findings. Both the per-protocol and FDA-specified analysis cohorts showed high levels of sensitivity, specificity, and imageability across study site types and enrollment categories, providing added validity for the entire cohort and its findings.</p>
              <p>Ease-of-use in primary care is important for application of an autonomous AI system because the intended user population includes technicians and staff with no prior retinal imaging experience. The findings of this study show this ease-of-use; the AI system’s performance at primary care sites, which included this user base, was good and comparable to the overall study. The high imageability for these operators suggests that, with standardized training, reliable disease detection results can be obtained by staff without prior retinal imaging experience. In addition, the need for dilation in only a few participants allows examinations to be more easily performed in non–eye care centers and/or in patients who refuse dilation.</p>
              <p>Use of point-of-care DR screening with the AI system is especially helpful for triage of 2 types of patients: those not requiring specialist referrals and those with vtDR. The referral rate in this study was 31.3% (546 of 1746) when referrals for disease were combined with ungradable eyes. Therefore, most patients do not require referrals, reducing the diagnostic burden on eye care specialists and time costs for patients. Second, the unique clearance by the FDA to identify vtDR allows for accelerated referrals to more rapidly confirm and treat potentially vision-threatening disease. This is important in triaging those patients to eye care specialists within the guideline-recommended referral time for urgent treatment.<sup><xref rid="zoi210963r9" ref-type="bibr">9</xref>,<xref rid="zoi210963r29" ref-type="bibr">29</xref></sup></p>
              <p>The automated AI screening system eliminates other patient-reported barriers inhibiting the routine completion of an eye examination, including high cost and limited access to eye care specialists.<sup><xref rid="zoi210963r4" ref-type="bibr">4</xref></sup> In this study, comparable efficacy was demonstrated by the AI system across primary care and eye care facilities. Therefore, patients can receive prompt, accurate, and consistent detection of mtmDR or vtDR at their facility of choice without specialist involvement. Furthermore, this prompt detection at primary care may help eliminate the disparity in care for patients who live far from eye care specialists. The rapid on-site eye-level DR detection by the AI system enables prompt diagnosis allowing for same-day referral requests for follow-up care, improving the chances of preventing vision loss. In addition, the ability for patients to receive an accurate diagnosis at nonspecialist sites can lower the cost to the patient and health system. Elimination of these patient-identified barriers can improve overall adherence to annual screenings and may result in decreased vision loss through earlier identification of vtDR. The study required a small number of eyes to be dilated to facilitate disease detection results, whereas a large proportion of participants (87.4%) did not require dilation.</p>
              <p>To our knowledge, only one other automated DR detection system has been examined in a prospective, multicenter study.<sup><xref rid="zoi210963r12" ref-type="bibr">12</xref></sup> The mtmDR findings reported on the IDx-DR system were 87.2% for sensitivity, 90.7% for specificity, and 96.1% for imageability rate after enrichment correction in a cohort of 819 participants. Using the EyeArt system, we found sensitivity of 95.5%, specificity of 87.8%, and imageability rate of 97.7% for mtmDR after enrichment correction in a cohort of 893 patients. Both studies used the same reference standard: ETDRS grading of 4-wide field stereoscopic dilated fundus photographs by FPRC graders. The IDx-DR system is indicated only for detection of mtmDR, whereas the EyeArt system is indicated for detection of both mtmDR and vtDR.</p>
              <sec id="H2-8-ZOI210963">
                <title>Strengths and Limitations</title>
                <p>Study strengths include the moderately sized, diverse analysis population and the inclusion of study centers representative of the intended use population. In addition, the analysis of both undilated and dilated images shows the applicability of the EyeArt system for locations or situations in which dilation is not possible or desired.</p>
                <p>This study has limitations. A limitation of the study is that optical coherence tomography was not used to determine CSME as an alternative reference standard. However, stereo measurement as used in this study from CFP is known to be an accurate, sufficient, and widely accepted clinical reference standard, including by the FDA.<sup><xref rid="zoi210963r27" ref-type="bibr">27</xref></sup></p>
              </sec>
            </sec>
            <sec id="H1-5-ZOI210963">
              <title>Conclusions</title>
              <p>This prospective multicenter cross-sectional diagnostic study observed safe and accurate clinical performance of the EyeArt Automated DR Detection System in detecting both mtmDR and vtDR without physician assistance. This AI system may broadly improve DR screening and monitoring in people with diabetes by non–eye care professionals to safely and reliably detect referable DR in clinical practice.</p>
            </sec>
          </body>
          <back>
            <ref-list id="REF-ZOI210963">
              <title>References</title>
              <ref id="zoi210963r1">
                <label>1</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Ogurtsova</surname><given-names>K</given-names></string-name>, <string-name><surname>da Rocha Fernandes</surname><given-names>JD</given-names></string-name>, <string-name><surname>Huang</surname><given-names>Y</given-names></string-name>, <etal/></person-group>. <article-title>IDF Diabetes Atlas: global estimates for the prevalence of diabetes for 2015 and 2040</article-title>. <source>Diabetes Res Clin Pract</source>. <year>2017</year>;<volume>128</volume>:<fpage>40</fpage>-<lpage>50</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.diabres.2017.03.024</pub-id><?supplied-pmid 28437734?><pub-id pub-id-type="pmid">28437734</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r2">
                <label>2</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Yau</surname><given-names>JW</given-names></string-name>, <string-name><surname>Rogers</surname><given-names>SL</given-names></string-name>, <string-name><surname>Kawasaki</surname><given-names>R</given-names></string-name>, <etal/>; <collab>Meta-analysis for Eye Disease (META-EYE) Study Group</collab></person-group>. <article-title>Global prevalence and major risk factors of diabetic retinopathy</article-title>. <source>Diabetes Care</source>. <year>2012</year>;<volume>35</volume>(<issue>3</issue>):<fpage>556</fpage>-<lpage>564</lpage>. doi:<pub-id pub-id-type="doi">10.2337/dc11-1909</pub-id><?supplied-pmid 22301125?><pub-id pub-id-type="pmid">22301125</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r3">
                <label>3</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Flaxel</surname><given-names>CJAR</given-names></string-name>, <string-name><surname>Bailey</surname><given-names>ST</given-names></string-name>, <string-name><surname>Fawzi</surname><given-names>A</given-names></string-name>, <string-name><surname>Lim</surname><given-names>JI</given-names></string-name>, <string-name><surname>Vemulakonda</surname><given-names>GA</given-names></string-name></person-group>. <article-title>Diabetic retinopathy preferred practice pattern</article-title>. <source>Ophthalmology.</source><year>2020</year>;<volume>127</volume>(<issue>1</issue>):<fpage>66</fpage>-<lpage>P145</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.ophtha.2019.09.025</pub-id><?supplied-pmid 31757498?><pub-id pub-id-type="pmid">31757498</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r4">
                <label>4</label>
                <mixed-citation publication-type="webpage"><person-group><collab>International Federation on Ageing</collab></person-group>. International Agency for the Prevention of Blindness; International Diabetes Federation. The Diabetic Retinopathy Barometer Report Global Findings. Accessed October 1, 2021. <ext-link xlink:href="https://www.iapb.org/wp-content/uploads/DR-Global-Report-1.pdf" ext-link-type="uri">https://www.iapb.org/wp-content/uploads/DR-Global-Report-1.pdf</ext-link></mixed-citation>
              </ref>
              <ref id="zoi210963r5">
                <label>5</label>
                <mixed-citation publication-type="book"><person-group><collab>Centers for Disease Control and Prevention</collab></person-group>. <source>Diabetes Report Card 2017.</source><publisher-name>US Dept of Health and Human Services</publisher-name>; <year>2018</year>.</mixed-citation>
              </ref>
              <ref id="zoi210963r6">
                <label>6</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Shi</surname><given-names>Q</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>Y</given-names></string-name>, <string-name><surname>Fonseca</surname><given-names>V</given-names></string-name>, <string-name><surname>Krousel-Wood</surname><given-names>M</given-names></string-name>, <string-name><surname>Shi</surname><given-names>L</given-names></string-name></person-group>. <article-title>Racial disparity of eye examinations among the U.S. working-age population with diabetes: 2002-2009</article-title>. <source>Diabetes Care</source>. <year>2014</year>;<volume>37</volume>(<issue>5</issue>):<fpage>1321</fpage>-<lpage>1328</lpage>. doi:<pub-id pub-id-type="doi">10.2337/dc13-1038</pub-id><?supplied-pmid 24574354?><pub-id pub-id-type="pmid">24574354</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r7">
                <label>7</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Lin</surname><given-names>S</given-names></string-name>, <string-name><surname>Ramulu</surname><given-names>P</given-names></string-name>, <string-name><surname>Lamoureux</surname><given-names>EL</given-names></string-name>, <string-name><surname>Sabanayagam</surname><given-names>C</given-names></string-name></person-group>. <article-title>Addressing risk factors, screening, and preventative treatment for diabetic retinopathy in developing countries: a review</article-title>. <source>Clin Exp Ophthalmol</source>. <year>2016</year>;<volume>44</volume>(<issue>4</issue>):<fpage>300</fpage>-<lpage>320</lpage>. doi:<pub-id pub-id-type="doi">10.1111/ceo.12745</pub-id><?supplied-pmid 26991970?><pub-id pub-id-type="pmid">26991970</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r8">
                <label>8</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Mehranbod</surname><given-names>C</given-names></string-name>, <string-name><surname>Genter</surname><given-names>P</given-names></string-name>, <string-name><surname>Serpas</surname><given-names>L</given-names></string-name>, <etal/></person-group>. <article-title>Automated reminders improve retinal screening rates in low income, minority patients with diabetes and correct the African American disparity</article-title>. <source>J Med Syst</source>. <year>2019</year>;<volume>44</volume>(<issue>1</issue>):<fpage>17</fpage>. doi:<pub-id pub-id-type="doi">10.1007/s10916-019-1510-3</pub-id><?supplied-pmid 31820116?><pub-id pub-id-type="pmid">31820116</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r9">
                <label>9</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Daskivich</surname><given-names>LP</given-names></string-name>, <string-name><surname>Vasquez</surname><given-names>C</given-names></string-name>, <string-name><surname>Martinez</surname><given-names>C</given-names><suffix>Jr</suffix></string-name>, <string-name><surname>Tseng</surname><given-names>CH</given-names></string-name>, <string-name><surname>Mangione</surname><given-names>CM</given-names></string-name></person-group>. <article-title>Implementation and evaluation of a large-scale teleretinal diabetic retinopathy screening program in the Los Angeles County Department of Health Services</article-title>. <source>JAMA Intern Med</source>. <year>2017</year>;<volume>177</volume>(<issue>5</issue>):<fpage>642</fpage>-<lpage>649</lpage>. doi:<pub-id pub-id-type="doi">10.1001/jamainternmed.2017.0204</pub-id><?supplied-pmid 28346590?><pub-id pub-id-type="pmid">28346590</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r10">
                <label>10</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Garg</surname><given-names>S</given-names></string-name>, <string-name><surname>Davis</surname><given-names>RM</given-names></string-name></person-group>. <article-title>Diabetic retinopathy screening update</article-title>. <source>Clin Diabetes</source>. <year>2009</year>;<volume>27</volume>(<issue>4</issue>):<fpage>140</fpage>-<lpage>145</lpage>. doi:<pub-id pub-id-type="doi">10.2337/diaclin.27.4.140</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r11">
                <label>11</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Gargeya</surname><given-names>R</given-names></string-name>, <string-name><surname>Leng</surname><given-names>T</given-names></string-name></person-group>. <article-title>Automated identification of diabetic retinopathy using deep learning</article-title>. <source>Ophthalmology</source>. <year>2017</year>;<volume>124</volume>(<issue>7</issue>):<fpage>962</fpage>-<lpage>969</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.ophtha.2017.02.008</pub-id><?supplied-pmid 28359545?><pub-id pub-id-type="pmid">28359545</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r12">
                <label>12</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Abràmoff</surname><given-names>MD</given-names></string-name>, <string-name><surname>Lavin</surname><given-names>PT</given-names></string-name>, <string-name><surname>Birch</surname><given-names>M</given-names></string-name>, <string-name><surname>Shah</surname><given-names>N</given-names></string-name>, <string-name><surname>Folk</surname><given-names>JC</given-names></string-name></person-group>. <article-title>Pivotal trial of an autonomous AI-based diagnostic system for detection of diabetic retinopathy in primary care offices</article-title>. <source>NPJ Digit Med</source>. <year>2018</year>;<volume>1</volume>:<fpage>39</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41746-018-0040-6</pub-id><?supplied-pmid 31304320?><pub-id pub-id-type="pmid">31304320</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r13">
                <label>13</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Agurto</surname><given-names>C</given-names></string-name>, <string-name><surname>Barriga</surname><given-names>ES</given-names></string-name>, <string-name><surname>Murray</surname><given-names>V</given-names></string-name>, <etal/></person-group>. <article-title>Automatic detection of diabetic retinopathy and age-related macular degeneration in digital fundus images</article-title>. <source>Invest Ophthalmol Vis Sci</source>. <year>2011</year>;<volume>52</volume>(<issue>8</issue>):<fpage>5862</fpage>-<lpage>5871</lpage>. doi:<pub-id pub-id-type="doi">10.1167/iovs.10-7075</pub-id><?supplied-pmid 21666234?><pub-id pub-id-type="pmid">21666234</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r14">
                <label>14</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Bhaskaranand</surname><given-names>M</given-names></string-name>, <string-name><surname>Ramachandra</surname><given-names>C</given-names></string-name>, <string-name><surname>Bhat</surname><given-names>S</given-names></string-name>, <etal/></person-group>. <article-title>The value of automated diabetic retinopathy screening with the EyeArt system: a study of more than 100,000 consecutive encounters from people with diabetes</article-title>. <source>Diabetes Technol Ther</source>. <year>2019</year>;<volume>21</volume>(<issue>11</issue>):<fpage>635</fpage>-<lpage>643</lpage>. doi:<pub-id pub-id-type="doi">10.1089/dia.2019.0164</pub-id><?supplied-pmid 31335200?><pub-id pub-id-type="pmid">31335200</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r15">
                <label>15</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Fleming</surname><given-names>AD</given-names></string-name>, <string-name><surname>Goatman</surname><given-names>KA</given-names></string-name>, <string-name><surname>Philip</surname><given-names>S</given-names></string-name>, <string-name><surname>Prescott</surname><given-names>GJ</given-names></string-name>, <string-name><surname>Sharp</surname><given-names>PF</given-names></string-name>, <string-name><surname>Olson</surname><given-names>JA</given-names></string-name></person-group>. <article-title>Automated grading for diabetic retinopathy: a large-scale audit using arbitration by clinical experts</article-title>. <source>Br J Ophthalmol</source>. <year>2010</year>;<volume>94</volume>(<issue>12</issue>):<fpage>1606</fpage>-<lpage>1610</lpage>. doi:<pub-id pub-id-type="doi">10.1136/bjo.2009.176784</pub-id><?supplied-pmid 20858722?><pub-id pub-id-type="pmid">20858722</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r16">
                <label>16</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Gulshan</surname><given-names>V</given-names></string-name>, <string-name><surname>Peng</surname><given-names>L</given-names></string-name>, <string-name><surname>Coram</surname><given-names>M</given-names></string-name>, <etal/></person-group>. <article-title>Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs</article-title>. <source>JAMA</source>. <year>2016</year>;<volume>316</volume>(<issue>22</issue>):<fpage>2402</fpage>-<lpage>2410</lpage>. doi:<pub-id pub-id-type="doi">10.1001/jama.2016.17216</pub-id><?supplied-pmid 27898976?><pub-id pub-id-type="pmid">27898976</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r17">
                <label>17</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Tufail</surname><given-names>A</given-names></string-name>, <string-name><surname>Rudisill</surname><given-names>C</given-names></string-name>, <string-name><surname>Egan</surname><given-names>C</given-names></string-name>, <etal/></person-group>. <article-title>Automated diabetic retinopathy image assessment software: diagnostic accuracy and cost-effectiveness compared with human graders</article-title>. <source>Ophthalmology</source>. <year>2017</year>;<volume>124</volume>(<issue>3</issue>):<fpage>343</fpage>-<lpage>351</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.ophtha.2016.11.014</pub-id><?supplied-pmid 28024825?><pub-id pub-id-type="pmid">28024825</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r18">
                <label>18</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Davis</surname><given-names>RM</given-names></string-name>, <string-name><surname>Fowler</surname><given-names>S</given-names></string-name>, <string-name><surname>Bellis</surname><given-names>K</given-names></string-name>, <string-name><surname>Pockl</surname><given-names>J</given-names></string-name>, <string-name><surname>Al Pakalnis</surname><given-names>V</given-names></string-name>, <string-name><surname>Woldorf</surname><given-names>A</given-names></string-name></person-group>. <article-title>Telemedicine improves eye examination rates in individuals with diabetes: a model for eye-care delivery in underserved communities</article-title>. <source>Diabetes Care</source>. <year>2003</year>;<volume>26</volume>(<issue>8</issue>):<fpage>2476</fpage>. doi:<pub-id pub-id-type="doi">10.2337/diacare.26.8.2476</pub-id><?supplied-pmid 12882889?><pub-id pub-id-type="pmid">12882889</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r19">
                <label>19</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Bhaskaranand</surname><given-names>M</given-names></string-name>, <string-name><surname>Ramachandra</surname><given-names>C</given-names></string-name>, <string-name><surname>Bhat</surname><given-names>S</given-names></string-name>, <etal/></person-group>. <article-title>Automated diabetic retinopathy screening and monitoring using retinal fundus image analysis</article-title>. <source>J Diabetes Sci Technol</source>. <year>2016</year>;<volume>10</volume>(<issue>2</issue>):<fpage>254</fpage>-<lpage>261</lpage>. doi:<pub-id pub-id-type="doi">10.1177/1932296816628546</pub-id><?supplied-pmid 26888972?><pub-id pub-id-type="pmid">26888972</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r20">
                <label>20</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Ting</surname><given-names>DSW</given-names></string-name>, <string-name><surname>Cheung</surname><given-names>CY</given-names></string-name>, <string-name><surname>Lim</surname><given-names>G</given-names></string-name>, <etal/></person-group>. <article-title>Development and validation of a deep learning system for diabetic retinopathy and related eye diseases using retinal images from multiethnic populations with diabetes</article-title>. <source>JAMA</source>. <year>2017</year>;<volume>318</volume>(<issue>22</issue>):<fpage>2211</fpage>-<lpage>2223</lpage>. doi:<pub-id pub-id-type="doi">10.1001/jama.2017.18152</pub-id><?supplied-pmid 29234807?><pub-id pub-id-type="pmid">29234807</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r21">
                <label>21</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Lee</surname><given-names>AY</given-names></string-name>, <string-name><surname>Yanagihara</surname><given-names>RT</given-names></string-name>, <string-name><surname>Lee</surname><given-names>CS</given-names></string-name>, <etal/></person-group>. <article-title>Multicenter, head-to-head, real-world validation study of seven automated artificial intelligence diabetic retinopathy screening systems</article-title>. <source>Diabetes Care</source>. <year>2021</year>;<volume>44</volume>(<issue>5</issue>):<fpage>1168</fpage>-<lpage>1175</lpage>. doi:<pub-id pub-id-type="doi">10.2337/dc20-1877</pub-id><?supplied-pmid 33402366?><pub-id pub-id-type="pmid">33402366</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r22">
                <label>22</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Wong</surname><given-names>TY</given-names></string-name>, <string-name><surname>Sun</surname><given-names>J</given-names></string-name>, <string-name><surname>Kawasaki</surname><given-names>R</given-names></string-name>, <etal/></person-group>. <article-title>Guidelines on Diabetic Eye Care: The International Council of Ophthalmology recommendations for screening, follow-up, referral, and treatment based on resource settings</article-title>. <source>Ophthalmology</source>. <year>2018</year>;<volume>125</volume>(<issue>10</issue>):<fpage>1608</fpage>-<lpage>1622</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.ophtha.2018.04.007</pub-id><?supplied-pmid 29776671?><pub-id pub-id-type="pmid">29776671</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r23">
                <label>23</label>
                <mixed-citation publication-type="webpage"><person-group><collab>International Council for Harmonisation</collab></person-group>. Guideline for good clinical practice E6. Accessed November 19, 2019. <ext-link xlink:href="https://www.ich.org/products/guidelines/efficacy/efficacy-single/article/good-clinical-practice.html" ext-link-type="uri">https://www.ich.org/products/guidelines/efficacy/efficacy-single/article/good-clinical-practice.html</ext-link></mixed-citation>
              </ref>
              <ref id="zoi210963r24">
                <label>24</label>
                <mixed-citation publication-type="webpage"><person-group><collab>World Medical Association</collab></person-group>. World Medical Association Declaration of Helsinki—ethical principles for medical research involving human subjects. Accessed November 21, 2019. <ext-link xlink:href="https://www.wma.net/policies-post/wma-declaration-of-helsinki-ethical-principles-for-medical-research-involving-human-subjects/" ext-link-type="uri">https://www.wma.net/policies-post/wma-declaration-of-helsinki-ethical-principles-for-medical-research-involving-human-subjects/</ext-link></mixed-citation>
              </ref>
              <ref id="zoi210963r25">
                <label>25</label>
                <mixed-citation publication-type="webpage"><person-group><collab>The Wisconsin Reading Center</collab></person-group>. Department of Ophthalmology and Visual Sciences, University of Wisconsin School of Medicine and Public Health. Accessed October 20, 2021. <ext-link xlink:href="https://www.ophth.wisc.edu/research/wrc/" ext-link-type="uri">https://www.ophth.wisc.edu/research/wrc/</ext-link></mixed-citation>
              </ref>
              <ref id="zoi210963r26">
                <label>26</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Gangaputra</surname><given-names>S</given-names></string-name>, <string-name><surname>Almukhtar</surname><given-names>T</given-names></string-name>, <string-name><surname>Glassman</surname><given-names>AR</given-names></string-name>, <etal/>; <collab>Diabetic Retinopathy Clinical Research Network</collab></person-group>. <article-title>Comparison of film and digital fundus photographs in eyes of individuals with diabetes mellitus</article-title>. <source>Invest Ophthalmol Vis Sci</source>. <year>2011</year>;<volume>52</volume>(<issue>9</issue>):<fpage>6168</fpage>-<lpage>6173</lpage>. doi:<pub-id pub-id-type="doi">10.1167/iovs.11-7321</pub-id><?supplied-pmid 21571677?><pub-id pub-id-type="pmid">21571677</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r27">
                <label>27</label>
                <mixed-citation publication-type="journal"><person-group><collab>Early Treatment Diabetic Retinopathy Study Research Group</collab></person-group>. <article-title>Grading diabetic retinopathy from stereoscopic color fundus photographs—an extension of the modified Airlie House classification: ETDRS report number 10</article-title>. <source>Ophthalmology</source>. <year>1991</year>;<volume>98</volume>(<issue>5</issue>)(<supplement>suppl</supplement>):<fpage>786</fpage>-<lpage>806</lpage>. doi:<pub-id pub-id-type="doi">10.1016/S0161-6420(13)38012-9</pub-id><?supplied-pmid 2062513?><pub-id pub-id-type="pmid">2062513</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r28">
                <label>28</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Jung</surname><given-names>SH</given-names></string-name>, <string-name><surname>Kang</surname><given-names>SH</given-names></string-name>, <string-name><surname>Ahn</surname><given-names>C</given-names></string-name></person-group>. <article-title>Sample size calculations for clustered binary data</article-title>. <source>Stat Med</source>. <year>2001</year>;<volume>20</volume>(<issue>13</issue>):<fpage>1971</fpage>-<lpage>1982</lpage>. doi:<pub-id pub-id-type="doi">10.1002/sim.846</pub-id><?supplied-pmid 11427953?><pub-id pub-id-type="pmid">11427953</pub-id></mixed-citation>
              </ref>
              <ref id="zoi210963r29">
                <label>29</label>
                <mixed-citation publication-type="journal"><person-group><string-name><surname>Kim</surname><given-names>HM</given-names></string-name>, <string-name><surname>Lowery</surname><given-names>JC</given-names></string-name>, <string-name><surname>Kurtz</surname><given-names>R</given-names></string-name></person-group>. <article-title>Accuracy of digital images for assessing diabetic retinopathy</article-title>. <source>J Diabetes Sci Technol</source>. <year>2007</year>;<volume>1</volume>(<issue>4</issue>):<fpage>531</fpage>-<lpage>539</lpage>. doi:<pub-id pub-id-type="doi">10.1177/193229680700100411</pub-id><?supplied-pmid 19885116?><pub-id pub-id-type="pmid">19885116</pub-id></mixed-citation>
              </ref>
            </ref-list>
            <notes notes-type="supplementary-material" id="note-ZOI210963-1">
              <supplementary-material id="note-ZOI210963-1-s" position="float" content-type="local-data">
                <label>Supplement 1.</label>
                <caption>
                  <p><bold>eAppendix.</bold> FDA-Specified Analysis of the Subgroup of Participants Specified by the FDA to Support Clearance</p>
                  <p><bold>eFigure 1.</bold> Participant Disposition and Cohorts Used for FDA-Specified Analyses to Support FDA Clearance</p>
                  <p><bold>eTable 1.</bold> Baseline Characteristics From the FDA-Specified Population and Original Population</p>
                  <p><bold>eTable 2.</bold> EyeArt Performance From the FDA-Specified Analysis of the Sequentially Enrolled Cohort</p>
                  <p><bold>eTable 3.</bold> EyeArt Performance From the FDA-Specified Analysis of the Enrichment-Permitted Cohort</p>
                  <p><bold>eTable 4.</bold> EyeArt Imageability From the FDA-Specified Analysis of Participants Enrolled at Primary Care Centers</p>
                  <p><bold>eTable 5.</bold> EyeArt Imageability From the FDA-Specified Analysis of Participants Enrolled at Eye Care Centers</p>
                  <p><bold>eTable 6.</bold> EyeArt Performance by Study Center Type in the Per-Protocol Population</p>
                  <p><bold>eTable 7.</bold> Best- and Worst-Case Imputation Analyses in the Per-Protocol Population</p>
                </caption>
                <media xlink:href="jamanetwopen-e2134254-s001.pdf">
                  <caption>
                    <p>Click here for additional data file.</p>
                  </caption>
                </media>
              </supplementary-material>
              <supplementary-material position="float" content-type="local-data">
                <label>Supplement 2.</label>
                <caption>
                  <p><bold>Nonauthor Collaborators.</bold> The EyeArt Study Group</p>
                </caption>
                <media xlink:href="jamanetwopen-e2134254-s002.pdf">
                  <caption>
                    <p>Click here for additional data file.</p>
                  </caption>
                </media>
              </supplementary-material>
            </notes>
          </back>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
