<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2024-05-03T03:34:38Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:8118267" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:8118267</identifier>
        <datestamp>2021-05-24</datestamp>
        <setSpec>plosone</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" article-type="research-article">
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
              <journal-id journal-id-type="iso-abbrev">PLoS One</journal-id>
              <journal-id journal-id-type="publisher-id">plos</journal-id>
              <journal-id journal-id-type="pmc">plosone</journal-id>
              <journal-title-group>
                <journal-title>PLoS ONE</journal-title>
              </journal-title-group>
              <issn pub-type="epub">1932-6203</issn>
              <publisher>
                <publisher-name>Public Library of Science</publisher-name>
                <publisher-loc>San Francisco, CA USA</publisher-loc>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC8118267</article-id>
              <article-id pub-id-type="pmcid">PMC8118267</article-id>
              <article-id pub-id-type="pmc-uid">8118267</article-id>
              <article-id pub-id-type="pmid">33983969</article-id>
              <article-id pub-id-type="publisher-id">PONE-D-20-29382</article-id>
              <article-id pub-id-type="doi">10.1371/journal.pone.0250176</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Research Article</subject>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Biology and Life Sciences</subject>
                  <subj-group>
                    <subject>Anatomy</subject>
                    <subj-group>
                      <subject>Head</subject>
                      <subj-group>
                        <subject>Face</subject>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Medicine and Health Sciences</subject>
                  <subj-group>
                    <subject>Anatomy</subject>
                    <subj-group>
                      <subject>Head</subject>
                      <subj-group>
                        <subject>Face</subject>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Biology and Life Sciences</subject>
                  <subj-group>
                    <subject>Psychology</subject>
                    <subj-group>
                      <subject>Emotions</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Social Sciences</subject>
                  <subj-group>
                    <subject>Psychology</subject>
                    <subj-group>
                      <subject>Emotions</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Biology and Life Sciences</subject>
                  <subj-group>
                    <subject>Anatomy</subject>
                    <subj-group>
                      <subject>Head</subject>
                      <subj-group>
                        <subject>Eyes</subject>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Medicine and Health Sciences</subject>
                  <subj-group>
                    <subject>Anatomy</subject>
                    <subj-group>
                      <subject>Head</subject>
                      <subj-group>
                        <subject>Eyes</subject>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Biology and Life Sciences</subject>
                  <subj-group>
                    <subject>Anatomy</subject>
                    <subj-group>
                      <subject>Ocular System</subject>
                      <subj-group>
                        <subject>Eyes</subject>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Medicine and Health Sciences</subject>
                  <subj-group>
                    <subject>Anatomy</subject>
                    <subj-group>
                      <subject>Ocular System</subject>
                      <subj-group>
                        <subject>Eyes</subject>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Medicine and Health Sciences</subject>
                  <subj-group>
                    <subject>Mental Health and Psychiatry</subject>
                    <subj-group>
                      <subject>Mood Disorders</subject>
                      <subj-group>
                        <subject>Depression</subject>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Medicine and Health Sciences</subject>
                  <subj-group>
                    <subject>Mental Health and Psychiatry</subject>
                    <subj-group>
                      <subject>Neuropsychiatric Disorders</subject>
                      <subj-group>
                        <subject>Anxiety Disorders</subject>
                        <subj-group>
                          <subject>Social Anxiety Disorder</subject>
                        </subj-group>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Medicine and Health Sciences</subject>
                  <subj-group>
                    <subject>Mental Health and Psychiatry</subject>
                    <subj-group>
                      <subject>Neuroses</subject>
                      <subj-group>
                        <subject>Anxiety Disorders</subject>
                        <subj-group>
                          <subject>Social Anxiety Disorder</subject>
                        </subj-group>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Biology and Life Sciences</subject>
                  <subj-group>
                    <subject>Neuroscience</subject>
                    <subj-group>
                      <subject>Cognitive Science</subject>
                      <subj-group>
                        <subject>Cognitive Psychology</subject>
                        <subj-group>
                          <subject>Perception</subject>
                          <subj-group>
                            <subject>Sensory Perception</subject>
                            <subj-group>
                              <subject>Vision</subject>
                            </subj-group>
                          </subj-group>
                        </subj-group>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Biology and Life Sciences</subject>
                  <subj-group>
                    <subject>Psychology</subject>
                    <subj-group>
                      <subject>Cognitive Psychology</subject>
                      <subj-group>
                        <subject>Perception</subject>
                        <subj-group>
                          <subject>Sensory Perception</subject>
                          <subj-group>
                            <subject>Vision</subject>
                          </subj-group>
                        </subj-group>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Social Sciences</subject>
                  <subj-group>
                    <subject>Psychology</subject>
                    <subj-group>
                      <subject>Cognitive Psychology</subject>
                      <subj-group>
                        <subject>Perception</subject>
                        <subj-group>
                          <subject>Sensory Perception</subject>
                          <subj-group>
                            <subject>Vision</subject>
                          </subj-group>
                        </subj-group>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Biology and Life Sciences</subject>
                  <subj-group>
                    <subject>Neuroscience</subject>
                    <subj-group>
                      <subject>Sensory Perception</subject>
                      <subj-group>
                        <subject>Vision</subject>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Medicine and Health Sciences</subject>
                  <subj-group>
                    <subject>Mental Health and Psychiatry</subject>
                    <subj-group>
                      <subject>Neuropsychiatric Disorders</subject>
                      <subj-group>
                        <subject>Anxiety Disorders</subject>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Medicine and Health Sciences</subject>
                  <subj-group>
                    <subject>Mental Health and Psychiatry</subject>
                    <subj-group>
                      <subject>Neuroses</subject>
                      <subj-group>
                        <subject>Anxiety Disorders</subject>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Biology and Life Sciences</subject>
                  <subj-group>
                    <subject>Psychology</subject>
                    <subj-group>
                      <subject>Emotions</subject>
                      <subj-group>
                        <subject>Anxiety</subject>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v3">
                  <subject>Social Sciences</subject>
                  <subj-group>
                    <subject>Psychology</subject>
                    <subj-group>
                      <subject>Emotions</subject>
                      <subj-group>
                        <subject>Anxiety</subject>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>Visual attention toward emotional stimuli: Anxiety symptoms correspond to distinct gaze patterns</article-title>
                <alt-title alt-title-type="running-head">Anxiety and visual attention to the mouth</alt-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author">
                  <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8852-7602</contrib-id>
                  <name>
                    <surname>Rutter</surname>
                    <given-names>Lauren A.</given-names>
                  </name>
                  <role content-type="https://casrai.org/credit/">Data curation</role>
                  <role content-type="https://casrai.org/credit/">Formal analysis</role>
                  <role content-type="https://casrai.org/credit/">Funding acquisition</role>
                  <role content-type="https://casrai.org/credit/">Investigation</role>
                  <role content-type="https://casrai.org/credit/">Methodology</role>
                  <role content-type="https://casrai.org/credit/">Project administration</role>
                  <role content-type="https://casrai.org/credit/">Writing – original draft</role>
                  <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
                  <xref ref-type="aff" rid="aff001">
                    <sup>1</sup>
                  </xref>
                  <xref ref-type="corresp" rid="cor001">*</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Norton</surname>
                    <given-names>Daniel J.</given-names>
                  </name>
                  <role content-type="https://casrai.org/credit/">Conceptualization</role>
                  <role content-type="https://casrai.org/credit/">Data curation</role>
                  <role content-type="https://casrai.org/credit/">Formal analysis</role>
                  <role content-type="https://casrai.org/credit/">Methodology</role>
                  <role content-type="https://casrai.org/credit/">Project administration</role>
                  <role content-type="https://casrai.org/credit/">Writing – original draft</role>
                  <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
                  <xref ref-type="aff" rid="aff002">
                    <sup>2</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Brown</surname>
                    <given-names>Timothy A.</given-names>
                  </name>
                  <role content-type="https://casrai.org/credit/">Conceptualization</role>
                  <role content-type="https://casrai.org/credit/">Funding acquisition</role>
                  <role content-type="https://casrai.org/credit/">Investigation</role>
                  <role content-type="https://casrai.org/credit/">Methodology</role>
                  <role content-type="https://casrai.org/credit/">Project administration</role>
                  <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
                  <xref ref-type="aff" rid="aff003">
                    <sup>3</sup>
                  </xref>
                </contrib>
              </contrib-group>
              <aff id="aff001">
                <label>1</label>
                <addr-line>Department of Psychological and Brain Sciences, Indiana University-Bloomington, Bloomington, Indiana, United States of America</addr-line>
              </aff>
              <aff id="aff002">
                <label>2</label>
                <addr-line>Department of Psychology, Gordon College, Wenham, Massachusetts, United States of America</addr-line>
              </aff>
              <aff id="aff003">
                <label>3</label>
                <addr-line>Department of Psychological and Brain Sciences, Boston University, Boston, Massachusetts, United States of America</addr-line>
              </aff>
              <contrib-group>
                <contrib contrib-type="editor">
                  <name>
                    <surname>Hills</surname>
                    <given-names>Peter James</given-names>
                  </name>
                  <role>Editor</role>
                  <xref ref-type="aff" rid="edit1"/>
                </contrib>
              </contrib-group>
              <aff id="edit1">
                <addr-line>Bournemouth University, UNITED KINGDOM</addr-line>
              </aff>
              <author-notes>
                <fn fn-type="COI-statement" id="coi001">
                  <p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
                </fn>
                <corresp id="cor001">* E-mail: <email>larutter@iu.edu</email></corresp>
              </author-notes>
              <pub-date pub-type="collection">
                <year>2021</year>
              </pub-date>
              <pub-date pub-type="epub">
                <day>13</day>
                <month>5</month>
                <year>2021</year>
              </pub-date>
              <volume>16</volume>
              <issue>5</issue>
              <elocation-id>e0250176</elocation-id>
              <history>
                <date date-type="received">
                  <day>17</day>
                  <month>9</month>
                  <year>2020</year>
                </date>
                <date date-type="accepted">
                  <day>31</day>
                  <month>3</month>
                  <year>2021</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>© 2021 Rutter et al</copyright-statement>
                <copyright-year>2021</copyright-year>
                <copyright-holder>Rutter et al</copyright-holder>
                <license>
                  <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
                  <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
                </license>
              </permissions>
              <self-uri content-type="pdf" xlink:href="pone.0250176.pdf"/>
              <abstract>
                <p>Decades of research have established a link between emotional disorders and attentional biases for emotional stimuli, but the relationship between symptom severity and visual attention is still not fully understood. Depression has been associated with increased attention towards dysphoric stimuli and decreased attention on positive stimuli (“negativity bias”), and some studies have also shown this trend in anxiety disorders. We examined eye fixation variables in 47 participants with emotional disorders completing an emotion recognition task. Results showed that depression severity was not associated with increased fixations on dysphoric stimuli, however, higher levels of generalized anxiety predicted increased fixations in the mouth region of sad and happy faces. Higher levels of social interaction anxiety predicted reduced fixations in the eye region of happy faces. While we did not replicate the negativity bias that has been shown in prior studies, our sample was highly comorbid, indicating the need to consider comorbidity, disorder severity, and the task itself when conducting research on visual attention in clinical samples. Additionally, more attention should be paid to the mouth region of emotional faces, as it may provide more specific information regarding the visual processing of emotions.</p>
              </abstract>
              <funding-group>
                <award-group id="award001">
                  <funding-source>
                    <institution-wrap>
                      <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000025</institution-id>
                      <institution>National Institute of Mental Health</institution>
                    </institution-wrap>
                  </funding-source>
                  <award-id>MH039096</award-id>
                  <principal-award-recipient>
                    <name>
                      <surname>Brown</surname>
                      <given-names>Timothy A.</given-names>
                    </name>
                  </principal-award-recipient>
                </award-group>
                <award-group id="award002">
                  <funding-source>
                    <institution>Boston University Clara Mayo Fellowship</institution>
                  </funding-source>
                  <principal-award-recipient>
                    <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8852-7602</contrib-id>
                    <name>
                      <surname>Rutter</surname>
                      <given-names>Lauren A.</given-names>
                    </name>
                  </principal-award-recipient>
                </award-group>
                <funding-statement>This work was supported by the National Institute of Mental Health (grant number MH039096 to T.A.B.); and the Boston University Clara Mayo Fellowship (to L.A.R.). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
              </funding-group>
              <counts>
                <fig-count count="1"/>
                <table-count count="2"/>
                <page-count count="15"/>
              </counts>
              <custom-meta-group>
                <custom-meta id="data-availability">
                  <meta-name>Data Availability</meta-name>
                  <meta-value>The data that support the findings of this study are openly available through the Open Science Framework <ext-link ext-link-type="uri" xlink:href="https://osf.io/6ug5d/">https://osf.io/6ug5d/</ext-link>.</meta-value>
                </custom-meta>
              </custom-meta-group>
            </article-meta>
            <notes>
              <title>Data Availability</title>
              <p>The data that support the findings of this study are openly available through the Open Science Framework <ext-link ext-link-type="uri" xlink:href="https://osf.io/6ug5d/">https://osf.io/6ug5d/</ext-link>.</p>
            </notes>
          </front>
          <body>
            <sec sec-type="intro" id="sec001">
              <title>Introduction</title>
              <p>A large body of research has demonstrated attentional biases when viewing emotional stimuli in individuals with emotional disorders. Eye tracking technology provides a direct and continuous measure of overt visual attention, and has been used as an important metric in emotion recognition (ER) tasks. In a meta-analytic review of eye-tracking and affective disorders, results showed that when presented with an array of at least two stimuli, depressed individuals were characterized by reduced orienting to positive stimuli, reduced maintenance of gaze on positive stimuli, and increased gaze on dysphoric stimuli [<xref rid="pone.0250176.ref001" ref-type="bibr">1</xref>, <xref rid="pone.0250176.ref002" ref-type="bibr">2</xref>]. Individuals with depression may voluntarily gaze less at positive stimuli because they are less sensitive to the pleasantness of it, reducing their incentive to maintain gaze. Research has suggested that the strong anhedonic bias in depression is not unique to depression, but an aspect of low positive affect more generally [<xref rid="pone.0250176.ref001" ref-type="bibr">1</xref>, <xref rid="pone.0250176.ref003" ref-type="bibr">3</xref>, <xref rid="pone.0250176.ref004" ref-type="bibr">4</xref>].</p>
              <p>The relationship between anxiety-related processes and visual attention has been the subject of many research studies (e.g., [<xref rid="pone.0250176.ref005" ref-type="bibr">5</xref>–<xref rid="pone.0250176.ref007" ref-type="bibr">7</xref>]), but there is still not a consensus on how different types of anxiety symptoms and their severity impact visual attention. In general, individuals with anxiety disorders show increased vigilance to threat during free viewing and visual search and difficulty disengaging from threat during visual search but not during free viewing tasks relative to controls [<xref rid="pone.0250176.ref001" ref-type="bibr">1</xref>]. Recent work has examined the relations between worry, rumination, and visual attention, and found that self-reported rumination is linked to greater attention to sad stimuli [<xref rid="pone.0250176.ref008" ref-type="bibr">8</xref>, <xref rid="pone.0250176.ref009" ref-type="bibr">9</xref>] but worry, compared with rumination, leads to relative avoidance of positive information [<xref rid="pone.0250176.ref010" ref-type="bibr">10</xref>]. Whether this is true across anxiety disorders, representing a transdiagnostic process, remains to be tested.</p>
              <p>Relative to common anxiety disorders like generalized anxiety disorder, more is known about visual attention in social anxiety disorder, where eye gaze is likely to be more relevant to the maintenance of symptoms (e.g., [<xref rid="pone.0250176.ref011" ref-type="bibr">11</xref>]; see Staugaard [<xref rid="pone.0250176.ref012" ref-type="bibr">12</xref>] for a review). Individuals with social anxiety disorder may be more sensitive to detecting threat, and may misinterpret faces as threatening when they make quick judgments [<xref rid="pone.0250176.ref013" ref-type="bibr">13</xref>, <xref rid="pone.0250176.ref014" ref-type="bibr">14</xref>]. In a dot-probe task with emotional faces, Schofield and colleagues [<xref rid="pone.0250176.ref014" ref-type="bibr">14</xref>] found that social anxiety was associated with attention to emotional (rather than neutral) faces over time, and difficulty engaging attention from angry faces. Heuer and colleagues [<xref rid="pone.0250176.ref013" ref-type="bibr">13</xref>] administered a morphed faces task (a task involving watching a series of computer-morphed faces that change slowly from a neutral to a fully emotional expression) to socially anxious individuals and non-anxious controls with time pressure (restricted viewing task, RVT) or with unlimited viewing of the faces (free viewing task, FVT). Participants with high levels of social anxiety demonstrated a threat bias (disgust interpreted as contempt) in the RVT, contrasting with the non-anxious control group’s positive bias (disgust interpreted as happy). No group differences were found in the FVT. Thus, time spent on faces and the pressure of making an accurate judgment in ER tasks may be linked with levels of anxiety and social anxiety. Additionally, more recent research has indicated that performance-based social anxiety specifically, when compared to panic disorder with agoraphobia, appears to present a sustained bias for vigilant attention to aversive facial expressions, but for the most severe social anxiety, patients show an opposing avoidance of aversive facial expressions [<xref rid="pone.0250176.ref015" ref-type="bibr">15</xref>]. This indicates that the severity as well as type of social anxiety play a role in emotional face perception and visual attention.</p>
              <p>While much of the literature has looked at the eye region as an area of interest in ER some researchers have defined areas in the lower face (mouth) as particularly important in recognizing emotion. It is important to consider areas of interest within the entire face, not just the eye region, when examining emotion recognition in clinical groups, as there may be differences in visual attention patterns based on disorder status or severity. For example, in highly socially anxious individuals, looking at the mouth may be more comforting than staring into eyes. Wong and colleagues [<xref rid="pone.0250176.ref016" ref-type="bibr">16</xref>] examined patterns of visual scanning as predictors of emotion identification in older adults and younger adults. Older adults who made more fixations in the top halves of faces were more accurate at identifying emotions than those who made more fixations in the lower halves of faces. However, for the emotion of disgust in particular, older adult participants were more accurate when they fixated on the lower half of the face. In the younger adult group, analyses revealed a significant positive correlation between emotion-identification accuracy and difference scores computed on the number of fixations made to the top half versus bottom halves of faces [<xref rid="pone.0250176.ref016" ref-type="bibr">16</xref>]. In another study, individuals with high-functioning autism fixated more in the mouth region of faces even when the faces were inverted [<xref rid="pone.0250176.ref017" ref-type="bibr">17</xref>]). These authors suggest that abnormal gaze in individuals with high-functioning autism is driven by an impaired top-down strategy for allocating visual attention. Accordingly, it seems necessary to examine eye gaze patterns for each of the emotional faces when gauging where participants are attending.</p>
              <p>The current study examines clinical factors as dimensional variables within a patient sample that is highly comorbid on depression and anxiety diagnoses. While prior research has compared visual attention patterns in depressed and anxious groups to healthy controls, the comparison of visual attention patterns in clinical groups is lacking. Moreover, while the emotion recognition literature has established impairments in emotion recognition in samples with anxiety and mood disorders compared to the general population, we do not yet know if a reason for these deficits is based in differences in time spent on certain regions of interest on an emotional face (eyes vs. mouth) or due to other reasons. Previous group-based comparisons may have led to inconsistent or weaker ER results because individual differences in symptom severity were collapsed into a binary variable. Our approach takes into consideration the heterogeneity of depression symptoms, the severity of anxiety symptoms, and their comorbidity [<xref rid="pone.0250176.ref018" ref-type="bibr">18</xref>]. In addition, we were equipped to attempt to disentangle social anxiety factors from other forms of anxiety.</p>
              <p>In order to clarify the relationship between visual attention and anxiety and mood symptom severity, we used an entirely clinical sample with anxiety and mood disorder diagnoses. We had four hypotheses, each based on prior research. First, we expected there would be more fixations on negative faces in depressed participants compared to anxious based on the prior finding that depressed individuals attend more to dysphoric stimuli (e.g., [<xref rid="pone.0250176.ref001" ref-type="bibr">1</xref>]). Of note, this hypothesis was based on a finding comparing depressed individuals to healthy control subjects, and it remains to be tested to see if the anxiety group differs significantly from the depressed group. Next, we hypothesized that higher levels of depression would be associated with more fixations on sad faces based on the established finding that depressed individuals show a specific attentional bias to sad, but not angry or threatening facial expressions (e.g., [<xref rid="pone.0250176.ref008" ref-type="bibr">8</xref>, <xref rid="pone.0250176.ref019" ref-type="bibr">19</xref>]). Third, we predicted that higher anxiety scores would predict more fixations in threatening faces (fear) based on the prior finding that social anxiety is associated with difficulty disengaging from threat (e.g., [<xref rid="pone.0250176.ref014" ref-type="bibr">14</xref>, <xref rid="pone.0250176.ref020" ref-type="bibr">20</xref>]), specifically the indirect or ambiguous threat of a fearful face. Of note, we used an emotion recognition task that was different from the findings for which we based our prediction, as many tests of threat-bias include a paired face forced choice paradigm, and we used a dynamic emotional face task. Additionally, there is a body of work that shows that angry faces can elicit a threat-related attentional bias in anxious individuals (see Bar-Haim et al, 2007) [<xref rid="pone.0250176.ref021" ref-type="bibr">21</xref>], so we examined visual attention differences in angry faces (direct threat) in addition to fearful faces (indirect threat) based on level of anxiety. Last, we wanted to explore if there was reduced fixation on positive faces in high levels of worry and anxiety. Based on the finding that worry, compared to rumination, leads to relative avoidance of positive information ([<xref rid="pone.0250176.ref010" ref-type="bibr">10</xref>] we expected that higher anxiety severity would predict reduced fixation on happy faces.</p>
            </sec>
            <sec sec-type="materials|methods" id="sec002">
              <title>Materials and methods</title>
              <sec id="sec003">
                <title>Participants</title>
                <p>This study was approved by the Boston University Institutional Review Board. Written informed consent was obtained from all individual participants included in the study.</p>
                <p>Eligible participants were males and females &gt;= 18 years of age with a principal diagnosis of an anxiety or mood disorder who presented for assessment and treatment at the Center for Anxiety and Related Disorders at Boston University. Participants were recruited for a study examining the effect of intranasal oxytocin on emotion recognition performance and visual attention (see Rutter et al., 2019a) [<xref rid="pone.0250176.ref022" ref-type="bibr">22</xref>]. Exclusionary criteria were: (1) current delusions or hallucinations, (2) current suicidal or homicidal risk meriting intervention, (3) two or more hospitalizations in the last 5 years for severe psychopathology (psychosis, suicide attempts), (4) not fluent English speakers (those unable to complete a phone screen and clinical interview in English), (5) pregnancy, (6) a current or past autism spectrum disorder diagnosis, (7) regular smokers (smoking more than 15 cigarettes/day), or consumers of non-prescription or illicit drugs (except for oral contraceptives), (8) major sensory impairment and/or visual acuity score (binocular) worse than 20/40, (9) those who are currently experiencing a respiratory illness requiring medication (i.e., allergy, cold, or flu symptoms), and (10) those who are suffering from a chronic medical condition (i.e., heart disease, uncontrolled hypertension, myocardial infarction, cardiac arrhythmia, kidney or liver disease, vascular disease, epilepsy, migraine, asthma, nephritis, diabetes or another endocrine disease, frequent or unexplained fainting, stroke, aneurism or brain hemorrhage, or other neurological illness).</p>
                <p>Individuals with a variety of anxiety and mood disorders were recruited for this study (N = 60). We recruited participants with the following clinical diagnoses into our depression (n = 30) cohort: major depressive disorder, persistent depressive disorder, other specified depressive disorder, and unspecified depressive disorder. We recruited individuals with the following diagnoses into our anxiety (n = 30) cohort: panic, agoraphobia, specific phobia, separation anxiety, social anxiety, generalized anxiety, other specified and unspecified anxiety, obsessive-compulsive, and posttraumatic stress disorders. While OCD and PTSD are not technically anxiety disorders as defined by DSM-5, we included them in this group because of their similarities to other anxiety disorders (and differences from depressive disorders). Of note, participants in the anxiety cohort could not have a current clinical mood disorder, but comorbid anxiety disorders were allowed into the depressed group. Thus, the depression group represented higher levels of mood and anxiety disorder comorbidity, while the anxiety group was purposely designed to filter out mood disorders. Individuals in both the depressed group and anxiety group may have been assigned multiple anxiety disorder diagnoses, but no one in the anxiety group had a clinical level of mood disorder psychopathology present at the time of their diagnostic interview. The main difference between the depression group and anxiety group was the presence of a unipolar depressive disorder in the depressed group and the absence of a unipolar depressive disorder in the anxiety group.</p>
                <p>The average age was 27.21 (SD = 9.73, range = 18—65). The sample was predominantly female (n = 28; 59.57%), Caucasian (n = 34; 72.3%; Asian = 10.1%; African American = 6.4%, Other/not reported = 4.2%), and non-Hispanic (n = 36; 76%). Visual acuity was calculated while participants used corrective eyewear. The average visual acuity score was above 20/20 (M = 1.19), and ranged from 0.58 to 1.34 (SD = .17). Based on exclusionary criteria of vision being 20/40 or better, all participants were eligible.</p>
                <p>The sample breakdown of principal diagnoses was as follows: generalized anxiety disorder (23.3%), social phobia (21.7%), coprincipal diagnosis (10%), specific phobia (10%), PDD (8.3%), obsessive-compulsive disorder (8.3%), MDD (6.7%), body dysmorphic disorder (3.3%), other specified anxiety disorder (3.3%), panic disorder (1.7%), other specified obsessive-compulsive and related disorder (1.7%), other specified trauma/stressor-related disorder (1.7%). Of note, 70% in the depressed group had a principal or co-principal anxiety disorder (see [<xref rid="pone.0250176.ref022" ref-type="bibr">22</xref>]).</p>
              </sec>
              <sec id="sec004">
                <title>Measures</title>
                <p><bold>Anxiety and Related Disorders Interview Schedule for DSM-5</bold> (<bold>ADIS-5</bold> [<xref rid="pone.0250176.ref023" ref-type="bibr">23</xref>]). The ADIS-5 is a semi-structured interview designed to establish a diagnosis of DSM-5 anxiety, mood, somatoform, obsessive-compulsive, trauma, and substance use disorders, and to screen for other disorders (e.g., psychotic disorders). The ADIS-5 was administered by trained Ph.D.-level psychologists and advanced doctoral students in clinical psychology with extensive training to meet strict certification criteria (see [<xref rid="pone.0250176.ref023" ref-type="bibr">23</xref>] for details). We used the ADIS to determine participants’ primary diagnoses and place them into the anxious or depressed groups.</p>
                <p><bold>Beck Depression Inventory-II</bold> (<bold>BDI</bold>; [<xref rid="pone.0250176.ref024" ref-type="bibr">24</xref>]). The BDI-II is a widely used 21-item self-report measure of severity of depressive symptoms. Higher scores represent more severe depression. The BDI-II has been shown to have strong psychometric properties in outpatient samples [<xref rid="pone.0250176.ref025" ref-type="bibr">25</xref>].</p>
                <p><bold>Beck Anxiety Inventory</bold> (<bold>BAI</bold>; [<xref rid="pone.0250176.ref026" ref-type="bibr">26</xref>]). The BAI is a widely used 21-item self-report measure of severity of anxiety symptoms. Higher scores represent more severe anxiety. The BAI has been shown to have strong psychometric properties in outpatient samples [<xref rid="pone.0250176.ref026" ref-type="bibr">26</xref>].</p>
                <p><bold>Social Interaction Anxiety Scale</bold> (<bold>SIAS</bold>; [<xref rid="pone.0250176.ref027" ref-type="bibr">27</xref>]). The SIAS is 20-item self-report measure of anxiety surrounding social interactions. Higher scores indicate more severe social interaction anxiety [<xref rid="pone.0250176.ref027" ref-type="bibr">27</xref>]. The SIAS is shown to be a useful measure in screening, designing personalized treatments, and evaluating outcomes of treatments for social anxiety [<xref rid="pone.0250176.ref028" ref-type="bibr">28</xref>]</p>
                <p><bold>Emotion recognition task</bold> (“<bold>facial morphing</bold>”). This task entails watching computer-morphed faces that change slowly from a neutral (0% emotionality) to a fully emotional expression (100%). Stimuli faces were taken from Ekman and Friesen’s (1976) Series of Facial Affect [<xref rid="pone.0250176.ref029" ref-type="bibr">29</xref>]. Using Matlab software, each face was presented for 500ms. The black-and-white face images were approximately 12.25 x 9 cm in size, presented on the middle of the screen on black background of a Hewlett Packard FP2141sb 21” CRT monitor. Participants were presented with a neutral face (0% emotionality), which progressed in 2% increments toward 100% emotionality. Each increment of emotionality, or frame, was displayed for 500 ms, with every fifth frame jittered to be 1, 2, 3, 4, or 5 times the normal 500 ms length, to weaken the relationship between time and emotional intensity. After responding to two practice trials, participants were shown 40 morphed sequences (male and female actor expressing angry, happy, fear, and sad emotion five times each) of the faces in random order [<xref rid="pone.0250176.ref022" ref-type="bibr">22</xref>]. These 40 test trials were each comprised of a dynamic sequence of a face changing from a neutral expression to an emotional expression.</p>
                <p>Participants were asked to press a keyboard key as soon as they detected an identifiable emotional expression. Pressing the key cleared the screen and prompted participants to identify the face as expressing happiness, sadness, fear, or anger. Accuracy was recorded for each emotion type, as was the emotional intensity of the morphed expression at the time of the keyboard press. Possible intensities ranged from 0 (neutral) to 100 (fully morphed emotion). Higher intensity scores indicate that participants required greater emotion to identify the emotion type, and were slower to respond. Intensity scores were only calculated for accurate trials only. Trials where participants pressed the space bar to select face type at 0% intensity (i.e., neutral) were not scored as accurate or incorrect, and intensity scores were not calculated, because this response style indicates that the participants were holding down the space bar when the trial began and never saw the emotional face stimulus.</p>
              </sec>
              <sec id="sec005">
                <title>Eye tracking</title>
                <sec id="sec006">
                  <title>Hardware</title>
                  <p>An Applied Science Laboratories Eye-Trac 6 eye-tracking system was used to record the position of eye gaze throughout the task (see [<xref rid="pone.0250176.ref022" ref-type="bibr">22</xref>] for more specific procedures). The system has maximum accuracy of 0.5 degrees of visual angle, with a resolution of 0.25 degrees. The temporal resolution of the camera was set at 120 Hz. A chin rest was used to reduce head movement. After adjusting the camera of the eyetracker to be centered on the participant’s dominant eye, a short calibration sequence was administered whereby the participant looked at 9 points across the display monitor. After this sequence, the eye-tracking system was able to accurately and continually calculate the participant’s point of gaze relative to the display.</p>
                </sec>
                <sec id="sec007">
                  <title>Data reduction</title>
                  <p>After the initial 9-point calibration, the accuracy of the system was checked at the beginning of each trial for a period of 1500 milliseconds during which the participant fixated centrally (i.e., fixation cross). An average of the calibration checks across the 40 trials was used to refine the original calibration. Individual trials where the fixation during this 1500 millisecond period were aberrant were excluded. Data from each trial were only analyzed if valid eye data were collected for at least 50% of the duration of that trial. Data from particular subjects were excluded from analysis if that participant lost more than 50% of their trials. Of the 60 participants recruited, a total of 13 were lost due to this system. This system of data reduction eliminates erroneous and missing data due to issues with calibration, mechanical problems, and experimenter error [<xref rid="pone.0250176.ref022" ref-type="bibr">22</xref>]. Our final sample size was 47 participants, with 22 in the Depressed group and 25 in the Anxious group.</p>
                </sec>
                <sec id="sec008">
                  <title>Eye fixation variables</title>
                  <p>Eye movement parameters reflecting the topographical characteristics of scanning behavior were the proportion of fixations on previously defined regions of interest of the face: entire face, eye region, and mouth region. For each trial, we calculated average percent fixation data in the eye region relative to data in the face, and mouth region relative to face [<xref rid="pone.0250176.ref030" ref-type="bibr">30</xref>]. For this reason, we did not remove eye and mouth regions when examining fixations in the face, as data was calculated based on proportion of fixations relative to the entire face. Fixations were defined as the participant keeping their gaze within a 1 degree area for at least 100 milliseconds. Thus, from the reduced eye data we calculated proportion of fixation data relative to other data (i.e., sum of time length of each fixation during the trial divided by length of the trial) in each region of interest (i.e., face, eyes, mouth) for each face type (i.e., happy, sad, angry, fearful). For example, “Eye/face” is the proportion of fixation data captured in the eye region relative to the proportion of data captured in the face region, and “Mouth/face” is the proportion of fixation data captured in the mouth region relative to proportion of data captured in the face region [<xref rid="pone.0250176.ref030" ref-type="bibr">30</xref>]. <xref rid="pone.0250176.t001" ref-type="table">Table 1</xref> presents proportion of fixation data relative to other data in each region of interest (i.e., face, eyes, mouth) for each face type (i.e., happy, sad, angry, fearful). We also took the average of all emotional conditions to calculate a grand mean of face, eye, and mouth proportions for the fixation data. Since, for the majority of each trial, the emotional faces are indistinguishable from each other (in fact, the subject ends the trial immediately once they are able to discern what emotion the face bears), this represents an additional primary outcome measure, see <xref rid="pone.0250176.t002" ref-type="table">Table 2</xref>.</p>
                  <table-wrap id="pone.0250176.t001" orientation="portrait" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pone.0250176.t001</object-id>
                    <label>Table 1</label>
                    <caption>
                      <title>Summary of visual attention by diagnostic group status.</title>
                    </caption>
                    <alternatives>
                      <graphic id="pone.0250176.t001g" xlink:href="pone.0250176.t001"/>
                      <table frame="box" rules="all" border="0">
                        <colgroup span="1">
                          <col align="left" valign="top" span="1"/>
                          <col align="left" valign="top" span="1"/>
                          <col align="left" valign="top" span="1"/>
                          <col align="left" valign="top" span="1"/>
                          <col align="left" valign="top" span="1"/>
                        </colgroup>
                        <thead>
                          <tr>
                            <th align="left" rowspan="2" colspan="1"/>
                            <th align="center" colspan="2" rowspan="1">Depressed (<italic>n</italic> = 22)</th>
                            <th align="center" colspan="2" rowspan="1">Anxious only (<italic>n</italic> = 25)</th>
                          </tr>
                          <tr>
                            <th align="center" rowspan="1" colspan="1">Mean</th>
                            <th align="center" rowspan="1" colspan="1">
                              <italic>SD</italic>
                            </th>
                            <th align="center" rowspan="1" colspan="1">Mean</th>
                            <th align="center" rowspan="1" colspan="1">
                              <italic>SD</italic>
                            </th>
                          </tr>
                        </thead>
                        <tbody>
                          <tr>
                            <td align="left" colspan="5" rowspan="1">Sad expressions</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1"> Face/screen</td>
                            <td align="char" char="." rowspan="1" colspan="1">.90</td>
                            <td align="char" char="." rowspan="1" colspan="1">.11</td>
                            <td align="char" char="." rowspan="1" colspan="1">.93</td>
                            <td align="char" char="." rowspan="1" colspan="1">.11</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1"> Eye/face</td>
                            <td align="char" char="." rowspan="1" colspan="1">.49</td>
                            <td align="char" char="." rowspan="1" colspan="1">.23</td>
                            <td align="char" char="." rowspan="1" colspan="1">.60</td>
                            <td align="char" char="." rowspan="1" colspan="1">.16</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1"> Mouth/face</td>
                            <td align="char" char="." rowspan="1" colspan="1">.21</td>
                            <td align="char" char="." rowspan="1" colspan="1">.14</td>
                            <td align="char" char="." rowspan="1" colspan="1">.19</td>
                            <td align="char" char="." rowspan="1" colspan="1">.14</td>
                          </tr>
                          <tr>
                            <td align="left" colspan="5" rowspan="1">Happy expressions</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1"> Face/screen</td>
                            <td align="char" char="." rowspan="1" colspan="1">.90</td>
                            <td align="char" char="." rowspan="1" colspan="1">.13</td>
                            <td align="char" char="." rowspan="1" colspan="1">.94</td>
                            <td align="char" char="." rowspan="1" colspan="1">.09</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1"> Eye/face</td>
                            <td align="char" char="." rowspan="1" colspan="1">.48</td>
                            <td align="char" char="." rowspan="1" colspan="1">.22</td>
                            <td align="char" char="." rowspan="1" colspan="1">.56</td>
                            <td align="char" char="." rowspan="1" colspan="1">.16</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1"> Mouth/face</td>
                            <td align="char" char="." rowspan="1" colspan="1">.24</td>
                            <td align="char" char="." rowspan="1" colspan="1">.16</td>
                            <td align="char" char="." rowspan="1" colspan="1">.26</td>
                            <td align="char" char="." rowspan="1" colspan="1">.18</td>
                          </tr>
                          <tr>
                            <td align="left" colspan="5" rowspan="1">Fearful expressions</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1"> Face/screen</td>
                            <td align="char" char="." rowspan="1" colspan="1">.86</td>
                            <td align="char" char="." rowspan="1" colspan="1">.20</td>
                            <td align="char" char="." rowspan="1" colspan="1">.92</td>
                            <td align="char" char="." rowspan="1" colspan="1">.12</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1"> Eye/face</td>
                            <td align="char" char="." rowspan="1" colspan="1">.50</td>
                            <td align="char" char="." rowspan="1" colspan="1">.25</td>
                            <td align="char" char="." rowspan="1" colspan="1">.60</td>
                            <td align="char" char="." rowspan="1" colspan="1">.18</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1"> Mouth/face</td>
                            <td align="char" char="." rowspan="1" colspan="1">.21</td>
                            <td align="char" char="." rowspan="1" colspan="1">.16</td>
                            <td align="char" char="." rowspan="1" colspan="1">.18</td>
                            <td align="char" char="." rowspan="1" colspan="1">.15</td>
                          </tr>
                          <tr>
                            <td align="left" colspan="5" rowspan="1">Angry expressions</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1"> Face/screen</td>
                            <td align="char" char="." rowspan="1" colspan="1">.90</td>
                            <td align="char" char="." rowspan="1" colspan="1">.10</td>
                            <td align="char" char="." rowspan="1" colspan="1">.93</td>
                            <td align="char" char="." rowspan="1" colspan="1">.10</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1"> Eye/face</td>
                            <td align="char" char="." rowspan="1" colspan="1">.48</td>
                            <td align="char" char="." rowspan="1" colspan="1">.22</td>
                            <td align="char" char="." rowspan="1" colspan="1">.56</td>
                            <td align="char" char="." rowspan="1" colspan="1">.18</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1"> Mouth/face</td>
                            <td align="char" char="." rowspan="1" colspan="1">.24</td>
                            <td align="char" char="." rowspan="1" colspan="1">.15</td>
                            <td align="char" char="." rowspan="1" colspan="1">.20</td>
                            <td align="char" char="." rowspan="1" colspan="1">.15</td>
                          </tr>
                        </tbody>
                      </table>
                    </alternatives>
                    <table-wrap-foot>
                      <fn id="t001fn001">
                        <p><italic>Note</italic>. Face/Screen = the proportion of fixation data captured in the face region relative to data captured outside of the face, on the computer screen. Eye/face = the proportion of fixation data captured in the eye region relative to the proportion of data captured in the face region. Mouth/face = the proportion of fixation data captured in the mouth region relative to proportion of data captured in the face region.</p>
                      </fn>
                    </table-wrap-foot>
                  </table-wrap>
                  <table-wrap id="pone.0250176.t002" orientation="portrait" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pone.0250176.t002</object-id>
                    <label>Table 2</label>
                    <caption>
                      <title>Correlations between fixations and symptom severity scores.</title>
                    </caption>
                    <alternatives>
                      <graphic id="pone.0250176.t002g" xlink:href="pone.0250176.t002"/>
                      <table frame="box" rules="all" border="0">
                        <colgroup span="1">
                          <col align="left" valign="top" span="1"/>
                          <col align="left" valign="top" span="1"/>
                          <col align="left" valign="top" span="1"/>
                          <col align="left" valign="top" span="1"/>
                        </colgroup>
                        <thead>
                          <tr>
                            <th align="left" rowspan="1" colspan="1">Variable</th>
                            <th align="center" rowspan="1" colspan="1">BDI</th>
                            <th align="center" rowspan="1" colspan="1">BAI</th>
                            <th align="center" rowspan="1" colspan="1">SIAS</th>
                          </tr>
                        </thead>
                        <tbody>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Proportion of fixations on sad face</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.06</td>
                            <td align="char" char="." rowspan="1" colspan="1">.26</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.07</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Proportion of fixations on sad eyes</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.21</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.03</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.32<xref ref-type="table-fn" rid="t002fn002">*</xref></td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Proportion of fixations on sad mouth</td>
                            <td align="char" char="." rowspan="1" colspan="1">.16</td>
                            <td align="char" char="." rowspan="1" colspan="1">.38<xref ref-type="table-fn" rid="t002fn002">*</xref></td>
                            <td align="char" char="." rowspan="1" colspan="1">.18</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Proportion of fixations on happy face</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.07</td>
                            <td align="char" char="." rowspan="1" colspan="1">.15</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.10</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Proportion of fixations on happy eyes</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.23</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.16</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.41<xref ref-type="table-fn" rid="t002fn003">**</xref></td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Proportion of fixations on happy mouth</td>
                            <td align="char" char="." rowspan="1" colspan="1">.13</td>
                            <td align="char" char="." rowspan="1" colspan="1">.34<xref ref-type="table-fn" rid="t002fn002">*</xref></td>
                            <td align="char" char="." rowspan="1" colspan="1">.25</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Proportion of fixations on fearful face</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.22</td>
                            <td align="char" char="." rowspan="1" colspan="1">.25</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.07</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Proportion of fixations on fearful eyes</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.26</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.01</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.34<xref ref-type="table-fn" rid="t002fn002">*</xref></td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Proportion of fixations on fearful mouth</td>
                            <td align="char" char="." rowspan="1" colspan="1">.13</td>
                            <td align="char" char="." rowspan="1" colspan="1">.30<xref ref-type="table-fn" rid="t002fn002">*</xref></td>
                            <td align="char" char="." rowspan="1" colspan="1">.26</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Proportion of fixations on angry face</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.17</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.09</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.06</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Proportion of fixations on angry eyes</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.21</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.19</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.28</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Proportion of fixations on angry mouth</td>
                            <td align="char" char="." rowspan="1" colspan="1">.13</td>
                            <td align="char" char="." rowspan="1" colspan="1">.28</td>
                            <td align="char" char="." rowspan="1" colspan="1">.26</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Grand proportion of fixations on faces</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.16</td>
                            <td align="char" char="." rowspan="1" colspan="1">.19</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.09</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Grand proportion of fixations on eyes</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.24</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.10</td>
                            <td align="char" char="." rowspan="1" colspan="1">-.36<xref ref-type="table-fn" rid="t002fn002">*</xref></td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Grand proportion of fixations on mouths</td>
                            <td align="char" char="." rowspan="1" colspan="1">.15</td>
                            <td align="char" char="." rowspan="1" colspan="1">.34<xref ref-type="table-fn" rid="t002fn002">*</xref></td>
                            <td align="char" char="." rowspan="1" colspan="1">.25</td>
                          </tr>
                        </tbody>
                      </table>
                    </alternatives>
                    <table-wrap-foot>
                      <fn id="t002fn001">
                        <p><italic>Note</italic>.</p>
                      </fn>
                      <fn id="t002fn002">
                        <p>* <italic>p</italic> &lt;.05,</p>
                      </fn>
                      <fn id="t002fn003">
                        <p>** <italic>p</italic> &lt;.01. BDI = Beck Depression Inventory; BAI = Beck Anxiety Inventory; SIAS = Social Interaction Anxiety Scale.</p>
                      </fn>
                    </table-wrap-foot>
                  </table-wrap>
                </sec>
                <sec id="sec009">
                  <title>Data analyses</title>
                  <p>RStudio was used to conduct analyses. We conducted a series of regression analyses to test our hypotheses and control for covariates. We used a conservative Bonferroni correction of p &lt;.017 to account for multiple comparisons. For Hypotheses 1 we conducted t-tests to compare eye fixation data between depressed and anxious groups. For Hypothesis 2, we regressed depression severity (BDI-II) onto fixations in the eye region of sad faces. For Hypothesis 3, we regressed anxiety severity (BAI and SIAS) onto proportion of fixations on the entire face, the eye region, and the mouth region of fearful faces. For Hypothesis 4, we regressed anxiety severity onto fixations in regions of interest in happy faces. As mentioned, these data are part of a larger randomized controlled study [<xref rid="pone.0250176.ref022" ref-type="bibr">22</xref>] where half of the participants received oxytocin and half received placebo before completing the emotion recognition task.</p>
                  <p>We used R pwr package to verify that our sample was adequately powered to detect significance after lost participants due to calibration errors and missing eye data. Our final sample size of 47 provided adequate power (<italic>β</italic> = .80) to detect effects of medium to large size (f<sup>2</sup> = .25; <italic>α</italic> = .05) using multiple regression (Cohen, 1992) and t-tests (d = .58, <italic>α</italic> = .05).</p>
                </sec>
              </sec>
            </sec>
            <sec sec-type="results" id="sec010">
              <title>Results</title>
              <p>Descriptive statistics are presented in Tables <xref rid="pone.0250176.t001" ref-type="table">1</xref> and <xref rid="pone.0250176.t002" ref-type="table">2</xref>. With regard to emotion recognition performance, average accuracy scores for all faces in our sample was.93 (SD = .06, range .78 –1.0)[happy = .999, angry = .84, fearful = .93, sad = .97) while intensity scores averaged 40.57 (SD = 9.10) and ranged from 21.03—70.77)[happy = 29.40, angry = 46.25, fearful = 43.61, sad = 44.83]. There were no differences in accuracy or intensity scores between the Depressed and Anxious groups (p &gt;.05). The differences between ER accuracy and intensity scores based on drug status (oxytocin vs. placebo) between Depressed and Anxious groups is the subject of prior work [<xref rid="pone.0250176.ref022" ref-type="bibr">22</xref>]. The average BAI score in our sample was 18.20 (SD = 9.60, range = 0-44), indicating moderate anxiety. The average BDI score in our sample was 19.37 (SD = 10.99, range = 0—41), indicating mild depression. The average SIAS score in our sample was 35.42 (SD = 19.64, range = 0-77), indicating moderate social interaction anxiety.</p>
              <p>Before proceeding with any analyses, we tested to see that there were no significant differences in eye gaze patterns between participants who received oxytocin (n = 22) and those who received placebo (n = 25) in our sample using a series of Welch Two Sample-tests. <xref ref-type="fig" rid="pone.0250176.g001">Fig 1</xref> displays the proportion of fixations in the face, eye, and mouth regions for all emotional faces (happy, sad, angry, and fearful), plotted by anxiety severity (BAI) and placebo and oxytocin status. There were no significant differences in proportion of fixations in any region of the face for any emotion between the oxytocin and placebo groups (p range.11 in mouth region of happy faces to.80 in sad faces). We then tested the relationship between a mood disorder and fixations on negative faces, expecting more fixations on sad, angry, and fearful faces if the participant was depressed vs. anxious using a series of Welch Two Sample-tests (Anxious only n = 25; Depressed n = 22). None of these were significant (p range.21 for proportion in fearful faces to.44 for proportion fixations in sad faces).</p>
              <fig id="pone.0250176.g001" orientation="portrait" position="float">
                <object-id pub-id-type="doi">10.1371/journal.pone.0250176.g001</object-id>
                <label>Fig 1</label>
                <caption>
                  <title>Proportion of fixations in regions of interest by Beck Anxiety Inventory (BAI) scores and oxytocin/placebo status.</title>
                  <p>The black circle represents participants who received placebo. The white circle represents participants who received oxytocin. BAI = Beck Anxiety Inventory.</p>
                </caption>
                <graphic xlink:href="pone.0250176.g001"/>
              </fig>
              <p>We expected that higher depression scores based on BDI-II would be associated with more fixations on sad faces. Results showed that higher depression scores were not significantly associated with increased fixations in sad faces overall (p = .7), or in the eye (p = .17) or mouth regions (p = .30) of sad faces. Thus, contrary to our hypothesis, depression severity did not predict fixations on sad faces. To follow up on this unexpected finding, we tested the relationship between depression severity and fixations on angry, happy, and fearful faces, and found that depression severity did not predict any fixations on negative (angry, fearful) or positive (happy) faces (p &gt;.05).</p>
              <p>Next, we tested the hypothesis that higher anxiety scores would be correlated with more fixations on threat, i.e., fearful faces. Using fearful faces, we examined the relationship between proportion of fixations on the entire face, the eye region, and the mouth region using regression. Results showed that higher anxiety scores based on BAI were associated with more fixations in the mouth region of fearful faces (R<sup>2</sup> = .09, F (1, 41) = 4.18, <italic>β</italic> = .30, p &lt;.05), although the effect size was small (f<sup>2</sup> = .10), and did not survive Bonferroni correction. The relationship between level of anxiety and proportion of fixations in the entire face and eye region of fearful faces was not significant (p &gt;.05). We then examined the connection between levels of social anxiety, based on the SIAS, and fixations in regions of interest. Results showed that higher levels of social anxiety were associated with decreased attention to the eye region of fearful faces (R<sup>2</sup> = .12, F (1, 41) = 5.48, <italic>β</italic> = -.34, p &lt;.05, f<sup>2</sup> = .14). This did not remain significant after Bonferroni correction. Higher levels of social anxiety did not predict fixations in the mouth or entire face (p &gt;.05), see <xref rid="pone.0250176.t002" ref-type="table">Table 2</xref>.</p>
              <p>To test our last hypothesis, we examined the relationship between anxiety severity and eye gaze fixation using multiple regression, with the hypothesis that higher anxiety severity (based on BAI) would be associated with reduced fixations in happy faces. Higher anxiety scores did not predict reduced fixations on happy faces overall, or in the eye region of happy faces. There were, however, significant differences in attention to the mouth region for happiness and other emotional faces, described below.</p>
              <p>To examine the relationship between BAI and eye gaze fixations, we controlled for depression status, thinking that the relationship between eye tracking and anxiety may be changed by the presence of mood disorder. Additionally, although we had already established that there was no main effect for oxytocin on eye gaze variables, we controlled for oxytocin here to confirm that there was not an interaction effect of drug and anxiety severity. Results showed that higher anxiety (BAI) was associated with increased fixations in the mouth region of happy faces (R<sup>2</sup> = .18, F (3, 39) = 2.86, <italic>β</italic> = .38, p&lt;.05) and mouth region of sad faces (R<sup>2</sup> = .20, F (3, 39) = 3.28, <italic>β</italic> = .39, p&lt;.05), with small effects range f<sup>2</sup> = .22—.25, which survived Bonferroni correction. We also explored the relationship between social anxiety severity and visual attention, and found that increased social interaction anxiety, as measured by the SIAS, was associated with significantly decreased fixations in the eye region of happy faces (R<sup>2</sup> = .23, F (3, 39) = 3.81, <italic>β</italic> = -.38, f<sup>2</sup> = .30), which was significant after Bonferroni correction. Additionally, increased social anxiety severity was associated with decreased fixations in the eye region of fearful faces (R<sup>2</sup> = .19, F (3, 39) = 3.11, <italic>β</italic> = -.31, p&lt;.05), f<sup>2</sup> = .23), which did not remain significant after accounting for multiple comparisons using Bonferroni methods. The relationship between social anxiety severity and attention to the eye region of sad faces approached significance (R<sup>2</sup> = .18, F (3, 39) = 2.82, <italic>β</italic> = -.29, p = .051). When oxytocin was removed as a covariate, this finding was significant: social anxiety severity predicted decreased attention to the eye region of sad faces (R<sup>2</sup> = .14, F (2, 40) = 3.39, <italic>β</italic> = -.29, p&lt;.05). Interestingly, this indicates that oxytocin may have a particular effect on visual attention in individuals with higher levels of social anxiety, even though oxytocin failed to produce a main effect on visual attention overall. This finding is consistent with the research using oxytocin to enhance treatment of social anxiety disorder [<xref rid="pone.0250176.ref031" ref-type="bibr">31</xref>]</p>
            </sec>
            <sec sec-type="conclusions" id="sec011">
              <title>Discussion</title>
              <p>While a large body of literature has shown that emotional disorders are characterized by attentional biases for emotional stimuli, to our knowledge, this study was the first to examine the impact of symptom severity on attention to specific regions of interrest in emotional faces in a comorbid and transdiagnostic entirely clinical sample. This advance from the existing research is notable, given high rates of comorbidity between anxiety and mood disorders [<xref rid="pone.0250176.ref032" ref-type="bibr">32</xref>] and lack of consensus in the field as to whether biases in attention represent a general or specific deficit in emotion recognition [<xref rid="pone.0250176.ref033" ref-type="bibr">33</xref>, <xref rid="pone.0250176.ref034" ref-type="bibr">34</xref>].</p>
            </sec>
            <sec id="sec012">
              <title>Comorbidity</title>
              <p>Our results showed that having a depression diagnosis vs. anxiety only diagnosis did not significantly impact visual attention: there were no differences between attention to sad, happy, angry, or fearful faces based on depression status. Next, results showed that higher anxiety scores based on the BAI were associated with more fixations in the mouth region of happy faces and sad faces, but not angry or fearful faces. In contrast, higher SIAS scores did not predict visual attention to the mouth region. Higher SIAS scores were associated with decreased fixations in the eye region of happy faces.</p>
              <sec id="sec013">
                <title>Depression and negativity bias</title>
                <p>Because depression has been associated with increased attention to negative stimuli, one might have expected some bias in our study on sad, fearful, or angry faces particularly, as compared with happy faces. Indeed, we made hypotheses that depression severity would be associated with a negativity bias. However, when carefully considering the nature of prior paradigms in contrast to the current one, it makes sense that we did not in fact find that depression severity correlated with any measure of visual attention. Prior studies showed a bias for depressed individuals to gaze at negative stimuli comparatively more than controls when presented with a negative and non-negative stimulus simultaneously [<xref rid="pone.0250176.ref008" ref-type="bibr">8</xref>]. Our paradigm only had a single stimulus. The only observable bias was the proportion of gaze allocated to the various “zones” of eyes versus face and mouth regions. Given that we do not possess clear hypotheses for why an eye or a mouth on a face of a given emotion would be systematically considered more negative, we do not believe that a negative gaze bias in depression would reveal itself at all in our paradigm.</p>
              </sec>
              <sec id="sec014">
                <title>Anxiety, but not social anxiety, and attention to the mouth</title>
                <p>This study explored how visual attention was related to both generalized anxiety severity and social interaction anxiety severity in a transdiagnostic sample. More research has established a connection between social anxiety and visual attention than generalized anxiety and visual attention, due to the clear connections between social anxiety disorder and eye contact. Thus, one might have expected an especially strong relation between social anxiety and eye tracking variables for two reasons. First, social anxiety is associated with biased gaze patterns in several studies [<xref rid="pone.0250176.ref011" ref-type="bibr">11</xref>, <xref rid="pone.0250176.ref012" ref-type="bibr">12</xref>, <xref rid="pone.0250176.ref014" ref-type="bibr">14</xref>]. Second, the social nature of the face stimuli might call for biases such as averting gaze from the eyes. However, we found that general anxiety, as measured by the BAI, was correlated with mouth gaze, but social anxiety, as measured by the SIAS, was not. The reasons for this are unclear, but one scenario might be that a desire for sureity which is linked to anxiety generally, and not social anxiety specifically. All our stimuli were ambiguous at the outset, since they started as neutral faces. Overall, the visual shift in mouth movements for emotional signals (such as the corners rising or falling) are more overt and stronger than those in the eyes, which rely on higher spatial frequency information such as wrinkles beginning to form. Individuals with high levels of anxiety and low comfort with uncertainty may prefer, relatively, to view the mouth as a sure thing, at least on some trials. Of course, that factor would be at work along with others in determining scanning behavior, which the high-anxiety individuals in this study did mostly in a fashion similar to those with low-anxiety.</p>
                <p>Our study was not the first to show the importance of examining the mouth region of emotional faces. Indeed, early research [<xref rid="pone.0250176.ref035" ref-type="bibr">35</xref>] showed that both upper and lower regions are involved in processing visual cues of different face types, and more recent work has suggested that the mouth is the most important cue for static and dynamic faces [<xref rid="pone.0250176.ref036" ref-type="bibr">36</xref>]. Prior work in nonclinical samples has shown a bias towards examining the mouth region of happy faces compared to fearful or neutral expressions, where there is a consistent pattern of preferentially scanning the eye region [<xref rid="pone.0250176.ref037" ref-type="bibr">37</xref>] Reduced attention to the eye region has been linked to amygdala hypoactivation and genetic differences in the 5-HTTLPR promoter polymorphism [<xref rid="pone.0250176.ref038" ref-type="bibr">38</xref>], but we did not examine these variables in our study, and instead focused on symptom severity.</p>
                <p>There are many ways that our study expands on the literature and several reasons for the differences in our results from previous studies. First, our sample is entirely clinical without a healthy control group. To date, much of the research on visual attention and emotion recognition compares disordered cohorts to control groups, showing more deficits in the disordered sample. Our study represents an advance through an entirely clinical sample, allowing us to explore differences based on severity. However, substantial heterogeneity, comorbidity, and individual differences within diagnostic groups may provide explanations of nonsignificant effects visual attention in clinical samples. Additionally, because we examined relationships dimensionally within a clinical group, it is possible that our current dimensional approach was unsuccessful is because our sample did not have severe enough levels of anxiety and depression and to detect differences [<xref rid="pone.0250176.ref018" ref-type="bibr">18</xref>]. For example, comparing a clinical group to a healthy control group is more powered to detect differences than a dimensional approach such as ours, especially if the range of anxiety and depression symptoms is not wide enough to adequately represent more severe clinical cases.</p>
                <p>While our diverse clinical sample was a major strength of our research design, some limitations should be considered. Due to the lack of research in this area, and the failure to standardize ER and eye tracking procedures, the generalizability of findings is limited. Additionally, we could not use 13 out of 60 participants’ eye data due to mechanical or calibration errors. Eye tracking results should be interpreted with caution. Using more fine-grained eye tracking methods or advanced technologies is a recommended direction for future research. Furthermore, while significant, our effect sizes were small and some did not remain significant when corrected for multiple comparisons with a conservative Bonferroni estimate. Additionally, it is not clear if the ER task we used is the best way to measure visual attention towards emotional stimuli. In fact, despite the advantage in ecological validity to use dynamic faces over static ones, some recent studies have used negative and positive images to measure visual attention in clinical cohorts, including the recent Lewis et al [<xref rid="pone.0250176.ref010" ref-type="bibr">10</xref>] study that influenced our study hypotheses. Moreover, despite their potential advantage in ecological validity, traditional ER tasks are riddled with measurement constraints such as ceiling effects for happiness and response bias [<xref rid="pone.0250176.ref039" ref-type="bibr">39</xref>–<xref rid="pone.0250176.ref041" ref-type="bibr">41</xref>].</p>
              </sec>
              <sec id="sec015">
                <title>Conclusions</title>
                <p>In sum, we found that higher anxiety scores on the BAI were associated with more fixations in the mouth region of happy and sad faces. These results indicate the value of looking at dynamic visual stimuli, as the same patterns were not observed in all regions, and the importance of considering severity of symptoms in addition to diagnostic labels. Our findings indicate the need for future studies in clinical samples, with additional variables, including personality factors [<xref rid="pone.0250176.ref042" ref-type="bibr">42</xref>], that can explore mechanisms for differences in visual attention and ER. Moreover, future work should continue to recruit transdiagnostic and comorbid samples to better understand the complex relationship between emotion recognition, visual attention, and depression and anxiety. Future research should continue to examine if there is a bias in attending to positive emotions that could be responsible for maintenance of negative affect, and how to correct this in treatment. If attentional biases could be corrected, there are important clinical implications for symptom improvement and disorder recovery.</p>
              </sec>
            </sec>
          </body>
          <back>
            <ack>
              <p>The authors thank Bonnie Brown, Alice Cronin-Golomb, and Kristin Long for their assistance with this study.</p>
            </ack>
            <ref-list>
              <title>References</title>
              <ref id="pone.0250176.ref001">
                <label>1</label>
                <mixed-citation publication-type="journal"><name><surname>Armstrong</surname><given-names>T</given-names></name>, <name><surname>Olatunji</surname><given-names>BO</given-names></name>. <article-title>Eye tracking of attention in the affective disorders: A meta-analytic review and synthesis</article-title>. <source>Clinical psychology review</source>. <year>2012</year>;<volume>32</volume>(<issue>8</issue>):<fpage>704</fpage>–<lpage>723</lpage>. <pub-id pub-id-type="doi">10.1016/j.cpr.2012.09.004</pub-id>
<?supplied-pmid 23059623?><pub-id pub-id-type="pmid">23059623</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref002">
                <label>2</label>
                <mixed-citation publication-type="journal"><name><surname>Bourke</surname><given-names>C</given-names></name>, <name><surname>Douglas</surname><given-names>K</given-names></name>, <name><surname>Porter</surname><given-names>R</given-names></name>. <article-title>Processing of facial emotion expression in major depression: a review</article-title>. <source>Australian &amp; New Zealand Journal of Psychiatry</source>. <year>2010</year>;<volume>44</volume>(<issue>8</issue>):<fpage>681</fpage>–<lpage>696</lpage>. <pub-id pub-id-type="doi">10.3109/00048674.2010.496359</pub-id>
<?supplied-pmid 20636189?><pub-id pub-id-type="pmid">20636189</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref003">
                <label>3</label>
                <mixed-citation publication-type="journal"><name><surname>Lichtenstein-Vidne</surname><given-names>L</given-names></name>, <name><surname>Okon-Singer</surname><given-names>H</given-names></name>, <name><surname>Cohen</surname><given-names>N</given-names></name>, <name><surname>Todder</surname><given-names>D</given-names></name>, <name><surname>Aue</surname><given-names>T</given-names></name>, <name><surname>Nemets</surname><given-names>B</given-names></name>, <etal>et al</etal>. <article-title>Attentional bias in clinical depression and anxiety: the impact of emotional and non-emotional distracting information</article-title>. <source>Biological psychology</source>. <year>2017</year>;<volume>122</volume>:<fpage>4</fpage>–<lpage>12</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsycho.2016.07.012</pub-id>
<?supplied-pmid 27422409?><pub-id pub-id-type="pmid">27422409</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref004">
                <label>4</label>
                <mixed-citation publication-type="journal"><name><surname>Hills</surname><given-names>PJ</given-names></name>, <name><surname>Werno</surname><given-names>MA</given-names></name>, <name><surname>Lewis</surname><given-names>MB</given-names></name>. <article-title>Sad people are more accurate at face recognition than happy people</article-title>. <source>Consciousness and cognition</source>. <year>2011</year>;<volume>20</volume>(<issue>4</issue>):<fpage>1502</fpage>–<lpage>1517</lpage>. <pub-id pub-id-type="doi">10.1016/j.concog.2011.07.002</pub-id>
<?supplied-pmid 21813288?><pub-id pub-id-type="pmid">21813288</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref005">
                <label>5</label>
                <mixed-citation publication-type="journal"><name><surname>Mogg</surname><given-names>K</given-names></name>, <name><surname>Bradley</surname><given-names>BP</given-names></name>. <article-title>Attentional bias in generalized anxiety disorder versus depressive disorder</article-title>. <source>Cognitive therapy and research</source>. <year>2005</year>;<volume>29</volume>(<issue>1</issue>):<fpage>29</fpage>–<lpage>45</lpage>. <pub-id pub-id-type="doi">10.1007/s10608-005-1646-y</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref006">
                <label>6</label>
                <mixed-citation publication-type="journal"><name><surname>Waters</surname><given-names>A</given-names></name>, <name><surname>Bradley</surname><given-names>B</given-names></name>, <name><surname>Mogg</surname><given-names>K</given-names></name>. <article-title>Biased attention to threat in paediatric anxiety disorders (generalized anxiety disorder, social phobia, specific phobia, separation anxiety disorder) as a function of ‘distress’ versus ‘fear’diagnostic categorization</article-title>. <source>Psychological medicine</source>. <year>2014</year>;<volume>44</volume>(<issue>3</issue>):<fpage>607</fpage>–<lpage>616</lpage>. <pub-id pub-id-type="doi">10.1017/S0033291713000779</pub-id>
<?supplied-pmid 23591000?><pub-id pub-id-type="pmid">23591000</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref007">
                <label>7</label>
                <mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>J</given-names></name>, <name><surname>Wang</surname><given-names>Z</given-names></name>, <name><surname>Wu</surname><given-names>Y</given-names></name>, <name><surname>Cai</surname><given-names>Y</given-names></name>, <name><surname>Shen</surname><given-names>Y</given-names></name>, <name><surname>Wang</surname><given-names>L</given-names></name>, <etal>et al</etal>. <article-title>Differential attentional bias in generalized anxiety disorder and panic disorder</article-title>. <source>Neuropsychiatric Disease and Treatment</source>. <year>2013</year>;<volume>9</volume>:<fpage>73</fpage>. <pub-id pub-id-type="doi">10.2147/NDT.S36822</pub-id><?supplied-pmid 23326197?><pub-id pub-id-type="pmid">23326197</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref008">
                <label>8</label>
                <mixed-citation publication-type="journal"><name><surname>Duque</surname><given-names>A</given-names></name>, <name><surname>Vázquez</surname><given-names>C</given-names></name>. <article-title>Double attention bias for positive and negative emotional faces in clinical depression: Evidence from an eye-tracking study</article-title>. <source>Journal of behavior therapy and experimental psychiatry</source>. <year>2015</year>;<volume>46</volume>:<fpage>107</fpage>–<lpage>114</lpage>. <pub-id pub-id-type="doi">10.1016/j.jbtep.2014.09.005</pub-id>
<?supplied-pmid 25305417?><pub-id pub-id-type="pmid">25305417</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref009">
                <label>9</label>
                <mixed-citation publication-type="journal"><name><surname>Owens</surname><given-names>M</given-names></name>, <name><surname>Gibb</surname><given-names>BE</given-names></name>. <article-title>Brooding rumination and attentional biases in currently non-depressed individuals: an eye-tracking study</article-title>. <source>Cognition and Emotion</source>. <year>2017</year>;<volume>31</volume>(<issue>5</issue>):<fpage>1062</fpage>–<lpage>1069</lpage>. <pub-id pub-id-type="doi">10.1080/02699931.2016.1187116</pub-id>
<?supplied-pmid 27224305?><pub-id pub-id-type="pmid">27224305</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref010">
                <label>10</label>
                <mixed-citation publication-type="journal"><name><surname>Lewis</surname><given-names>EJ</given-names></name>, <name><surname>Blanco</surname><given-names>I</given-names></name>, <name><surname>Raila</surname><given-names>H</given-names></name>, <name><surname>Joormann</surname><given-names>J</given-names></name>. <article-title>Does repetitive negative thinking affect attention? Differential effects of worry and rumination on attention to emotional stimuli</article-title>. <source>Emotion</source>. <year>2019</year>;<volume>19</volume>(<issue>8</issue>):<fpage>1450</fpage>. <pub-id pub-id-type="doi">10.1037/emo0000535</pub-id><?supplied-pmid 30714778?><pub-id pub-id-type="pmid">30714778</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref011">
                <label>11</label>
                <mixed-citation publication-type="journal"><name><surname>Button</surname><given-names>K</given-names></name>, <name><surname>Lewis</surname><given-names>G</given-names></name>, <name><surname>Penton-Voak</surname><given-names>I</given-names></name>, <name><surname>Munafò</surname><given-names>M</given-names></name>. <article-title>Social anxiety is associated with general but not specific biases in emotion recognition</article-title>. <source>Psychiatry Research</source>. <year>2013</year>;<volume>210</volume>(<issue>1</issue>):<fpage>199</fpage>–<lpage>207</lpage>. <pub-id pub-id-type="doi">10.1016/j.psychres.2013.06.005</pub-id>
<?supplied-pmid 23845415?><pub-id pub-id-type="pmid">23845415</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref012">
                <label>12</label>
                <mixed-citation publication-type="journal"><name><surname>Staugaard</surname><given-names>SR</given-names></name>. <article-title>Threatening faces and social anxiety: a literature review</article-title>. <source>Clinical psychology review</source>. <year>2010</year>;<volume>30</volume>(<issue>6</issue>):<fpage>669</fpage>–<lpage>690</lpage>. <pub-id pub-id-type="doi">10.1016/j.cpr.2010.05.001</pub-id>
<?supplied-pmid 20554362?><pub-id pub-id-type="pmid">20554362</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref013">
                <label>13</label>
                <mixed-citation publication-type="journal"><name><surname>Heuer</surname><given-names>K</given-names></name>, <name><surname>Lange</surname><given-names>WG</given-names></name>, <name><surname>Isaac</surname><given-names>L</given-names></name>, <name><surname>Rinck</surname><given-names>M</given-names></name>, <name><surname>Becker</surname><given-names>ES</given-names></name>. <article-title>Morphed emotional faces: emotion detection and misinterpretation in social anxiety</article-title>. <source>Journal of Behavior Therapy and Experimental Psychiatry</source>. <year>2010</year>;<volume>41</volume>(<issue>4</issue>):<fpage>418</fpage>–<lpage>425</lpage>. <pub-id pub-id-type="doi">10.1016/j.jbtep.2010.04.005</pub-id>
<?supplied-pmid 20511123?><pub-id pub-id-type="pmid">20511123</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref014">
                <label>14</label>
                <mixed-citation publication-type="journal"><name><surname>Schofield</surname><given-names>CA</given-names></name>, <name><surname>Johnson</surname><given-names>AL</given-names></name>, <name><surname>Inhoff</surname><given-names>AW</given-names></name>, <name><surname>Coles</surname><given-names>ME</given-names></name>. <article-title>Social anxiety and difficulty disengaging threat: Evidence from eye-tracking</article-title>. <source>Cognition &amp; emotion</source>. <year>2012</year>;<volume>26</volume>(<issue>2</issue>):<fpage>300</fpage>–<lpage>311</lpage>. <pub-id pub-id-type="doi">10.1080/02699931.2011.602050</pub-id>
<?supplied-pmid 21970428?><pub-id pub-id-type="pmid">21970428</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref015">
                <label>15</label>
                <mixed-citation publication-type="journal"><name><surname>McTeague</surname><given-names>LM</given-names></name>, <name><surname>Laplante</surname><given-names>MC</given-names></name>, <name><surname>Bulls</surname><given-names>HW</given-names></name>, <name><surname>Shumen</surname><given-names>JR</given-names></name>, <name><surname>Lang</surname><given-names>PJ</given-names></name>, <name><surname>Keil</surname><given-names>A</given-names></name>. <article-title>Face perception in social anxiety: Visuocortical dynamics reveal propensities for hypervigilance or avoidance</article-title>. <source>Biological psychiatry</source>. <year>2018</year>;<volume>83</volume>(<issue>7</issue>):<fpage>618</fpage>–<lpage>628</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsych.2017.10.004</pub-id>
<?supplied-pmid 29157845?><pub-id pub-id-type="pmid">29157845</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref016">
                <label>16</label>
                <mixed-citation publication-type="journal"><name><surname>Wong</surname><given-names>B</given-names></name>, <name><surname>Cronin-Golomb</surname><given-names>A</given-names></name>, <name><surname>Neargarder</surname><given-names>S</given-names></name>. <article-title>Patterns of visual scanning as predictors of emotion identification in normal aging</article-title>. <source>Neuropsychology</source>. <year>2005</year>;<volume>19</volume>(<issue>6</issue>):<fpage>739</fpage>. <pub-id pub-id-type="doi">10.1037/0894-4105.19.6.739</pub-id><?supplied-pmid 16351349?><pub-id pub-id-type="pmid">16351349</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref017">
                <label>17</label>
                <mixed-citation publication-type="journal"><name><surname>Neumann</surname><given-names>D</given-names></name>, <name><surname>Spezio</surname><given-names>ML</given-names></name>, <name><surname>Piven</surname><given-names>J</given-names></name>, <name><surname>Adolphs</surname><given-names>R</given-names></name>. <article-title>Looking you in the mouth: abnormal gaze in autism resulting from impaired top-down modulation of visual attention</article-title>. <source>Social cognitive and affective neuroscience</source>. <year>2006</year>;<volume>1</volume>(<issue>3</issue>):<fpage>194</fpage>–<lpage>202</lpage>. <pub-id pub-id-type="doi">10.1093/scan/nsl030</pub-id>
<?supplied-pmid 18985106?><pub-id pub-id-type="pmid">18985106</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref018">
                <label>18</label>
                <mixed-citation publication-type="journal"><name><surname>Rutter</surname><given-names>LA</given-names></name>, <name><surname>Norton</surname><given-names>DJ</given-names></name>, <name><surname>Brown</surname><given-names>TA</given-names></name>. <article-title>The Impact of Self-Reported Depression Severity and Age on Facial Emotion Recognition in Outpatients with Anxiety and Mood Disorders</article-title>. <source>Journal of Psychopathology and Behavioral Assessment</source>. <year>2020</year>;<volume>42</volume>(<issue>1</issue>):<fpage>86</fpage>–<lpage>92</lpage>. <pub-id pub-id-type="doi">10.1007/s10862-019-09755-w</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref019">
                <label>19</label>
                <mixed-citation publication-type="journal"><name><surname>Sanchez</surname><given-names>A</given-names></name>, <name><surname>Vazquez</surname><given-names>C</given-names></name>, <name><surname>Marker</surname><given-names>C</given-names></name>, <name><surname>LeMoult</surname><given-names>J</given-names></name>, <name><surname>Joormann</surname><given-names>J</given-names></name>. <article-title>Attentional disengagement predicts stress recovery in depression: An eye-tracking study</article-title>. <source>Journal of abnormal psychology</source>. <year>2013</year>;<volume>122</volume>(<issue>2</issue>):<fpage>303</fpage>. <pub-id pub-id-type="doi">10.1037/a0031529</pub-id><?supplied-pmid 23421524?><pub-id pub-id-type="pmid">23421524</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref020">
                <label>20</label>
                <mixed-citation publication-type="journal"><name><surname>Mogg</surname><given-names>K</given-names></name>, <name><surname>Millar</surname><given-names>N</given-names></name>, <name><surname>Bradley</surname><given-names>BP</given-names></name>. <article-title>Biases in eye movements to threatening facial expressions in generalized anxiety disorder and depressive disorder</article-title>. <source>Journal of abnormal psychology</source>. <year>2000</year>;<volume>109</volume>(<issue>4</issue>):<fpage>695</fpage>. <pub-id pub-id-type="doi">10.1037/0021-843X.109.4.695</pub-id><?supplied-pmid 11195993?><pub-id pub-id-type="pmid">11195993</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref021">
                <label>21</label>
                <mixed-citation publication-type="journal"><name><surname>Bar-Haim</surname><given-names>Y</given-names></name>, <name><surname>Lamy</surname><given-names>D</given-names></name>, <name><surname>Pergamin</surname><given-names>L</given-names></name>, <name><surname>Bakermans-Kranenburg</surname><given-names>MJ</given-names></name>, <name><surname>Van Ijzendoorn</surname><given-names>MH</given-names></name>. <article-title>Threat-related attentional bias in anxious and nonanxious individuals: a meta-analytic study</article-title>. <source>Psychological bulletin</source>. <year>2007</year>;<volume>133</volume>(<issue>1</issue>):<fpage>1</fpage>. <pub-id pub-id-type="doi">10.1037/0033-2909.133.1.1</pub-id><?supplied-pmid 17201568?><pub-id pub-id-type="pmid">17201568</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref022">
                <label>22</label>
                <mixed-citation publication-type="journal"><name><surname>Rutter</surname><given-names>LA</given-names></name>, <name><surname>Norton</surname><given-names>DJ</given-names></name>, <name><surname>Brown</surname><given-names>BS</given-names></name>, <name><surname>Brown</surname><given-names>TA</given-names></name>. <article-title>A Double-Blind Placebo Controlled Study of Intranasal Oxytocin’s Effect on Emotion Recognition and Visual Attention in Outpatients with Emotional Disorders</article-title>. <source>Cognitive therapy and research</source>. <year>2019</year>;<volume>43</volume>(<issue>3</issue>):<fpage>523</fpage>–<lpage>534</lpage>. <pub-id pub-id-type="doi">10.1007/s10608-018-9974-x</pub-id>
<?supplied-pmid 31130760?><pub-id pub-id-type="pmid">31130760</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref023">
                <label>23</label>
                <mixed-citation publication-type="book"><name><surname>Brown</surname><given-names>TA</given-names></name>. <source>Anxiety and Related Disorders Interview Schedule for DSM-5RG (ADIS-5)-Adult and Lifetime Version: Clinician Manual</source>. <publisher-name>Oxford University Press</publisher-name>, <publisher-loc>USA</publisher-loc>; <year>2014</year>.</mixed-citation>
              </ref>
              <ref id="pone.0250176.ref024">
                <label>24</label>
                <mixed-citation publication-type="other">Beck AT, Steer RA, Brown G. Beck depression inventory–II. Psychological Assessment. 1996.</mixed-citation>
              </ref>
              <ref id="pone.0250176.ref025">
                <label>25</label>
                <mixed-citation publication-type="journal"><name><surname>Steer</surname><given-names>RA</given-names></name>, <name><surname>Ball</surname><given-names>R</given-names></name>, <name><surname>Ranieri</surname><given-names>WF</given-names></name>, <name><surname>Beck</surname><given-names>AT</given-names></name>. <article-title>Further evidence for the construct validity of the Beck Depression Inventory-II with psychiatric outpatients</article-title>. <source>Psychological reports</source>. <year>1997</year>;<volume>80</volume>(<issue>2</issue>):<fpage>443</fpage>–<lpage>446</lpage>. <pub-id pub-id-type="doi">10.2466/pr0.1997.80.2.443</pub-id>
<?supplied-pmid 9129364?><pub-id pub-id-type="pmid">9129364</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref026">
                <label>26</label>
                <mixed-citation publication-type="journal"><name><surname>Beck</surname><given-names>AT</given-names></name>, <name><surname>Epstein</surname><given-names>N</given-names></name>, <name><surname>Brown</surname><given-names>G</given-names></name>, <name><surname>Steer</surname><given-names>RA</given-names></name>. <article-title>An inventory for measuring clinical anxiety: psychometric properties</article-title>. <source>Journal of consulting and clinical psychology</source>. <year>1988</year>;<volume>56</volume>(<issue>6</issue>):<fpage>893</fpage>. <pub-id pub-id-type="doi">10.1037/0022-006X.56.6.893</pub-id><?supplied-pmid 3204199?><pub-id pub-id-type="pmid">3204199</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref027">
                <label>27</label>
                <mixed-citation publication-type="journal"><name><surname>Mattick</surname><given-names>RP</given-names></name>, <name><surname>Clarke</surname><given-names>JC</given-names></name>. <article-title>Development and validation of measures of social phobia scrutiny fear and social interaction anxiety</article-title>. <source>Behaviour research and therapy</source>. <year>1998</year>;<volume>36</volume>(<issue>4</issue>):<fpage>455</fpage>–<lpage>470</lpage>. <pub-id pub-id-type="doi">10.1016/S0005-7967(97)10031-6</pub-id>
<?supplied-pmid 9670605?><pub-id pub-id-type="pmid">9670605</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref028">
                <label>28</label>
                <mixed-citation publication-type="journal"><name><surname>Brown</surname><given-names>EJ</given-names></name>, <name><surname>Turovsky</surname><given-names>J</given-names></name>, <name><surname>Heimberg</surname><given-names>RG</given-names></name>, <name><surname>Juster</surname><given-names>HR</given-names></name>, <name><surname>Brown</surname><given-names>TA</given-names></name>, <name><surname>Barlow</surname><given-names>DH</given-names></name>. <article-title>Validation of the Social Interaction Anxiety Scale and the Social Phobia Scale across the anxiety disorders</article-title>. <source>Psychological Assessment</source>. <year>1997</year>;<volume>9</volume>(<issue>1</issue>):<fpage>21</fpage>. <pub-id pub-id-type="doi">10.1037/1040-3590.9.1.21</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref029">
                <label>29</label>
                <mixed-citation publication-type="book"><name><surname>Ekman</surname><given-names>P</given-names></name>. <source>Pictures of facial affect</source>. <publisher-name>Consulting Psychologists Press</publisher-name>. <year>1976</year>.</mixed-citation>
              </ref>
              <ref id="pone.0250176.ref030">
                <label>30</label>
                <mixed-citation publication-type="journal"><name><surname>Lischke</surname><given-names>A</given-names></name>, <name><surname>Berger</surname><given-names>C</given-names></name>, <name><surname>Prehn</surname><given-names>K</given-names></name>, <name><surname>Heinrichs</surname><given-names>M</given-names></name>, <name><surname>Herpertz</surname><given-names>SC</given-names></name>, <name><surname>Domes</surname><given-names>G</given-names></name>. <article-title>Intranasal oxytocin enhances emotion recognition from dynamic facial expressions and leaves eye-gaze unaffected</article-title>. <source>Psychoneuroendocrinology</source>. <year>2012</year>;<volume>37</volume>(<issue>4</issue>):<fpage>475</fpage>–<lpage>481</lpage>. <pub-id pub-id-type="doi">10.1016/j.psyneuen.2011.07.015</pub-id>
<?supplied-pmid 21862223?><pub-id pub-id-type="pmid">21862223</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref031">
                <label>31</label>
                <mixed-citation publication-type="journal"><name><surname>Guastella</surname><given-names>AJ</given-names></name>, <name><surname>Howard</surname><given-names>AL</given-names></name>, <name><surname>Dadds</surname><given-names>MR</given-names></name>, <name><surname>Mitchell</surname><given-names>P</given-names></name>, <name><surname>Carson</surname><given-names>DS</given-names></name>. <article-title>A randomized controlled trial of intranasal oxytocin as an adjunct to exposure therapy for social anxiety disorder</article-title>. <source>Psychoneuroendocrinology</source>. <year>2009</year>;<volume>34</volume>(<issue>6</issue>):<fpage>917</fpage>–<lpage>923</lpage>. <pub-id pub-id-type="doi">10.1016/j.psyneuen.2009.01.005</pub-id>
<?supplied-pmid 19246160?><pub-id pub-id-type="pmid">19246160</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref032">
                <label>32</label>
                <mixed-citation publication-type="journal"><name><surname>Kessler</surname><given-names>RC</given-names></name>, <name><surname>Gruber</surname><given-names>M</given-names></name>, <name><surname>Hettema</surname><given-names>JM</given-names></name>, <name><surname>Hwang</surname><given-names>I</given-names></name>, <name><surname>Sampson</surname><given-names>N</given-names></name>, <name><surname>Yonkers</surname><given-names>KA</given-names></name>. <article-title>Comorbid major depression and generalized anxiety disorders in the National Comorbidity Survey follow-up</article-title>. <source>Psychological medicine</source>. <year>2008</year>;<volume>38</volume>(<issue>3</issue>):<fpage>365</fpage>. <pub-id pub-id-type="doi">10.1017/S0033291707002012</pub-id><?supplied-pmid 18047766?><pub-id pub-id-type="pmid">18047766</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref033">
                <label>33</label>
                <mixed-citation publication-type="journal"><name><surname>Gur</surname><given-names>RC</given-names></name>, <name><surname>Erwin</surname><given-names>RJ</given-names></name>, <name><surname>Gur</surname><given-names>RE</given-names></name>, <name><surname>Zwil</surname><given-names>AS</given-names></name>, <name><surname>Heimberg</surname><given-names>C</given-names></name>, <name><surname>Kraemer</surname><given-names>HC</given-names></name>. <article-title>Facial emotion discrimination: II. Behavioral findings in depression</article-title>. <source>Psychiatry research</source>. <year>1992</year>;<volume>42</volume>(<issue>3</issue>):<fpage>241</fpage>–<lpage>251</lpage>. <pub-id pub-id-type="doi">10.1016/0165-1781(92)90116-K</pub-id>
<?supplied-pmid 1496056?><pub-id pub-id-type="pmid">1496056</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref034">
                <label>34</label>
                <mixed-citation publication-type="journal"><name><surname>Persad</surname><given-names>SM</given-names></name>, <name><surname>Polivy</surname><given-names>J</given-names></name>. <article-title>Differences between depressed and nondepressed individuals in the recognition of and response to facial emotional cues</article-title>. <source>Journal of abnormal psychology</source>. <year>1993</year>;<volume>102</volume>(<issue>3</issue>):<fpage>358</fpage>. <pub-id pub-id-type="doi">10.1037/0021-843X.102.3.358</pub-id><?supplied-pmid 8408947?><pub-id pub-id-type="pmid">8408947</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref035">
                <label>35</label>
                <mixed-citation publication-type="journal"><name><surname>Hanawalt</surname><given-names>NG</given-names></name>. <article-title>The role of the upper and the lower parts of the face as a basis for judging facial expressions: II. In posed expressions and “candid-camera” pictures</article-title>. <source>The Journal of General Psychology</source>. <year>1944</year>;<volume>31</volume>(<issue>1</issue>):<fpage>23</fpage>–<lpage>36</lpage>. <pub-id pub-id-type="doi">10.1080/00221309.1944.10545217</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref036">
                <label>36</label>
                <mixed-citation publication-type="journal"><name><surname>Blais</surname><given-names>C</given-names></name>, <name><surname>Roy</surname><given-names>C</given-names></name>, <name><surname>Fiset</surname><given-names>D</given-names></name>, <name><surname>Arguin</surname><given-names>M</given-names></name>, <name><surname>Gosselin</surname><given-names>F</given-names></name>. <article-title>The eyes are not the window to basic emotions</article-title>. <source>Neuropsychologia</source>. <year>2012</year>;<volume>50</volume>(<issue>12</issue>):<fpage>2830</fpage>–<lpage>2838</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2012.08.010</pub-id>
<?supplied-pmid 22974675?><pub-id pub-id-type="pmid">22974675</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref037">
                <label>37</label>
                <mixed-citation publication-type="journal"><name><surname>Scheller</surname><given-names>E</given-names></name>, <name><surname>Büchel</surname><given-names>C</given-names></name>, <name><surname>Gamer</surname><given-names>M</given-names></name>. <article-title>Diagnostic features of emotional expressions are processed preferentially</article-title>. <source>PloS one</source>. <year>2012</year>;<volume>7</volume>(<issue>7</issue>):<fpage>e41792</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0041792</pub-id><?supplied-pmid 22848607?><pub-id pub-id-type="pmid">22848607</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref038">
                <label>38</label>
                <mixed-citation publication-type="journal"><name><surname>Boll</surname><given-names>S</given-names></name>, <name><surname>Gamer</surname><given-names>M</given-names></name>. <article-title>5-HTTLPR modulates the recognition accuracy and exploration of emotional facial expressions</article-title>. <source>Frontiers in Behavioral Neuroscience</source>. <year>2014</year>;<volume>8</volume>:<fpage>255</fpage>. <pub-id pub-id-type="doi">10.3389/fnbeh.2014.00255</pub-id><?supplied-pmid 25100964?><pub-id pub-id-type="pmid">25100964</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref039">
                <label>39</label>
                <mixed-citation publication-type="journal"><name><surname>Rutter</surname><given-names>LA</given-names></name>, <name><surname>Passell</surname><given-names>E</given-names></name>, <name><surname>Scheuer</surname><given-names>L</given-names></name>, <name><surname>Germine</surname><given-names>L</given-names></name>. <article-title>Depression severity is associated with impaired facial emotion processing in a large international sample</article-title>. <source>Journal of affective disorders</source>. <year>2020</year>;<volume>275</volume>:<fpage>175</fpage>–<lpage>179</lpage>. <pub-id pub-id-type="doi">10.1016/j.jad.2020.07.006</pub-id>
<?supplied-pmid 32734904?><pub-id pub-id-type="pmid">32734904</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref040">
                <label>40</label>
                <mixed-citation publication-type="journal"><name><surname>Rutter</surname><given-names>LA</given-names></name>, <name><surname>Scheuer</surname><given-names>L</given-names></name>, <name><surname>Vahia</surname><given-names>IV</given-names></name>, <name><surname>Forester</surname><given-names>BP</given-names></name>, <name><surname>Smoller</surname><given-names>JW</given-names></name>, <name><surname>Germine</surname><given-names>L</given-names></name>. <article-title>Emotion sensitivity and self-reported symptoms of generalized anxiety disorder across the lifespan: A population-based sample approach</article-title>. <source>Brain and behavior</source>. <year>2019</year>;<volume>9</volume>(<issue>6</issue>):<fpage>e01282</fpage>. <pub-id pub-id-type="doi">10.1002/brb3.1282</pub-id><?supplied-pmid 30993908?><pub-id pub-id-type="pmid">30993908</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref041">
                <label>41</label>
                <mixed-citation publication-type="journal"><name><surname>Rutter</surname><given-names>LA</given-names></name>, <name><surname>Dodell-Feder</surname><given-names>D</given-names></name>, <name><surname>Vahia</surname><given-names>IV</given-names></name>, <name><surname>Forester</surname><given-names>BP</given-names></name>, <name><surname>Ressler</surname><given-names>KJ</given-names></name>, <name><surname>Wilmer</surname><given-names>JB</given-names></name>, <etal>et al</etal>. <article-title>Emotion sensitivity across the lifespan: Mapping clinical risk periods to sensitivity to facial emotion intensity</article-title>. <source>Journal of experimental psychology: general</source>. <year>2019</year>. <pub-id pub-id-type="doi">10.1037/xge0000559</pub-id><?supplied-pmid 30777778?><pub-id pub-id-type="pmid">30777778</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0250176.ref042">
                <label>42</label>
                <mixed-citation publication-type="journal"><name><surname>Marsh</surname><given-names>AA</given-names></name>, <name><surname>Blair</surname><given-names>RJR</given-names></name>. <article-title>Deficits in facial affect recognition among antisocial populations: a meta-analysis</article-title>. <source>Neuroscience &amp; Biobehavioral Reviews</source>. <year>2008</year>;<volume>32</volume>(<issue>3</issue>):<fpage>454</fpage>–<lpage>465</lpage>. <pub-id pub-id-type="doi">10.1016/j.neubiorev.2007.08.003</pub-id>
<?supplied-pmid 17915324?><pub-id pub-id-type="pmid">17915324</pub-id></mixed-citation>
              </ref>
            </ref-list>
          </back>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
