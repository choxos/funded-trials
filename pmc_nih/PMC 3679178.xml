<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2024-05-03T07:14:34Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:3679178" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:3679178</identifier>
        <datestamp>2013-06-17</datestamp>
        <setSpec>plosone</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" article-type="research-article">
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
              <journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id>
              <journal-id journal-id-type="publisher-id">plos</journal-id>
              <journal-id journal-id-type="pmc">plosone</journal-id>
              <journal-title-group>
                <journal-title>PLoS ONE</journal-title>
              </journal-title-group>
              <issn pub-type="epub">1932-6203</issn>
              <publisher>
                <publisher-name>Public Library of Science</publisher-name>
                <publisher-loc>San Francisco, USA</publisher-loc>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC3679178</article-id>
              <article-id pub-id-type="pmcid">PMC3679178</article-id>
              <article-id pub-id-type="pmc-uid">3679178</article-id>
              <article-id pub-id-type="pmid">23776509</article-id>
              <article-id pub-id-type="pmid">23776509</article-id>
              <article-id pub-id-type="publisher-id">PONE-D-13-04329</article-id>
              <article-id pub-id-type="doi">10.1371/journal.pone.0065601</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Research Article</subject>
                </subj-group>
                <subj-group subj-group-type="Discipline-v2">
                  <subject>Biology</subject>
                  <subj-group>
                    <subject>Neuroscience</subject>
                    <subj-group>
                      <subject>Cognitive Neuroscience</subject>
                      <subj-group>
                        <subject>Cognition</subject>
                      </subj-group>
                    </subj-group>
                    <subj-group>
                      <subject>Sensory Systems</subject>
                      <subj-group>
                        <subject>Visual System</subject>
                      </subj-group>
                    </subj-group>
                    <subj-group>
                      <subject>Learning and Memory</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v2">
                  <subject>Medicine</subject>
                  <subj-group>
                    <subject>Mental Health</subject>
                    <subj-group>
                      <subject>Psychology</subject>
                      <subj-group>
                        <subject>Behavior</subject>
                        <subj-group>
                          <subject>Attention (Behavior)</subject>
                        </subj-group>
                      </subj-group>
                      <subj-group>
                        <subject>Cognitive Psychology</subject>
                        <subj-group>
                          <subject>Memory</subject>
                        </subj-group>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v2">
                  <subject>Social and Behavioral Sciences</subject>
                  <subj-group>
                    <subject>Psychology</subject>
                    <subj-group>
                      <subject>Behavior</subject>
                      <subj-group>
                        <subject>Attention (Behavior)</subject>
                      </subj-group>
                    </subj-group>
                    <subj-group>
                      <subject>Cognitive Psychology</subject>
                      <subj-group>
                        <subject>Memory</subject>
                      </subj-group>
                    </subj-group>
                    <subj-group>
                      <subject>Experimental Psychology</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>Is Attention Based on Spatial Contextual Memory Preferentially Guided by Low Spatial Frequency Signals?</article-title>
                <alt-title alt-title-type="running-head">Low-Spatial Frequencies &amp; Memory-Based Attention</alt-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author">
                  <name>
                    <surname>Patai</surname>
                    <given-names>Eva Zita</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff1">
                    <sup>1</sup>
                  </xref>
                  <xref ref-type="aff" rid="aff2">
                    <sup>2</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Buckley</surname>
                    <given-names>Alice</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff1">
                    <sup>1</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Nobre</surname>
                    <given-names>Anna Christina</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff1">
                    <sup>1</sup>
                  </xref>
                  <xref ref-type="aff" rid="aff3">
                    <sup>3</sup>
                  </xref>
                  <xref ref-type="corresp" rid="cor1">
                    <sup>*</sup>
                  </xref>
                </contrib>
              </contrib-group>
              <aff id="aff1">
                <label>1</label>
                <addr-line>Department of Experimental Psychology, University of Oxford, Oxford, United Kingdom</addr-line>
              </aff>
              <aff id="aff2">
                <label>2</label>
                <addr-line>Institute of Child Health, University College London, London, United Kingdom</addr-line>
              </aff>
              <aff id="aff3">
                <label>3</label>
                <addr-line>Oxford Centre for Human Brain Activity, University of Oxford, Oxford, United Kingdom</addr-line>
              </aff>
              <contrib-group>
                <contrib contrib-type="editor">
                  <name>
                    <surname>Chambers</surname>
                    <given-names>Chris</given-names>
                  </name>
                  <role>Editor</role>
                  <xref ref-type="aff" rid="edit1"/>
                </contrib>
              </contrib-group>
              <aff id="edit1">
                <addr-line>Cardiff University, United Kingdom</addr-line>
              </aff>
              <author-notes>
                <corresp id="cor1">* E-mail: <email>kia.nobre@ohba.ox.ac.uk</email></corresp>
                <fn fn-type="COI-statement">
                  <p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
                </fn>
                <fn fn-type="con">
                  <p>Conceived and designed the experiments: EZP ACN. Performed the experiments: EZP AB. Analyzed the data: EZP AB ACN. Contributed reagents/materials/analysis tools: ACN. Wrote the paper: EZP ACN.</p>
                </fn>
              </author-notes>
              <pub-date pub-type="collection">
                <year>2013</year>
              </pub-date>
              <pub-date pub-type="epub">
                <day>11</day>
                <month>6</month>
                <year>2013</year>
              </pub-date>
              <volume>8</volume>
              <issue>6</issue>
              <elocation-id>e65601</elocation-id>
              <history>
                <date date-type="received">
                  <day>23</day>
                  <month>1</month>
                  <year>2013</year>
                </date>
                <date date-type="accepted">
                  <day>29</day>
                  <month>4</month>
                  <year>2013</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>© 2013 Patai et al</copyright-statement>
                <copyright-year>2013</copyright-year>
                <copyright-holder>Patai et al</copyright-holder>
                <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
                  <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are properly credited.</license-p>
                </license>
              </permissions>
              <abstract>
                <p>A popular model of visual perception states that coarse information (carried by low spatial frequencies) along the dorsal stream is rapidly transmitted to prefrontal and medial temporal areas, activating contextual information from memory, which can in turn constrain detailed input carried by high spatial frequencies arriving at a slower rate along the ventral visual stream, thus facilitating the processing of ambiguous visual stimuli. We were interested in testing whether this model contributes to memory-guided orienting of attention. In particular, we asked whether global, low-spatial frequency (LSF) inputs play a dominant role in triggering contextual memories in order to facilitate the processing of the upcoming target stimulus. We explored this question over four experiments. The first experiment replicated the LSF advantage reported in perceptual discrimination tasks by showing that participants were faster and more accurate at matching a low spatial frequency version of a scene, compared to a high spatial frequency version, to its original counterpart in a forced-choice task. The subsequent three experiments tested the relative contributions of low versus high spatial frequencies during memory-guided covert spatial attention orienting tasks. Replicating the effects of memory-guided attention, pre-exposure to scenes associated with specific spatial memories for target locations (memory cues) led to higher perceptual discrimination and faster response times to identify targets embedded in the scenes. However, either high or low spatial frequency cues were equally effective; LSF signals did not selectively or preferentially contribute to the memory-driven attention benefits to performance. Our results challenge a generalized model that LSFs activate contextual memories, which in turn bias attention and facilitate perception.</p>
              </abstract>
              <funding-group>
                <funding-statement>This research was supported by a Project Grant to A.C.N. from the Wellcome Trust [WT082791MA]. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. In addition, the research was supported by the National Institute for Health Research (NIHR) Oxford Biomedical Research Centre based at Oxford University Hospitals Trust Oxford University as part of the Cognitive Health Programme. The views expressed are those of the author(s) and not necessarily those of the NHS, the NIHR or the Department of Health.</funding-statement>
              </funding-group>
              <counts>
                <page-count count="11"/>
              </counts>
            </article-meta>
          </front>
          <body>
            <sec id="s1">
              <title>Introduction</title>
              <p>Memory is a fundamental mental faculty ever tuning our adaptation to the environment, and influencing perception and attentional processes directly <xref rid="pone.0065601-Chun1" ref-type="bibr">[1]</xref>–<xref rid="pone.0065601-Moores1" ref-type="bibr">[3]</xref>. Recently, we developed an experimental paradigm to investigate how long-term memory (LTM) can guide attention, and showed that the pre-exposure to a complex scene in which a target location had been learned modulates neural activity and facilitates behavioural responses to the subsequent appearance of the target at the remembered location <xref rid="pone.0065601-Doallo1" ref-type="bibr">[4]</xref>–<xref rid="pone.0065601-Patai1" ref-type="bibr">[8]</xref>. Given this robust and well replicated memory-guided attention effect, we asked: what are the low-level visual mechanisms driving the memory signal?</p>
              <p>The notion that fine perceptual discriminations are guided by feedback from high-order areas after an initial coarse (rapid and early) representation has been a prevalent notion in psychology <xref rid="pone.0065601-Bullier1" ref-type="bibr">[9]</xref>–<xref rid="pone.0065601-Ullman1" ref-type="bibr">[12]</xref>. Since Navon’s initial proposal of a global-to-local processing theory of vision <xref rid="pone.0065601-Navon1" ref-type="bibr">[13]</xref>, much of the research regarding visual processing has taken the approach that perhaps multiple streams of information run in parallel and influence one another, or alternatively are constructed in some hierarchical way in which different brain areas interact with different components of a visual image to construct a whole. A more recent model, the Reverse-Hierarchy-Theory <xref rid="pone.0065601-Hochstein1" ref-type="bibr">[11]</xref> states that visual processing proceeds rapidly from the lower-level visual areas to higher-level prefrontal areas, and that feedback connections along this path are activated when more visual scrutiny is required. Specifically, the feed-forward process is automatic, and leads to a coarse, or global, representation of the visual input. As more detailed information is required, activation proceeds from prefrontal areas downward. This model can explain how identification of global properties is possible under sub-second exposures given the large receptive field properties in higher-order areas. One example would be the ability to discriminate the presence versus absence of an animal in a complex scene at very brief exposures (<xref rid="pone.0065601-Thorpe1" ref-type="bibr">[14]</xref>. The model also proposes that re-activation of low-level areas can proceed in a serial fashion when required, as during effortful serial visual search <xref rid="pone.0065601-Treisman1" ref-type="bibr">[15]</xref>. This would indicate that vision at a glance is functionally equivalent to global precedence as proposed by Navon <xref rid="pone.0065601-Navon1" ref-type="bibr">[13]</xref>, and that this process is primarily the result of rapid feed-forward connections from early visual areas to higher-level prefrontal areas, which in turn trigger the ‘vision with scrutiny’ processes through feedback connections <xref rid="pone.0065601-Hochstein1" ref-type="bibr">[11]</xref>.</p>
              <p>In light of these functional architectures, the general concept of coarse-to-fine processing has dominated the field of visual image processing <xref rid="pone.0065601-Bullier1" ref-type="bibr">[9]</xref>, <xref rid="pone.0065601-Hegd1" ref-type="bibr">[10]</xref>, <xref rid="pone.0065601-Laycock1" ref-type="bibr">[16]</xref>, and has been extensively detailed and studied by Bar and colleagues using magnetic-resonance imaging and magnetoencephalography experiments <xref rid="pone.0065601-Kveraga1" ref-type="bibr">[17]</xref>–<xref rid="pone.0065601-Bar6" ref-type="bibr">[24]</xref>. The general idea is as follows: the visual system extracts both low and high spatial-frequency information from a visual input. These different sets of information are largely processed independently. The low spatial-frequency (LSF) information is primarily conveyed by magnocellular projections following the dorsal visual stream, and high spatial-frequency (HSF) information is mainly conveyed by parvocellular projections following the ventral visual stream. The rapid processing speed of the magnocellular pathway allows for information to reach higher-order areas such as the prefrontal cortex (PFC), which in turn bias the processing of HSF signals arriving along the slower parvocellular projections to the inferior-temporal cortex (IT) <xref rid="pone.0065601-Laycock1" ref-type="bibr">[16]</xref>, <xref rid="pone.0065601-Bar2" ref-type="bibr">[20]</xref>, <xref rid="pone.0065601-Bar3" ref-type="bibr">[21]</xref>, <xref rid="pone.0065601-Bar5" ref-type="bibr">[23]</xref>–<xref rid="pone.0065601-Peyrin1" ref-type="bibr">[25]</xref>. Thus global, contextual information from re-entrant feedback connections can influence the slower feed-forward process of object identification. More recently, Bar has also proposed that the retrosplenial cortex (RSC) and parahippocampal cortex (PHC) are involved in the contextual guidance of scene processing (<xref rid="pone.0065601-Bar2" ref-type="bibr">[20]</xref>, <xref rid="pone.0065601-Bar3" ref-type="bibr">[21]</xref>, <xref rid="pone.0065601-Bar5" ref-type="bibr">[23]</xref>, <xref rid="pone.0065601-Bar6" ref-type="bibr">[24]</xref>; but see <xref rid="pone.0065601-Henderson1" ref-type="bibr">[26]</xref> for opposing views). The advantage of such a system would be that predictive information from the environmental context could constrain the possible outcomes during the decoding of ambiguous input signals.</p>
              <p>A few qualifications are worth mentioning before we accept the generalized model of coarse-to-fine visual-contextual processing. Though the distinction between a ventral and a dorsal stream of visual processing is useful for understanding the different aspects of visual perception and action <xref rid="pone.0065601-Goodale1" ref-type="bibr">[27]</xref>, <xref rid="pone.0065601-Ungerleider1" ref-type="bibr">[28]</xref>, it is not case that these two pathways are entirely segregated <xref rid="pone.0065601-VanEssen1" ref-type="bibr">[29]</xref>. In addition, the general misconception that the dorsal pathway uses magnocellular projections and the ventral pathway is based on solely parvocellular input is much too simplified <xref rid="pone.0065601-Hegd1" ref-type="bibr">[10]</xref>, <xref rid="pone.0065601-Merigan1" ref-type="bibr">[30]</xref>, and LSFs and HSFs are not processed exclusively by magnocellular and parvocellular cells, respectively <xref rid="pone.0065601-Laycock1" ref-type="bibr">[16]</xref>, <xref rid="pone.0065601-Merigan1" ref-type="bibr">[30]</xref>. Nevertheless, the model provides a simplified anatomically plausible and functionally well-documented framework for understanding how visual input is processed.</p>
              <p>There have been studies that directly assess the contribution of the different visual pathways in the computation of natural image properties by using spatial filters, in order to separate the input into various visual processing channels. For example, it has been shown that LSF information is processed more rapidly and provides a ‘raw estimate’ for incoming HSF information, and that this effect is dependent on exposure times <xref rid="pone.0065601-Schyns1" ref-type="bibr">[31]</xref>. Specifically, at short exposures the LSF information was preferentially processed, whereas when longer processing time was available, HSF information was utilized <xref rid="pone.0065601-Schyns1" ref-type="bibr">[31]</xref>. Recently, using random-dot sterograms, it was shown that human pattern vision follows the coarse-to-fine order as well, indicating that this process starts from the basic visual input level, not just during scene-viewing <xref rid="pone.0065601-Neri1" ref-type="bibr">[32]</xref>. In addition, it has recently been proposed that the neural signatures underlying global and local processing (which can be loosely equated with low and high spatial-frequency processing) can be separated: low frequency oscillation in the theta band corresponds to global information processing, while higher frequency beta band activity underlies local processing <xref rid="pone.0065601-Romei1" ref-type="bibr">[33]</xref>, <xref rid="pone.0065601-Smith1" ref-type="bibr">[34]</xref>. All these findings converge to support the coarse-to-fine hypothesis, namely that activity from higher-order areas may precede and enhance neural activity in early visual cortices; it is on this premise that we conducted a set of experiments to test whether LTM benefits to perception depending on contextual signals is carried by a coarse-to-fine mechanism.</p>
              <p>The different proposals of how such a mechanism may work are indicative that the brain is no longer seen as a passive computing device, but is instead actively involved in selecting and modulating incoming information. In this case, an internal signal, such as memory, could plausibly interact with incoming information directly. Memory guided attention is not only a robust effect in magnitude, but also very rapid, being firmly established by 100 ms lead time <xref rid="pone.0065601-Summerfield1" ref-type="bibr">[5]</xref>. Thus, we were interested in whether the mechanisms of rapid scene perception are invoked during memory-guided attentional orienting, specifically whether memory-guided biases are selectively driven by coarse visual representations.</p>
              <p>The basis for our experiments was the coarse-to-fine model of scene recognition, and the assumption that contextual information coming from MTL areas should further boost the LSF effect, especially if the contextual memories are highly relevant for a difficult discrimination task. Given that the contextual-guidance model proposed by Bar involves medial-temporal areas (MTL) <xref rid="pone.0065601-Bar2" ref-type="bibr">[20]</xref>, <xref rid="pone.0065601-Bar3" ref-type="bibr">[21]</xref>, <xref rid="pone.0065601-Bar5" ref-type="bibr">[23]</xref>, <xref rid="pone.0065601-Bar6" ref-type="bibr">[24]</xref>, which are typically associated with spatial navigation and/or memory processes <xref rid="pone.0065601-Bird1" ref-type="bibr">[35]</xref>–<xref rid="pone.0065601-Squire2" ref-type="bibr">[39]</xref>, we manipulated directly the low and high spatial-frequency information that activates the contextual memories in order to test for the anticipated LSF advantage in behaviour relating to scene processing. We hypothesized that if LSFs are faster at guiding scene recognition, they should also be quicker at activating relevant contextual memories, thus facilitating target selection in a previously memorized location.</p>
              <p>Experiment 1 was a control scene-perception task designed to ensure that the stimulus and task parameters were appropriate for replicating the well documented LSF advantage (for early example see <xref rid="pone.0065601-Schyns1" ref-type="bibr">[31]</xref>). Filtered scenes containing only low or high spatial-frequency information were presented very briefly (two refresh rates on a 60 Hz screen) followed by a choice of two scenes. Participants made a forced-choice discrimination. Once the LSF advantage was clearly replicated, it was possible to use the filtered images as memory cues in the memory-guided attention task we have developed <xref rid="pone.0065601-Summerfield1" ref-type="bibr">[5]</xref>.</p>
              <p>In all the following experiments (Exp. 2–4), there was a learning phase, during which participants learned specific context-target associations, followed by a perceptual discrimination task, in which the cue scene preceded the presentation of the target to be identified. The cues were filtered in order to provide only low or high spatial-frequency information. The main experimental question of interest was whether the top-down memory signal biasing perception during memory-guided orienting is comprised primarily of LSF signals, acting in a way that is analogous to the top-down feedback signals during natural scene perception. If so, activation of memory cues using LSF stimulation should trigger memory biases that can be established more quickly and which can act more effectively than HSF stimulation.</p>
            </sec>
            <sec sec-type="materials|methods" id="s2">
              <title>Materials and Methods</title>
              <sec id="s2a">
                <title>Stimuli</title>
                <p>For the following experiments, the stimuli used were digital photographs of scenes filtered to contain either low (LSF) or high spatial-frequency (HSF) information only. All scene stimuli were created from photographs obtained collectively by the lab. Images contained indoor environments, cityscapes, or landscapes, without any conspicuous human characters or animals. All images were converted to greyscale, and resized to 1000×750 pixel images using Matlab (Mathworks, Natick, MA). They were filtered using a Gaussian filter, with a cut-off frequency of 2 cpd (cycles per degree) for low spatial-frequency images (keeping all frequencies below this value), and 6 cpd for high spatial-frequency images (keeping all frequencies above this value). These cut-off values are typical for filtering images <xref rid="pone.0065601-Schyns1" ref-type="bibr">[31]</xref>, <xref rid="pone.0065601-Peyrin2" ref-type="bibr">[40]</xref>, and provide a distance and image-size independent measure of spatial frequency.</p>
                <p>Luminance values were tested with a customized Matlab protocol, which used saturation values in the red, green and blue channels to estimate luminance. This step was implemented to ensure that the behavioural effects relating to the spatial frequency filtering were not overshadowed by other low-level differences of perceptual saliency in the images, which result from the filtering process itself. Luminance values of the filtered scenes were extracted and tested for differences with two-sample independent t-tests, which were found to be non-significant (comparing non-filtered to LSF, t(286) = –.52; p = .61; non-filtered to HSF, t(286) = –.06; p = .95; HSF to LSF, t(286) = .33, p = .74).</p>
              </sec>
              <sec id="s2b">
                <title>Ethics Statement</title>
                <p>All participants were volunteers recruited from a subject pool at the University of Oxford, and gave written consent to participate in this study for monetary compensation. The studies were approved by the University of Oxford Central University Research Ethics Committee (CUREC).</p>
              </sec>
            </sec>
            <sec id="s3">
              <title>Experiment 1</title>
              <p>In order to confirm that the stimuli were suitable for the subsequent experiments, a short scene discrimination task was used. Participants viewed a filtered image presented for two refresh rates (33 ms for the 60 Hz monitor used), which, after a short inter-stimulus interval (33 ms), was followed by a display of two images, one matching the probe stimulus, the other a foil. The task was to indicate which of the two images matched the filtered sample scene. We expected an advantage for low spatial-frequency sample scenes, borne out by faster reaction times and higher identification accuracy. The reasoning behind using very short exposure durations was to maximize the advantage of fast processing speeds usually observed for LSF stimuli <xref rid="pone.0065601-Schyns1" ref-type="bibr">[31]</xref>.</p>
              <sec id="s3a">
                <title>Methods</title>
                <sec id="s3a1">
                  <title>Participants</title>
                  <p>Twelve volunteers (11 females, mean age: 19 years, 1 left-handed) participated in this study.</p>
                </sec>
                <sec id="s3a2">
                  <title>Scene stimuli</title>
                  <p>Ninety six greyscale scenes were used in the experiment.</p>
                </sec>
                <sec id="s3a3">
                  <title>Procedure</title>
                  <p>Participants performed 96 trials in which a HSF or LSF sample scene appeared briefly (33 ms, subtending a visual angle of 19.9°×14.9°) and was followed shortly afterward (inter-stimulus interval – ISI - of 33 ms) by a probe array containing two full-greyscale scenes (200 ms, subtending a visual angle of 8.3°×6.5°, on either side of fixation). One of the scenes in the probe array matched the filtered sample scene and one was a novel scene. Participants made a speeded forced-choice response indicating which of the two probe scenes matched the previous filtered sample scene (<xref ref-type="fig" rid="pone-0065601-g001">Figure 1a</xref>) using a mouse-click (left mouse button if scene on left matched the previously presented filtered scene, right mouse for right-sided match). They were instructed to respond as quickly and as accurately as possible (<xref ref-type="fig" rid="pone-0065601-g001">Figure 1a</xref>). Trials containing HSF and LSF scenes appeared in a random order, and assignment of each scene to the HSF or LSF condition in the sample and to side of presentation in the probe array was counterbalanced across subjects. No feedback was given, and participants had 1000 ms to respond. The inter-trial-interval was jittered between 2 and 3 seconds.</p>
                  <fig id="pone-0065601-g001" orientation="portrait" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pone.0065601.g001</object-id>
                    <label>Figure 1</label>
                    <caption>
                      <title>Experiment 1 task design and results.</title>
                      <p>a) Trial sequence in the perceptual choice task. A jittered pre-trial fixation was followed by one of two types of image: low or high spatial- frequency filtered sample scene. This was followed by an ISI of 2 refresh rates, and finally the probe images, which were never filtered. Participants had to indicate with a mouse press which of the two images matched the preceding filtered sample (left mouse button for left-sided match, right mouse button for right-sided match). b) Results showed RT and accuracy benefits for probes preceded by LSF filtered sample scenes (error bars represent standard errors).</p>
                    </caption>
                    <graphic xlink:href="pone.0065601.g001"/>
                  </fig>
                </sec>
              </sec>
              <sec id="s3b">
                <title>Results and Discussion</title>
                <p>Reaction times to identify the sample scene were recorded, and accuracy scores calculated (percent correct). A paired-samples t-test was used to assess the differences between the mean RTs and accuracy scores of the different spatial frequencies. Low spatial-frequency images resulted in significantly more accurate, t(11) = 5.34, p&lt;.001 (two-tailed), and faster, t(11) = 3.49, p = .005 (two-tailed), responses. <xref ref-type="fig" rid="pone-0065601-g001">Figure 1b</xref> shows the mean performance on the choice task.</p>
                <p>In this experiment, the typical finding of a LSF advantage during the rapid perceptual categorization of natural scenes (for example: <xref rid="pone.0065601-Schyns1" ref-type="bibr">[31]</xref>, <xref rid="pone.0065601-Oliva1" ref-type="bibr">[41]</xref>) was replicated, thus confirming that the stimuli are appropriate for use in subsequent experiments.</p>
              </sec>
            </sec>
            <sec id="s4">
              <title>Experiment 2</title>
              <p>The main purpose of the subsequent experiments was to test whether long-term memory (LTM) biases on perception are primarily or selectively activated by rapid, LSF information. In Experiment 2, we tested whether the spatial-frequency memory-cues would modulate subsequent target processing differently from memory-cues containing the full image information (no filter). Participants performed a memory-guided perceptual discrimination task, which consisted of a learning phase and a memory-guided attention phase. Participants performed these two experimental phases over three days. Over the first two days, they completed a Learning Task, in which they explored visual scenes to learn the location of a target (a small gold key) in each scene (50% of scenes contained a key). By the end of the learning task, participants had formed strong spatial contextual memories of the target location for scenes containing a target, but they had no specific target-context associations for those scenes that did not contain a target (all scenes however, were familiar).</p>
              <p>On the third day, they completed a memory-guided attention Orienting Task in which they discriminated the presence or absence of a target (also a small gold key) embedded within a full greyscale scene. Pre-exposure to a filtered version of the scene (without any target) provided memory-based cues to orient contextual spatial attention to the location of the remembered target.</p>
              <p>If the contextual memories formed during learning are activated more quickly and/or more strongly when they are driven by only LSF information, then we would expect to find a greater behavioural benefit in reaction times and accuracy after pre-exposure to filtered cues containing LSF compared to HSF information. This would be borne out by an interaction between the effects of spatial memory carried by the cue and the spatial-frequency of the cues (i.e. valid LSF memory cues should facilitate attentional processes and lead to better behavioural performance than HSF memory cues, or neutral cues with no specific memory associations for the target location).</p>
              <sec id="s4a">
                <title>Methods</title>
                <sec id="s4a1">
                  <title>Participants</title>
                  <p>Power calculations based on Experiment 1 and on our previous memory-guided orienting study using a similar paradigm <xref rid="pone.0065601-Patai1" ref-type="bibr">[8]</xref> showed that a minimum of 6–10 participants was required to reveal significant orienting effects. The number of participants in this and subsequent experiments was determined by the number of participants required to counterbalance all relevant experimental factors. Twenty-four volunteers (5 male, 19 female, mean age = 24 yrs) participated in this study.</p>
                </sec>
                <sec id="s4a2">
                  <title>Scene stimuli</title>
                  <p>One hundred and forty four greyscale scenes were used in the experiment. For the learning task, a small key (size: 0.5 cm×1 cm, subtending a visual angle of 0.25°×0.50°) was placed in one of the four quadrants of the scene, preferably in a hidden location (the key looked like a typical door lock key, oriented vertically upwards). Five versions of each learning-task display were generated for each scene, with the key placed in one of each of the four quadrants or with the key absent – this was done for counterbalancing purposes. For the orienting task, the scenes with keys were re-made to include a larger and brighter key (size: 1 cm×1.8 cm, subtending a visual angle of 0.5°×0.9°) in the location of the original key target. Two additional types of scenes, with a filter, were prepared for the orienting task.</p>
                </sec>
                <sec id="s4a3">
                  <title>Learning task</title>
                  <p>Participants viewed each of the 144 scenes in a random order, repeated over six blocks (the learning task was broken down into three blocks each, over two consecutive days). Half of the scenes contained a small key target in one of the four quadrants. The remaining 72 scenes did not contain a target. Participants viewed the scenes and searched for the target overtly. Once located, participants clicked once with the mouse to activate a cursor, after which they clicked on the location of the key with the mouse. After a response, or after available search time expired, the next scene was presented. The available search time decreased as the blocks progressed, with the maximum duration of each scene randomized within a range (16–24 s in block 1, 12–20 s in blocks 2 and 3, 10–18 s in blocks 4 and 5, 8–16 s in block 6). Exposure times for key-absent scenes were yoked to the exposure of key-present scenes. Participants had to find as many keys as possible and memorize their locations. Eye movements were recorded using an infrared eye-tracking system (ISCAN, Woburn, MA). Only participants that located more than 80% of keys in target-present scenes progressed to the next phase of the experiment.</p>
                </sec>
                <sec id="s4a4">
                  <title>Orienting task</title>
                  <p>Participants performed 144 trials. The task was to detect, using covert attention, the presence or absence of a bright key within the familiar scenes that had previously been studied. Each trial began with the presentation of a familiar scene (100 ms), which was used to cue the participant’s attention to a particular location within the scene. This cue contained no embedded key target, and could be presented in one of three conditions: normal (NSF, unfiltered), low spatial-frequency (LSF), or high spatial-frequency (HSF) (<xref ref-type="fig" rid="pone-0065601-g002">Figure 2a</xref>). After a variable ISI (200, 400 or 800 ms), the probe scene appeared (200 ms), with or without a target embedded. The probe scene was never filtered. Participants indicated with a mouse button press whether a target was present in the probe scene (left button: target present; right button: target absent). They were instructed to respond as quickly as possible but to avoid making mistakes.</p>
                  <fig id="pone-0065601-g002" orientation="portrait" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pone.0065601.g002</object-id>
                    <label>Figure 2</label>
                    <caption>
                      <title>Paradigm and Results of Experiment 2.</title>
                      <p>a) Trial sequence in the orienting task. A jittered pre-trial fixation was followed by one of three types of cue: non-filtered, low- or high-spatial-frequency filtered image. This was followed by a variable inter-stimulus interval, and finally the target image, which was never filtered. Participants had to indicate with a mouse press whether or not there was a target currently present in the target image. b) Sensitivity scores and c) reaction times (for target present trials only) for each cue type (NSF, LSF, HSF) by memory condition (memory, no-memory). Error bars represent standard errors.</p>
                    </caption>
                    <graphic xlink:href="pone.0065601.g002"/>
                  </fig>
                  <p>The design crossed the factors of spatial-frequency of cue (NSF, LSF, HSF), spatial memory (memory, no-memory), and target presence (present, absent). There were twelve trials in each cell.</p>
                </sec>
              </sec>
              <sec id="s4b">
                <title>Results and Discussion</title>
                <p>The total number of subjects included in the analysis was twenty two (two subjects were excluded: one participant failed to locate at least 80% of targets in the learning task, and one participant was excluded for having a d’ score that was more than 2.5 standard deviations below the mean.</p>
                <sec id="s4b1">
                  <title>Learning task</title>
                  <p>Search times were calculated as time from scene onset to the time that the subject made their first mouse click (to activate the cursor). As the learning blocks progressed, reaction times decreased and more targets were located (block 1 mean accuracy = 65%±3.7 SEM, mean search times = 6 s±0.4; block 6 mean accuracy = 83%±4.2; mean search times: 1.5 s±0.2) Repeated-measures ANOVAs testing for linear decreases in reaction time and linear increases in accuracy over the learning blocks revealed significant linear contrasts for both measures (reaction time: F(1,21) = 118.17, p&lt;.001; accuracy: F(1,21) = 369.59, p&lt;.001).</p>
                </sec>
                <sec id="s4b2">
                  <title>Orienting task</title>
                  <p>Support for the hypothesis that magnocellular signals guide contextual cueing by LTM would be borne out by an interaction between memory and spatial-frequency. A repeated-measures ANOVA of d’ revealed significant main effects of spatial-frequency (F(1,21) = 5.39, p = .008) and memory (F(1,21) = 12.89, p = .002). Perceptual discrimination scores were higher for memory trials; and performance in normal (NSF) and low spatial-frequency conditions (LSF) was better than in the high-spatial-frequency (HSF) condition (<xref ref-type="fig" rid="pone-0065601-g002">Figure 2b</xref>). However, critically, no interaction was observed between these two factors (F(1,42) = .614,p = 0.55).</p>
                  <p>A repeated-measures ANOVA on reaction times (<xref ref-type="fig" rid="pone-0065601-g002">Figure 2c</xref>) revealed significant effects of SF (F(1,42) = 16.85, p&lt;.001), with LSF cues resulting in faster RTs. In addition, there was a significant effect of,target presence (F(1,21) = 28.75, p&lt;.001), and an interaction between memory and target presence (F(1,21) = 42.1, p&lt;.001). Participants were faster to respond in target-present trials, especially when they had a memory for the target location. Again, there was no interaction of spatial-frequency and memory (F(1,42) = 2.51, p = .78). No other main effects or interactions were significant (all p&gt;.1). When looking at reaction times relating to target-present trials only, there was a significant effect of SF (F(1,21) = 7.492, p = .002), and memory (F(1,21) = 14.357, p = .001), but no interaction (F(1,42) = .431, p = .65). Detailed p-values for each condition and interaction, along with effect sizes are available in <xref ref-type="supplementary-material" rid="pone.0065601.s001">Table S1</xref>.</p>
                  <p>Inverse efficiency scores (RT/accuracy) showed a significant effect of SF (F(2,42) = 8.895, p = .001), memory (F(1,21) = 15.907, p = .001), a trend for target presence (F(1,21) = 3.879, p = .062), and an interaction between memory and target presence (F(1,21) = 41.774, p&lt;.001). But again no interaction occurred involving memory and spatial frequency (F(1,21) = .550, p = .581).</p>
                  <p>The findings of this experiment show that the memory-based attentional guidance observed in previous reports (for example see: <xref rid="pone.0065601-Summerfield1" ref-type="bibr">[5]</xref>) can be replicated even when using cues with limited spatial-frequency information However, the lack of interaction between the spatial-frequency and memory factors suggests that either these two mechanisms operate independently, or our experiment was not sensitive to this interaction.</p>
                </sec>
              </sec>
            </sec>
            <sec id="s5">
              <title>Experiment 3</title>
              <p>In this experiment, the aim was to probe further for the potential interaction, by reducing the number of conditions.</p>
              <sec id="s5a">
                <title>Methods</title>
                <p>Sixteen healthy students (10 male, mean age = 22yrs, 3 left-handed) participated. The stimuli and training procedures were the same as in Experiment 2, except 160 scenes were used. The orienting task was the same as in Experiment 2, except for two differences: (1) the unfiltered cue scenes were removed, leaving only two spatial-frequency cue conditions: LSF and HSF, (2) only two ISIs were used, one short (100 ms) and one long (700 ms). The design crossed the factors of spatial-frequency of cue (LSF, HSF), spatial memory (memory, no-memory), target presence (present, absent), and ISIs (100, 700), resulting in ten trials in each cell.</p>
                <sec id="s5a1">
                  <title>Spatial memory recall task</title>
                  <p>In order to get an approximate measure of the state of recollective memory in the session, following the orienting task, participants performed a recall task that measured explicit memory for target locations. Participants viewed all 160 scenes (greyscale, but unfiltered, as in learning task), without any targets. For scenes in which they had a memory for the target location, they used the mouse to click on the remembered target location from the learning phase. If they had no memory, they were instructed to click the centre of the screen. Participants were also instructed to rate their confidence in their responses after each scene by clicking one of the three mouse buttons to indicate strength of confidence (range: not at all confident, fairly confident, and very confident).</p>
                </sec>
              </sec>
              <sec id="s5b">
                <title>Results and Discussion</title>
                <sec id="s5b1">
                  <title>Learning task</title>
                  <p>As the learning blocks progressed, reaction times decreased and more targets were located (block 1 mean accuracy = 63%±4.7SEM, mean search times = 6.6 s±0.29; block 6 mean accuracy = 87.8%±5.7; mean search times: 1.8 s±0.13). Repeated-measures ANOVAs testing for linear decreases in reaction time and linear increases in accuracy over the learning blocks revealed significant linear contrasts for both measures (reaction time: F(1,15) = 187.35, p&lt;.001; accuracy: F(1,15) = 103.71, p&lt;.001).</p>
                </sec>
                <sec id="s5b2">
                  <title>Orienting task</title>
                  <p>A repeated-measures ANOVA of d’ (<xref ref-type="fig" rid="pone-0065601-g003">Figure 3a</xref>) revealed a significant main effect of memory (F(1,15) = 20.38, p&lt;.001). Perceptual discriminations were higher when cues carried memory for the target location. No other significant main effects (spatial-frequency (F(1,15) = 2.78, p = .12), ISI (F(1,15) = .149,p = 0.71)) or interactions (all p&gt;.1) were observed. The interaction of interest, between memory and spatial frequency was far from significant (F(1,15) = .284, p = 0.6), as was the three-way interaction of memory, spatial frequency and ISI (F(1,15) = .182, p = 0.7).</p>
                  <fig id="pone-0065601-g003" orientation="portrait" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pone.0065601.g003</object-id>
                    <label>Figure 3</label>
                    <caption>
                      <title>Results of Experiment 3.</title>
                      <p>a) Sensitivity scores and b) reaction times (for target present trials only) for each cue type (LSF, HSF) by memory condition (memory, no-memory), grouped by ISI (100 ms, 700 ms). Error bars represent standard errors.</p>
                    </caption>
                    <graphic xlink:href="pone.0065601.g003"/>
                  </fig>
                  <p>A repeated-measures ANOVA on reaction times (<xref ref-type="fig" rid="pone-0065601-g003">Figure 3b</xref>) revealed participants were faster at responding to LSF cues (F(1,15) = 19.79, p&lt;.001), target present trials (F(1,15) = 35.26, p&lt;.001), and trials where the ISI was shorter (F(1,15) = 16.13, p = .001). There was an interaction between memory and target presence (F(1,15) = 14.92, p = .002), but no main effect of memory (F(1,15) = .73, p = .41), and no interaction between spatial-frequency and memory (F(1,14) = .01, p = .93). No other interactions were significant (all p&gt;.1). When looking at reaction times relating to target-present trials only, there was a significant effect of SF (F(1,15) = 6.15, p = .026) and ISI (F(1,15) = 9.28, p = .008 ), a trend towards an effect of memory (F(1,15) = 4.263, p = 0.057), but no interaction between memory and spatial frequency (F(1,15) = .007, p = .933), and no three-way interaction (F(1,15) = 0.63, p = 0.44), and no other significant interactions (p&gt;.1). Detailed p-values for each condition and interaction, along with effect sizes are available in <xref ref-type="supplementary-material" rid="pone.0065601.s001">Table S1</xref>.</p>
                  <p>In addition, inverse efficiency scores (RT/accuracy) were used to analyse results independent of any possible speed-accuracy trade-offs. Analysis of inverse efficiency yielded significant effects of SF (F(1,14) = 5.73, p = .031), memory (F(1,14) = 6.31, p = .025), and a trend towards target presence (F (1,14) = 5.327, p = .081); as well as interactions between memory and target presence (F(1,14) = 11.105, p = .005); among spatial-frequency, target presence, and ISI (F(1,14) = 4.823, p = .045); and a trend for memory, target presence and ISI (F(1,14) = 4. 286, p = .057). Again, no interactions involving memory and SF approached significance (SF×memory (F(1,15) = 2.0, p = .18), SF×memory×ISI (F(1,15) = 1.4, p = .25), SF×memory×target presence (F(1,15) = .41, p = .53)).</p>
                </sec>
                <sec id="s5b3">
                  <title>Spatial memory recall task</title>
                  <p>In order to obtain a rough estimate of participants’ explicit memory for the target location, the number of scenes was calculated in which participants placed the key within a 150-pixel diameter circle around the original target location (approximately 3.4°visual angle/15% of screen). This calculation was performed only for trials that were target-absent in the orienting task, in order to avoid any contamination effects from being re-exposed to the target locations. The majority of subjects correctly identified the locations of the learned targets (group mean correct = 67±17% significantly different from chance (t = 3.8, p = 0.002)). In addition, participants’ confidence increased proportionally with their accuracy, which was measured by the distance between the remembered location and actual location of the key (mean distance from original target location of confidence rating 1– not at all confident = 68 pixels±4 SEM, rating 2– fairly confident = 66 pixels±6 SEM, rating 3– very confident = 40 pixels±2.5 SEM). A repeated-measures ANOVA testing for linear decreases in pixel distance from original key location over confidence ratings revealed significant a linear contrast (F(1,7) = 9.37, p = .018).</p>
                  <p>The results of this experiment show that, even when correcting for possible trade-offs in speed and accuracy, and separating short versus long ISIs, the effects of spatial-frequency and of memory are not accompanied by an interaction between these factors. LSF cues and memory cues each independently result in faster reaction times, but when combined do not offer an added benefit, as indexed by the lack of interaction. Memory cues also lead to higher perceptual discrimination, but again independently of any interaction with spatial frequency. One remaining important possibility to test was whether interaction between memory and spatial frequency would only be unveiled under even shorter duration exposures for the filtered cue scenes, and cue-target stimulus-onset asynchronies. Perhaps a selective LSF-driven memory effect only occurs before there has been time to invoke analysis of fine details in the slower HSF pathway. To test for this, in the last experiment of the series, the durations of cue and SOA were reduced to the values used in Experiment 1.</p>
                </sec>
              </sec>
            </sec>
            <sec id="s6">
              <title>Experiment 4</title>
              <p>Experiment 4 used a very short cue duration and cue-target interval in order to test whether LSF signals play a prevalent role in memory-guided contextual cueing early on. The design was identical to that of Experiment 3, except for the stimulus timings: the cue and ISI were both at two refresh rates (33 ms). These values were chosen based on Experiment 1, which demonstrated a behavioural advantage for perceptually driven contextual priming at these intervals.</p>
              <sec id="s6a">
                <title>Methods</title>
                <p>Twenty-one students (6 male, mean age = 22 yrs, 2 left-handed) participated. The stimuli and training procedures were the same as in Experiments 2 and 3, except that 96 scenes were used. As a result, the six blocks were considerably shorter, and therefore training was conducted in a single two hour session.</p>
                <sec id="s6a1">
                  <title>Orienting task</title>
                  <p>The orienting task was the same as in Experiment 3, except that the exposure time of the cue and ISI were changed to be 2 refresh rates each (33 ms). The full factorial design included the factors of spatial-frequency of cue (LSF, HSF), spatial memory (memory, no-memory), and target presence (present, absent).</p>
                </sec>
                <sec id="s6a2">
                  <title>Spatial memory recall task</title>
                  <p>The subsequent test for recall of the spatial position targets within scenes used the identical procedure as Experiment 3.</p>
                </sec>
              </sec>
              <sec id="s6b">
                <title>Results and Discussion</title>
                <sec id="s6b1">
                  <title>Learning task</title>
                  <p>As the learning blocks progressed, reaction times decreased and more targets were located (block 1 mean accuracy = 70%±2.7SEM, mean search times = 6.7±0.2 SEM; block 6 mean accuracy = 89%±1.5; mean search times: 1.3 s±0.1). Repeated-measures ANOVAs testing for linear decreases in reaction time and linear increases in accuracy over the learning blocks revealed significant linear contrasts for both measures (reaction time: F(1,20) = 468.32, p&lt;.001; accuracy: F(1,20) = 225.06, p&lt;.001).</p>
                </sec>
                <sec id="s6b2">
                  <title>Orienting task</title>
                  <p>This final experiment reduced exposure times in an attempt to isolate the early effects of LSF processing, and its potential contribution to relaying top-down memory-related signals to facilitate perception. A repeated-measures ANOVA of d’ (<xref ref-type="table" rid="pone-0065601-t001">Table 1</xref>) revealed a trend for spatial-frequency (F(1,20) = 3.028, p = 0.097), but no effect of memory (F(1,20) = .373, p = .548). The interaction of interest between these two factors was also far from significant (F(1,20) = .024, p = 0.879).</p>
                  <table-wrap id="pone-0065601-t001" orientation="portrait" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pone.0065601.t001</object-id>
                    <label>Table 1</label>
                    <caption>
                      <title>Results from Experiment 4.</title>
                    </caption>
                    <alternatives>
                      <graphic id="pone-0065601-t001-1" xlink:href="pone.0065601.t001"/>
                      <table frame="hsides" rules="groups">
                        <colgroup span="1">
                          <col align="left" span="1"/>
                          <col align="center" span="1"/>
                          <col align="center" span="1"/>
                        </colgroup>
                        <thead>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">Condition</td>
                            <td align="left" rowspan="1" colspan="1">Reaction Time (ms)</td>
                            <td align="left" rowspan="1" colspan="1">Sensitivity (d’)</td>
                          </tr>
                        </thead>
                        <tbody>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">LSF memory</td>
                            <td align="left" rowspan="1" colspan="1">680 (22)/855 (24)</td>
                            <td align="left" rowspan="1" colspan="1">1.85 (0.16)</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">LSF no-memory</td>
                            <td align="left" rowspan="1" colspan="1">687 (19)/806 (28)</td>
                            <td align="left" rowspan="1" colspan="1">1.90 (0.13)</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">HSF memory</td>
                            <td align="left" rowspan="1" colspan="1">696 (22)/887 (26)</td>
                            <td align="left" rowspan="1" colspan="1">1.63 (0.12)</td>
                          </tr>
                          <tr>
                            <td align="left" rowspan="1" colspan="1">HSF no-memory</td>
                            <td align="left" rowspan="1" colspan="1">723 (19)/821 (23)</td>
                            <td align="left" rowspan="1" colspan="1">1.72 (0.12)</td>
                          </tr>
                        </tbody>
                      </table>
                    </alternatives>
                    <table-wrap-foot>
                      <fn id="nt101">
                        <p>For reaction time, data is shown for target present and absent trials separately, with target present values presented on the left, target absent on the right. Values in parentheses denote standard error.</p>
                      </fn>
                    </table-wrap-foot>
                  </table-wrap>
                  <p>A repeated-measures ANOVA on reaction times (<xref ref-type="table" rid="pone-0065601-t001">Table 1</xref>) revealed significant main effects of SF (F(1,20) = 9.04, p = 0.007), memory (F(1,20) = 5.508, p = 0.029), and target presence (F(1,20) = 48.7, p&lt;0.001). Responses were faster in trials with LSF cues, in trials with valid memory cues, and in target-present trials. There was no significant interaction between spatial frequency and memory (F(1,20) = .007, p = .932), or for the three-way interaction of memory (F(1,15) = .029, p = 0.87), or spatial frequency and target presence (F(1,15) = 2.08, p = 0.17). Only the interaction between memory and target presence was significant (F(1,20) = 14.29, p = 0.001). Detailed p-values for each condition and interaction, along with effect sizes are available in <xref ref-type="supplementary-material" rid="pone.0065601.s001">Table S1</xref>.</p>
                  <p>A repeated-measures ANOVA on inverse-efficiency scores revealed a significant effect of spatial-frequency (F(1,20) = 5.312, p = .032) and no other main effects (all p&gt;.1). An interaction between memory and target presence (F(1,20) = 16.423, p&lt;.001) also occurred. Post-hoc analysis showed that this interaction was driven by the fact that memory facilitated identification of key presence but tended to interfere with correct rejection of key absence (<xref ref-type="table" rid="pone-0065601-t001">Table 1</xref>).</p>
                  <p>Again, there was no interaction of spatial-frequency and memory (F(1,20) = .223, p = .642), however a trend towards a three-way interaction of spatial-frequency, memory, and target presence was observed (F(1,20) = 3.195, p = 0.089). Given the potential relevance of this effect to the experimental hypotheses, subsidiary ANOVAs were used to characterise the nature of this trend. A 2×2 ANOVA on spatial frequency and memory focusing on target-present trials revealed a trend towards spatial frequency (F(1,20) = 3.8, p = 0.06), a significant effect of memory (F(1,20) = 6.65, p = 0.018), but no interaction (F(1,20) = 1.48, p = 0.24). In target-absent trials, the effect of spatial frequency was no longer significant (F(1,20) = 1.64, p = 0.22), however there was a significant effect of memory (F(1,20) = 14.9, p = 0.001), but again not interaction (F(1,20) = 0.73, p = 0.41). We can conclude from this analysis that in the three-way interaction the spatial frequency effect observed was driven by the presence of the target, while memory effects were consistent. These results further corroborate previous evidence that spatial frequency and memory do not interact in this task.</p>
                </sec>
                <sec id="s6b3">
                  <title>Spatial memory recall task</title>
                  <p>Performance in spatial memory recall task was calculated as described in Experiment 3. The majority of subjects correctly identified the locations of the learned targets (group mean correct = 78%), and confidence increased proportionally with the distance between the remembered location and actual location of the key (mean distance from original target location of confidence rating 1– not at all confident = 60 pixels±8.1 SE, rating 2– fairly confident = 51 pixels±4.4 SE, rating 3– very confident = 37 pixels±1.8 SE). A repeated-measures ANOVA testing for linear decreases in pixel distance from original key location over confidence ratings revealed a significant linear contrast (F(1,19) = 9.15, p = .007).</p>
                  <p>The results of this experiment do not provide any evidence for prevalent effect of LSF in carrying memory signals. The trend towards a three-way interaction of spatial-frequency, memory and target presence is a potential indication that a simpler task, such as a detection task may be more appropriate for probing the spatial-frequency and memory interaction at such short exposure durations.</p>
                </sec>
              </sec>
            </sec>
            <sec id="s7">
              <title>Bayesian Null-Hypothesis Testing</title>
              <p>Bayesian null-hypothesis testing is an alternative to traditional null-hypothesis significance testing, allowing for a way of generating a graded level of evidence regarding which model (null or alternative hypothesis) is more strongly supported by the data <xref rid="pone.0065601-Masson1" ref-type="bibr">[42]</xref>, <xref rid="pone.0065601-Wagenmakers1" ref-type="bibr">[43]</xref>. We used a simple formula available from Masson <xref rid="pone.0065601-Masson1" ref-type="bibr">[42]</xref>, which is calculated from the user input of: number of independent observations, degrees of freedom error, sum of squares effect and sum of squares error. This formula is based on the Bayesian probability theory, which takes into account the a priori probability of the hypothesis being true and the probability of obtaining the observed data independent of any hypothesis, resulting in posterior probabilities of both the null (H<sub>0</sub>) and alternative (H<sub>1)</sub> hypothesis (as opposed to NHST where a binary decision is made whether to favour the H<sub>0</sub> or H<sub>1</sub> based on a cut-off value of p = 0.05). We used this formula to test the absence of the interaction effect between spatial frequency and memory observed in the data, over the three experiments (Experiment 2,3 and 4), in order to determine whether the lack of effect can be explained by support for the null hypothesis. The data presented in the <xref ref-type="table" rid="pone-0065601-t002">Table 2</xref> show the values in support of the null and alternative hypotheses, where the closer a number is to one, the more the associated hypothesis is supported by the data, with any number over 0.75 being positive evidence for the given hypothesis <xref rid="pone.0065601-Raftery1" ref-type="bibr">[44]</xref>. The data clearly show that using this method, we are able to provide secondary, numerical support favouring the null hypothesis, i.e. no interaction between spatial-frequency and memory signals.</p>
              <table-wrap id="pone-0065601-t002" orientation="portrait" position="float">
                <object-id pub-id-type="doi">10.1371/journal.pone.0065601.t002</object-id>
                <label>Table 2</label>
                <caption>
                  <title>Results from the Bayesian null-hypothesis testing.</title>
                </caption>
                <alternatives>
                  <graphic id="pone-0065601-t002-2" xlink:href="pone.0065601.t002"/>
                  <table frame="hsides" rules="groups">
                    <colgroup span="1">
                      <col align="left" span="1"/>
                      <col align="center" span="1"/>
                      <col align="center" span="1"/>
                      <col align="center" span="1"/>
                      <col align="center" span="1"/>
                    </colgroup>
                    <thead>
                      <tr>
                        <td align="left" rowspan="1" colspan="1"/>
                        <td colspan="2" align="left" rowspan="1">Reaction Times</td>
                        <td colspan="2" align="left" rowspan="1">d’ (Sensitivity)</td>
                      </tr>
                      <tr>
                        <td align="left" rowspan="1" colspan="1"/>
                        <td align="left" rowspan="1" colspan="1">H<sub>0</sub>
</td>
                        <td align="left" rowspan="1" colspan="1">H<sub>1</sub>
</td>
                        <td align="left" rowspan="1" colspan="1">H<sub>0</sub>
</td>
                        <td align="left" rowspan="1" colspan="1">H<sub>1</sub>
</td>
                      </tr>
                    </thead>
                    <tbody>
                      <tr>
                        <td align="left" rowspan="1" colspan="1">Experiment 2</td>
                        <td align="left" rowspan="1" colspan="1">
                          <bold>0.99</bold>
                        </td>
                        <td align="left" rowspan="1" colspan="1">1.44E-06</td>
                        <td align="left" rowspan="1" colspan="1">
                          <bold>0.96</bold>
                        </td>
                        <td align="left" rowspan="1" colspan="1">0.04</td>
                      </tr>
                      <tr>
                        <td align="left" rowspan="1" colspan="1">Experiment 3</td>
                        <td align="left" rowspan="1" colspan="1">
                          <bold>0.87</bold>
                        </td>
                        <td align="left" rowspan="1" colspan="1">0.13</td>
                        <td align="left" rowspan="1" colspan="1">
                          <bold>0.82</bold>
                        </td>
                        <td align="left" rowspan="1" colspan="1">0.18</td>
                      </tr>
                      <tr>
                        <td align="left" rowspan="1" colspan="1">Experiment 4</td>
                        <td align="left" rowspan="1" colspan="1">
                          <bold>0.89</bold>
                        </td>
                        <td align="left" rowspan="1" colspan="1">0.11</td>
                        <td align="left" rowspan="1" colspan="1">
                          <bold>0.88</bold>
                        </td>
                        <td align="left" rowspan="1" colspan="1">0.12</td>
                      </tr>
                    </tbody>
                  </table>
                </alternatives>
                <table-wrap-foot>
                  <fn id="nt102">
                    <p>Evidence for both the null and alternative hypothesis for the spatial-frequency by memory interaction are presented for all three experiments.</p>
                  </fn>
                </table-wrap-foot>
              </table-wrap>
              <sec id="s7a">
                <title>General Discussion</title>
                <p>The goal of this set of experiments was to explore whether manipulating the spatial-frequency information available during the cueing period could modulate memory-guided attention. Given the coarse-to-fine hypothesis of visual processing, and the model of contextual facilitation in object perception <xref rid="pone.0065601-Bar3" ref-type="bibr">[21]</xref>, <xref rid="pone.0065601-Bar6" ref-type="bibr">[24]</xref>, we expected to find a greater benefit for memories that were cued by LSF information, as opposed to HSF. Behaviourally this would be borne out by an interaction between spatial-frequency and memory. However, neither sensitivity scores nor reaction times provided any evidence for a privileged or dominant role of LSF in carrying memory-based contextual cueing effects. There are many possible reasons for this.</p>
                <p>Firstly, it is possible that there was something amiss with the stimuli used. This is unlikely. <xref ref-type="sec" rid="s3">Experiment 1</xref> confirmed the expected LSF advantage when participants had to match a probe to one of two target scenes, a task which is commonly used in the literature. Additionally, basic properties of the filtered images themselves may contain information that is different, leading to a benefit of one stimulus type over another <xref rid="pone.0065601-Rotshtein1" ref-type="bibr">[45]</xref>. In a series of experiments, Rotshtein and colleagues found conflicting evidence of spatial-frequency usage, so they carried out an analysis of low-level stimulus properties and found that the main diagnostic element was orientation information. Moreover, this information could explain why certain stimuli were preferred in one spatial-frequency in one task, but not in another <xref rid="pone.0065601-Rotshtein1" ref-type="bibr">[45]</xref>. In their task, stimuli within categories (house or flower) usually had similar orientation information, which could be diagnostic for task performance. In contrast, in the current tasks the stimuli were pictures of indoor and outdoor scenes, and the general make-up of diagnostic information was similar. In addition, assignment of stimuli across the experimental conditions of interest was counterbalanced across participants. It is therefore safe to conclude that the differential role of LSF and HSF information in the stimuli did not cause the lack of effects. Additionally, we replicated the LSF benefits previously shown in the literature; however, these just did not interact with our memory manipulation.</p>
                <p>The second possible explanation relates to the task design. Over the course of the three memory-guided experiments, various effects of spatial-frequency and memory, as well as other factors, were observed. It is possible that the interaction of spatial-frequency and memory was overshadowed by the difficulty of the task or the low number of trials in the conditions. The former is most probably not the case, as the inverse efficiency scores show the same pattern of data, indicating that the interaction could not have been masked by poor or biased performance. Problems of statistical power were addressed by condensing the design in Experiment 3 and Experiment 4, to include a greater number of trials per condition. The consistency of the pattern of results across the multiple experiments, using both traditional and Bayesian null-hypothesis significance testing, also speaks for the reliability of the data.</p>
                <p>Additionally, it is possible that participants were not using the cues enough to trigger a spatial-frequency by memory interaction. Since the targets were always embedded in the given context (which contained the relevant memory-related information), the cue may not have been necessary to perform the task. This criticism can be dismissed, because there were reliable effects of memory, as well of spatial-frequency, which would indicate that the information in the cues did influence the processing of the upcoming target stimulus.</p>
                <p>It may be informative to run an experiment where only the cue contains spatial-frequency/memory-related information. Perhaps given that fine discriminations need to be made in order to separate the target form the background, HSF signals are just as important, and therefore the interaction of spatial frequency and memory is masked by the nature of the task. An alternative would be to present the target on a blank background, after a filtered cue scene, which could provide a memory-based spatial cue (context) as well as an opportunity to observe the effects of the different frequencies present in the cue. The problem with this alternative approach is that it does not rule out the confound that the target selection itself may operate independently (on HSF signals) from attentional guidance, which may or may not be selectively facilitated by LSF cues. Given the subsidiary analyses performed on the results of this task, it seems that the spatial frequency signals and the memory-driven attention effect are largely independent. Further studies are needed to separate the cueing effects from target-in-context effects.</p>
                <p>Accepting the pattern of results across our experiments as representative, it is worth re-evaluating the hypothesis and models upon which the experiments were based. The coarse-to-fine model states that LSF information is processed more quickly, mainly due to it being carried by magnocellular pathways, and it thus provides a coarse representation of the visual input sufficient for processing its general attributes. The experiments described here generally adhered to this expectation, as sensitivity and RT measures tended to be better in LSF conditions across the experiments, though independently of memory effects. It is worth noting that in the experiments where Bar elaborates his model of contextual guidance of object processing, the context, and familiarity with it, are mainly assumed. Indeed, other than in one experiment <xref rid="pone.0065601-Bar2" ref-type="bibr">[20]</xref>, the contextual association of the objects is determined by a questionnaire on a different set of participants, who classify the objects into ‘weak-’ and ‘strong-context’ categories. In the current set of experiments, context familiarity was controlled, and arbitrary associations were established between a given background contextual stimulus and a target location. Nevertheless, the discrepancy may stem from the very different natures of the tasks used. We hypothesized, based on previous findings that if LSFs drive the rapid recognition of objects, especially those with strong contextual associations, that in our experiment the targets with contextual memories would be selectively facilitated by LSFs as well. The fact that we did not observe this effect may be simply due to the fact that the ‘context’ in the Bar studies and in ours was of a different nature. In our experiments, they are specific, spatial-contextual long-term memories, perhaps episodic in nature, as opposed to familiar objects, embedded in a ‘schema’ of semantic associations, which may be processed in their contexts by a different set of neural structures in the MTL <xref rid="pone.0065601-Moscovitch1" ref-type="bibr">[46]</xref>.</p>
              </sec>
              <sec id="s7b">
                <title>Conclusions</title>
                <p>The results from our experiments are more in line with theories that suggest that the differential contribution of spatial frequencies may be task dependent <xref rid="pone.0065601-Rotshtein1" ref-type="bibr">[45]</xref>. In the tasks described in this paper, both types of spatial frequencies may have aided in making a visual discrimination. Future studies will be needed to differentiate the effects of specific spatial frequencies in driving and/or aiding memory-guided attention in complex context-based visual search.</p>
              </sec>
            </sec>
            <sec sec-type="supplementary-material" id="s8">
              <title>Supporting Information</title>
              <supplementary-material content-type="local-data" id="pone.0065601.s001">
                <label>Table S1</label>
                <caption>
                  <p>Detailed F and p-values, and effect sizes for all conditions and interactions, across experiments 2–4.</p>
                  <p>(DOCX)</p>
                </caption>
                <media xlink:href="pone.0065601.s001.docx">
                  <caption>
                    <p>Click here for additional data file.</p>
                  </caption>
                </media>
              </supplementary-material>
            </sec>
          </body>
          <back>
            <ref-list>
              <title>References</title>
              <ref id="pone.0065601-Chun1">
                <label>1</label>
                <mixed-citation publication-type="journal"><name><surname>Chun</surname><given-names>MM</given-names></name>, <name><surname>Jiang</surname><given-names>Y</given-names></name> (<year>1998</year>) <article-title>Contextual cueing: implicit learning and memory of visual context guides spatial attention</article-title>. <source>Cognitive psychology</source>
<volume>36</volume>: <fpage>28</fpage>–<lpage>71</lpage>.<pub-id pub-id-type="pmid">9679076</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Chaumon1">
                <label>2</label>
                <mixed-citation publication-type="journal"><name><surname>Chaumon</surname><given-names>M</given-names></name>, <name><surname>Drouet</surname><given-names>V</given-names></name>, <name><surname>Tallon-Baudry</surname><given-names>C</given-names></name> (<year>2008</year>) <article-title>Unconscious associative memory affects visual processing before 100 ms</article-title>. <source>Journal of vision</source>
<volume>8</volume>: <fpage>1</fpage>–<lpage>10</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0065601-Moores1">
                <label>3</label>
                <mixed-citation publication-type="journal"><name><surname>Moores</surname><given-names>E</given-names></name>, <name><surname>Laiti</surname><given-names>L</given-names></name>, <name><surname>Chelazzi</surname><given-names>L</given-names></name> (<year>2003</year>) <article-title>Associative knowledge controls deployment of visual selective attention</article-title>. <source>Nature neuroscience</source>
<volume>6</volume>: <fpage>182</fpage>–<lpage>189</lpage>.<pub-id pub-id-type="pmid">12514738</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Doallo1">
                <label>4</label>
                <mixed-citation publication-type="journal"><name><surname>Doallo</surname><given-names>S</given-names></name>, <name><surname>Patai</surname><given-names>E</given-names></name>, <name><surname>Nobre</surname><given-names>A</given-names></name> (<year>2013</year>) <article-title>Reward associations magnify memory-based biases on perception</article-title>. <source>Journal of cognitive neuroscience</source>
<volume>25</volume>: <fpage>245</fpage>–<lpage>257</lpage>.<pub-id pub-id-type="pmid">23066690</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Summerfield1">
                <label>5</label>
                <mixed-citation publication-type="journal"><name><surname>Summerfield</surname><given-names>JJ</given-names></name>, <name><surname>Lepsien</surname><given-names>J</given-names></name>, <name><surname>Gitelman</surname><given-names>DR</given-names></name>, <name><surname>Mesulam</surname><given-names>MM</given-names></name>, <name><surname>Nobre</surname><given-names>AC</given-names></name> (<year>2006</year>) <article-title>Orienting attention based on long-term memory experience</article-title>. <source>Neuron</source>
<volume>49</volume>: <fpage>905</fpage>–<lpage>916</lpage>.<pub-id pub-id-type="pmid">16543137</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Summerfield2">
                <label>6</label>
                <mixed-citation publication-type="journal"><name><surname>Summerfield</surname><given-names>JJ</given-names></name>, <name><surname>Rao</surname><given-names>A</given-names></name>, <name><surname>Garside</surname><given-names>N</given-names></name>, <name><surname>Nobre</surname><given-names>AC</given-names></name> (<year>2011</year>) <article-title>Biasing Perception by Spatial Long-Term Memory</article-title>. <source>The Journal of Neuroscience</source>
<volume>31</volume>: <fpage>14952</fpage>–<lpage>14960</lpage>.<pub-id pub-id-type="pmid">22016528</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Stokes1">
                <label>7</label>
                <mixed-citation publication-type="journal"><name><surname>Stokes</surname><given-names>MG</given-names></name>, <name><surname>Atherton</surname><given-names>K</given-names></name>, <name><surname>Patai</surname><given-names>EZ</given-names></name>, <name><surname>Nobre</surname><given-names>AC</given-names></name> (<year>2012</year>) <article-title>Long-term memory prepares neural activity for perception</article-title>. <source>Proceedings of the National Academy of Sciences</source>
<volume>109</volume>: <fpage>E360</fpage>–<lpage>E367</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0065601-Patai1">
                <label>8</label>
                <mixed-citation publication-type="journal"><name><surname>Patai</surname><given-names>E</given-names></name>, <name><surname>Doallo</surname><given-names>S</given-names></name>, <name><surname>Nobre</surname><given-names>A</given-names></name> (<year>2012</year>) <article-title>Long-term Memories Bias Sensitivity and Target Selection in Complex Scenes</article-title>. <source>Journal of Cognitive Neuroscience</source>
<volume>24</volume>: <fpage>2281</fpage>–<lpage>2291</lpage>.<pub-id pub-id-type="pmid">23016670</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Bullier1">
                <label>9</label>
                <mixed-citation publication-type="journal"><name><surname>Bullier</surname><given-names>J</given-names></name> (<year>2001</year>) <article-title>Integrated model of visual processing</article-title>. <source>Brain research</source>
<volume>36</volume>: <fpage>96</fpage>–<lpage>107</lpage>.<pub-id pub-id-type="pmid">11690606</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Hegd1">
                <label>10</label>
                <mixed-citation publication-type="journal"><name><surname>Hegdé</surname><given-names>J</given-names></name> (<year>2008</year>) <article-title>Time course of visual perception: coarse-to-fine processing and beyond</article-title>. <source>Progress in neurobiology</source>
<volume>84</volume>: <fpage>405</fpage>–<lpage>439</lpage>.<pub-id pub-id-type="pmid">17976895</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Hochstein1">
                <label>11</label>
                <mixed-citation publication-type="journal"><name><surname>Hochstein</surname><given-names>S</given-names></name>, <name><surname>Ahissar</surname><given-names>M</given-names></name> (<year>2002</year>) <article-title>View from the Top: Hierarchies and Reverse Hierarchies in the Visual System</article-title>. <source>Neuron</source>
<volume>36</volume>: <fpage>791</fpage>–<lpage>804</lpage>.<pub-id pub-id-type="pmid">12467584</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Ullman1">
                <label>12</label>
                <mixed-citation publication-type="journal"><name><surname>Ullman</surname><given-names>S</given-names></name> (<year>1995</year>) <article-title>Sequence Seeking and Counter Streams: A Computational Model for Bidirectional Information Flow in the Visual Cortex</article-title>. <source>Cerebral cortex</source>
<volume>5</volume>: <fpage>1</fpage>–<lpage>11</lpage>.<pub-id pub-id-type="pmid">7719126</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Navon1">
                <label>13</label>
                <mixed-citation publication-type="journal"><name><surname>Navon</surname><given-names>D</given-names></name> (<year>1977</year>) <article-title>Forest Before Trees?: The Precedence of Global in Visual Perception</article-title>. <source>Cognitive Psychology</source>
<volume>383</volume>: <fpage>353</fpage>–<lpage>383</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0065601-Thorpe1">
                <label>14</label>
                <mixed-citation publication-type="journal"><name><surname>Thorpe</surname><given-names>SJ</given-names></name>, <name><surname>Fize</surname><given-names>D</given-names></name>, <name><surname>Marlot</surname><given-names>C</given-names></name> (<year>1996</year>) <article-title>Speed of processing in the human visual cortex</article-title>. <source>Nature</source>
<volume>381</volume>: <fpage>520</fpage>–<lpage>522</lpage>.<pub-id pub-id-type="pmid">8632824</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Treisman1">
                <label>15</label>
                <mixed-citation publication-type="journal"><name><surname>Treisman</surname><given-names>A</given-names></name>, <name><surname>Gelade</surname><given-names>G</given-names></name> (<year>1980</year>) <article-title>A Feature-Integration of Attention</article-title>. <source>Cognitive Psychology</source>
<volume>136</volume>: <fpage>97</fpage>–<lpage>136</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0065601-Laycock1">
                <label>16</label>
                <mixed-citation publication-type="journal"><name><surname>Laycock</surname><given-names>R</given-names></name>, <name><surname>Crewther</surname><given-names>DP</given-names></name>, <name><surname>Crewther</surname><given-names>SG</given-names></name> (<year>2008</year>) <article-title>The advantage in being magnocellular: a few more remarks on attention and the magnocellular system</article-title>. <source>Neuroscience and biobehavioral reviews</source>
<volume>32</volume>: <fpage>1409</fpage>–<lpage>1415</lpage>.<pub-id pub-id-type="pmid">18514901</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Kveraga1">
                <label>17</label>
                <mixed-citation publication-type="journal"><name><surname>Kveraga</surname><given-names>K</given-names></name>, <name><surname>Boshyan</surname><given-names>J</given-names></name>, <name><surname>Bar</surname><given-names>M</given-names></name> (<year>2007</year>) <article-title>Magnocellular Projections as the Trigger of Top-Down Facilitation in Recognition</article-title>. <source>Journal of Neuroscience</source>
<volume>27</volume>: <fpage>13232</fpage>–<lpage>13240</lpage>.<pub-id pub-id-type="pmid">18045917</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Kveraga2">
                <label>18</label>
                <mixed-citation publication-type="journal"><name><surname>Kveraga</surname><given-names>K</given-names></name>, <name><surname>Ghuman</surname><given-names>A</given-names></name> (<year>2011</year>) <article-title>Early onset of neural synchronization in the contextual associations network</article-title>. <source>Proceedings of the National Academy of Sciences</source>
<volume>108</volume>: <fpage>3389</fpage>–<lpage>3394</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0065601-Bar1">
                <label>19</label>
                <mixed-citation publication-type="journal"><name><surname>Bar</surname><given-names>M</given-names></name>, <name><surname>Aminoff</surname><given-names>E</given-names></name>, <name><surname>Schacter</surname><given-names>DL</given-names></name> (<year>2008</year>) <article-title>Scenes unseen: the parahippocampal cortex intrinsically subserves contextual associations, not scenes or places per se</article-title>. <source>The Journal of Neuroscience</source>
<volume>28</volume>: <fpage>8539</fpage>–<lpage>8544</lpage>.<pub-id pub-id-type="pmid">18716212</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Bar2">
                <label>20</label>
                <mixed-citation publication-type="journal"><name><surname>Bar</surname><given-names>M</given-names></name>, <name><surname>Aminoff</surname><given-names>E</given-names></name> (<year>2003</year>) <article-title>Cortical analysis of visual context</article-title>. <source>Neuron</source>
<volume>38</volume>: <fpage>347</fpage>–<lpage>358</lpage>.<pub-id pub-id-type="pmid">12718867</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Bar3">
                <label>21</label>
                <mixed-citation publication-type="journal"><name><surname>Bar</surname><given-names>M</given-names></name> (<year>2004</year>) <article-title>Visual objects in context</article-title>. <source>Nature Reviews Neuroscience</source>
<volume>5</volume>: <fpage>617</fpage>–<lpage>629</lpage>.<pub-id pub-id-type="pmid">15263892</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Bar4">
                <label>22</label>
                <mixed-citation publication-type="journal"><name><surname>Bar</surname><given-names>M</given-names></name>, <name><surname>Kassam</surname><given-names>KS</given-names></name>, <name><surname>Ghuman a</surname><given-names>S</given-names></name>, <name><surname>Boshyan</surname><given-names>J</given-names></name>, <name><surname>Schmid a</surname><given-names>M</given-names></name>, <etal>et al</etal> (<year>2006</year>) <article-title>Top-down facilitation of visual recognition</article-title>. <source>Proceedings of the National Academy of Sciences</source>
<volume>103</volume>: <fpage>449</fpage>–<lpage>454</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0065601-Bar5">
                <label>23</label>
                <mixed-citation publication-type="journal"><name><surname>Bar</surname><given-names>M</given-names></name> (<year>2007</year>) <article-title>The proactive brain: using analogies and associations to generate predictions</article-title>. <source>Trends in cognitive sciences</source>
<volume>11</volume>: <fpage>280</fpage>–<lpage>289</lpage>.<pub-id pub-id-type="pmid">17548232</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Bar6">
                <label>24</label>
                <mixed-citation publication-type="journal"><name><surname>Bar</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>The proactive brain: memory for predictions</article-title>. <source>Philosophical transactions of the Royal Society of London Series B, Biological sciences</source>
<volume>364</volume>: <fpage>1235</fpage>–<lpage>1243</lpage>.<pub-id pub-id-type="pmid">19528004</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Peyrin1">
                <label>25</label>
                <mixed-citation publication-type="journal"><name><surname>Peyrin</surname><given-names>C</given-names></name>, <name><surname>Michel</surname><given-names>CM</given-names></name>, <name><surname>Schwartz</surname><given-names>S</given-names></name>, <name><surname>Thut</surname><given-names>G</given-names></name>, <name><surname>Seghier</surname><given-names>M</given-names></name>, <etal>et al</etal> (<year>2010</year>) <article-title>The neural substrates and timing of top-down processes during coarse-to-fine categorization of visual scene: a combined fMRI and ERP study</article-title>. <source>Journal of Cognitive Neuroscience</source>
<volume>22</volume>: <fpage>2768</fpage>–<lpage>2780</lpage>.<pub-id pub-id-type="pmid">20044901</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Henderson1">
                <label>26</label>
                <mixed-citation publication-type="journal"><name><surname>Henderson</surname><given-names>JM</given-names></name>, <name><surname>Larson</surname><given-names>CL</given-names></name>, <name><surname>Zhu</surname><given-names>DC</given-names></name> (<year>2008</year>) <article-title>Full scenes produce more activation than close-up scenes and scene-diagnostic objects in parahippocampal and retrosplenial cortex: an fMRI study</article-title>. <source>Brain and cognition</source>
<volume>66</volume>: <fpage>40</fpage>–<lpage>49</lpage>.<pub-id pub-id-type="pmid">17606317</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Goodale1">
                <label>27</label>
                <mixed-citation publication-type="journal"><name><surname>Goodale</surname><given-names>MA</given-names></name>, <name><surname>Milner</surname><given-names>AD</given-names></name> (<year>1992</year>) <article-title>Separate visual pathways for perception and action</article-title>. <source>Trends in neurosciences</source>
<volume>15</volume>: <fpage>20</fpage>–<lpage>25</lpage>.<pub-id pub-id-type="pmid">1374953</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Ungerleider1">
                <label>28</label>
                <mixed-citation publication-type="book">Ungerleider LG, Mishkin M (1982) Two cortical visual systems. In: Ingle D, Goodale M, Mansfield R, editors. Analysis of visual behaviour. Cambridge University Press. 549–586.</mixed-citation>
              </ref>
              <ref id="pone.0065601-VanEssen1">
                <label>29</label>
                <mixed-citation publication-type="journal"><name><surname>Van Essen</surname><given-names>DC</given-names></name>, <name><surname>Anderson</surname><given-names>CH</given-names></name>, <name><surname>Felleman</surname><given-names>DJ</given-names></name> (<year>1992</year>) <article-title>Information Processing Strategies and Pathways in the Primate Visual System</article-title>. <source>Science</source>
<volume>255</volume>: <fpage>419</fpage>–<lpage>423</lpage>.<pub-id pub-id-type="pmid">1734518</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Merigan1">
                <label>30</label>
                <mixed-citation publication-type="journal"><name><surname>Merigan</surname><given-names>WH</given-names></name>, <name><surname>Maunsell</surname><given-names>JH</given-names></name> (<year>1993</year>) <article-title>How parallel are the primate visual pathways?</article-title>
<source>Annual review of neuroscience</source>
<volume>16</volume>: <fpage>369</fpage>–<lpage>402</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0065601-Schyns1">
                <label>31</label>
                <mixed-citation publication-type="journal"><name><surname>Schyns</surname><given-names>PG</given-names></name>, <name><surname>Oliva</surname><given-names>A</given-names></name> (<year>1994</year>) <article-title>From blobls to boundary edges</article-title>. <source>Physiological Science</source>
<volume>5</volume>: <fpage>195</fpage>–<lpage>200</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0065601-Neri1">
                <label>32</label>
                <mixed-citation publication-type="journal"><name><surname>Neri</surname><given-names>P</given-names></name> (<year>2011</year>) <article-title>Coarse to fine dynamics of monocular and binocular processing in human pattern vision</article-title>. <source>Proceedings of the National Academy of Sciences</source>
<volume>108</volume>: <fpage>10726</fpage>–<lpage>10731</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0065601-Romei1">
                <label>33</label>
                <mixed-citation publication-type="journal"><name><surname>Romei</surname><given-names>V</given-names></name>, <name><surname>Driver</surname><given-names>J</given-names></name>, <name><surname>Schyns</surname><given-names>PG</given-names></name>, <name><surname>Thut</surname><given-names>G</given-names></name> (<year>2011</year>) <article-title>Rhythmic TMS over parietal cortex links distinct brain frequencies to global versus local visual processing</article-title>. <source>Current Biology</source>
<volume>21</volume>: <fpage>334</fpage>–<lpage>337</lpage>.<pub-id pub-id-type="pmid">21315592</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Smith1">
                <label>34</label>
                <mixed-citation publication-type="journal"><name><surname>Smith</surname><given-names>ML</given-names></name>, <name><surname>Gosselin</surname><given-names>F</given-names></name>, <name><surname>Schyns</surname><given-names>PG</given-names></name> (<year>2006</year>) <article-title>Perceptual moments of conscious visual experience inferred from oscillatory brain activity</article-title>. <source>Proceedings of the National Academy of Sciences</source>
<volume>103</volume>: <fpage>5626</fpage>–<lpage>5631</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0065601-Bird1">
                <label>35</label>
                <mixed-citation publication-type="journal"><name><surname>Bird</surname><given-names>CM</given-names></name>, <name><surname>Burgess</surname><given-names>N</given-names></name> (<year>2008</year>) <article-title>The hippocampus and memory: insights from spatial processing</article-title>. <source>Nature Reviews Neuroscience</source>
<volume>9</volume>: <fpage>182</fpage>–<lpage>194</lpage>.<pub-id pub-id-type="pmid">18270514</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Burgess1">
                <label>36</label>
                <mixed-citation publication-type="book">Burgess N (2002) The hippocampus, space, and viewpoints in episodic memory. Memory: 1057–1080.</mixed-citation>
              </ref>
              <ref id="pone.0065601-Squire1">
                <label>37</label>
                <mixed-citation publication-type="book">Squire LR, Wixted JT (2010) The Cognitive Neuroscience of Human Memory Since H.M. Annual review of neuroscience: 259–288.</mixed-citation>
              </ref>
              <ref id="pone.0065601-Vann1">
                <label>38</label>
                <mixed-citation publication-type="journal"><name><surname>Vann</surname><given-names>SD</given-names></name>, <name><surname>Aggleton</surname><given-names>JP</given-names></name>, <name><surname>Maguire</surname><given-names>EA</given-names></name> (<year>2009</year>) <article-title>What does the retrosplenial cortex do?</article-title>
<source>Nature Reviews Neuroscience</source>
<volume>10</volume>: <fpage>792</fpage>–<lpage>802</lpage>.<pub-id pub-id-type="pmid">19812579</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Squire2">
                <label>39</label>
                <mixed-citation publication-type="journal"><name><surname>Squire</surname><given-names>LR</given-names></name>, <name><surname>Stark</surname><given-names>CEL</given-names></name>, <name><surname>Clark</surname><given-names>RE</given-names></name> (<year>2004</year>) <article-title>The medial temporal lobe</article-title>. <source>Annual review of neuroscience</source>
<volume>27</volume>: <fpage>279</fpage>–<lpage>306</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0065601-Peyrin2">
                <label>40</label>
                <mixed-citation publication-type="journal"><name><surname>Peyrin</surname><given-names>C</given-names></name>, <name><surname>Baciu</surname><given-names>M</given-names></name>, <name><surname>Segebarth</surname><given-names>C</given-names></name>, <name><surname>Marendaz</surname><given-names>C</given-names></name> (<year>2004</year>) <article-title>Cerebral regions and hemispheric specialization for processing spatial frequencies during natural scene recognition. An event-related fMRI study</article-title>. <source>NeuroImage</source>
<volume>23</volume>: <fpage>698</fpage>–<lpage>707</lpage>.<pub-id pub-id-type="pmid">15488419</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Oliva1">
                <label>41</label>
                <mixed-citation publication-type="journal"><name><surname>Oliva</surname><given-names>A</given-names></name>, <name><surname>Torralba</surname><given-names>A</given-names></name> (<year>2006</year>) <article-title>Building the gist of scene: the role of global image features in recognition</article-title>. <source>Progress in Brain Research</source>
<volume>155</volume>: <fpage>23</fpage>–<lpage>36</lpage>.<pub-id pub-id-type="pmid">17027377</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Masson1">
                <label>42</label>
                <mixed-citation publication-type="journal"><name><surname>Masson</surname><given-names>MEJ</given-names></name> (<year>2011</year>) <article-title>A tutorial on a practical Bayesian alternative to null-hypothesis significance testing</article-title>. <source>Behavior research methods</source>
<volume>43</volume>: <fpage>679</fpage>–<lpage>690</lpage>.<pub-id pub-id-type="pmid">21302025</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Wagenmakers1">
                <label>43</label>
                <mixed-citation publication-type="journal"><name><surname>Wagenmakers</surname><given-names>E-J</given-names></name> (<year>2007</year>) <article-title>A practical solution to the pervasive problems of p values</article-title>. <source>Psychonomic bulletin &amp; review</source>
<volume>14</volume>: <fpage>779</fpage>–<lpage>804</lpage>.<pub-id pub-id-type="pmid">18087943</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0065601-Raftery1">
                <label>44</label>
                <mixed-citation publication-type="book">Raftery A (1995) Bayesian model selection in social research. Sociological methodology: 111–196.</mixed-citation>
              </ref>
              <ref id="pone.0065601-Rotshtein1">
                <label>45</label>
                <mixed-citation publication-type="journal"><name><surname>Rotshtein</surname><given-names>P</given-names></name>, <name><surname>Schofield</surname><given-names>A</given-names></name>, <name><surname>Funes</surname><given-names>MJ</given-names></name>, <name><surname>Humphreys</surname><given-names>GW</given-names></name> (<year>2010</year>) <article-title>Effects of spatial frequency bands on perceptual decision?: It is not the stimuli but the comparison</article-title>. <source>Journal of Vision</source>
<volume>10</volume>: <fpage>1</fpage>–<lpage>20</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0065601-Moscovitch1">
                <label>46</label>
                <mixed-citation publication-type="journal"><name><surname>Moscovitch</surname><given-names>M</given-names></name>, <name><surname>Rosenbaum</surname><given-names>RS</given-names></name>, <name><surname>Gilboa</surname><given-names>A</given-names></name>, <name><surname>Addis</surname><given-names>DR</given-names></name>, <name><surname>Westmacott</surname><given-names>R</given-names></name>, <etal>et al</etal> (<year>2005</year>) <article-title>Functional neuroanatomy of remote episodic, semantic and spatial memory: a unified account based on multiple trace theory</article-title>. <source>Journal of anatomy</source>
<volume>207</volume>: <fpage>35</fpage>–<lpage>66</lpage>.<pub-id pub-id-type="pmid">16011544</pub-id></mixed-citation>
              </ref>
            </ref-list>
          </back>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
