<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2024-05-03T03:35:45Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:4352277" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:4352277</identifier>
        <datestamp>2015-03-08</datestamp>
        <setSpec>trials</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" article-type="research-article">
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">Trials</journal-id>
              <journal-id journal-id-type="iso-abbrev">Trials</journal-id>
              <journal-title-group>
                <journal-title>Trials</journal-title>
              </journal-title-group>
              <issn pub-type="epub">1745-6215</issn>
              <publisher>
                <publisher-name>BioMed Central</publisher-name>
                <publisher-loc>London</publisher-loc>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC4352277</article-id>
              <article-id pub-id-type="pmcid">PMC4352277</article-id>
              <article-id pub-id-type="pmc-uid">4352277</article-id>
              <article-id pub-id-type="pmid">25885963</article-id>
              <article-id pub-id-type="publisher-id">574</article-id>
              <article-id pub-id-type="doi">10.1186/s13063-015-0574-8</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Research</subject>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>The Stroke Hyperglycemia Insulin Network Effort (SHINE) trial: an adaptive trial design case study</article-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author" corresp="yes">
                  <name>
                    <surname>Connor</surname>
                    <given-names>Jason T</given-names>
                  </name>
                  <address>
                    <email>jason@berryconsultants.com</email>
                  </address>
                  <xref ref-type="aff" rid="Aff1"/>
                  <xref ref-type="aff" rid="Aff2"/>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Broglio</surname>
                    <given-names>Kristine R</given-names>
                  </name>
                  <address>
                    <email>kristine@berryconsultants.com</email>
                  </address>
                  <xref ref-type="aff" rid="Aff1"/>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Durkalski</surname>
                    <given-names>Valerie</given-names>
                  </name>
                  <address>
                    <email>durkalsv@musc.edu</email>
                  </address>
                  <xref ref-type="aff" rid="Aff3"/>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Meurer</surname>
                    <given-names>William J</given-names>
                  </name>
                  <address>
                    <email>wmeurer@med.umich.edu</email>
                  </address>
                  <xref ref-type="aff" rid="Aff4"/>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Johnston</surname>
                    <given-names>Karen C</given-names>
                  </name>
                  <address>
                    <email>KJ4V@hscmail.mcc.virginia.edu</email>
                  </address>
                  <xref ref-type="aff" rid="Aff5"/>
                </contrib>
                <aff id="Aff1"><label/>Berry Consultants, LLC, 4301 Westbank Dr Bldg B Suite 140, Austin, TX 78746 USA </aff>
                <aff id="Aff2"><label/>University of Central Florida College of Medicine, 6850 Lake Nona Blvd, Orlando, FL 32827 USA </aff>
                <aff id="Aff3"><label/>Department of Public Health Sciences, Medical University of South Carolina, 135 Cannon Street Suit 303, Charleston, SC 29425 USA </aff>
                <aff id="Aff4"><label/>Department of Emergency Medicine, University of Michigan Health System, 1500 E Medical Center Dr, Ann Arbor, MI 48109 USA </aff>
                <aff id="Aff5"><label/>Department of Neurology, University of Virginia Health System, PO Box 800394, Charlottesville, VA 22908 USA </aff>
              </contrib-group>
              <pub-date pub-type="epub">
                <day>4</day>
                <month>3</month>
                <year>2015</year>
              </pub-date>
              <pub-date pub-type="pmc-release">
                <day>4</day>
                <month>3</month>
                <year>2015</year>
              </pub-date>
              <pub-date pub-type="collection">
                <year>2015</year>
              </pub-date>
              <volume>16</volume>
              <elocation-id>72</elocation-id>
              <history>
                <date date-type="received">
                  <day>30</day>
                  <month>7</month>
                  <year>2014</year>
                </date>
                <date date-type="accepted">
                  <day>20</day>
                  <month>1</month>
                  <year>2015</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>© Connor et al.; licensee BioMed Central. 2015</copyright-statement>
                <license license-type="open-access">
                  <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0">http://creativecommons.org/licenses/by/4.0</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly credited. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
                </license>
              </permissions>
              <abstract id="Abs1">
                <sec>
                  <title>Background</title>
                  <p>The ‘Adaptive Designs Accelerating Promising Trials into Treatments (ADAPT-IT)’ project is a collaborative effort supported by the National Institutes of Health (NIH) and United States Food &amp; Drug Administration (FDA) to explore how adaptive clinical trial design might improve the evaluation of drugs and medical devices. ADAPT-IT uses the National Institute of Neurologic Disorders &amp; Stroke-supported Neurological Emergencies Treatment Trials (NETT) network as a ‘laboratory’ in which to study the development of adaptive clinical trial designs in the confirmatory setting. The Stroke Hyperglycemia Insulin Network Effort (SHINE) trial was selected for funding by the NIH-NINDS at the start of ADAPT-IT and is currently an ongoing phase III trial of tight glucose control in hyperglycemic acute ischemic stroke patients. Within ADAPT-IT, a Bayesian adaptive Goldilocks trial design alternative was developed.</p>
                </sec>
                <sec>
                  <title>Methods</title>
                  <p>The SHINE design includes response adaptive randomization, a sample size re-estimation, and monitoring for early efficacy and futility according to a group sequential design. The Goldilocks design includes more frequent monitoring for predicted success or futility and a longitudinal model of the primary endpoint. Both trial designs were simulated and compared in terms of their mean sample size and power across a range of treatment effects and success rates for the control group.</p>
                </sec>
                <sec>
                  <title>Results</title>
                  <p>As simulated, the SHINE design tends to have slightly higher power and the Goldilocks design has a lower mean sample size. Both designs were tuned to have approximately 80% power to detect a difference of 25% versus 32% between control and treatment, respectively. In this scenario, mean sample sizes are 1,114 and 979 for the SHINE and Goldilocks designs, respectively.</p>
                </sec>
                <sec>
                  <title>Conclusions</title>
                  <p>Two designs were brought forward, and both were evaluated, revised, and improved based on the input of all parties involved in the ADAPT-IT process. However, the SHINE investigators were tasked with choosing only a single design to implement and ultimately elected not to implement the Goldilocks design. The Goldilocks design will be retrospectively executed upon completion of SHINE to later compare the designs based on their use of patient resources, time, and conclusions in a real world setting.</p>
                </sec>
                <sec>
                  <title>Trial registration</title>
                  <p>ClinicalTrials.gov <ext-link ext-link-type="uri" xlink:href="https://clinicaltrials.gov/ct2/show/NCT01369069">NCT01369069</ext-link> June 2011.</p>
                </sec>
              </abstract>
              <kwd-group xml:lang="en">
                <title>Keywords</title>
                <kwd>Bayesian adaptive design</kwd>
                <kwd>Group sequential</kwd>
                <kwd>Sample size estimation</kwd>
                <kwd>Predictive probabilities</kwd>
                <kwd>Neurologic emergencies</kwd>
              </kwd-group>
              <custom-meta-group>
                <custom-meta>
                  <meta-name>issue-copyright-statement</meta-name>
                  <meta-value>© The Author(s) 2015</meta-value>
                </custom-meta>
              </custom-meta-group>
            </article-meta>
          </front>
          <body>
            <sec id="Sec1" sec-type="introduction">
              <title>Background</title>
              <p>In 2010, The National Institutes of Health (NIH) and the Food and Drug Administration (FDA) jointly awarded four grants to support research in the area of regulatory science [<xref ref-type="bibr" rid="CR1">1</xref>]. One of these awards, ‘Adaptive Designs Accelerating Promising Trials into Treatments (ADAPT-IT)’, is a collaborative effort between the University of Michigan, Medical University of South Carolina, and Berry Consultants, LLC. The overall objective of ADAPT-IT is to explore how adaptive designs in a confirmatory setting might improve the evaluation of drugs and medical devices in neurologic emergency settings [<xref ref-type="bibr" rid="CR2">2</xref>]. ADAPT-IT uses the NINDS-supported Neurological Emergencies Treatment Trials (NETT) network as a ‘laboratory’ in which to study the development of adaptive clinical trial designs. The NETT Network includes 22 hubs, along with a clinical coordinating center (University of Michigan), and statistical and data management center (Medical University of South Carolina) and focuses on conducting large trials in acute injuries and illnesses affecting the brain, spinal cord, and peripheral nervous system [<xref ref-type="bibr" rid="CR3">3</xref>]. For each of five randomized clinical trials undergoing proposal development for implementation within NETT, the ADAPT-IT investigators developed an adaptive trial design in collaboration with each study’s principal investigators and statisticians at the data coordinating center. During this process another research team used both qualitative and quantitative methods to characterize the beliefs, opinions, and concerns of the trial’s key stakeholders regarding the ethics, scientific validity, and integrity of the adaptive designs and how these beliefs may have changed over the course of the design process.</p>
              <p>The ADAPT-IT process begins with an initial meeting of clinical investigators and statisticians to describe the scientific question and sketch out potential designs. An initial adaptive design is then constructed and presented to the trial team for feedback. There are several iterations of the design and accompanying discussions. Once a final design is agreed upon, the trial is submitted for funding.</p>
              <p>Each of the five trials included in ADAPT-IT were at varying stages of development and funding. The first trial considered within ADAPT-IT, the Stroke Hyperglycemia Insulin Network Effort (SHINE) trial had a completed design. Also, unlike the other four trials, SHINE was approved for funding by the NIH-NINDS at the time the ADAPT-IT project began. Regardless, through the ADAPT-IT process, an alternative adaptive design was developed. We present the SHINE trial design that is currently being conducted, which is an adaptive design including group sequential stopping, response adaptive randomization, and a blinded sample size re-estimation. We also present the alternative ADAPT-IT design, which is a Bayesian adaptive Goldilocks trial design [<xref ref-type="bibr" rid="CR4">4</xref>]. We compare the performance of the two designs via simulation and then describe how SHINE will be virtually re-executed according to the Goldilocks design.</p>
              <p>There are examples where an alternative trial design has been retrospectively created and executed in order to compare the potential benefits of different design features [<xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR6">6</xref>]. However, SHINE is a unique learning opportunity in that the same team developed, in a prospective manner, two different trial designs with the same scientific objectives in mind. In the trial design process, it is typical to consider several different candidate designs. One design is selected for conduct and the alternatives are discarded. However, we propose to consider both the selected design and the counterfactual, comparing and contrasting both the design and the execution of two innovative adaptive trial designs.</p>
              <p>The two designs we will describe have several differences, and therefore, this is not an ‘apples to apples’ comparison where we compare one simple difference at a time. However, this is also not an academic exercise in which the goal is to consider only the difference between the frequentist and the Bayesian perspectives. Rather, we present a more ‘real world’ setting in which two candidate designs are weighed against each other based on their own unique sets of benefits and drawbacks.</p>
            </sec>
            <sec id="Sec2" sec-type="materials|methods">
              <title>Methods</title>
              <sec id="Sec3">
                <title>SHINE trial design</title>
                <p>The SHINE trial design is completely described elsewhere [<xref ref-type="bibr" rid="CR7">7</xref>]. SHINE is a randomized multicenter Phase III trial comparing tight glucose control with IV insulin (experimental) to a therapy of subcutaneous insulin (control) in hyperglycemic acute ischemic stroke patients. The SHINE protocol was approved by IRBs at the University of Virginia, the NETT Clinical Coordinating Center (University of Michigan), and Statistics and Data Management Center (Medical University of South Carolina), as well as all enrolling sites. The name of the ethical body that approved the SHINE protocol at each enrolling site is shown in the appendix. Consent is obtained either from patients, or where cognitively impaired from stroke, a legally authorized representative, before a patient is enrolled in the SHINE trial.</p>
                <p>The primary efficacy endpoint is a dichotomized modified Rankin scale (mRS), adjusted to the baseline stroke severity score (NIHSS), measured at 90 days following randomization. The null hypothesis is that the success rates for the two arms are equal. The alterative hypothesis is two-sided, that the success rates for the two arms are not equal. The alternative hypothesis will be accepted if either the experimental therapy is significantly better than the control or if the control therapy is significantly better than the experimental. Based on preliminary data, it is expected that 25% of patients in the control group will achieve success. At least a 7% absolute difference in the proportion of patients achieving a success between the treatment and control arms would be considered clinically meaningful. Based on a chi-square test, four interim analyses, an overall 0.05 Type I error rate, a control success rate of 25%, and a 3% lost to follow-up rate, 1,400 patients would provide 80% power to detect the 7% absolute difference between treatment arms.</p>
                <p>SHINE will be monitored for both early efficacy and futility according to a group sequential design. The stopping boundaries are defined by the gamma family spending function with a parameter of −4 for both the upper and lower bounds. Four interim analyses are scheduled when complete information on the primary endpoint (90-day data) is available for 500, 700, 900, and 1,100 patients. The two-sided <italic>P</italic> values required for stopping for efficacy or futility at each of these interim looks are shown in Table <xref rid="Tab1" ref-type="table">1</xref>. To control the overall two-sided Type I error rate to less than 5%, the final analysis will be conducted at the 0.043 significance level. The primary efficacy analysis will be a logistic regression model with terms for treatment group, baseline NIHSS strata, and use of IV thrombolysis use (yes or no). Multiple imputation will be implemented when the 90-day outcome is missing or collected outside of the allowable window of −14 day/+30 days from the 90-day visit.<table-wrap id="Tab1"><label>Table 1</label><caption><p><bold>SHINE two-sided</bold><bold><italic>P</italic></bold><bold>values for stopping for success or futility at each interim analysis</bold></p></caption><table frame="hsides" rules="groups"><thead><tr valign="top"><th><bold>Information fraction</bold></th><th><bold>Success</bold><bold><italic>P</italic></bold><bold>Value</bold></th><th><bold>Futility</bold><bold><italic>P</italic></bold><bold>Value</bold></th></tr></thead><tbody><tr valign="top"><td>36%</td><td>0.003</td><td>0.949</td></tr><tr valign="top"><td>50%</td><td>0.004</td><td>0.896</td></tr><tr valign="top"><td>64%</td><td>0.008</td><td>0.652</td></tr><tr valign="top"><td>78%</td><td>0.016</td><td>0.293</td></tr><tr valign="top"><td>100%</td><td>0.043</td><td>0.043</td></tr></tbody></table></table-wrap></p>
                <p>SHINE also contains a sample-size re-estimation analysis to ensure 80% power if the control success rate is higher than expected and variance is increased. The sample size re-estimation will follow the approach of Gould and Shih [<xref ref-type="bibr" rid="CR8">8</xref>], and will be based on the observed overall success rate and assuming a 7% absolute difference between treatment arms. If the overall pooled success rate is greater than 31%, the maximum sample size may be increased. As specified in Gould and Shih, to maintain the blind, the sample size re-estimation is planned just prior to the first unblinded interim analysis. If the sample size is increased, the timing of the interim looks will be adjusted accordingly to preserve the planned information fraction at each look. The largest possible increase to the maximum sample size would be 318 patients.</p>
                <p>Finally, patients will be randomized to either the experimental or control arm based on a randomization scheme that includes both covariate balancing and response adaptive randomization. Covariates to be balanced are the baseline NIHSS (3 strata), use of IV thrombolysis (yes or no), and site. As SHINE is currently ongoing, to prevent operational bias, the details of the response adaptive randomization component of the design have not been provided to the SHINE study investigators who are potentially enrolling patients and are not included in this manuscript.</p>
              </sec>
              <sec id="Sec4">
                <title>Goldilocks design alternative</title>
                <p>The only constraints applied to the alternative design for the SHINE design were having a maximum sample size of 1,400 patients, and the assumptions of a control rate favorable outcome of 25% where a 7% improvement would be clinically meaningful. All other design parameters were subject to change.</p>
                <p>The alternative SHINE trial design is a Bayesian adaptive Goldilocks design that includes frequent interim looks, based on predictive probabilities, to stop early for efficacy or futility [<xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR9">9</xref>]. Because patients can also be assessed for mRS at 6 weeks, we use a longitudinal model of the primary endpoint to allow the 6-week measure of mRS to aid prediction of mRS at 90 days. Patients are equally randomized to either the experimental or control arm. The minimum sample size is 500 patients, and the maximum sample size is 1,400 patients and there are scheduled interim analyses after every additional 100 patients are enrolled. The primary analysis is fully Bayesian, comparing the posterior distributions of the success rates between the two arms. In this design, the alternative hypothesis is one-sided, that the success rate on the experimental arm is greater than on the control arm. The rationale for a one-sided alternative hypothesis is that the clinical implications of either futility (the two treatments being similar) or the experimental therapy being worse than control are the same - patients would continue to receive the control treatment, the current standard of care. Therefore this design would not continue in order to show that the experimental therapy is significantly worse than control.</p>
              </sec>
              <sec id="Sec5">
                <title>Interim monitoring</title>
                <p>Interim monitoring for early efficacy or futility begins when 500 patients are enrolled and interim analyses are planned after every additional 100 patient are enrolled for a total of nine possible interim analyses. Interim monitoring for futility is based on the predictive probability that the trial will be successful at the maximum sample size of 1,400 patients, <italic>P</italic><sub><italic>max</italic></sub>. If, at any interim analysis <italic>P</italic><sub><italic>max</italic></sub> is less than 5%<sub>,</sub> the trial will stop for futility. Interim monitoring for efficacy is based on the predictive probability that the trial will be successful at the current sample size, <italic>n</italic>, if accrual to the trial would stop and all currently enrolled patients completed follow-up, <italic>P</italic><sub><italic>n</italic></sub>. If, at any interim analysis <italic>P</italic><sub><italic>n</italic></sub> is greater than 99%, accrual will stop for predicted success. If the trial is not stopped early for futility or if accrual is not stopped early for predicted success (<italic>P</italic><sub><italic>max</italic></sub> &gt;5% and <italic>P</italic><sub><italic>n</italic></sub> &lt;99%), then the trial will continue enrollment to the maximum sample size. If accrual stops early for predicted success, or the trial continues to the maximum sample size of 1,400 patients, the primary efficacy analysis will be conducted when all enrolled patients have completed their 90-day follow-up.</p>
              </sec>
              <sec id="Sec6">
                <title>Primary efficacy analysis</title>
                <p>The primary efficacy analysis will be conducted after all enrolled patients have completed follow-up for the primary endpoint. We assume the probability of success, <italic>θ</italic><sub><italic>j</italic></sub>, has a Beta prior distribution<disp-formula id="Equa"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \left[{\theta}_j\right]\sim Beta\left(1,\ 1\right), $$\end{document}</tex-math><mml:math id="M2"><mml:mfenced close="]" open="["><mml:msub><mml:mi>θ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced><mml:mo>~</mml:mo><mml:mi mathvariant="italic">Beta</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mtext>,</mml:mtext></mml:math><graphic xlink:href="13063_2015_574_Article_Equa.gif" position="anchor"/></alternatives></disp-formula></p>
                <p>where <italic>j</italic> = C is the control arm and <italic>j</italic> = E is the experimental arm. This prior distribution is equivalent to a uniform prior across the unknown event rates and equates to observing two patients’ worth of information where one experienced a success and one did not. Therefore even with the minimum sample size of 250 patients per group, the prior contributes less than 1% of the information in the posterior. At each interim analysis and at the final analysis the number of observed successes, <italic>x</italic><sub><italic>j</italic></sub>, among the currently enrolled patients, <italic>n</italic><sub><italic>j</italic></sub>, is modeled as a binomial distribution<disp-formula id="Equb"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \left[{x}_j\right]\sim Binomial\left({n}_j,{\theta}_j\right). $$\end{document}</tex-math><mml:math id="M4"><mml:mfenced close="]" open="["><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced><mml:mo>~</mml:mo><mml:mi mathvariant="italic">Binomial</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mtext>.</mml:mtext></mml:math><graphic xlink:href="13063_2015_574_Article_Equb.gif" position="anchor"/></alternatives></disp-formula></p>
                <p>We update the prior distribution with the currently observed data (<italic>x</italic><sub><italic>j</italic></sub>, <italic>n</italic><sub><italic>j</italic></sub>) and the resulting posterior distribution is<disp-formula id="Equc"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \left[{\theta}_j\Big|{x}_j,{n}_j\right]\sim Beta\left(1+{x}_{j,}1+{n}_j-{x}_j\right). $$\end{document}</tex-math><mml:math id="M6"><mml:mfenced close="]" open="["><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="true">|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mo>~</mml:mo><mml:mi mathvariant="italic">Beta</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:msub><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mtext>.</mml:mtext></mml:math><graphic xlink:href="13063_2015_574_Article_Equc.gif" position="anchor"/></alternatives></disp-formula></p>
                <p>Given the number of successes in each group <italic>x</italic><sub><italic>C</italic></sub> and x<sub><italic>E</italic></sub> and the total number randomized to each group, <italic>n</italic><sub><italic>C</italic></sub> and <italic>n</italic><sub><italic>E</italic></sub>, the primary analysis is<disp-formula id="Equd"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \Pr \left({\theta}_E&gt;{\theta}_C\Big|\mathrm{Trial}\ \mathrm{Data}\right)={\displaystyle {\int}_0^1{\displaystyle {\int}_0^{\theta_E}\frac{\Gamma \left(2+{n}_E\right)}{\Gamma \left(1+{x}_E\right)\Gamma \left(1+{n}_E-{x}_E\right)}{\theta}_E^{x_E}{\left(1-{\theta}_E\right)}^{n_E-{x}_E}\frac{\Gamma \left(2+{n}_C\right)}{\Gamma \left(1+{x}_C\right)\varGamma \left(1+{n}_C-{x}_C\right)}}}{\theta}_C^{x_C}{\left(1-{\theta}_C\right)}^{n_C-{x}_C}d{\theta}_Cd{\theta}_E. $$\end{document}</tex-math><mml:math id="M8"><mml:mo>Pr</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>E</mml:mi></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi mathvariant="normal">Trial</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">Data</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo stretchy="true">∫</mml:mo><mml:mn>0</mml:mn><mml:mn>1</mml:mn></mml:msubsup><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo stretchy="true">∫</mml:mo><mml:mn>0</mml:mn><mml:msub><mml:mi>θ</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:msubsup><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mi mathvariant="normal">Γ</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>E</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:msubsup><mml:mi>θ</mml:mi><mml:mi>E</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:msubsup><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>E</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mi>Γ</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle><mml:msubsup><mml:mi>θ</mml:mi><mml:mi>C</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:msubsup><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mi>d</mml:mi><mml:msub><mml:mi>θ</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>θ</mml:mi><mml:mi>E</mml:mi></mml:msub><mml:mtext>.</mml:mtext></mml:math><graphic xlink:href="13063_2015_574_Article_Equd.gif" position="anchor"/></alternatives></disp-formula></p>
                <p>This value is compared to 0.979 in the final analysis. If the posterior probability that the success rate on the experimental arm, <italic>θ</italic><sub><italic>E</italic></sub>, is greater than the success rate on the control arm, <italic>θ</italic><sub><italic>C</italic></sub>, is greater than 0.979, the treatment will be considered successful,<disp-formula id="Eque"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \Pr \left({\uptheta}_{\mathrm{E}}&gt;{\uptheta}_{\mathrm{C}}\Big|\ \mathrm{Trial}\ \mathrm{Data}\right) &gt; 0.979. $$\end{document}</tex-math><mml:math id="M10"><mml:mo>Pr</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi mathvariant="normal">θ</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi mathvariant="normal">θ</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:msub><mml:mo stretchy="true">|</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">Trial</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">Data</mml:mi></mml:mrow></mml:mfenced><mml:mspace width="0.25em"/><mml:mo>&gt;</mml:mo><mml:mspace width="0.25em"/><mml:mn>0.979</mml:mn><mml:mtext>.</mml:mtext></mml:math><graphic xlink:href="13063_2015_574_Article_Eque.gif" position="anchor"/></alternatives></disp-formula></p>
                <p>The probability of 0.979 is similar to a one-sided critical value of 0.021 in a frequentist trial. This critical value for the final analysis was selected through simulation to control the one-sided Type I error rate of this trial, given the multiple interim analyses, to less than 0.025. SHINE’s two-sided 0.05 and the Goldilocks’ one-sided 0.025 Type I error rates are equivalent. However, the overall Type I error was assessed for the Goldilocks design by simulation. The null space is defined both by the accrual rate and the response rates for both groups. Type I error control was shown by simulation only considering an accrual rate of 33 patients per month and for a response rate of 25% in both arms. The overall Type I error of the design may be larger or smaller at other points in the null space.</p>
              </sec>
              <sec id="Sec7">
                <title>Longitudinal model and predictive probabilities</title>
                <p>As described above, interim analyses for efficacy and futility are based on predictive probability calculations. Because of a lag between enrollment and when the primary endpoint is observed, at each interim analysis there will be patients who have complete information through 90 days, more recently enrolled patients who may have only 6-week assessment of mRS, and the most recently enrolled patients who provide only baseline information. For the predictive probability calculations, we utilize the information from patients with incomplete information to the extent that the baseline and 6-week assessments are associated with the primary endpoint at 90 days. Patients with complete information inform this association.</p>
                <p>A Bayesian model is built to learn the associations between the earlier 6-week time point and the primary endpoint at 90 days. For each arm, we use three beta-binomial distributions to model the transition:<list list-type="order"><list-item><p>from baseline to 90-days for patients with baseline information only,</p></list-item><list-item><p>from 6 weeks to 90-days for patients who were a success at 6 weeks, and</p></list-item><list-item><p>from 6 weeks to 90-days for patients who were not a success at 6 weeks.</p></list-item></list></p>
                <p>Because the arms are modeled independently and identically, we present the longitudinal model generically without reference to treatment group. At each interim analysis with a total of <italic>n</italic> patients enrolled, the number of patients with complete follow-up through 90-days is <italic>n</italic><sub><italic>c</italic></sub>. The number of these patients who have achieved a success is <italic>x</italic> and the number of these patients who did not achieve success is <italic>z</italic>. The number of patients enrolled but who have incomplete information is <italic>n</italic><sup><italic>*</italic></sup>. Thus <italic>n = n</italic><sub><italic>c</italic></sub> 
<italic>+ n</italic><sup><italic>*</italic></sup> 
<italic>= x + z</italic> + <italic>n</italic><sup><italic>*</italic></sup>.</p>
                <p>For the <italic>n</italic><sup><italic>*</italic></sup> patients with incomplete information, they either 1) have no 6-week follow-up<italic>, n</italic><sup><italic>*</italic></sup><sub><italic>0</italic></sub>, 2) have achieved success at 6 weeks, <italic>n</italic><sup><italic>*</italic></sup><sub><italic>+</italic></sub> or 3) have not achieved success at 6 week, <italic>n</italic><sup><italic>*</italic></sup><sub><italic>-.</italic></sub> For each of these three groups, we use a beta-binomial model to predict the number of these patients who will be a success on the primary 90-day endpoint. Given the currently observed <italic>n</italic><sub><italic>c</italic></sub> patients with complete data, the number of patients in each of the three incomplete information groups who will be a success on the primary endpoint is<disp-formula id="Equf"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \begin{array}{l}{x^{*}}_0\Big|\ \mathrm{Current}\ \mathrm{Data} \sim \mathrm{Beta}-\mathrm{binomial}\left({n^{*}}_0,\ 1 + x,\ 1 + z\right)\\ {}{x^{*}}_{+}\Big|\ \mathrm{Current}\ \mathrm{Data} \sim \mathrm{Beta}-\mathrm{binomial}\left({n^{*}}_{+},\ 1 + {x}_{+},\ 1 + {z}_{+}\right)\\ {}{x^{*}}_{-}\Big|\ \mathrm{Current}\ \mathrm{Data} \sim \mathrm{Beta}-\mathrm{binomial}\left({n^{*}}_{-},\ 1 + {\mathrm{x}}_{-},\ 1 + {z}_{-}\right)\end{array} $$\end{document}</tex-math><mml:math id="M12"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:msup><mml:mi>x</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mn>0</mml:mn></mml:msub><mml:mo>|</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">Current</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">Data</mml:mi><mml:mspace width="0.25em"/><mml:mo>~</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">Beta</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="normal">binomial</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:msup><mml:mi>n</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mn>1</mml:mn><mml:mspace width="0.25em"/><mml:mo>+</mml:mo><mml:mspace width="0.25em"/><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mn>1</mml:mn><mml:mspace width="0.25em"/><mml:mo>+</mml:mo><mml:mspace width="0.25em"/><mml:mi>z</mml:mi></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:msup><mml:mi>x</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>+</mml:mo></mml:msub><mml:mo>|</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">Current</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">Data</mml:mi><mml:mspace width="0.25em"/><mml:mo>~</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">Beta</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="normal">binomial</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:msup><mml:mi>n</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mn>1</mml:mn><mml:mspace width="0.25em"/><mml:mo>+</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi>x</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mn>1</mml:mn><mml:mspace width="0.25em"/><mml:mo>+</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi>z</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:msup><mml:mi>x</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>−</mml:mo></mml:msub><mml:mo stretchy="true">|</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">Current</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">Data</mml:mi><mml:mspace width="0.25em"/><mml:mo>~</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">Beta</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="normal">binomial</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:msup><mml:mi>n</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>−</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mn>1</mml:mn><mml:mspace width="0.25em"/><mml:mo>+</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi mathvariant="normal">x</mml:mi><mml:mo>−</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mn>1</mml:mn><mml:mspace width="0.25em"/><mml:mo>+</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi>z</mml:mi><mml:mo>−</mml:mo></mml:msub></mml:mrow></mml:mfenced></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="13063_2015_574_Article_Equf.gif" position="anchor"/></alternatives></disp-formula></p>
                <p>where x and z are the number of patients who are 90-day successes and failures, respectively; <italic>x</italic><sub><italic>+</italic></sub> and <italic>z</italic><sub><italic>+</italic></sub> are the number of patients who were 6-week successes who were successes (<italic>x</italic><sub><italic>+</italic></sub>) and failures (<italic>z</italic><sub><italic>+</italic></sub>) at 90-days, respectively; and <italic>x</italic><sub><italic>−</italic></sub> and <italic>z</italic><sub><italic>−</italic></sub> are the number of patients who were not 6-week successes who were successes (<italic>x</italic><sub><italic>−</italic></sub>) and failures (<italic>z</italic><sub><italic>−</italic></sub>) at 90-days.</p>
                <p>For each value of <italic>x</italic><sup><italic>*</italic></sup><sub><italic>0</italic></sub><italic>, x</italic><sup><italic>*</italic></sup><sub><italic>+</italic></sub><italic>, x</italic><sup><italic>*</italic></sup><sub><italic>−</italic></sub><italic>,</italic> there is an associated probability based upon the described distributions, and correspondingly, there is an associated probability for every possible number of total successes if all patients were to complete follow-up.</p>
                <p>For each pair of possible total successes between the experimental and control group, we can determine if that combination would result in a success on the primary efficacy analysis, whether Pr(<italic>θ</italic><sub><italic>E</italic></sub> &gt; <italic>θ</italic><sub><italic>C</italic></sub> &gt;0.979). Summing the probabilities for the cases that would result in trial success is the predictive probability of trial success for the currently enrolled patients.</p>
                <p>For the predictive probability of success at the maximum sample size, we perform a similar calculation but assume the trial continues enrollment to the maximum sample size of 1,400 patients. However, this requires calculation of the predictive distribution of success for patients not yet enrolled. These future patients are included in the predictive probability calculation described above as patients that have only a baseline assessment (no available interim data).</p>
              </sec>
            </sec>
            <sec id="Sec8" sec-type="results">
              <title>Results</title>
              <p>Table <xref rid="Tab2" ref-type="table">2</xref> summarizes the differences between the two designs. Both designs are innovative and complex, and both offer many features that help address the primary objective of the trial. There is little common ground for a head-to-head comparison, except to explore how each design behaves in terms of power and mean sample size across a range of scenarios.<table-wrap id="Tab2"><label>Table 2</label><caption><p><bold>Summary of design features for SHINE and the Goldilocks alternative</bold></p></caption><table frame="hsides" rules="groups"><thead><tr valign="top"><th/><th><bold>SHINE</bold></th><th><bold>Goldilocks</bold></th></tr></thead><tbody><tr valign="top"><td>Hypothesis testing</td><td>Two-sided</td><td>One sided</td></tr><tr valign="top"><td>Primary analysis</td><td>Covariate adjusted</td><td>Unadjusted</td></tr><tr valign="top"><td>Randomization</td><td>Response adaptive</td><td>1:1</td></tr><tr valign="top"><td>Minimum sample size</td><td>Approx 600</td><td>Fixed at 500</td></tr><tr valign="top"><td>Maximum sample size</td><td>Between 1,400 and 1,718</td><td>Fixed at 1,400</td></tr><tr valign="top"><td>Planned interim analyses</td><td>4</td><td>9</td></tr><tr valign="top"><td>Stopping boundaries</td><td>Group sequential</td><td>Predictive probabilities, incorporating early information</td></tr><tr valign="top"><td>Complete follow-up of all patients in event of early termination</td><td>Undefined critical value</td><td>Explicitly defined critical value</td></tr></tbody></table></table-wrap></p>
              <p>To determine the operating characteristics of each design, we simulated both the SHINE design and the Goldilocks design across a range of treatment effects and a range of success rates for the control group. The SHINE design was simulated including the group sequential stopping boundaries, the sample size re-estimation, and using a chi-square test between treatment groups as the primary analysis (consistent with the primary power calculation). The response adaptive randomization component of the design was not included in order to preserve the operational integrity of the trial. The Goldilocks design was simulated exactly as described above. Simulation code was written in the R statistical language [<xref ref-type="bibr" rid="CR10">10</xref>] and 10,000 trials were simulated for each scenario. All simulations assume no lost to follow-up, and an accrual rate of 33 patients per month. Thus, at each interim analysis there are approximately 100 patients enrolled but without complete follow-up through 90 days. The nature of the longitudinal data necessary for simulation of the Goldilocks design was estimated based on the transitions in mRS observed within the raw data from the NINDS tPA trial including both the tPA and control groups since SHINE includes both [<xref ref-type="bibr" rid="CR11">11</xref>].</p>
              <sec id="Sec9">
                <title>Sample size</title>
                <p>The left panel of Figure <xref rid="Fig1" ref-type="fig">1</xref> shows the total mean number of patients enrolled for the two designs. Generally, when the treatment effects are null or small, both designs stop early for futility and when the treatment effects are large, both designs stop early for success. Thus, sample sizes are smaller at each end of the treatment effect range than in the middle.<fig id="Fig1"><label>Figure 1</label><caption><p><bold>Mean total sample size enrolled (left panel) and probability of trial success (right panel).</bold> SHINE is plotted with a circle and the Goldilocks is plotted with an x. Heavy line represents a control success rate of 25%, medium line represents a control success rate of 30%, and light line represents a control rate of 35%. Dashed line on the right panel shows 80% power for reference.</p></caption><graphic xlink:href="13063_2015_574_Fig1_HTML" id="MO1"/></fig></p>
                <p>Across all simulated scenarios, the SHINE design tends to enroll a greater number of patients than the Goldilocks design. The difference in sample size between the two designs is attributable to a different number of interim analyses, different mechanisms for early stopping, differing aggressiveness of the stopping boundaries, and that SHINE is based on a two-sided alternative hypothesis while the Goldilocks design is based on a one-sided alternative hypothesis.</p>
                <p>The SHINE design includes four interim analyses and the Goldilocks design includes nine. With more interim analyses, the Goldilocks design has more opportunities to stop early. Additionally, the two designs have different mechanisms for early stopping and differently account for complete follow-up of all enrolled patients should the trial stop early. Early stopping for the SHINE design is based on the information fraction, or the number of patients with observed 90-day outcomes. It stops early only when observed 90-day data produces an overwhelming effect for efficacy or futility. For example, when 1,000 patients are enrolled, we expect that 900 patients will have complete data. The trial will stop for efficacy if, based on these 900 patients, the <italic>P</italic> value is less than 0.008 (Table <xref rid="Tab1" ref-type="table">1</xref>) and the trial is considered a success. There is no defined critical value for a later analysis that might include the 100 outstanding patients once they have completed follow-up.</p>
                <p>Early stopping in the Goldilocks design is based on the number of patients enrolled and allows for complete follow-up of all enrolled patients. Thus, the Goldilocks design is able to have more aggressive early stopping behavior, stopping accrual and then allowing for the additional follow-up of enrolled patients in order to observe the necessary information for success, whereas the SHINE design stops only once the necessary information for success is already observed. The Goldilocks design might stop when 900 patients are enrolled, and 800 patients have complete data, as long as there is a high probability that including the outstanding 100 patients in the final analysis (many of whom have interim 6-week mRS values) would result in trial success. In the Goldilocks design, all enrolled patients are explicitly included in the final analysis.</p>
                <p>The difference in expected sample size is largest when the control is only slightly better than the experimental arm. The alternative hypothesis for the SHINE design is two-sided, but is one-sided for the Goldilocks design. This contributes to different stopping behavior when the control arm is only slightly better than the treatment. In these scenarios, the Goldilocks design stops early for futility, reacting to the fact that it is unlikely the experimental treatment will be proven to be superior to the control. The SHINE design continues in these scenarios, not crossing a futility boundary (the treatments are the same), and not seeing a large enough treatment effect to cross a success boundary (the control is significantly better than the experimental).</p>
              </sec>
              <sec id="Sec10">
                <title>Probability of trial success</title>
                <p>The right panel of Figure <xref rid="Fig1" ref-type="fig">1</xref> shows the probability of trial success for the two designs. When the treatment effect is null, SHINE has an analytically controlled two-sided overall Type I error rate of 5% and the Goldilocks design has a simulated one-sided Type I error rate of approximately 2.5%. We present only one null scenario, and the Type I error rate for the Goldilocks design may vary across the null space. When the treatment arm is slightly worse than control, the SHINE design may conclude success of control over treatment, whereas the Goldilocks design cannot. Thus, the SHINE design has a higher probability of trial success in these scenarios.</p>
                <p>When the control rate is 25%, the probability of success in scenarios where the treatment is better than control is similar between the two designs. As the control rate increases, a small amount of power is lost in the Goldilocks design. The Goldilocks design loses approximately 2% power when the control rate increases from 25% to 30%, and approximately another 2% power when the control rate increases from 30% to 35%.</p>
                <p>The SHINE design includes a sample size re-estimation to preserve power if the control rate is higher than expected. Thus, as the control rate increases, the power of the design is unchanged. However, the mean sample size increases (left panel Figure <xref rid="Fig1" ref-type="fig">1</xref>). In the most extreme case, the Data Safety and Monitoring Board (DSMB) could be asked to increase the sample size from 1,400 to 1,718 patients. Figure <xref rid="Fig2" ref-type="fig">2</xref> shows the probability that the SHINE maximum sample size is increased and the mean number of patients added. The size of the sample size re-estimation is proportional to the pooled success rate and so depends on both the control success rate and the treatment effect. Because the sample size re-estimation is blinded it is not possible to diagnose whether a high pooled event rate is due to a higher than expected control rate, or to a larger than expected treatment effect. In fact, because the treatment effect is fixed at 7% in the sample size re-estimation procedure, a high pooled event rate is always attributed to a higher than expected control rate. As a result, even when the true control rate is 25%, a large treatment effect can trigger a sample size increase and the larger the treatment effect, the larger the increase to the maximum sample size. However, with a large treatment effect, the trial is then also likely to stop early for success. The trial’s mean sample size does not increase by exactly the number of patients added to the maximum sample size because of this potential for early success stopping. However, the potential delay to the first interim look may translate to an increase in the mean sample size.<fig id="Fig2"><label>Figure 2</label><caption><p><bold>Probability of increasing the maximum sample size (left panel) and mean number of patients added (right panel).</bold> SHINE is plotted with a circle (Goldilocks design does not include sample size re-estimation). Heavy line represents a control success rate of 25%, medium line represents a control success rate of 30%, and light line represents a control rate of 35%.</p></caption><graphic xlink:href="13063_2015_574_Fig2_HTML" id="MO2"/></fig></p>
              </sec>
              <sec id="Sec11">
                <title>Compare and contrast</title>
                <p>The strengths of the SHINE design include the sample size re-estimation and the covariate adjusted final analysis. SHINE has analytical control of overall Type I error, and as simulated, the SHINE design offers a slight advantage in terms of power. Covariates were not included in the simulation study, but a covariate adjusted primary analysis is likely to increase the trial’s overall power from what was simulated. With fewer interim analyses, there is also less operational complexity. However, the adaptive randomization component was not included in the simulations. This type of randomization scheme has the potential to increase operational complexity and reduce power. While response adaptive randomization would likely randomize more patients to the more effective therapy, the power of the trial could be reduced because in a two-arm trial, equal allocation between arms should provide maximum power.</p>
                <p>The strengths of the Goldilocks design include more frequent interim analyses, the longitudinal model of the primary outcome, and explicitly accounting for patients with incomplete follow-up if accrual to the trial where to stop early. The Goldilocks design offers advantages in terms of sample size. If accrual to the trial is faster than expected, the difference in sample size between the two designs will be greater than described here. If accrual to the trial is slower than expected, the difference in sample size will be smaller. Accrual to clinical trials is frequently slower than expected. While the Goldilocks design randomizes patients equally to the two treatment arms, an increased potential to stop the trial earlier would allow results to be communicated earlier and would allow patients outside the trial to be treated with the more effective therapy sooner.</p>
                <p>The comparison of operating characteristics should be interpreted with caution bearing in mind the many differences between the two designs (Table <xref rid="Tab2" ref-type="table">2</xref>), in particular the differences in the stopping boundaries and the limitations of the simulation study, specifically that covariates and the adaptive randomization component of the SHINE design were not included. The operating characteristics of the Goldilocks design, in particular Type I error control, are assessed with simulation and so the Type I error rates of the two designs may not be exactly equal across the entire null space. While we see that the SHINE design offers advantages in terms of power and that the Goldilocks offers advantages in terms of sample size, we expect that a greater sample size would confer greater power. The largest difference in power we observed in the simulations was when the control rate was 35% and the treatment rate was 41%. In this scenario SHINE has 9.5% more power (58.6% versus 68.1%) and enrolls an average of 308 additional patients.</p>
                <p>None of the simulated scenarios showed a similar sample size between the two designs, the Goldilocks design always had a smaller mean sample size. In the primary expected scenario of 32% vs. 25%, both designs are tuned to have approximately 80% power, and the average sample size in SHINE is 135 patients higher than in the Goldilocks design (1,114 vs. 979). For similar powers the Goldilocks trial saves at least 100 patients, oftentimes more. When the difference between arms is very small, only 2%, the two designs have similar power, approximately 12%, regardless of the control rate. The SHINE design averages 273, 322, and 429 more patients at control rates of 25%, 30%, and 35%, respectively. When the treatment effect is large, 10%, SHINE has an additional 1 to 3% power, but averages and additional 139, 178, and 213 patients at control rates of 25%, 30%, and 35%, respectively.</p>
              </sec>
              <sec id="Sec12">
                <title>Trial execution</title>
                <p>SHINE is currently ongoing. The Goldilocks design will be virtually executed upon completion of SHINE using the observed patient data from SHINE. The purpose of this virtual trial execution is to determine the resources used and resulting evidence for the comparison of the experimental versus control arms had SHINE been conducted according to the Goldilocks design. The outcomes of the two trial executions can be compared in terms of final trial conclusions, total number of patients enrolled, number of patients enrolled to the most effective treatment arm, and trial duration.</p>
                <p>This exercise will require datasets that provide snapshots of the accumulated data from SHINE to conduct each of the planned interim analyses and the final analysis. The trial’s data coordinating center has agreed to provide these snap shots and store these blinded datasets until the SHINE results are released. If SHINE stops accrual early, but the Goldilocks design indicates continuing enrollment, patients for the future interim analyses for the Goldilocks design will be simulated by re-sampling the observed SHINE patients. We emphasize that we have a prospectively defined design and execution plan. Limitations in the re-execution approach will be assessed and reported at the time the re-execution is performed.</p>
              </sec>
            </sec>
            <sec id="Sec13" sec-type="discussion">
              <title>Discussion</title>
              <p>The original SHINE design presented within ADAPT-IT included response adaptive randomization and had one futility analysis (700 patients with complete data, 50% information) and one early success stopping analysis (938 patients with complete data, 67% information). As the work within ADAPT-IT progressed, the potential benefits of additional interim analyses were discussed. The number of interim analyses for SHINE was re-evaluated and the design was updated to the four interim analyses for early stopping as described here. The Goldilocks design was then finalized. External to the ADAPT-IT process, a sample size re-estimation was then added to the SHINE design and the simulation exercise presented here was then performed. Certainly, the two designs could continue to be iterated to be more similar or pieces of one design could be included in the other. For example, the Goldilocks design could allow a larger sample size and a covariate adjusted final analysis, which are strengths in the SHINE trial design. The SHINE design could have more frequent interim analyses or account for patients with incomplete follow-up when the study stops, which are strengths in the Goldilocks design. However, we present the Goldilocks design as it was developed at the time and we present the SHINE design as it is being conducted.</p>
              <p>The SHINE investigators were tasked with choosing only a single design to implement and ultimately elected not to implement the Goldilocks alternative. A main aspect for consideration was the potential for formal ‘flip-flop’. The Goldilocks design stops accrual for predicted success if the probability for success with the currently enrolled patients, allowing for the outstanding (approximately) 100 patients to reach their 90-day endpoint, is greater than 99%. There is a small chance that the trial could stop for predicted success, complete follow-up of the enrolled patients, and then at the final analysis, miss the 0.979 posterior probability threshold required for trial success. For example, in the scenario where the experimental treatment offers a 7% absolute benefit, the trial stopped early for predicted success 62% of the time and in 0.5% of those cases, failed to obtain the final critical value for success. Most likely, if such a flip-flop occurs, the experimental treatment is not effective. While such flip-flops occur in 0.5% of early stopping cases when the treatment is effective (+7%) they occurred in 6% of cases when the treatment is ineffective - largely because of regression to the mean in those cases and this in fact helps to conserve Type I error. Even if this were to occur, the final <italic>P</italic> value would likely still be just a little larger than the critical value.</p>
              <p>It is important to recognize that this potential exists in a group sequential design as well. While such an occurrence is similarly unlikely, it is not well characterized or formally accounted for. Stopping based on predictive probabilities explicitly accounts for complete follow-up of all enrolled patients and so it is natural to quantify the ‘flip-flop’. Group sequential stopping is typically based on the amount of information observed and while methods exist to account for ‘overrun’ [<xref ref-type="bibr" rid="CR12">12</xref>], the typical implementation of group sequential designs does not dictate how to handle patients with incomplete information should the trial stop early. These designs typically do not include a formal analysis on all enrolled patients and so do not specify the critical value needed for such an analysis. Our simulations of the SHINE design show that in this case such an analysis would likely not meet the <italic>P</italic> value that was required for early stopping, simply due to regression to the mean, but is likely to meet the <italic>P</italic> value required for success at the end of the trial with complete information (data not shown).</p>
              <p>A second consideration for the SHINE investigators surrounding the Goldilocks design was a wholesale change of the design after it had already been through the NIH peer review process and had been selected for funding. Additionally, there was concern from the SHINE PI about whether the design and final analysis would be accepted by the clinical community given the small number phase III trials that have utilized a Bayesian approach.</p>
              <p>One of the larger differences between the two designs is that SHINE is a two-sided alternative hypothesis while the Goldilocks design is one-sided. Although the error rates are similar, differences in sample size and power between the two designs are confounded with this difference in hypothesis testing in the setting where the standard of care arm is slightly better than the tight control arm. While two-sided trials are standard, and hence the choice for the SHINE investigators, the Goldilocks design considers it unlikely that a DSMB would let a trial proceed only to show that an expensive, more laborious therapy is in fact significantly inferior to the standard of care. However, the clinical community is currently quite divided on the utility of intensive glucose control in stroke and both the SHINE and the NETT leadership believe that the greatest opportunity for SHINE to leave stroke physicians with a definitive answer is through the two-sided design. Certainly, there are many stroke physicians who would be satisfied with the one-sided hypothesis tested by the Goldilocks design, yet there is a concern that practice will not be changed unless there is a definitive answer in favor of one treatment or the other. Of course, even the two-sided design may end in the null space; given the additional resources required to perform the intense glucose controls it is likely that most would abandon this treatment.</p>
              <p>The primary lesson learned in the ADAPT-IT design process for SHINE was about the value of trial simulation. Trial simulation may typically be associated Bayesian designs or with more complex adaptive designs, such as where a close form solution for Type I error and power are not available. In the ADAPT-IT design process, clinical trial simulation illuminated several points of discussion with both designs. Clinical trial simulation of the Goldilocks design was necessary to understand its early stopping behavior and the potential for ‘flip-flop’. A remedy for ‘flip-flop’ is to increase the threshold required for early stopping, which was done during the design process, but this will decrease the probability of early stopping and increase mean sample size. Such trade-offs can only be assessed through the process of clinical trial simulation. Trial simulation also illuminated the differences in trial behavior due to two-sided versus one-sided hypothesis testing for the investigators and initiated the discussion about which test would ultimately be used in the conduct of the trial.</p>
              <p>Finally, the SHINE design includes two ‘well understood’ [<xref ref-type="bibr" rid="CR13">13</xref>] adaptive trial features that are commonly used in phase III trials: a blinded sample size re-estimation and group sequential stopping boundaries. While the statistical properties of each are completely understood separately, combining two well-understood design features does not add up to a well-understood design. For example, when the experimental therapy is performing better than control, the sample size may be increased due to the sample size re-estimation and the first interim analysis will be delayed. The trial may stop for success, though with additional patients and more time than it might require otherwise. Given that the experimental therapy is performing well, the additional patients and time could be undesirable. On the other hand, the delay could be considered small and worth the protection of power that the sample size re-estimation provides. Even with the simulation exercise presented here, the SHINE design is still not completely characterized because covariates and the adaptive randomization component are not included.</p>
            </sec>
            <sec id="Sec14" sec-type="conclusion">
              <title>Conclusions</title>
              <p>The goal of this project was to illustrate two alternative real-world designs, the two primary designs considered for a multi-center NIH-funded randomized clinical trial. Because they are two real-world designs, simple head-to-head comparisons changing one feature at a time are not possible and the alternative trials must be judged on the totality of their operating characteristics.</p>
              <p>The consideration of alternative trial designs was a successful venture in that two designs were brought forward, and both were evaluated, revised, and improved based on the input of all parties involved in the ADAPT-IT process. Simulation of an entire design as it will be conducted was necessary to evaluate the selected design features in concert with each other and to inform the study team of the gains/losses associated with various design choices. Trial simulation should not be reserved for only complex adaptive designs. Rather, all trialists should consider trial simulation an important tool for developing a complete understanding of the statistical properties of their trial design [<xref ref-type="bibr" rid="CR14">14</xref>].</p>
            </sec>
          </body>
          <back>
            <app-group>
              <app id="App1">
                <sec id="Sec15">
                  <title>Appendix</title>
                  <p>The following list contains the ethics boards or institutional review boards that approved the SHINE study at each participating clinical site in the Neurological Emergency Treatment Trials Network (Table <xref rid="Tab3" ref-type="table">3</xref>).<table-wrap id="Tab3"><label>Table 3</label><caption><p><bold>Ethical body at each enrolling site</bold></p></caption><table frame="hsides" rules="groups"><thead><tr valign="top"><th><bold>Spoke</bold></th><th><bold>IRB name</bold></th></tr></thead><tbody><tr valign="top"><td>University of Arizona Medical Center - University Campus, Tucson, AZ</td><td>University of Arizona Human Subjects Protection Program IRB</td></tr><tr valign="top"><td>University of Arizona Medical Center - South Campus, Tucson, AZ</td><td>University of Arizona Human Subjects Protection Program IRB</td></tr><tr valign="top"><td>University of Cincinnati Medical Center, Cincinnati, OH</td><td>University of Cincinnati Institutional Review Board</td></tr><tr valign="top"><td>Emory University Hospital, Atlanta, GA</td><td>Emory University Institutional Review Board</td></tr><tr valign="top"><td>Emory University Hospital Midtown, Atlanta, GA</td><td>Emory University Institutional Review Board</td></tr><tr valign="top"><td>Grady Memorial Hospital, Atlanta, GA</td><td>Emory University Institutional Review Board</td></tr><tr valign="top"><td>University of Michigan Medical Center, Ann Arbor, MI</td><td>University of Michigan IRBMED</td></tr><tr valign="top"><td>Henry Ford Hospital, Detroit, MI</td><td>Henry Ford Health System Institutional Review Board</td></tr><tr valign="top"><td>University of Kentucky Hospital, Lexington, KY</td><td>University of Kentucky Medical Institutional Review Board</td></tr><tr valign="top"><td>University of Maryland Medical Center, Baltimore, MD</td><td>University of Maryland, Baltimore (UMB) Institutional Review Board (IRB)</td></tr><tr valign="top"><td>Massachusetts General Hospital</td><td>Partners Human Research Committee</td></tr><tr valign="top"><td>Hennepin County Medical Center, Minneapolis, MN</td><td>Hennepin County Medical Center Human Subjects Research Review Committee</td></tr><tr valign="top"><td>University of Kansas Hospital, Kansas City, KS</td><td>Kansas University Medical Center Institutional Review Board</td></tr><tr valign="top"><td>University of Minnesota Medical Center Fairview, Minneapolis, MN</td><td>University of Minnesota Institutional Review Board</td></tr><tr valign="top"><td>NYP Columbia University Medical Center, New York, NY</td><td>Columbia University Medical Center Institutional Review Board</td></tr><tr valign="top"><td>OSU Wexner Medical Center, Columbus, OH</td><td>Biomedical Sciences Institutional Review Board</td></tr><tr valign="top"><td>Summa Akron City Hospital, Akron, OH</td><td>Summa Health System Institutional Review Board</td></tr><tr valign="top"><td>Harborview Medical Center, Seattle, WA</td><td>University of Washington Human Subjects Division Institutional Review Board</td></tr><tr valign="top"><td>UPMC Presbyterian Hospital, Pittsburgh, PA</td><td>University of Pittsburgh Institutional Review Board</td></tr><tr valign="top"><td>UPMC Mercy Hospital, Pittsburgh, PA</td><td>University of Pittsburgh Institutional Review Board</td></tr><tr valign="top"><td>NYP Weill Cornell Medical Center, New York, NY</td><td>Weill Cornell Medical College Institutional Review Board</td></tr><tr valign="top"><td>WVU Healthcare Ruby Memorial Hospital, Morgantown, WV</td><td>West Virginia University Institutional Review Board (IRB)</td></tr><tr valign="top"><td>Buffalo General Medical Center, Buffalo, NY</td><td>SUNY University at Buffalo Health Sciences IRB (HSIRB)</td></tr><tr valign="top"><td>Northwestern University</td><td>Northwestern University Biomedical IRB</td></tr><tr valign="top"><td>UT Southwestern - Parkland Hospital</td><td>UT Southwestern Institutional Review Board (IRB)</td></tr><tr valign="top"><td>UT Southwestern University Hospital-Zale Lipshy, Dallas, TX</td><td>UT Southwestern Institutional Review Board (IRB)</td></tr><tr valign="top"><td>Baylor College of Medicine, Houston, TX</td><td>Baylor College of Medicine Institutional Review Board</td></tr><tr valign="top"><td>Vanderbilt University Medical Center</td><td>Vanderbilt University Institutional Review Board</td></tr><tr valign="top"><td>St. Thomas Hospital, Nashville, TN</td><td>Sterling Institutional Review Board</td></tr><tr valign="top"><td>UVA Medical Center, Charlottesville, VA</td><td>University of Virginia Institutional Review Board for Health Sciences Research</td></tr><tr valign="top"><td>OSF Saint Francis Medical Center</td><td>University of Illinois College of Medicine at Peoria Institutional Review Board</td></tr><tr valign="top"><td>Penn State Hershey Medical Center, Hershey, PA</td><td>Penn State Hershey College of Medicine Institutional Review Board</td></tr><tr valign="top"><td>Georgia Regents Medical Center, Augusta, GA</td><td>Georgia Regents University Institutional Review Board</td></tr><tr valign="top"><td>University of Utah Healthcare, Salt Lake City, UT</td><td>University of Utah Institutional Review Board</td></tr><tr valign="top"><td>Mayo Clinic, Jacksonville, FL</td><td>Mayo Clinic Institutional Review Board</td></tr><tr valign="top"><td>Stanford University Medical Center, Stanford, CA</td><td>Stanford University Human Subjects Committee IRB</td></tr><tr valign="top"><td>SUNY Downstate</td><td>Biomedical Research Alliance of New York (BRANY) Institutional Review Board</td></tr><tr valign="top"><td>Kings County Hospital</td><td>Biomedical Research Alliance of New York (BRANY) Institutional Review Board</td></tr><tr valign="top"><td>Lincoln Medical and Mental Health Center, Bronx, NY</td><td>Biomedical Research Alliance of New York (BRANY) Institutional Review Board</td></tr><tr valign="top"><td>Maimonides Medical Center</td><td>Biomedical Research Alliance of New York (BRANY) Institutional Review Board</td></tr><tr valign="top"><td>Allegheny General Hospital</td><td>Allegheny Singer Research Institute Institutional Review Board</td></tr><tr valign="top"><td>Thomas Jefferson University Hospital, Philadelphia, PA</td><td>Thomas Jefferson University Institutional Review Board</td></tr><tr valign="top"><td>Hackensack University Medical Center, Hackensack, NJ</td><td>Hackensack UMC Institutional Review Board</td></tr><tr valign="top"><td>Temple University Hospital, Philadelphia, PA</td><td>Temple University Institutional Review Board</td></tr><tr valign="top"><td>University Medical Center Brackenridge, Austin, TX</td><td>Seton Institutional Review Board</td></tr><tr valign="top"><td>Seton Medical Center, Austin, TX</td><td>Seton Institutional Review Board</td></tr><tr valign="top"><td>Valley Baptist Medical Center - Harlingen, Harlingen, TX</td><td>Valley Baptist Medical Center Institutional Review Board</td></tr><tr valign="top"><td>Memorial Hermann Texas Medical Center, Houston, TX</td><td>UT Health Committee for the Protection of Human Subjects</td></tr><tr valign="top"><td>Long Beach Memorial Medical Center, Long Beach, CA</td><td>Memorialcare Health System Institutional Review Board</td></tr><tr valign="top"><td>Ronald Reagan UCLA Medical Center, Los Angeles, CA</td><td>University of California Los Angeles Institutional Review Board</td></tr><tr valign="top"><td>San Francisco General Hospital, San Francisco, CA</td><td>University of California at San Francisco Committee on Human Research</td></tr><tr valign="top"><td>UCSF Medical Center, San Francisco, CA</td><td>University of California at San Francisco Committee on Human Research</td></tr><tr valign="top"><td>California Pacific Medical Center Pacific Campus, San Francisco, CA</td><td>Sutter Health Institutional Review Board</td></tr><tr valign="top"><td>California Pacific Medical Center Davies Campus, San Francisco, CA</td><td>Sutter Health Institutional Review Board</td></tr><tr valign="top"><td>Hospital of the University of Pennsylvania, Philadelphia, PA</td><td>University of Pennsylvania Institutional Review Board</td></tr><tr valign="top"><td>WellSpan York Hospital, York, PA</td><td>WellSpan Health Institutional Review Board</td></tr><tr valign="top"><td>Abington Memorial Hospital, Abington, PA</td><td>Abington Memorial Hospital Institutional Review Board</td></tr><tr valign="top"><td>VCU Medical Center, Richmond, VA</td><td>Virginia Commonwealth University Institutional Review Board</td></tr><tr valign="top"><td>Detroit Receiving Hospital, Detroit, MI</td><td>Wayne State University Institutional Review Board</td></tr><tr valign="top"><td>Sinai-Grace Hospital, Detroit, MI</td><td>Wayne State University Institutional Review Board</td></tr><tr valign="top"><td>William Beaumont Hospital-Troy, Troy, MI</td><td>Beaumont Research Institute Human Investigation Committee</td></tr><tr valign="top"><td>William Beaumont Hospital, Royal Oak, MI</td><td>Beaumont Research Institute Human Investigation Committee</td></tr><tr valign="top"><td>Froedtert Memorial Lutheran Hospital, Milwaukee, WI</td><td>Medical College of Wisconsin Institutional Review Board</td></tr></tbody></table></table-wrap></p>
                </sec>
              </app>
            </app-group>
            <glossary>
              <title>Abbreviations</title>
              <def-list>
                <def-list>
                  <def-item>
                    <term>ADAPT-IT</term>
                    <def>
                      <p>Adaptive Designs Accelerating Promising Trials into Treatments</p>
                    </def>
                  </def-item>
                  <def-item>
                    <term>DSMB</term>
                    <def>
                      <p>Data safety and monitoring board</p>
                    </def>
                  </def-item>
                  <def-item>
                    <term>FDA</term>
                    <def>
                      <p>Food and Drug Administration</p>
                    </def>
                  </def-item>
                  <def-item>
                    <term>IV</term>
                    <def>
                      <p>Intravenous</p>
                    </def>
                  </def-item>
                  <def-item>
                    <term>IRB</term>
                    <def>
                      <p>Institutional review board</p>
                    </def>
                  </def-item>
                  <def-item>
                    <term>mRS</term>
                    <def>
                      <p>Modified Rankin Score</p>
                    </def>
                  </def-item>
                  <def-item>
                    <term>NETT</term>
                    <def>
                      <p>Neurologic emergencies treatment trials</p>
                    </def>
                  </def-item>
                  <def-item>
                    <term>NIH</term>
                    <def>
                      <p>National Institutes of Health</p>
                    </def>
                  </def-item>
                  <def-item>
                    <term>NIHSS</term>
                    <def>
                      <p>NIH Stroke Scale</p>
                    </def>
                  </def-item>
                  <def-item>
                    <term>NINDS</term>
                    <def>
                      <p>National Institute of Neurologic Disorders and Stroke</p>
                    </def>
                  </def-item>
                  <def-item>
                    <term>SHINE</term>
                    <def>
                      <p>The Stroke Hyperglycemia Insulin Network Effort</p>
                    </def>
                  </def-item>
                </def-list>
              </def-list>
            </glossary>
            <fn-group>
              <fn>
                <p>
                  <bold>Competing interests</bold>
                </p>
                <p>The authors declare that they have no competing interests.</p>
              </fn>
              <fn>
                <p>
                  <bold>Authors’ contributions</bold>
                </p>
                <p>JT, KB, WM, VD, and KJ participated in the design and simulation of the two trials presented and helped to draft the manuscript. All authors read and approved the final manuscript.</p>
              </fn>
              <fn>
                <p>
                  <bold>Authors’ information</bold>
                </p>
                <p>Dr. Johnston is the PI of the SHINE Trial.</p>
                <p>Dr. Durkalski coordinates the trial from the NETT Data Coordinating Center.</p>
                <p>Dr Connor and Ms Broglio are employees of Berry Consultants LLC, a company that designs adaptive clinical trials for pharmaceutical and medical device companies and National Institutes of Health cooperative groups.</p>
              </fn>
            </fn-group>
            <ack>
              <title>Acknowledgements</title>
              <p>On behalf of the ADAPT-IT and SHINE investigators. The SHINE trial is funded by an NIH/NINDS grant U01-NS069498. The ADAPT-IT project was supported jointly by the NIH Common Fund and the FDA, with funding administered by the National Institutes of Neurological Disorders and Stroke (NINDS) (U01NS073476). The NETT Network Clinical Coordinating Center (U01NS056975) and Statistical and Data Management Center (U01NS059041) are funded by the NINDS.</p>
            </ack>
            <ref-list id="Bib1">
              <title>References</title>
              <ref id="CR1">
                <label>1.</label>
                <mixed-citation publication-type="other">NIH and FDA announce awards to advance regulatory science. [<ext-link ext-link-type="uri" xlink:href="http://www.nih.gov/news/health/sep2010/od-27.htm">http://www.nih.gov/news/health/sep2010/od-27.htm</ext-link>]</mixed-citation>
              </ref>
              <ref id="CR2">
                <label>2.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Meurer</surname>
                      <given-names>WJ</given-names>
                    </name>
                    <name>
                      <surname>Lewis</surname>
                      <given-names>RJ</given-names>
                    </name>
                    <name>
                      <surname>Tagle</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Fetters</surname>
                      <given-names>MD</given-names>
                    </name>
                    <name>
                      <surname>Legocki</surname>
                      <given-names>L</given-names>
                    </name>
                    <name>
                      <surname>Berry</surname>
                      <given-names>S</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>An overview of the adaptive designs accelerating promising trials into treatments (ADAPT-IT) project</article-title>
                  <source>Ann Emerg Med</source>
                  <year>2012</year>
                  <volume>60</volume>
                  <fpage>451</fpage>
                  <lpage>7</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.annemergmed.2012.01.020</pub-id>
                  <?supplied-pmid 22424650?>
                  <pub-id pub-id-type="pmid">22424650</pub-id>
                </element-citation>
              </ref>
              <ref id="CR3">
                <label>3.</label>
                <mixed-citation publication-type="other">NETT Neurological Emergency Treatment Trials [<ext-link ext-link-type="uri" xlink:href="http://nett.umich.edu/nett/welcome">http://nett.umich.edu/nett/welcome</ext-link>]</mixed-citation>
              </ref>
              <ref id="CR4">
                <label>4.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Broglio</surname>
                      <given-names>KR</given-names>
                    </name>
                    <name>
                      <surname>Connor</surname>
                      <given-names>JT</given-names>
                    </name>
                    <name>
                      <surname>Berry</surname>
                      <given-names>SM</given-names>
                    </name>
                  </person-group>
                  <article-title>Not too big, not too small: a goldilocks approach to sample size selection</article-title>
                  <source>J Biopharm Stat</source>
                  <year>2014</year>
                  <volume>24</volume>
                  <fpage>685</fpage>
                  <lpage>705</lpage>
                  <pub-id pub-id-type="doi">10.1080/10543406.2014.888569</pub-id>
                  <?supplied-pmid 24697532?>
                  <pub-id pub-id-type="pmid">24697532</pub-id>
                </element-citation>
              </ref>
              <ref id="CR5">
                <label>5.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Sutton</surname>
                      <given-names>L</given-names>
                    </name>
                    <name>
                      <surname>Julious</surname>
                      <given-names>SA</given-names>
                    </name>
                    <name>
                      <surname>Goodacre</surname>
                      <given-names>SW</given-names>
                    </name>
                  </person-group>
                  <article-title>Influence of adaptive analysis on unnecessary patient recruitment: reanalysis of the RATPAC trial</article-title>
                  <source>Ann Emerg Med.</source>
                  <year>2012</year>
                  <volume>60</volume>
                  <fpage>442</fpage>
                  <lpage>8</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.annemergmed.2012.03.032</pub-id>
                  <?supplied-pmid 22632776?>
                  <pub-id pub-id-type="pmid">22632776</pub-id>
                </element-citation>
              </ref>
              <ref id="CR6">
                <label>6.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Connor</surname>
                      <given-names>JT</given-names>
                    </name>
                    <name>
                      <surname>Luce</surname>
                      <given-names>BR</given-names>
                    </name>
                    <name>
                      <surname>Broglio</surname>
                      <given-names>KR</given-names>
                    </name>
                    <name>
                      <surname>Ishak</surname>
                      <given-names>KJ</given-names>
                    </name>
                    <name>
                      <surname>Mullins</surname>
                      <given-names>CD</given-names>
                    </name>
                    <name>
                      <surname>Vanness</surname>
                      <given-names>DJ</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>Do Bayesian adaptive trials offer advantages for comparative effectiveness research? Protocol for the RE-ADAPT study</article-title>
                  <source>Clin Trials</source>
                  <year>2013</year>
                  <volume>10</volume>
                  <fpage>807</fpage>
                  <lpage>27</lpage>
                  <pub-id pub-id-type="doi">10.1177/1740774513497293</pub-id>
                  <?supplied-pmid 23983160?>
                  <pub-id pub-id-type="pmid">23983160</pub-id>
                </element-citation>
              </ref>
              <ref id="CR7">
                <label>7.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Bruno</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Durkalski</surname>
                      <given-names>VL</given-names>
                    </name>
                    <name>
                      <surname>Hall</surname>
                      <given-names>CE</given-names>
                    </name>
                    <name>
                      <surname>Juneja</surname>
                      <given-names>R</given-names>
                    </name>
                    <name>
                      <surname>Barsan</surname>
                      <given-names>WG</given-names>
                    </name>
                    <name>
                      <surname>Janis</surname>
                      <given-names>S</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>The Stroke Hyperglycemia Insulin Network Effort (SHINE) trial protocol: a randomized, blinded, efficacy trial of standard vs. intensive hyperglycemia management in acute stroke</article-title>
                  <source>Int J Stroke</source>
                  <year>2014</year>
                  <volume>9</volume>
                  <fpage>246</fpage>
                  <lpage>51</lpage>
                  <pub-id pub-id-type="doi">10.1111/ijs.12045</pub-id>
                  <?supplied-pmid 23506245?>
                  <pub-id pub-id-type="pmid">23506245</pub-id>
                </element-citation>
              </ref>
              <ref id="CR8">
                <label>8.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Gould</surname>
                      <given-names>AL</given-names>
                    </name>
                    <name>
                      <surname>Shih</surname>
                      <given-names>WJ</given-names>
                    </name>
                  </person-group>
                  <article-title>Modifying the design of ongoing trials without unblinding</article-title>
                  <source>Stat Med</source>
                  <year>1998</year>
                  <volume>17</volume>
                  <fpage>89</fpage>
                  <lpage>100</lpage>
                  <pub-id pub-id-type="doi">10.1002/(SICI)1097-0258(19980115)17:1&lt;89::AID-SIM730&gt;3.0.CO;2-D</pub-id>
                  <?supplied-pmid 9463852?>
                  <pub-id pub-id-type="pmid">9463852</pub-id>
                </element-citation>
              </ref>
              <ref id="CR9">
                <label>9.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Saville</surname>
                      <given-names>BR</given-names>
                    </name>
                    <name>
                      <surname>Connor</surname>
                      <given-names>JT</given-names>
                    </name>
                    <name>
                      <surname>Ayers</surname>
                      <given-names>GD</given-names>
                    </name>
                    <name>
                      <surname>Alvarez</surname>
                      <given-names>J</given-names>
                    </name>
                  </person-group>
                  <article-title>The utility of Bayesian predictive probabilities for interim monitoring of clinical trials</article-title>
                  <source>Clin Trials</source>
                  <year>2014</year>
                  <volume>11</volume>
                  <fpage>485</fpage>
                  <lpage>93</lpage>
                  <pub-id pub-id-type="doi">10.1177/1740774514531352</pub-id>
                  <?supplied-pmid 24872363?>
                  <pub-id pub-id-type="pmid">24872363</pub-id>
                </element-citation>
              </ref>
              <ref id="CR10">
                <label>10.</label>
                <mixed-citation publication-type="other">R Core Development Team. R: A language and environment for statistical computing. R Foundation for Statistical Computing Vienna Austria 2014. http:<ext-link ext-link-type="uri" xlink:href="http://www.r-project.org">www.R-project.org</ext-link>.</mixed-citation>
              </ref>
              <ref id="CR11">
                <label>11.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <collab>The National Institute of Neurological Disorders and Stroke rt-PA Stroke Study Group</collab>
                  </person-group>
                  <article-title>Tissue plasminogen activator for acute ischemic stroke</article-title>
                  <source>N Engl J Med</source>
                  <year>1995</year>
                  <volume>333</volume>
                  <fpage>1581</fpage>
                  <lpage>7</lpage>
                  <pub-id pub-id-type="doi">10.1056/NEJM199512143332401</pub-id>
                  <pub-id pub-id-type="pmid">7477192</pub-id>
                </element-citation>
              </ref>
              <ref id="CR12">
                <label>12.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Hampson</surname>
                      <given-names>LV</given-names>
                    </name>
                    <name>
                      <surname>Jennison</surname>
                      <given-names>C</given-names>
                    </name>
                  </person-group>
                  <article-title>Group sequential tests for delayed responses (with discussion): Group Sequential Tests</article-title>
                  <source>J Royal Stat Soc Ser B</source>
                  <year>2013</year>
                  <volume>75</volume>
                  <fpage>3</fpage>
                  <lpage>54</lpage>
                  <pub-id pub-id-type="doi">10.1111/j.1467-9868.2012.01030.x</pub-id>
                </element-citation>
              </ref>
              <ref id="CR13">
                <label>13.</label>
                <mixed-citation publication-type="other">Food and Drug Administration. Guidance for industry adaptive design clinical trials for drugs and biologics. 2010; <ext-link ext-link-type="uri" xlink:href="http://www.fda.gov/downloads/Drugs/Guidances/ucm201790.pdf">http://www.fda.gov/downloads/Drugs/Guidances/ucm201790.pdf</ext-link>.</mixed-citation>
              </ref>
              <ref id="CR14">
                <label>14.</label>
                <element-citation publication-type="book">
                  <person-group person-group-type="author">
                    <collab>Patient-Centered Outcomes Research Institute</collab>
                  </person-group>
                  <source>Draft Methodology Report: “Our Questions, Our Decisions: Standards for Patient-centered Outcomes Research”. Draft. Patient-Centered Outcomes Research Institute</source>
                  <year>2012</year>
                  <fpage>206</fpage>
                </element-citation>
              </ref>
            </ref-list>
          </back>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
