<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2024-05-03T04:00:36Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:6173230" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:6173230</identifier>
        <datestamp>2018-10-10</datestamp>
        <setSpec>bmjo</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" article-type="protocol">
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">BMJ Open</journal-id>
              <journal-id journal-id-type="iso-abbrev">BMJ Open</journal-id>
              <journal-id journal-id-type="hwp">bmjopen</journal-id>
              <journal-id journal-id-type="publisher-id">bmjopen</journal-id>
              <journal-title-group>
                <journal-title>BMJ Open</journal-title>
              </journal-title-group>
              <issn pub-type="epub">2044-6055</issn>
              <publisher>
                <publisher-name>BMJ Publishing Group</publisher-name>
                <publisher-loc>BMA House, Tavistock Square, London, WC1H 9JR</publisher-loc>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC6173230</article-id>
              <article-id pub-id-type="pmcid">PMC6173230</article-id>
              <article-id pub-id-type="pmc-uid">6173230</article-id>
              <article-id pub-id-type="pmid">30287612</article-id>
              <article-id pub-id-type="publisher-id">bmjopen-2018-023682</article-id>
              <article-id pub-id-type="doi">10.1136/bmjopen-2018-023682</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Mental Health</subject>
                  <subj-group>
                    <subject>Protocol</subject>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="hwp-journal-coll">
                  <subject>1506</subject>
                  <subject>1712</subject>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>Improving sensitivity to eye gaze cues in autism using serious game technology: study protocol for a phase I randomised controlled trial</article-title>
              </title-group>
              <contrib-group>
                <contrib id="author-62062495" contrib-type="author">
                  <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-0696-6362</contrib-id>
                  <name>
                    <surname>Scherf</surname>
                    <given-names>K. Suzanne</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff1">1</xref>
                </contrib>
                <contrib id="author-62082016" contrib-type="author">
                  <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-5341-0124</contrib-id>
                  <name>
                    <surname>Griffin</surname>
                    <given-names>Jason W</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff1">1</xref>
                </contrib>
                <contrib id="author-62082029" contrib-type="author">
                  <name>
                    <surname>Judy</surname>
                    <given-names>Brian</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff1">1</xref>
                </contrib>
                <contrib id="author-62082046" contrib-type="author">
                  <name>
                    <surname>Whyte</surname>
                    <given-names>Elisabeth M</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff1">1</xref>
                </contrib>
                <contrib id="author-62082072" contrib-type="author">
                  <name>
                    <surname>Geier</surname>
                    <given-names>Charles F</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff2">2</xref>
                </contrib>
                <contrib id="author-62082088" contrib-type="author">
                  <name>
                    <surname>Elbich</surname>
                    <given-names>Daniel</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff1">1</xref>
                </contrib>
                <contrib id="author-35211151" contrib-type="author">
                  <name>
                    <surname>Smyth</surname>
                    <given-names>Joshua M</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff3">3</xref>
                </contrib>
              </contrib-group>
              <aff id="aff1"><label>1</label><institution content-type="department">Department of Psychology</institution>, <institution>Pennsylvania State University</institution>, <addr-line content-type="city">University Park</addr-line>, <addr-line content-type="state">Pennsylvania</addr-line>, <country>USA</country></aff>
              <aff id="aff2"><label>2</label><institution content-type="department">Department of Human Development and Family Studies</institution>, <institution>Pennsylvania State University</institution>, <addr-line content-type="city">University Park</addr-line>, <addr-line content-type="state">Pennsylvania</addr-line>, <country>USA</country></aff>
              <aff id="aff3"><label>3</label><institution content-type="department">Department of Biobehavioral Health</institution>, <institution>Pennsylvania State University</institution>, <addr-line content-type="city">University Park</addr-line>, <addr-line content-type="state">Pennsylvania</addr-line>, <country>USA</country></aff>
              <author-notes>
                <corresp><label>Correspondence to</label> Dr K. Suzanne Scherf; <email>suzyscherf@psu.edu</email></corresp>
              </author-notes>
              <pub-date pub-type="collection">
                <year>2018</year>
              </pub-date>
              <pub-date pub-type="epub">
                <day>4</day>
                <month>10</month>
                <year>2018</year>
              </pub-date>
              <volume>8</volume>
              <issue>9</issue>
              <elocation-id>e023682</elocation-id>
              <history>
                <date date-type="received">
                  <day>18</day>
                  <month>4</month>
                  <year>2018</year>
                </date>
                <date date-type="rev-recd">
                  <day>23</day>
                  <month>7</month>
                  <year>2018</year>
                </date>
                <date date-type="accepted">
                  <day>22</day>
                  <month>8</month>
                  <year>2018</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>© Author(s) (or their employer(s)) 2018. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.</copyright-statement>
                <copyright-year>2018</copyright-year>
                <license license-type="open-access">
                  <license-p>This is an open access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited, appropriate credit is given, any changes made indicated, and the use is non-commercial. See: <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>.</license-p>
                </license>
              </permissions>
              <self-uri xlink:title="pdf" xlink:href="bmjopen-2018-023682.pdf"/>
              <self-uri content-type="reviewers-comments-pdf" xlink:href="bmjopen-2018-023682.reviewer_comments.pdf"/>
              <self-uri content-type="draft-revisions-pdf" xlink:href="bmjopen-2018-023682.draft_revisions.pdf"/>
              <abstract>
                <sec>
                  <title>Introduction</title>
                  <p>Autism spectrum disorder (ASD) is characterised by impairments in social communication. Core symptoms are deficits in social looking behaviours, including limited <italic>visual attention to faces</italic> and <italic>sensitivity to eye gaze cues.</italic> We designed an intervention game using serious game mechanics for adolescents with ASD. It is designed to train individuals with ASD to discover that the eyes, and shifts in gaze specifically, provide information about the external world. We predict that the game will increase understanding of gaze cues and attention to faces.</p>
                </sec>
                <sec>
                  <title>Methods and analysis</title>
                  <p>The Social Games for Adolescents with Autism (SAGA) trial is a preliminary, randomised controlled trial comparing the intervention game with a waitlist control condition. 34 adolescents (10–18 years) with ASD with a Full-Scale IQ between 70 and 130 and a minimum second grade reading level, and their parents, will be randomly assigned (equally to intervention or the control condition) following baseline assessments. Intervention participants will be instructed to play the computer game at home on a computer for ~30 min, three times a week. All families are tested in the lab at baseline and approximately 2 months following randomisation in all measures. Primary outcomes are assessed with eye tracking to measure sensitivity to eye gaze cues and social visual attention to faces; secondary outcomes are assessed with questionnaires to measure social skills and autism-like behaviours. The analyses will focus on evaluating the feasibility, safety and preliminary effectiveness of the intervention.</p>
                </sec>
                <sec>
                  <title>Ethics and dissemination</title>
                  <p>SAGA is approved by the Institutional Review Board at Pennsylvania State University (00005097). Findings will be disseminated via scientific conferences and peer-reviewed journals and to participants via newsletter. The intervention game will be available to families in the control condition after the full data are collected and if analyses indicate that it is effective.</p>
                </sec>
                <sec>
                  <title>Trial registration number</title>
                  <p><ext-link ext-link-type="uri" xlink:href="NCT02968225">NCT02968225</ext-link>.</p>
                </sec>
              </abstract>
              <kwd-group>
                <kwd>mental health</kwd>
              </kwd-group>
              <funding-group>
                <award-group id="funding-1">
                  <funding-source>
                    <institution-wrap>
                      <institution>U.S. National Institutes of Mental Health</institution>
                    </institution-wrap>
                  </funding-source>
                </award-group>
              </funding-group>
              <custom-meta-group>
                <custom-meta>
                  <meta-name>special-feature</meta-name>
                  <meta-value>unlocked</meta-value>
                </custom-meta>
              </custom-meta-group>
            </article-meta>
          </front>
          <body>
            <boxed-text id="BX1" position="float" orientation="portrait">
              <caption>
                <title>Strengths and limitations of this study</title>
              </caption>
              <list list-type="bullet">
                <list-item>
                  <p>This is a randomised controlled trial that employs an immersive computer game with serious game mechanics to maximise opportunities for adolescents with autism spectrum disorder (ASD) to discover the functional utility of eye gaze cues.</p>
                </list-item>
                <list-item>
                  <p>This intervention targets the developmental period of adolescence when eye gaze cues are especially important to changing social demands and when there are declining developmental trajectories in ASD.</p>
                </list-item>
                <list-item>
                  <p>Multiple eye tracking/behavioural metrics will be measured to assess improvements in social looking behaviour, which is a core symptom of ASD.</p>
                </list-item>
                <list-item>
                  <p>Given the nature of this design, the inability to use a completely blinded procedure is a limitation.</p>
                </list-item>
              </list>
            </boxed-text>
            <sec sec-type="intro" id="s1">
              <title>Introduction</title>
              <p>Autism spectrum disorder (ASD) is a neurodevelopmental disorder characterised by impairments in social communicative behaviours. Core symptoms of these impairments are deficits in social looking behaviours including limited <italic>visual attention to faces</italic> and <italic>sensitivity to eye gaze cues</italic>.<xref rid="R1" ref-type="bibr">1</xref> Reduced visual attention to faces is one of the earliest behavioural indicators of autism,<xref rid="R2" ref-type="bibr">2–4</xref> persists across the lifespan<xref rid="R5" ref-type="bibr">5–7</xref> and may serve as a reliable predictor of general social impairments in ASD.<xref rid="R8" ref-type="bibr">8</xref> It is related to difficulties recognising face identity<xref rid="R9" ref-type="bibr">9</xref> and emotional expressions<xref rid="R10" ref-type="bibr">10</xref> and interferes with learning in domains outside of face perception as well.<xref rid="R11" ref-type="bibr">11–13</xref> Similarly, reduced understanding of eye gaze cues is present in infants later diagnosed with autism<xref rid="R14" ref-type="bibr">14</xref> and persists through the first two decades of life.<xref rid="R12" ref-type="bibr">12 15 16</xref> It also has long-term consequences for understanding goal-directed behaviour,<xref rid="R6" ref-type="bibr">6 17 18</xref> learning language and social communication.<xref rid="R19" ref-type="bibr">19 20</xref> People with ASD have difficulty computing the trajectory of eye gaze, understanding the referential nature of gaze, and assigning social relevance to gazed-at objects.<xref rid="R17" ref-type="bibr">17 18</xref> This deficit impacts the ability to use eye gaze direction to predict the actions and intentions of others.</p>
              <p>One hypothesis about the underlying mechanism for these deficits suggests that individuals with ASD avoid looking at faces because doing so leads to an increased negative emotional response, as indexed by increased activation in the amygdala.<xref rid="R21" ref-type="bibr">21</xref> However, a review of the literature suggests that there is little support for this hypothesis.<xref rid="R22" ref-type="bibr">22</xref> Also, recent neuroimaging findings suggest that the neural systems for face processing are not impaired in autism; they are just tuned differently (ie, they exhibit typical levels of activation when looking at animal, but not human, faces).<xref rid="R23" ref-type="bibr">23</xref> Together, these findings suggest the need to consider other mechanisms for atypical social looking behaviour in ASD; we hypothesise an early disruption in the learning environment for individuals with autism that contributes to this altered tuning of the face processing system. Although the origin of this disruption is not clear, one hypothesis is that it emerges from atypical coordination between early developing subcortical social orienting and later developing cortical social perception systems.<xref rid="R24" ref-type="bibr">24</xref> The long-term developmental consequence from this disrupted learning environment is that it could deprive individuals with autism the opportunity to learn about the functional significance of social signals, like eye gaze, from the face. Accordingly, this atypical developmental context and learning cycle could lead to a state in which the face and eyes are not meaningful<xref rid="R25" ref-type="bibr">25</xref> to people with autism. Using this conceptual framework, we hypothesise that it may be possible to, in part, retune the face processing system by employing an intervention that encourages individuals with ASD to focus visual attention on faces and discover the functional significance of eye gaze cues. We propose to train individuals with ASD to discover that the eyes, and shifts in gaze specifically, provide critical information about the world around them. Our prediction is that attention to faces, particularly in more social contexts, will also improve as a result of increased understanding how to interpret eye gaze cues. The hope is that such training may begin to ameliorate core symptoms of ASD and potentially facilitate aspects of social functioning (eg, face processing and social communication).</p>
              <p>Existing studies have employed computer-based interventions for children and adolescents with ASD with the goal of improving aspects of face processing behaviour.<xref rid="R26" ref-type="bibr">26–29</xref> Most of these interventions, however, have not been very successful in producing long-term changes in behaviour for several reasons. First, they often target multiple components of face processing behaviour, including accuracy of gazed-at objects,<xref rid="R29" ref-type="bibr">29 30</xref> but do not isolate the active ingredients of the intervention on the outcome measures. Second, they often use highly repetitive and specific learning trials, which can lead to inflexible learning and behaviour in autism.<xref rid="R31" ref-type="bibr">31</xref> Third, none of the existing interventions evaluated changes in social visual attention, which is a diagnostic feature of ASD, using eye tracking measures as outcome behaviours. Fourth, although some of these studies have demonstrated learning during the course of the intervention, they have had only limited success in showing evidence of clinical change, particularly in real-world social skills.<xref rid="R32" ref-type="bibr">32</xref> We innovate beyond these previous computer-based interventions by embedding eye gaze direction cues within simulated social interactions with computer-animated characters and embed these interactions in an age-appropriate narrative storyline. This simulates the way social information cues are used in the real world and, we posit, is more likely to generalise to real-world behaviour. We designed the intervention game for adolescents because our prior work suggests that it is an important window of opportunity for altering declining developmental trajectories in autism.<xref rid="R33" ref-type="bibr">33–40</xref>
</p>
              <sec id="s1a">
                <title>Current serious game intervention</title>
                <p>We propose an intervention strategy that employs evidence-based ‘serious game’ mechanics (eg, storylines, long-term goals, and scaling difficulty) to design a learning environment that maximises opportunities for adolescents with ASD to discover the functional utility of eye gaze cues. <italic>Serious games</italic> are unique intervention tools that are designed to promote learning of targeted skills that are difficult and not rewarding for participants with the goal of improving real-life outcomes.<xref rid="R32" ref-type="bibr">32</xref> The game mechanics that are especially relevant for enhancing motivation in serious games include immersive storylines, goals directed around targeted skills, rewards and feedback about goal progress, increasing levels of difficulty, individualised training, and the provision of choice.<xref rid="R32" ref-type="bibr">32</xref> We designed a serious game in which participants discover that eye gaze cues are useful for guiding their own goal-directed behaviour to solve problems in the game. Participants learn to interpret non-verbal behaviours (eg, pointing, shoulder turns, head turning, and eye gaze cues) of game characters for the purpose of solving narrative-related quests (ie, mixing a potion in the chemistry lab to get gum off a locker in school). The game increases in task difficulty in response to successful demonstration of skills. Initial levels of the game allow participants to use multiple non-verbal behavioural cues to solve problems and increasingly focus on learning how to use eye gaze cues exclusively over time and with practice. This transitions to requiring participants to determine the direction of eye gaze cues with more precision, avoid highly salient objects that are not target gazed-at objects and differentiate predictive (eg, looking at an object of interest) from non-predictive (eg, avatar looking up as if to think before acting) eye gaze cues. Finally, in the most advanced levels of the game, participants learn to process eye gaze cues in episodes of joint attention between two avatars with all the same levels of complexity as are presented with the single avatar.</p>
              </sec>
              <sec id="s1b">
                <title>Aims and objectives</title>
                <p>The aims of this study are to assess the feasibility and safety of this serious game intervention and examine the initial evidence for its effectiveness to alter sensitivity to eye gaze and social visual attention to faces in adolescents with ASD. The preliminary randomised controlled trial (RCT) will be conducted to determine the following questions:<list list-type="order"><list-item><p>Is it possible to recruit and randomise participants into the serious game intervention versus a waitlist control condition?</p></list-item><list-item><p>Do adolescents engage with the game at the intended level (playing 90 min/week for 2 months)?</p></list-item><list-item><p>Is the intervention tolerable and safe (ie, does retention remain high across all data collection points with minimal to no adverse events)?</p></list-item><list-item><p>Does sensitivity to eye gaze improve disproportionately in the intervention compared with the waitlist control group?</p></list-item><list-item><p>Does social visual attention to faces improve disproportionately in the intervention compared with the waitlist control group?</p></list-item></list>
</p>
                <p>The trial will also allow exploratory analyses of changes in social skills and autism behaviours between the intervention and waitlist control group as a secondary measure of effectiveness of the intervention.</p>
              </sec>
            </sec>
            <sec sec-type="methods" id="s2">
              <title>Methods</title>
              <sec id="s2a">
                <title>Study design</title>
                <p>This study will be a preliminary, experimental RCT including an experimental group and a waitlist control group. The experimental group will consist of adolescents with ASD who will play an immersive computer game for 90 minutes a week over 2 months in their own home. This ‘dose’ of treatment was estimated based on the tolerance and relative amount of training required to evince learning in prior face-processing intervention studies of children and adolescents [28, Scherf, Whyte, Minshew &amp; Behrmann, ‘Adolescents with autism learn to individuate novel objects holistically: Replicated Longitudinal Intervention Studies’] and adults<xref rid="R41" ref-type="bibr">41</xref> with ASD. The goal is for participants to obtain a minimum of 10 hours of training specifically on eye gaze tasks across the 2-month training period, which may require a total of 15–20 hours of total game play. For this early trial, we will compare outcomes to a waitlist control group composed of adolescents with autism receiving treatment as usual in the community. The flow of participants through the study is shown in <xref ref-type="fig" rid="F1">figure 1</xref>. These methods are reported following the Standard Protocol Items: Recommendations for Interventional Trials guidelines.<xref rid="R42" ref-type="bibr">42</xref>
</p>
                <fig id="F1" orientation="portrait" position="float">
                  <label>Figure 1</label>
                  <caption>
                    <p>CONSORT diagram for SAGA protocol. ASD, autism spectrum disorder; CONSORT, Consolidated Standards of Reporting Trials; SAGA, Social Games for Adolescents with Autism.</p>
                  </caption>
                  <graphic xlink:href="bmjopen-2018-023682f01"/>
                </fig>
              </sec>
              <sec id="s2b">
                <title>Setting</title>
                <p>The study assessments will be conducted in the USA in the Laboratory of Developmental Neuroscience at Penn State University, University Park, Pennsylvania, and the intervention, itself, will be executed in the homes of intervention participants.</p>
              </sec>
              <sec id="s2c">
                <title>Participants</title>
                <sec id="s2c1">
                  <title>Inclusion criteria</title>
                  <p>Inclusion criteria are: (1) parent/caregiver of an adolescent with a diagnosis of ASD, (2) parent/caregiver and adolescent with ASD both native English speakers, (3) adolescent with ASD aged between 10 years and 18 years at enrolment, (4) adolescent has normal vision and hearing with correction as indicated by parent report, (5) adolescent is able to use a computer for the purposes of game play, (6) adolescent scores ≤80% correct (ie, 0.5 SD less than mean of TD adolescents (M=85.6%, SD=9.0%) on online eye gaze screening task, (7) ASD diagnosis of adolescent confirmed in the lab via the Autism Diagnostic Observation Schedule (ADOS),<xref rid="R43" ref-type="bibr">43</xref> (8) Full Scale IQ (FSIQ) of adolescent determined to be between 70 and 130 on the Kaufman Brief Intelligence Test,<xref rid="R44" ref-type="bibr">44</xref> (9) reading ability of adolescent determined to be at least a second grade level as assessed by the Oral and Written Language Scales,<xref rid="R45" ref-type="bibr">45</xref> (10) adolescent is capable of cooperating with testing, and (11) parent/caregiver and adolescent both consent/assent to participate in the research.</p>
                </sec>
                <sec id="s2c2">
                  <title>Exclusion criteria</title>
                  <p>Exclusion criteria are: (1) adolescent has had seizures within the previous 2 years, (2) family lacks stable home internet, (3) parent or adolescent refuses to consent/assent to take part in the research, (4) adolescent is 18 years and has a legal guardian, prohibiting him or her from legally consenting, or (5) adolescent is 18 years and cannot understand the consent (ie, fails consent quiz).</p>
                </sec>
              </sec>
              <sec id="s2d">
                <title>Sample size</title>
                <p>A meta-analysis indicates that computer-based interventions for individuals with ASD generally have a medium effect size (Cohen’s <italic>d</italic>=0.47).<xref rid="R46" ref-type="bibr">46</xref> Power calculations indicate that with a sample size of 34 (17 per group), and an expected correlation between the pretest/posttest measures of 0.58, we will have statistical power of 0.80 to detect a medium effect size for the expected group (intervention and control) × time (preintervention and postintervention) interaction with an <italic>α</italic> &lt;0.05 in this repeated-measures design.</p>
              </sec>
              <sec id="s2e">
                <title>Recruitment</title>
                <p>Our primary recruitment approach will be to recruit families who have registered with research databases like the Interactive Autism Network Research Database at the Kennedy Krieger Institute, Baltimore, and autismMatch at the Center for Autism Research, Philadelphia. Recruitment will proceed via a three-step process (see <xref ref-type="fig" rid="F1">figure 1</xref>). First, the initial inclusion/exclusion criteria will be determined via brief phone interview or by completing an online survey. Second, eligible adolescents will be invited to take an online test of sensitivity to eye gaze through a secure website (Testable.org). Participants view complex images of an actor in a naturalistic scene looking at one of many possible objects and have to identify the target gazed-at object from a list of four labels. We have used this task previously to investigate the influence of autistic-like traits on sensitivity to detect eye gaze cues in typically developing (TD) adults.<xref rid="R47" ref-type="bibr">47</xref> To evaluate the developmental appropriateness of the task, we tested a sample of 50 TD adolescents (ages 11–17 years). The TD adolescents performed above chance (<italic>M</italic>=85%, <italic>SD</italic>=9%) and below ceiling levels, which indicates sensitivity of the task to measure eye gaze cues in adolescents. Therefore, ASD participants who score minimally ½ <italic>SD</italic> below that of the TD adolescent mean (≤80%) on this online screening task will be invited to be evaluated for the remaining set of inclusion criteria. We will obtain written informed consent from the parent and 18-year-old adolescents and written assent from the adolescents aged 10–17 years to participate in the study (see <xref ref-type="supplementary-material" rid="SP2 SP3">supplementary appendices for consent/assent</xref>). Only after both consent and assent are obtained will we administer the remaining eligibility assessments. Participants who meet the final eligibility criteria are invited to continue with the pre-test procedures.</p>
              </sec>
              <sec id="s2f">
                <title>Randomisation procedures</title>
                <p>Following completion of the preintervention testing procedures, the principal investigator, who will not be involved in testing participants, will randomise participants in a 1:1 ratio into either the intervention game or waitlist control condition. The randomisation list will be computer-generated prior to the enrolment of any participants and will be stratified by sex and Full Scale IQ (&gt;100 and &lt;100). None of the researchers collecting data will have access to the randomisation list.</p>
              </sec>
              <sec id="s2g">
                <title>Blinding procedures</title>
                <p>Given the design of the study, parents and adolescents will know the condition to which they have been assigned. However, researchers involved in data collection will be blinded from condition assignment during the preintervention data collection session as these data will be collected prior to randomisation. Also, the research team is not involved in the randomisation process. The research team members who are involved in ensuring the fidelity of the intervention are not involved in data collection procedures. Although we will attempt to limit unblinding, it is not possible for researchers involved in data collection to be completely blinded to the assignment of participant condition at the postintervention visit as we cannot prohibit participants from talking to researchers about their experience in the study. Importantly, the primary outcome measures are believed to be robust to investigator bias.</p>
              </sec>
            </sec>
            <sec id="s3">
              <title>Intervention conducted in the experimental group</title>
              <p>The intervention video game is designed to engage and shape learning of sensitivity to eye gaze information and social attention to faces. Specifically, the game is structured around learning to use eye gaze as a cue for (1) directional reference (eg, put the object there; see <xref ref-type="fig" rid="F2">figure 2A</xref> for a screenshot from the game), first when gaze cues are highly predictive and subsequently when they are embedded in noisy cues that are not predictive of <italic>directional information</italic>; (2) reference to a specific object identity (eg, grab that one; see <xref ref-type="fig" rid="F2">figure 2B</xref>), first when gaze cues are highly predictive and subsequently when they are embedded in noisy cues that are not predictive of <italic>object information</italic>; and (3) joint attention episodes when two people (ie, avatars) engage in mutual gaze with each other and then engage in joint attention on the same specific object (eg, hey Matt, look at that one; see <xref ref-type="fig" rid="F2">figure 2C</xref>), first when gaze cues are highly predictive and subsequently when they are embedded in noisy cues that are not predictive of <italic>joint attention</italic>. The game is organised around three phases (see <xref ref-type="fig" rid="F3">figure 3A</xref>), which are composed of multiple levels (see <xref ref-type="fig" rid="F3">figure 3B</xref>), which are themselves composed of multiple stages (see <xref ref-type="fig" rid="F3">figure 3C</xref>). <xref ref-type="fig" rid="F3">Figure 3</xref> provides a schematic illustration of the structure of the game.</p>
              <fig id="F2" orientation="portrait" position="float">
                <label>Figure 2</label>
                <caption>
                  <p>Screenshots from multiple training conditions in the intervention game. (A). The avatar is instructing the participant to select 1 of 5 possible drawer locations using pointing, shoulder direction, head direction, and gaze cues in a room scene. (B). The avatar is directing the participant to select 1 of 6 possible tools to put on the peg board using pointing, shoulder direction, head direction, and gaze cues in a tool shed scene. (C). The two avatars are engaged in an episode of joint attention on the bowl and are inviting the participant to select it from 5 possible objects using pointing, shoulder direction, head direction, and gaze cues in a library scene.</p>
                </caption>
                <graphic xlink:href="bmjopen-2018-023682f02"/>
              </fig>
              <fig id="F3" orientation="portrait" position="float">
                <label>Figure 3</label>
                <caption>
                  <p>Schematic illustration of the intervention game structure. The game is designed to train learning about three functional uses of eye gaze cues including the use of gaze to reference locations and objects in the world via a single informant and in episodes of joint attention between multiple informants (A). The game is organised around three sequential phases. The tasks in phase 1 are structured to help participants learn that eye gaze is an important cue to solving problems in the game. The tasks in phase 2 help participants learn to estimate precise gaze trajectories by making target gazed-at objects closer together and to ignore salient objects that are not the target gazed-at object. Episodes of joint attention are also introduced in phase 2 in which participants have to determine the target object that two avatars are looking at together. This is difficult because the timing of the non-verbal cues to identify the object is not perfectly synchronous between the two avatars. In phase 3, the tasks are structured around helping participants learn the difference between a goal-directed gaze cue (eg, looking at a target object to solve a puzzle) and a non-goal-directed gaze cue (eg, looking around at all the objects before deciding which one to select). To complete a phase of the game, participants must finish all <italic>levels</italic> within a phase. Each phase has multiple levels (B). Levels are defined by the number of non-verbal cues avatars use to guide participants to solve puzzles in the game. Easy levels have multiple cues. Level progression increasingly focuses learning to use eye gaze cues exclusively by stripping away other cues. Within each level, there are six stages (C). Each stage represents the number of potential objects or locations that the participant has to discriminate between based on the cue from the avatar. In the easiest stage, the participant chooses between two objects or locations that the avatar is pointing, directing shoulders, head, and gaze to (as in level 1), whereas in stage 6, the participant chooses between six possible objects or locations that the avatar could be referring to with the non-verbal cue(s). Within each stage, participants have five trials. They must perform with 80% accuracy to advance to the next stage, and they must finish all stages within a level before they can progress to the next level within a phase. When they do not reach 80% accuracy within a stage, they are returned to the previous stage to reify the learning where they were recently successful. Sometimes that means they are returned to later stages of previous levels.</p>
                </caption>
                <graphic xlink:href="bmjopen-2018-023682f03"/>
              </fig>
              <p>The game is an adventure game with embedded gamification techniques in which participants solve mysteries in a 3D environment that is programmed in Unity (<ext-link ext-link-type="uri" xlink:href="https://unity3d.com/unity">https://unity3d.com/unity</ext-link>). The core training mechanisms are delivered via character interactions, with participants learning skills via simulated social interactions with avatars in the game as participants solve problems related to the game narrative. Each of these puzzles has variable elements so that they can be dynamically altered with different objects, locations, and levels of difficulty. Moreover, they are executed with a variety of characters and environmental contexts to support generalised learning opportunities.</p>
              <p>The training paradigm is much like a perceptual staircase paradigm in which participants start at a phase (<xref ref-type="fig" rid="F3">figure 3A</xref>), level (<xref ref-type="fig" rid="F3">figure 3B</xref>), and stage (<xref ref-type="fig" rid="F3">figure 3C</xref>) meant to be easily processed and accomplished by all participants. Individuals advance through stages within levels and then between levels and phases, until they hit a threshold where their skills plateau (see <xref ref-type="fig" rid="F3">figure 3C</xref>). When participants fail a stage, they go back to the preceding stage (and potentially phase or level) where they succeeded and must complete it before progressing to the failed stage/level/phase again. This keeps participants challenged without becoming too frustrated and allows them to practice and learn new skills. When participants repeat a stage or level, they do so in a new context with new avatars to foster generalisation of the learnt skills. If players are unable to progress from the easiest levels, they are redirected to remedial training in which more explicit guidance is afforded about how eye gaze cues provide information about objects and locations in the local environment (once completed, they are returned to the main game). See online <xref ref-type="supplementary-material" rid="SP1">supplementary figures 1–3</xref> for the full Unified Modeling Language (UML) diagrams illustrating progression through the game.</p>
              <supplementary-material content-type="local-data" id="SP1">
                <object-id pub-id-type="doi">10.1136/bmjopen-2018-023682.supp1</object-id>
                <label>Supplementary file 1</label>
                <p>
                  <inline-supplementary-material id="ss1" xlink:href="bmjopen-2018-023682supp001.pdf" mimetype="application" mime-subtype="pdf" content-type="local-data"/>
                </p>
              </supplementary-material>
              <p>Difficulty increases in several ways and is all controlled by choices of the individual participant, within design constraints of the game. First, the number of locations or objects that the avatars reference gradually increases across stages so that the precision of gaze sensitivity has to improve (see <xref ref-type="fig" rid="F3">figure 3C</xref>). Second, in the early levels of each phase of the game, participants are provided with multiple kinds of non-verbal social cues in their interactions with the avatars (see <xref ref-type="fig" rid="F3">figure 3B</xref>). For example, in the earliest levels of phase 1 of the game, the avatars simultaneously point, orient their shoulders, turn their head, and shift their eye gaze as cues to direct participants to solve quests in the game. As play progresses, learning is scaffolded by slowly removing the non-gaze social behaviours; ultimately avatars only direct participants via eye gaze cues (see <xref ref-type="fig" rid="F3">figure 3B</xref>). Third, once a participant has mastered the easiest levels of gaze shifts, the levels increase in difficulty by reducing the spacing between the objects (requiring more precise tracking of gaze trajectory) and by increasing the salience of the non-target objects (requiring increasing focus of attention on the target gazed-at object) as participants move into the more advanced phases of the game. Finally, at the most advanced phase and levels of the game, it is necessary to learn to ignore non-predictive shifts of gaze (eg, looking up pensively, looking across all objects before landing on target object) and only focus on the predictive gaze shifts (see <xref ref-type="fig" rid="F3">figure 3A</xref>).</p>
            </sec>
            <sec id="s4">
              <title>Outcome measures</title>
              <sec id="s4a">
                <title>Feasibility outcomes</title>
                <p>To measure intervention feasibility, in addition to participant attrition, we will report the mean number of sessions, total number of minutes played, total number of minutes engaged in eye gaze tasks, frequency of each level visited in the game, and accuracy of performance within each level of the game. The feasibility of the testing procedures will also be assessed. We will report adherence rates, means and SD for each outcome measure separately for each group in the preintervention and postintervention testing sessions. This will allow us to assess potential floor or ceiling effects in any of our measures, collect information relevant for determining effect sizes, and estimate sample sizes for a full trial.</p>
              </sec>
              <sec id="s4b">
                <title>Safety outcomes</title>
                <p>The intervention is expected to have minimal risk, because it is designed from an empirically informed approach, administered remotely, designed to flexibly accommodate participants’ schedule, and is semi-supervised. However, potential adverse events and unintended effects occurring during testing or the intervention period will be reported and explored. A Data Safety Monitoring Board (DSMB) will be instituted (see Study Monitoring). Additionally, self-report and behavioural measures will be used to monitor unanticipated risks. This includes a usability questionnaire about the intervention game experience in which participants rate multiple aspects of game play on a Likert scale (eg, Experience was fun; I felt discouraged) at the postintervention testing session. Procedures are in place to monitor suicidal ideation and self-injurious behaviour among adolescents and to make recommendations about care based on the assessment outcome.</p>
              </sec>
              <sec id="s4c">
                <title>Primary outcomes (intervention effectiveness)</title>
                <p>Primary and secondary outcomes will be measured at both the preintervention and postintervention sessions. We hypothesise that the intervention will improve eye gaze and social visual attention behaviours; therefore, all the primary measures of the intervention effectiveness are assessed with eye tracking technology. The analyses will focus on time spent looking at faces, which include the eyes, and gazed-at objects in the stimuli. Limiting the analyses to time spent looking at eyes may underestimate the effectiveness of the intervention, if adolescents only learn social communication cues related to turns of head, which are correlated with gaze cues, for example. Also, defining eye-specific areas of interest in dynamic stimuli can be imprecise and unreliable. The secondary measures evaluate changes in autism-like behaviours, social competence and problematic behaviours, which may be indirectly impacted by the intervention.</p>
                <sec id="s4c1">
                  <title>Visual attention to faces</title>
                  <p>This task is similar to that previously described.<xref rid="R48" ref-type="bibr">48</xref> Participants passively view six 42-second clips from age-appropriate movies of social interactions with two or more characters that are matched by adult raters on emotional intensity and valence, number of visible faces, and amount of time faces are present. Four of the movies are unique at each time point (pre and post) and two movies repeat across time points to assess reliability of measurement. The dependent measures include the <italic>average gaze time to faces</italic> and the <italic>proportion of total gaze time to faces</italic>.</p>
                </sec>
                <sec id="s4c2">
                  <title>Eye gaze sensitivity</title>
                  <p>We will assess eye gaze sensitivity in two tasks. In the <italic>static version</italic> of the task, participants view still images (n=40) of an actor in a naturalistic scene looking a one of many possible objects, like in the online eye gaze screening task.<xref rid="R17" ref-type="bibr">17 47</xref> Each image is displayed on a computer screen for 4 s. Participants must then identify the specific object that the person is looking at from a list of four labels presented on a subsequent screen. The dependent measures include both <italic>performance accuracy</italic> and the <italic>ratio of average gaze time to the target object versus average gaze time to non-target objects</italic>. Twenty-six images are unique at each time point and 14 images repeat across time points. None of the stimuli used in the online screening task will be used in the preintervention or postintervention testing sessions.</p>
                  <p>To measure sensitivity to real-time eye gaze cues, we will create a <italic>dynamic version</italic> of this static task that is modelled after dynamic stimuli used to test infant joint attention.<xref rid="R15" ref-type="bibr">15</xref> On each trial, participants watch a movie of a female actress looking into the camera, then directing her gaze to a target object, holding the gaze on the target object for several seconds, and returning her gaze back to the camera. At the end of each trial, participants identify the target gazed-at object from a list of four labels presented on a subsequent screen. The dependent measures include <italic>performance accuracy</italic>, <italic>gaze shifts between the face and target and non-target objects</italic>,<xref rid="R15" ref-type="bibr">15</xref> and <italic>ratio of average gaze time to the target object versus average gaze time to non-target objects</italic>. Twenty videos are unique at each time point and six videos repeat across time points.</p>
                </sec>
              </sec>
              <sec id="s4d">
                <title>Secondary outcomes (intervention effectiveness)</title>
                <sec id="s4d1">
                  <title>Autism, social, and problem behaviour questionnaires</title>
                  <p>To assess if the intervention influences autism symptoms, social skills, and adaptive functioning, parents and adolescents will complete the Social Skills Improvement System (SSIS)<xref rid="R49" ref-type="bibr">49</xref> and parents will complete the Social Responsiveness Scale, 2nd Edition (SRS-2).<xref rid="R50" ref-type="bibr">50</xref> On the SSIS measures, total scores will be computed separately for social skills and problem behaviour domains. Higher scores indicate the presence of more of these behaviours. We will compute the total score on the SRS-2; higher scores reflect more social impairment.</p>
                </sec>
              </sec>
              <sec id="s4e">
                <title>Patient and public involvement</title>
                <p>KSS has been working with adolescents with ASD and their families in research settings for 15 years. The decision to design an intervention that targets sensitivity to eye gaze cues has been informed by her personal interactions with families and their desire to improve adaptive social skills in their children. The decision to employ serious game mechanics was informed by positive feedback from adolescents with ASD who were tested in previous home-based computerised interventions [Scherf, Whyte, Minshew &amp; Behrmann, ‘Adolescents with autism learn to individuate novel objects holistically: Replicated Longitudinal Intervention Studies’]. The staff training and testing procedures used in this protocol, including accommodations in the testing rooms (ie, lighting, seating) and strategies for working with participants, are all informed by experiences and conversations with previous study participants with autism. Several adolescents with autism provided feedback to us about the intervention game during its development in pilot testing. Autism family networks will be used to facilitate recruitment into the study as described in the Recruitment section. We will inform participating families about findings from the study in the form of a newsletter (see Ethics and Dissemination). We will assess the burden of the intervention with a usability questionnaire (see Safety Outcomes). We thank all the families who have helped inform the development of this study.</p>
              </sec>
            </sec>
            <sec id="s5">
              <title>Data collection</title>
              <sec id="s5a">
                <title>Intervention data</title>
                <p>Strategies for maximising the fidelity of the video game intervention include: (1) establishing minimum computer requirements for participants, (2) designing instructional videos for participants about the game, (3) designing a web page portal for participants to find frequently asked questions about the game and submit electronic help tickets for technical problems, (4) establishing a texting reminder system on scheduled game play days for participants, (5) establishing a protocol for contacting parents when participants miss scheduled sessions of game play, (6) providing explicit directions to parents that no one else in the home is to play the intervention game, and (7) paying participants $5 for every 30 min of game play up to $200. Throughout the intervention, log files are generated for each participant with feasibility data (see Feasibility outcomes) for each day of game play. Log files will be uploaded every 8 min onto a secure, password-protected server that only designated research personnel can access. Data from the log files will be summarised across days and sessions for each participant.</p>
                <sec id="s5a1">
                  <title>Eye tracking data</title>
                  <p>Eye tracking data will be collected using a Tobii X2-60 eye tracker, which has a sampling rate of 60 Hz and approximate accuracy of 0.4° and precision of 0.34°. This eye tracker allows for bright and dark pupil eye tracking and small head movements, maximising comfort during testing (ie, no chin rest required). A nine-point automatic calibration procedure will be employed prior to each task to customise and accurately estimate gaze point calculations. To reduce fatigue and restlessness, we will incorporate multiple breaks in the eye tracking protocol for participants. To acclimate participants to the testing room and eye tracking equipment, we will include a 10 min warm up procedure and provide participants with an overview of the schedule of testing events. Based on pilot data collection with TD children, we estimate that the entire procedure for eye tracking will last approximately 70–90 min. The fidelity of the eye tracking data will be assessed through quality of the calibration procedure. Eye gaze samples in which there is no recordable information from at least one eye on the stimulus will be quantified as missing data. Measurement error of the eye tracking data will be minimised by having the same small number of highly trained researchers collect the data at both the preintervention and postintervention sessions.</p>
                </sec>
              </sec>
              <sec id="s5b">
                <title>Questionnaire data</title>
                <p>Parents complete questionnaires while adolescents are tested in the eye tracking protocol. Adolescents complete the questionnaires following completion of the eye tracking protocol. The SSIS is clinically relevant and is sensitive to changes in social abilities from behavioural interventions in individuals with ASD.<xref rid="R51" ref-type="bibr">51</xref> The SRS-2 is a reliable and valid measure of social impairment and repetitive behaviour as a single quantitative trait<xref rid="R52" ref-type="bibr">52</xref> and also includes multiple questions specifically related to eye gaze behaviours and face-processing abilities. Missing data will be handled in congruence with the standardised SSIS/SRS-2 procedures.</p>
              </sec>
            </sec>
            <sec id="s6">
              <title>Data management</title>
              <p>All analyses will be completed using standard statistical software (eg, R<sup>2</sup>). Data will be scored and entered into the programme for further preprocessing/data reduction and backed up in multiple locations (ie, lab server and back-up hard drive). Data will be deidentified and stored on in password-protected partitions of cloud and lab servers. Only research project investigators and staff approved to work on the project and listed in the Institutional Review Board (IRB) protocol will have access to the identified data.</p>
              <p>Prior to statistical analyses, all the data will be investigated for deviations from normality and transformed if necessary, and we will examine and manage statistical outlier data points (&gt;2 SD of the group mean) where appropriate. Following randomisation, and after the preintervention data are collected, we will determine whether the intervention and waitlist control groups differ on any demographic characteristics (eg, age, FSIQ, ADOS total score and online eye gaze screening scores). Variables with reliable differences will be submitted to the subsequent analyses of group differences as covariates.</p>
              <p>For the primary study outcomes, we will use linear mixed effects modelling to test the effectiveness of the intervention on outcome measures while accounting for repeated measures (ie, timepoint). Additionally, we plan to model variability in both stimulus items and participants by including them as random factors in our statistical models. For each dependent variable, we will fit a model with group (intervention and control) and timepoint (preintervention and postintervention) as fixed factors and age, IQ, and ADOS total score as covariates. The amount of missing eye gaze data will also be submitted as a covariate in analyses of intervention effectiveness.</p>
              <sec id="s6a">
                <title>Study monitoring</title>
                <p>A DSMB will be established and will be composed of independent researchers who have expertise complementary to the aims of the project. We will meet with the DSMB prior to enrolling participants in the study and biannually during the duration of the intervention to review the safety and tolerance of the intervention for our participants. Any adverse events will be reported to both the DSMB and the Penn State IRB.</p>
              </sec>
              <sec id="s6b">
                <title>Ethics and dissemination</title>
                <p>Results will be disseminated to the scientific community at scientific conferences and in the form of empirical articles in peer-reviewed scientific journals. Results will also be reported to the funding agency (National Institutes of Mental Health) annually and to ClinicalTrials.gov. Participants will be invited to share deidentified data acquired from this study with the National Institutes of Health Data Archive. Finally, we will present summaries of the findings in the form of a newsletter to study participants, and the intervention game will be made available to families in the waitlist control condition after the full data have been collected if analyses indicate that it is effective.</p>
              </sec>
            </sec>
            <sec sec-type="discussion" id="s7">
              <title>Discussion</title>
              <p>This intervention game may have great potential for translation and dissemination. By combining serious game design principles with intervention science, the resulting intervention game has the potential to be highly motivating, scalable to individual skill level, inexpensive, engaging, and accessible by adolescents in their own homes at their own convenience. Although we are enthusiastic about this approach, we do note several limitations of this study. First, we are not able to fully blind the researchers during the postintervention testing session; however, we think the outcome measures are likely to be fairly robust to experimenter bias. Second, our ability to estimate the feasibility of the intervention is potentially influenced by the fact that our participants are compensated for their time. Importantly, given that the intervention game was designed to foster intrinsic motivation, we expect that participants will want to play the game because it is interesting and motivating. Also, in order to be compensated for the full amount that is offered to participants, they have to play 25% more sessions (100) than the maximum we are asking them to play (72) and 75% than the minimum (24) we are asking them to play. Therefore, given the nature of the intervention game and compensation schedule, we think that the influence of financial compensation in this study will be less of a concern than it might be in other studies.</p>
              <p>In the future, we will continue to develop the intervention game with the goal of testing it against an active control game, evaluating if it is effective for improving a broader range of face processing behaviours that are difficult for individuals with ASD (eg, face identity recognition) and improving social skills in ASD. These data, including the generation of effect size estimates, will inform a future confirmatory clinical trial. More generally, these goals represent significant innovation in the design of RCTs for computer-based interventions for autism and may help advance theory and clinical practice.</p>
              <supplementary-material content-type="local-data" id="SP2">
                <object-id pub-id-type="doi">10.1136/bmjopen-2018-023682.supp2</object-id>
                <label>Supplementary file 2</label>
                <p>
                  <inline-supplementary-material id="ss2" xlink:href="bmjopen-2018-023682supp002.pdf" mimetype="application" mime-subtype="pdf" content-type="local-data"/>
                </p>
              </supplementary-material>
              <supplementary-material content-type="local-data" id="SP3">
                <object-id pub-id-type="doi">10.1136/bmjopen-2018-023682.supp3</object-id>
                <label>Supplementary file 3</label>
                <p>
                  <inline-supplementary-material id="ss3" xlink:href="bmjopen-2018-023682supp003.pdf" mimetype="application" mime-subtype="pdf" content-type="local-data"/>
                </p>
              </supplementary-material>
            </sec>
            <sec sec-type="supplementary-material">
              <title>Supplementary Material</title>
              <supplementary-material id="d35e224" content-type="local-data">
                <caption>
                  <title>Reviewer comments</title>
                </caption>
                <media mimetype="application" mime-subtype="pdf" xlink:href="bmjopen-2018-023682.reviewer_comments.pdf"/>
              </supplementary-material>
              <supplementary-material id="d35e225" content-type="local-data">
                <caption>
                  <title>Author's manuscript</title>
                </caption>
                <media mimetype="application" mime-subtype="pdf" xlink:href="bmjopen-2018-023682.draft_revisions.pdf"/>
              </supplementary-material>
            </sec>
          </body>
          <back>
            <fn-group>
              <fn fn-type="other">
                <p><bold>Contributors:</bold> KSS, EMW, JMS and CFG secured funding to support this project. KSS, EMW and JMS conceived and designed the study. KSS, EMW, JMS and BJ designed the intervention game. JWG will be responsible for testing participants. DE, JMS, CFG and KSS are responsible for designing the procedures to manage the fidelity of the intervention. JWG and DE will be responsible for managing the data generated during the project. JWG and KSS will conduct the statistical analyses of the data. KSS and JWG drafted the manuscript and all authors reviewed the manuscript for intellectual content and approved the final version.</p>
              </fn>
              <fn fn-type="other">
                <p><bold>Funding:</bold> This work is supported by National Institutes of Mental Health (R61-MH110624; PI KSS).</p>
              </fn>
              <fn fn-type="COI-statement">
                <p><bold>Competing interests:</bold> EMW was at the Department of Psychology at Pennsylvania State University when she contributed to this work. She is currently working for Daybreak Games in San Diego, California.</p>
              </fn>
              <fn fn-type="other">
                <p><bold>Patient consent:</bold> Next of kin consent obtained.</p>
              </fn>
              <fn fn-type="other">
                <p><bold>Ethics approval:</bold> Pennsylvania State University Institutional Review Board (IRB# 00005097).</p>
              </fn>
              <fn fn-type="other">
                <p><bold>Provenance and peer review:</bold> Not commissioned; externally peer reviewed.</p>
              </fn>
            </fn-group>
            <ref-list>
              <title>References</title>
              <ref id="R1">
                <label>1.</label>
                <mixed-citation publication-type="book"><collab>Association, AP</collab>. <source>Diagnostic and statistical manual of mental disorders: DSM-5</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>American Psychiatric Association</publisher-name>, <year>2013</year>.</mixed-citation>
              </ref>
              <ref id="R2">
                <label>2.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chawarska</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Macari</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Shic</surname><given-names>F</given-names></name></person-group><article-title>Decreased spontaneous attention to social scenes in 6-month-old infants later diagnosed with autism spectrum disorders</article-title>. <source>Biol Psychiatry</source><year>2013</year>;<volume>74</volume>:<fpage>195</fpage>–<lpage>203</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsych.2012.11.022</pub-id>
<pub-id pub-id-type="pmid">23313640</pub-id></mixed-citation>
              </ref>
              <ref id="R3">
                <label>3.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Falck-Ytter</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Bölte</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Gredebäck</surname><given-names>G</given-names></name></person-group><article-title>Eye tracking in early autism research</article-title>. <source>J Neurodev Disord</source><year>2013</year>;<volume>5</volume>:<fpage>28</fpage><pub-id pub-id-type="doi">10.1186/1866-1955-5-28</pub-id><pub-id pub-id-type="pmid">24069955</pub-id></mixed-citation>
              </ref>
              <ref id="R4">
                <label>4.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jones</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Klin</surname><given-names>A</given-names></name></person-group><article-title>Attention to eyes is present but in decline in 2-6-month-old infants later diagnosed with autism</article-title>. <source>Nature</source><year>2013</year>;<volume>504</volume>:<fpage>427</fpage>–<lpage>31</lpage>. <pub-id pub-id-type="doi">10.1038/nature12715</pub-id>
<pub-id pub-id-type="pmid">24196715</pub-id></mixed-citation>
              </ref>
              <ref id="R5">
                <label>5.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bird</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Press</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Richardson</surname><given-names>DC</given-names></name></person-group><article-title>The role of alexithymia in reduced eye-fixation in Autism spectrum conditions</article-title>. <source>J Autism Dev Disord</source><year>2011</year>;<volume>41</volume>:<fpage>1556</fpage>–<lpage>64</lpage>. <pub-id pub-id-type="doi">10.1007/s10803-011-1183-3</pub-id>
<pub-id pub-id-type="pmid">21298331</pub-id></mixed-citation>
              </ref>
              <ref id="R6">
                <label>6.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Guillon</surname><given-names>Q</given-names></name>, <name name-style="western"><surname>Hadjikhani</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Baduel</surname><given-names>S</given-names></name>, <etal>et al</etal></person-group><article-title>Visual social attention in autism spectrum disorder: insights from eye tracking studies</article-title>. <source>Neurosci Biobehav Rev</source><year>2014</year>;<volume>42</volume>:<fpage>279</fpage>–<lpage>97</lpage>. <pub-id pub-id-type="doi">10.1016/j.neubiorev.2014.03.013</pub-id>
<pub-id pub-id-type="pmid">24694721</pub-id></mixed-citation>
              </ref>
              <ref id="R7">
                <label>7.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jarrold</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Mundy</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Gwaltney</surname><given-names>M</given-names></name>, <etal>et al</etal></person-group><article-title>Social attention in a virtual public speaking task in higher functioning children with autism</article-title>. <source>Autism Res</source><year>2013</year>;<volume>6</volume>:<fpage>393</fpage>–<lpage>410</lpage>. <pub-id pub-id-type="doi">10.1002/aur.1302</pub-id>
<pub-id pub-id-type="pmid">23696132</pub-id></mixed-citation>
              </ref>
              <ref id="R8">
                <label>8.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Papagiannopoulou</surname><given-names>EA</given-names></name>, <name name-style="western"><surname>Chitty</surname><given-names>KM</given-names></name>, <name name-style="western"><surname>Hermens</surname><given-names>DF</given-names></name>, <etal>et al</etal></person-group><article-title>A systematic review and meta-analysis of eye-tracking studies in children with autism spectrum disorders</article-title>. <source>Soc Neurosci</source><year>2014</year>;<volume>9</volume>:<fpage>1</fpage>–<lpage>23</lpage>. <pub-id pub-id-type="doi">10.1080/17470919.2014.934966</pub-id>
<pub-id pub-id-type="pmid">24295535</pub-id></mixed-citation>
              </ref>
              <ref id="R9">
                <label>9.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Parish-Morris</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Chevallier</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Tonge</surname><given-names>N</given-names></name>, <etal>et al</etal></person-group><article-title>Visual attention to dynamic faces and objects is linked to face processing skills: a combined study of children with autism and controls</article-title>. <source>Front Psychol</source><year>2013</year>;<volume>4</volume>:<fpage>185</fpage><pub-id pub-id-type="doi">10.3389/fpsyg.2013.00185</pub-id><pub-id pub-id-type="pmid">23596436</pub-id></mixed-citation>
              </ref>
              <ref id="R10">
                <label>10.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bal</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Harden</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Lamb</surname><given-names>D</given-names></name>, <etal>et al</etal></person-group><article-title>Emotion recognition in children with autism spectrum disorders: relations to eye gaze and autonomic state</article-title>. <source>J Autism Dev Disord</source><year>2010</year>;<volume>40</volume>:<fpage>358</fpage>–<lpage>70</lpage>. <pub-id pub-id-type="doi">10.1007/s10803-009-0884-3</pub-id>
<pub-id pub-id-type="pmid">19885725</pub-id></mixed-citation>
              </ref>
              <ref id="R11">
                <label>11.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cornew</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Dobkins</surname><given-names>KR</given-names></name>, <name name-style="western"><surname>Akshoomoff</surname><given-names>N</given-names></name>, <etal>et al</etal></person-group><article-title>Atypical social referencing in infant siblings of children with autism spectrum disorders</article-title>. <source>J Autism Dev Disord</source><year>2012</year>;<volume>42</volume>:<fpage>2611</fpage>–<lpage>21</lpage>. <pub-id pub-id-type="doi">10.1007/s10803-012-1518-8</pub-id>
<pub-id pub-id-type="pmid">22456817</pub-id></mixed-citation>
              </ref>
              <ref id="R12">
                <label>12.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pickard</surname><given-names>KE</given-names></name>, <name name-style="western"><surname>Ingersoll</surname><given-names>BR</given-names></name></person-group><article-title>Brief report: High and low level initiations of joint attention, and response to joint attention: differential relationships with language and imitation</article-title>. <source>J Autism Dev Disord</source><year>2015</year>;<volume>45</volume>:<fpage>262</fpage>–<lpage>8</lpage>. <pub-id pub-id-type="doi">10.1007/s10803-014-2193-8</pub-id>
<pub-id pub-id-type="pmid">25035090</pub-id></mixed-citation>
              </ref>
              <ref id="R13">
                <label>13.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Freeman</surname><given-names>SF</given-names></name>, <name name-style="western"><surname>Gulsrud</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Kasari</surname><given-names>C</given-names></name></person-group><article-title>Brief report: linking early joint attention and play abilities to later reports of friendships for children with ASD</article-title>. <source>J Autism Dev Disord</source><year>2015</year>;<volume>45</volume>:<fpage>2259</fpage>–<lpage>66</lpage>. <pub-id pub-id-type="doi">10.1007/s10803-015-2369-x</pub-id>
<pub-id pub-id-type="pmid">25676684</pub-id></mixed-citation>
              </ref>
              <ref id="R14">
                <label>14.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bedford</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Elsabbagh</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Gliga</surname><given-names>T</given-names></name>, <etal>et al</etal></person-group><article-title>Precursors to social and communication difficulties in infants at-risk for autism: gaze following and attentional engagement</article-title>. <source>J Autism Dev Disord</source><year>2012</year>;<volume>42</volume>:<fpage>2208</fpage>–<lpage>18</lpage>. <pub-id pub-id-type="doi">10.1007/s10803-012-1450-y</pub-id>
<pub-id pub-id-type="pmid">22278030</pub-id></mixed-citation>
              </ref>
              <ref id="R15">
                <label>15.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Falck-Ytter</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Fernell</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Hedvall</surname><given-names>AL</given-names></name>, <etal>et al</etal></person-group><article-title>Gaze performance in children with autism spectrum disorder when observing communicative actions</article-title>. <source>J Autism Dev Disord</source><year>2012</year>;<volume>42</volume>:<fpage>2236</fpage>–<lpage>45</lpage>. <pub-id pub-id-type="doi">10.1007/s10803-012-1471-6</pub-id>
<pub-id pub-id-type="pmid">22354708</pub-id></mixed-citation>
              </ref>
              <ref id="R16">
                <label>16.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fletcher-Watson</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Leekam</surname><given-names>SR</given-names></name>, <name name-style="western"><surname>Benson</surname><given-names>V</given-names></name>, <etal>et al</etal></person-group><article-title>Eye-movements reveal attention to social information in autism spectrum disorder</article-title>. <source>Neuropsychologia</source><year>2009</year>;<volume>47</volume>:<fpage>248</fpage>–<lpage>57</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2008.07.016</pub-id>
<pub-id pub-id-type="pmid">18706434</pub-id></mixed-citation>
              </ref>
              <ref id="R17">
                <label>17.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Riby</surname><given-names>DM</given-names></name>, <name name-style="western"><surname>Hancock</surname><given-names>PJ</given-names></name>, <name name-style="western"><surname>Jones</surname><given-names>N</given-names></name>, <etal>et al</etal></person-group><article-title>Spontaneous and cued gaze-following in autism and Williams syndrome</article-title>. <source>J Neurodev Disord</source><year>2013</year>;<volume>5</volume>:<fpage>13</fpage><pub-id pub-id-type="doi">10.1186/1866-1955-5-13</pub-id><pub-id pub-id-type="pmid">23663405</pub-id></mixed-citation>
              </ref>
              <ref id="R18">
                <label>18.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vivanti</surname><given-names>G</given-names></name>, <name name-style="western"><surname>McCormick</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Young</surname><given-names>GS</given-names></name>, <etal>et al</etal></person-group><article-title>Intact and impaired mechanisms of action understanding in autism</article-title>. <source>Dev Psychol</source><year>2011</year>;<volume>47</volume>:<fpage>841</fpage>–<lpage>56</lpage>. <pub-id pub-id-type="doi">10.1037/a0023105</pub-id>
<pub-id pub-id-type="pmid">21401220</pub-id></mixed-citation>
              </ref>
              <ref id="R19">
                <label>19.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kasari</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Gulsrud</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Freeman</surname><given-names>S</given-names></name>, <etal>et al</etal></person-group><article-title>Longitudinal follow-up of children with autism receiving targeted interventions on joint attention and play</article-title>. <source>J Am Acad Child Adolesc Psychiatry</source><year>2012</year>;<volume>51</volume>:<fpage>487</fpage>–<lpage>95</lpage>. <pub-id pub-id-type="doi">10.1016/j.jaac.2012.02.019</pub-id>
<pub-id pub-id-type="pmid">22525955</pub-id></mixed-citation>
              </ref>
              <ref id="R20">
                <label>20.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gulsrud</surname><given-names>AC</given-names></name>, <name name-style="western"><surname>Hellemann</surname><given-names>GS</given-names></name>, <name name-style="western"><surname>Freeman</surname><given-names>SF</given-names></name>, <etal>et al</etal></person-group><article-title>Two to ten years: developmental trajectories of joint attention in children with ASD who received targeted social communication interventions</article-title>. <source>Autism Res</source><year>2014</year>;<volume>7</volume>:<fpage>207</fpage>–<lpage>15</lpage>. <pub-id pub-id-type="doi">10.1002/aur.1360</pub-id>
<pub-id pub-id-type="pmid">24550145</pub-id></mixed-citation>
              </ref>
              <ref id="R21">
                <label>21.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dalton</surname><given-names>KM</given-names></name>, <name name-style="western"><surname>Nacewicz</surname><given-names>BM</given-names></name>, <name name-style="western"><surname>Johnstone</surname><given-names>T</given-names></name>, <etal>et al</etal></person-group><article-title>Gaze fixation and the neural circuitry of face processing in autism</article-title>. <source>Nat Neurosci</source><year>2005</year>;<volume>8</volume>:<fpage>519</fpage>–<lpage>26</lpage>. <pub-id pub-id-type="doi">10.1038/nn1421</pub-id>
<pub-id pub-id-type="pmid">15750588</pub-id></mixed-citation>
              </ref>
              <ref id="R22">
                <label>22.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Falck-Ytter</surname><given-names>T</given-names></name>, <name name-style="western"><surname>von Hofsten</surname><given-names>C</given-names></name></person-group><article-title>How special is social looking in ASD: a review</article-title>. <source>Prog Brain Res</source><year>2011</year>;<volume>189</volume>:<fpage>209</fpage>–<lpage>22</lpage>. <pub-id pub-id-type="doi">10.1016/B978-0-444-53884-0.00026-9</pub-id>
<pub-id pub-id-type="pmid">21489391</pub-id></mixed-citation>
              </ref>
              <ref id="R23">
                <label>23.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Whyte</surname><given-names>EM</given-names></name>, <name name-style="western"><surname>Behrmann</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Minshew</surname><given-names>NJ</given-names></name>, <etal>et al</etal></person-group><article-title>Animal, but not human, faces engage the distributed face network in adolescents with autism</article-title>. <source>Dev Sci</source><year>2016</year>;<volume>19</volume>:<fpage>306</fpage>–<lpage>17</lpage>. <pub-id pub-id-type="doi">10.1111/desc.12305</pub-id>
<pub-id pub-id-type="pmid">25873084</pub-id></mixed-citation>
              </ref>
              <ref id="R24">
                <label>24.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Johnson</surname><given-names>MH</given-names></name></person-group><article-title>Autism: demise of the innate social orienting hypothesis</article-title>. <source>Curr Biol</source><year>2014</year>;<volume>24</volume>:<fpage>R30</fpage>–<lpage>R31</lpage>. <pub-id pub-id-type="doi">10.1016/j.cub.2013.11.021</pub-id>
<pub-id pub-id-type="pmid">24405675</pub-id></mixed-citation>
              </ref>
              <ref id="R25">
                <label>25.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Klin</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Jones</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Schultz</surname><given-names>R</given-names></name>, <etal>et al</etal></person-group><article-title>Visual fixation patterns during viewing of naturalistic social situations as predictors of social competence in individuals with autism</article-title>. <source>Arch Gen Psychiatry</source><year>2002</year>;<volume>59</volume>:<fpage>809</fpage>–<lpage>16</lpage>. <pub-id pub-id-type="doi">10.1001/archpsyc.59.9.809</pub-id>
<pub-id pub-id-type="pmid">12215080</pub-id></mixed-citation>
              </ref>
              <ref id="R26">
                <label>26.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Faja</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Webb</surname><given-names>SJ</given-names></name>, <name name-style="western"><surname>Jones</surname><given-names>E</given-names></name>, <etal>et al</etal></person-group><article-title>The effects of face expertise training on the behavioral performance and brain activity of adults with high functioning autism spectrum disorders</article-title>. <source>J Autism Dev Disord</source><year>2012</year>;<volume>42</volume>:<fpage>278</fpage>–<lpage>93</lpage>. <pub-id pub-id-type="doi">10.1007/s10803-011-1243-8</pub-id>
<pub-id pub-id-type="pmid">21484517</pub-id></mixed-citation>
              </ref>
              <ref id="R27">
                <label>27.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Golan</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Baron-Cohen</surname><given-names>S</given-names></name></person-group><article-title>Systemizing empathy: teaching adults with Asperger syndrome or high-functioning autism to recognize complex emotions using interactive multimedia</article-title>. <source>Dev Psychopathol</source><year>2006</year>;<volume>18</volume>:<fpage>591</fpage>–<lpage>617</lpage>. <pub-id pub-id-type="doi">10.1017/S0954579406060305</pub-id>
<pub-id pub-id-type="pmid">16600069</pub-id></mixed-citation>
              </ref>
              <ref id="R28">
                <label>28.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tanaka</surname><given-names>JW</given-names></name>, <name name-style="western"><surname>Wolf</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Klaiman</surname><given-names>C</given-names></name>, <etal>et al</etal></person-group><article-title>Using computerized games to teach face recognition skills to children with autism spectrum disorder: the Let’s Face It! program</article-title>. <source>J Child Psychol Psychiatry</source><year>2010</year>;<volume>51</volume>:<fpage>944</fpage>–<lpage>52</lpage>. <pub-id pub-id-type="doi">10.1111/j.1469-7610.2010.02258.x</pub-id>
<pub-id pub-id-type="pmid">20646129</pub-id></mixed-citation>
              </ref>
              <ref id="R29">
                <label>29.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hopkins</surname><given-names>IM</given-names></name>, <name name-style="western"><surname>Gower</surname><given-names>MW</given-names></name>, <name name-style="western"><surname>Perez</surname><given-names>TA</given-names></name>, <etal>et al</etal></person-group><article-title>Avatar assistant: improving social skills in students with an ASD through a computer-based intervention</article-title>. <source>J Autism Dev Disord</source><year>2011</year>;<volume>41</volume>:<fpage>1543</fpage>–<lpage>55</lpage>. <pub-id pub-id-type="doi">10.1007/s10803-011-1179-z</pub-id>
<pub-id pub-id-type="pmid">21287255</pub-id></mixed-citation>
              </ref>
              <ref id="R30">
                <label>30.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rice</surname><given-names>LM</given-names></name>, <name name-style="western"><surname>Wall</surname><given-names>CA</given-names></name>, <name name-style="western"><surname>Fogel</surname><given-names>A</given-names></name>, <etal>et al</etal></person-group><article-title>Computer-assisted face processing instruction improves emotion recognition, mentalizing, and social skills in students with ASD</article-title>. <source>J Autism Dev Disord</source><year>2015</year>;<volume>45</volume>:<fpage>2176</fpage>–<lpage>86</lpage>. <pub-id pub-id-type="doi">10.1007/s10803-015-2380-2</pub-id>
<pub-id pub-id-type="pmid">25694364</pub-id></mixed-citation>
              </ref>
              <ref id="R31">
                <label>31.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Harris</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Israeli</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Minshew</surname><given-names>N</given-names></name>, <etal>et al</etal></person-group><article-title>Perceptual learning in autism: over-specificity and possible remedies</article-title>. <source>Nat Neurosci</source><year>2015</year>;<volume>18</volume>:<fpage>1574</fpage>–<lpage>6</lpage>. <pub-id pub-id-type="doi">10.1038/nn.4129</pub-id>
<pub-id pub-id-type="pmid">26436903</pub-id></mixed-citation>
              </ref>
              <ref id="R32">
                <label>32.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Whyte</surname><given-names>EM</given-names></name>, <name name-style="western"><surname>Smyth</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Scherf</surname><given-names>KS</given-names></name></person-group><article-title>Designing serious game interventions for individuals with autism</article-title>. <source>J Autism Dev Disord</source><year>2015</year>;<volume>45</volume>:<fpage>3820</fpage>–<lpage>31</lpage>. <pub-id pub-id-type="doi">10.1007/s10803-014-2333-1</pub-id>
<pub-id pub-id-type="pmid">25488121</pub-id></mixed-citation>
              </ref>
              <ref id="R33">
                <label>33.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Scherf</surname><given-names>KS</given-names></name>, <name name-style="western"><surname>Behrmann</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Dahl</surname><given-names>RE</given-names></name></person-group><article-title>Facing changes and changing faces in adolescence: a new model for investigating adolescent-specific interactions between pubertal, brain and behavioral development</article-title>. <source>Dev Cogn Neurosci</source><year>2012</year>;<volume>2</volume>:<fpage>199</fpage>–<lpage>219</lpage>. <pub-id pub-id-type="doi">10.1016/j.dcn.2011.07.016</pub-id>
<pub-id pub-id-type="pmid">22483070</pub-id></mixed-citation>
              </ref>
              <ref id="R34">
                <label>34.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Garcia</surname><given-names>NV</given-names></name>, <name name-style="western"><surname>Scherf</surname><given-names>KS</given-names></name></person-group><article-title>Emerging sensitivity to socially complex expressions: a unique role for adolescence?</article-title><source>Child Dev Perspect</source><year>2015</year>;<volume>9</volume>:<fpage>84</fpage>–<lpage>90</lpage>. <pub-id pub-id-type="doi">10.1111/cdep.12114</pub-id>
</mixed-citation>
              </ref>
              <ref id="R35">
                <label>35.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Motta-Mena</surname><given-names>NV</given-names></name>, <name name-style="western"><surname>Scherf</surname><given-names>KS</given-names></name></person-group><article-title>Pubertal development shapes perception of complex facial expressions</article-title>. <source>Dev Sci</source><year>2017</year>;<volume>20</volume>:<fpage>e12451</fpage><pub-id pub-id-type="doi">10.1111/desc.12451</pub-id></mixed-citation>
              </ref>
              <ref id="R36">
                <label>36.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Scherf</surname><given-names>KS</given-names></name>, <name name-style="western"><surname>Behrmann</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Minshew</surname><given-names>N</given-names></name>, <etal>et al</etal></person-group><article-title>Atypical development of face and greeble recognition in autism</article-title>. <source>J Child Psychol Psychiatry</source><year>2008</year>;<volume>49</volume>:<fpage>838</fpage>–<lpage>47</lpage>. <pub-id pub-id-type="doi">10.1111/j.1469-7610.2008.01903.x</pub-id>
<pub-id pub-id-type="pmid">18422548</pub-id></mixed-citation>
              </ref>
              <ref id="R37">
                <label>37.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Scherf</surname><given-names>KS</given-names></name>, <name name-style="western"><surname>Luna</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Minshew</surname><given-names>N</given-names></name>, <etal>et al</etal></person-group><article-title>Location, location, location: Alterations in the functional topography of face- but not object- or place-related cortex in adolescents with autism</article-title>. <source>Front Hum Neurosci</source><year>2010</year>;<volume>4</volume>:<fpage>26</fpage><pub-id pub-id-type="doi">10.3389/fnhum.2010.00026</pub-id><pub-id pub-id-type="pmid">20631857</pub-id></mixed-citation>
              </ref>
              <ref id="R38">
                <label>38.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Scherf</surname><given-names>KS</given-names></name>, <name name-style="western"><surname>Luna</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Kimchi</surname><given-names>R</given-names></name>, <etal>et al</etal></person-group><article-title>Missing the big picture: impaired development of global shape processing in autism</article-title>. <source>Autism Res</source><year>2008</year>;<volume>1</volume>:<fpage>114</fpage>–<lpage>29</lpage>. <pub-id pub-id-type="doi">10.1002/aur.17</pub-id>
<pub-id pub-id-type="pmid">19360658</pub-id></mixed-citation>
              </ref>
              <ref id="R39">
                <label>39.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Scherf</surname><given-names>KS</given-names></name>, <name name-style="western"><surname>Elbich</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Minshew</surname><given-names>N</given-names></name>, <etal>et al</etal></person-group><article-title>Individual differences in symptom severity and behavior predict neural activation during face processing in adolescents with autism</article-title>. <source>Neuroimage Clin</source><year>2015</year>;<volume>7</volume>:<fpage>53</fpage>–<lpage>67</lpage>. <pub-id pub-id-type="doi">10.1016/j.nicl.2014.11.003</pub-id>
<pub-id pub-id-type="pmid">25610767</pub-id></mixed-citation>
              </ref>
              <ref id="R40">
                <label>40.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Picci</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Scherf</surname><given-names>KS</given-names></name></person-group><article-title>A two-hit model of autism: adolescence as the second hit</article-title>. <source>Clin Psychol Sci</source><year>2015</year>;<volume>3</volume>:<fpage>349</fpage>–<lpage>71</lpage>. <pub-id pub-id-type="doi">10.1177/2167702614540646</pub-id>
<pub-id pub-id-type="pmid">26609500</pub-id></mixed-citation>
              </ref>
              <ref id="R41">
                <label>41.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Damiano</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Churches</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Ring</surname><given-names>H</given-names></name>, <etal>et al</etal></person-group><article-title>The development of perceptual expertise for faces and objects in autism spectrum conditions</article-title>. <source>Autism Res</source><year>2011</year>;<volume>4</volume>:<fpage>297</fpage>–<lpage>301</lpage>. <pub-id pub-id-type="doi">10.1002/aur.205</pub-id>
<pub-id pub-id-type="pmid">21710603</pub-id></mixed-citation>
              </ref>
              <ref id="R42">
                <label>42.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chan</surname><given-names>AW</given-names></name>, <name name-style="western"><surname>Tetzlaff</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Altman</surname><given-names>DG</given-names></name>, <etal>et al</etal></person-group><article-title>SPIRIT 2013 statement: defining standard protocol items for clinical trials</article-title>. <source>Ann Intern Med</source><year>2013</year>;<volume>158</volume>:<fpage>200</fpage>–<lpage>7</lpage>. <pub-id pub-id-type="doi">10.7326/0003-4819-158-3-201302050-00583</pub-id>
<pub-id pub-id-type="pmid">23295957</pub-id></mixed-citation>
              </ref>
              <ref id="R43">
                <label>43.</label>
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Rutter</surname><given-names>M</given-names></name>, <name name-style="western"><surname>DiLavore</surname><given-names>PC</given-names></name>, <name name-style="western"><surname>Risi</surname><given-names>S</given-names></name>, <etal>et al</etal></person-group><source>Autism diagnostic observation schedule: ADOS-2</source>. <publisher-loc>Los Angeles, CA</publisher-loc>: <publisher-name>Western Psychological Services</publisher-name>, <year>2012</year>.</mixed-citation>
              </ref>
              <ref id="R44">
                <label>44.</label>
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Kaufman</surname><given-names>AS</given-names></name>, <name name-style="western"><surname>Kaufman</surname><given-names>NL</given-names></name></person-group><source>Kaufman Brief Intelligence Test</source>. <edition>2nd ed</edition><publisher-loc>Circle Pines, MN</publisher-loc>: <publisher-name>AGS</publisher-name>, <year>2004</year>.</mixed-citation>
              </ref>
              <ref id="R45">
                <label>45.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Carrow-Woolfolk</surname><given-names>E</given-names></name></person-group><article-title>OWLS, Oral and written language scales</article-title>. <source>NCS Pearson Incorporated</source><year>1995</year>.</mixed-citation>
              </ref>
              <ref id="R46">
                <label>46.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Grynszpan</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Weiss</surname><given-names>PL</given-names></name>, <name name-style="western"><surname>Perez-Diaz</surname><given-names>F</given-names></name>, <etal>et al</etal></person-group><article-title>Innovative technology-based interventions for autism spectrum disorders: a meta-analysis</article-title>. <source>Autism</source><year>2014</year>;<volume>18</volume>:<fpage>346</fpage>–<lpage>61</lpage>. <pub-id pub-id-type="doi">10.1177/1362361313476767</pub-id>
<pub-id pub-id-type="pmid">24092843</pub-id></mixed-citation>
              </ref>
              <ref id="R47">
                <label>47.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Whyte</surname><given-names>EM</given-names></name>, <name name-style="western"><surname>Scherf</surname><given-names>KS</given-names></name></person-group><article-title>Gaze following is related to the broader autism phenotype in a sex-specific way: building the case for distinct male and female autism phenotypes</article-title>. <source>Clin Psychol Sci</source><year>2018</year>;<volume>6</volume>:<fpage>280</fpage>–<lpage>7</lpage>. <pub-id pub-id-type="doi">10.1177/2167702617738380</pub-id>
<pub-id pub-id-type="pmid">29576931</pub-id></mixed-citation>
              </ref>
              <ref id="R48">
                <label>48.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rice</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Moriuchi</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Jones</surname><given-names>W</given-names></name>, <etal>et al</etal></person-group><article-title>Parsing heterogeneity in autism spectrum disorders: visual scanning of dynamic social scenes in school-aged children</article-title>. <source>J Am Acad Child Adolesc Psychiatry</source><year>2012</year>;<volume>51</volume>:<fpage>238</fpage>–<lpage>48</lpage>. <pub-id pub-id-type="doi">10.1016/j.jaac.2011.12.017</pub-id>
<pub-id pub-id-type="pmid">22365460</pub-id></mixed-citation>
              </ref>
              <ref id="R49">
                <label>49.</label>
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Gresham</surname><given-names>FM</given-names></name>, <name name-style="western"><surname>Elliott</surname><given-names>SN</given-names></name></person-group><source>Social Skills Improvement System: Rating Scales</source>. <publisher-loc>Bloomington, MN</publisher-loc>: <publisher-name>Pearson Assessments</publisher-name>, <year>2008</year>.</mixed-citation>
              </ref>
              <ref id="R50">
                <label>50.</label>
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Constantino</surname><given-names>JN</given-names></name></person-group><chapter-title>Gruber</chapter-title><source>Social Responsiveness Scale Manual SRS-2</source>. <edition>2Edn</edition><publisher-loc>Los Angeles, CA</publisher-loc>: <publisher-name>Western Psychological Services</publisher-name>, <year>2012</year>.</mixed-citation>
              </ref>
              <ref id="R51">
                <label>51.</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Anagnostou</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Jones</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Huerta</surname><given-names>M</given-names></name>, <etal>et al</etal></person-group><article-title>Measuring social communication behaviors as a treatment endpoint in individuals with autism spectrum disorder</article-title>. <source>Autism</source><year>2015</year>;<volume>19</volume><pub-id pub-id-type="doi">10.1177/1362361314542955</pub-id></mixed-citation>
              </ref>
              <ref id="R52">
                <label>52.</label>
                <mixed-citation publication-type="book"><collab>R Core Team</collab>. <source>R: A language and environment for statistical computing</source>. <publisher-loc>Vienna, Austria</publisher-loc>: <publisher-name>R Foundation for Statistical Computing</publisher-name>, <year>2018</year><uri xlink:href="https://www.R-project.org/">https://www.R-project.org/</uri>.</mixed-citation>
              </ref>
            </ref-list>
          </back>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
