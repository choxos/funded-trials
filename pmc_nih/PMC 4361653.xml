<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2024-05-03T05:18:16Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:4361653" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:4361653</identifier>
        <datestamp>2015-03-23</datestamp>
        <setSpec>plosone</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" article-type="research-article">
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
              <journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id>
              <journal-id journal-id-type="publisher-id">plos</journal-id>
              <journal-id journal-id-type="pmc">plosone</journal-id>
              <journal-title-group>
                <journal-title>PLoS ONE</journal-title>
              </journal-title-group>
              <issn pub-type="epub">1932-6203</issn>
              <publisher>
                <publisher-name>Public Library of Science</publisher-name>
                <publisher-loc>San Francisco, CA USA</publisher-loc>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC4361653</article-id>
              <article-id pub-id-type="pmcid">PMC4361653</article-id>
              <article-id pub-id-type="pmc-uid">4361653</article-id>
              <article-id pub-id-type="pmid">25774508</article-id>
              <article-id pub-id-type="pmid">25774508</article-id>
              <article-id pub-id-type="doi">10.1371/journal.pone.0119828</article-id>
              <article-id pub-id-type="publisher-id">PONE-D-14-43443</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Research Article</subject>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>Postural Sway and Gaze Can Track the Complex Motion of a Visual Target</article-title>
                <alt-title alt-title-type="running-head">Tracking of Complex Targets</alt-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author" equal-contrib="yes">
                  <name>
                    <surname>Hatzitaki</surname>
                    <given-names>Vassilia</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff001">
                    <sup>1</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author" equal-contrib="yes">
                  <name>
                    <surname>Stergiou</surname>
                    <given-names>Nicholas</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff002">
                    <sup>2</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author" equal-contrib="yes">
                  <name>
                    <surname>Sofianidis</surname>
                    <given-names>George</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff001">
                    <sup>1</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author" equal-contrib="yes">
                  <name>
                    <surname>Kyvelidou</surname>
                    <given-names>Anastasia</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff002">
                    <sup>2</sup>
                  </xref>
                  <xref rid="cor001" ref-type="corresp">*</xref>
                </contrib>
              </contrib-group>
              <aff id="aff001">
                <label>1</label>
                <addr-line>Motor Control and Learning Laboratory, School of Physical Education and Sport Science, Aristotle University of Thessaloniki, Thessaloniki, Greece</addr-line>
              </aff>
              <aff id="aff002">
                <label>2</label>
                <addr-line>Biomechanics Research Building, University of Nebraska at Omaha, Omaha, Nebraska, United States of America</addr-line>
              </aff>
              <contrib-group>
                <contrib contrib-type="editor">
                  <name>
                    <surname>Kapoula</surname>
                    <given-names>Zoi</given-names>
                  </name>
                  <role>Academic Editor</role>
                  <xref ref-type="aff" rid="edit1"/>
                </contrib>
              </contrib-group>
              <aff id="edit1">
                <addr-line>UMR8194, FRANCE</addr-line>
              </aff>
              <author-notes>
                <fn fn-type="COI-statement" id="coi001">
                  <p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
                </fn>
                <fn fn-type="con" id="contrib001">
                  <p>Conceived and designed the experiments: AK NS VH. Performed the experiments: VH GS. Analyzed the data: VH GS AK. Contributed reagents/materials/analysis tools: VH GS AK NS. Wrote the paper: VH GS AK NS.</p>
                </fn>
                <corresp id="cor001">* E-mail: <email>akyvelidou@unomaha.edu</email></corresp>
              </author-notes>
              <pub-date pub-type="epub">
                <day>16</day>
                <month>3</month>
                <year>2015</year>
              </pub-date>
              <pub-date pub-type="collection">
                <year>2015</year>
              </pub-date>
              <volume>10</volume>
              <issue>3</issue>
              <elocation-id>e0119828</elocation-id>
              <history>
                <date date-type="received">
                  <day>30</day>
                  <month>9</month>
                  <year>2014</year>
                </date>
                <date date-type="accepted">
                  <day>18</day>
                  <month>1</month>
                  <year>2015</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>© 2015 Hatzitaki et al</copyright-statement>
                <copyright-year>2015</copyright-year>
                <copyright-holder>Hatzitaki et al</copyright-holder>
                <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
                  <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are properly credited.</license-p>
                </license>
              </permissions>
              <self-uri content-type="pdf" xlink:type="simple" xlink:href="pone.0119828.pdf"/>
              <abstract>
                <p>Variability is an inherent and important feature of human movement. This variability has form exhibiting a chaotic structure. Visual feedback training using regular predictive visual target motions does not take into account this essential characteristic of the human movement, and may result in task specific learning and loss of visuo-motor adaptability. In this study, we asked how well healthy young adults can track visual target cues of varying degree of complexity during whole-body swaying in the Anterior-Posterior (AP) and Medio-Lateral (ML) direction. Participants were asked to track three visual target motions: a complex (Lorenz attractor), a noise (brown) and a periodic (sine) moving target while receiving online visual feedback about their performance. Postural sway, gaze and target motion were synchronously recorded and the degree of force-target and gaze-target coupling was quantified using spectral coherence and Cross-Approximate entropy. Analysis revealed that both force-target and gaze-target coupling was sensitive to the complexity of the visual stimuli motions. Postural sway showed a higher degree of coherence with the Lorenz attractor than the brown noise or sinusoidal stimulus motion. Similarly, gaze was more synchronous with the Lorenz attractor than the brown noise and sinusoidal stimulus motion. These results were similar regardless of whether tracking was performed in the AP or ML direction. Based on the theoretical model of optimal movement variability tracking of a complex signal may provide a better stimulus to improve visuo-motor adaptation and learning in postural control.</p>
              </abstract>
              <funding-group>
                <funding-statement>Funding was provided by the University of Nebraska Faculty Research International grant (2013-2014) “A USA-Greece partnership to promote research in Biomechanics and Motor Control”, to NS VH; and National Institutes of Health Centers of Biomedical Research Excellence (1P20GM109090-01), to NS AK. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
              </funding-group>
              <counts>
                <fig-count count="5"/>
                <table-count count="0"/>
                <page-count count="14"/>
              </counts>
              <custom-meta-group>
                <custom-meta id="data-availability">
                  <meta-name>Data Availability</meta-name>
                  <meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
                </custom-meta>
              </custom-meta-group>
            </article-meta>
            <notes>
              <title>Data Availability</title>
              <p>All relevant data are within the paper and its Supporting Information files.</p>
            </notes>
          </front>
          <body>
            <sec sec-type="intro" id="sec001">
              <title>Introduction</title>
              <p>Intentional postural tracking of visual cues is used in balance assessment [<xref rid="pone.0119828.ref001" ref-type="bibr">1</xref>] and rehabilitation [<xref rid="pone.0119828.ref002" ref-type="bibr">2</xref>] for improving visuo-motor integration through a recalibration of the sensory systems contributing to postural control [<xref rid="pone.0119828.ref003" ref-type="bibr">3</xref>]. The amount and type of visual information provided in the target and feedback signals determines how visuo-motor learning generalizes to other sensory-motor tasks [<xref rid="pone.0119828.ref004" ref-type="bibr">4</xref>]. One major concern is that the regularity of visual target motions used to guide tracking performance evokes the use of predictive mechanisms [<xref rid="pone.0119828.ref005" ref-type="bibr">5</xref>] with limited access to sensory-motor recalibration (perception-action) processes. It is therefore possible that an internal plan, developed through practice, controls the motor output with no need to attend to the target motion anymore, which may explain why this type of visuo-motor learning is task specific. The specificity of visuo-motor learning together with the re-organization of posture into a single degree of freedom control strategy [<xref rid="pone.0119828.ref006" ref-type="bibr">6</xref>] may limit the number of functional coordination solutions the motor system uses in order to adapt to novel tasks or environmental constraints.</p>
              <p>Healthy movement behavior on the other hand assumes the maintenance of some degree of intrinsic variability and flexibility in the motor output. Optimal movement variability is associated with complex interactions across multiple control systems, feedback loops and regulatory processes that enable an organism to function and adapt to the demands of everyday life [<xref rid="pone.0119828.ref007" ref-type="bibr">7</xref>,<xref rid="pone.0119828.ref008" ref-type="bibr">8</xref>]. It has been suggested that the structure of these flexible multi-scale interactions resembles mathematical chaos [<xref rid="pone.0119828.ref007" ref-type="bibr">7</xref>,<xref rid="pone.0119828.ref008" ref-type="bibr">8</xref>]. In fact recent literature from several disciplines and medical areas, including brain function and disease dynamics have shown that many apparently “noisy” phenomena are the result of nonlinear interactions and have deterministic origins. Thus, complexity in human movement is organized and could be described as highly variable fluctuations in physiological processes resembling mathematical chaos [<xref rid="pone.0119828.ref009" ref-type="bibr">9</xref>]. This physiological organized complexity is recognized as an inherent attribute of healthy biological systems, whereas its loss due to pathology or aging is thought to reduce the adaptive capabilities of the individual [<xref rid="pone.0119828.ref010" ref-type="bibr">10</xref>,<xref rid="pone.0119828.ref011" ref-type="bibr">11</xref>]. A loss of this complexity can refer to either an overly constrained, periodic system, or an overly random, incoherent system. Thus, healthy human function requires the coexistence of the oppositional factors of coherence and chaos.</p>
              <p>Based on this theoretical paradigm, visuo-motor learning should allow the system’s intrinsic variability to be maintained or even exploited. One way to attain this goal in postural tracking practice is to introduce visual cues of varying degree of organized complexity. However, one question that needs to be addressed first is how well humans can track with their gaze and posture a visual target that moves in an unpredictable, chaotic pattern. Evidence from auditory synchronization research introduced the notion of strong anticipation as a new framework for explaining the coordination of tapping behavior with chaotic signals [<xref rid="pone.0119828.ref012" ref-type="bibr">12</xref>]. In this context, tapping is sensitive to the non-local temporal structure of environmental (chaotic) stimuli whereas an internal cognitive model is not viable anymore to explain synchronization to unpredictable chaotic auditory cues [<xref rid="pone.0119828.ref013" ref-type="bibr">13</xref>].</p>
              <p>In a recent study examining the dynamic response of posture and gaze to visual target motions of varying complexity [<xref rid="pone.0119828.ref014" ref-type="bibr">14</xref>], gaze was particularly sensitive to the complexity of the visual target motion whereas posture remained relatively unaffected. Spontaneous looking while standing however may not be a sufficiently challenging task for the visual regulation of stance as opposed to intentional tracking of a visual target, which requires the modulation of posture according to the visual stimulus motion information. In the latter case, the coupling between visual motion stimuli of different frequency and the body-head movement is stronger when compared to spontaneous unconscious looking [<xref rid="pone.0119828.ref015" ref-type="bibr">15</xref>]. When postural tracking of a predictable and an unpredictable visual target motion was compared [<xref rid="pone.0119828.ref001" ref-type="bibr">1</xref>], performers tracked the predictable target motion with a shorter delay and higher accuracy than the unpredictable target motion. This may be explained by the fact that humans tend to rely on the stationary properties of the target signal rather than the less stationary performance feedback signal for controlling postural sway [<xref rid="pone.0119828.ref004" ref-type="bibr">4</xref>,<xref rid="pone.0119828.ref016" ref-type="bibr">16</xref>]. The target motion used in this study however was completely random. It is still not known what visual stimulus parameters/characteristics along the spectrum of complexity regarding the structure motion can optimize the perception, processing and integration of visual information in order to control posture.</p>
              <p>The aim of the present study was to examine how well healthy adults can track (with their whole body) visual target cues that differ in the degree of complexity (periodic, chaotic, noise) during voluntary visually guided sway in the Anterior-Posterior (A/P) and Medio-Lateral (M/L) direction. This was reflected in the degree of target-performance (posture and gaze) coupling assessed using both linear (coherence) and non-linear metrics (Cross-Approximate entropy). We hypothesized that participants would entrain their posture and gaze better to the chaotic rather than the noise or periodic visual target motion because chaos is an inherent feature of biological motion.</p>
            </sec>
            <sec sec-type="materials|methods" id="sec002">
              <title>Methods</title>
              <sec id="sec003">
                <title>Participants</title>
                <p>Ten (10) healthy young male adults (age: 23.5±3.5 years, height: 175.4 ± 4.3 cm, mass: 79.6 ± 7.43kg), recruited from the university students, volunteered to participate in this study. All participants were free from any neurological or musculoskeletal impairment and had normal or corrected to normal vision. Participants gave their informed consent prior to their inclusion in the study. The experiment was performed with the approval of Aristotle University’s ethics committee on human research in accordance with the Declaration of Helsinki. Participants gave their written informed consent prior to their inclusion in the study.</p>
              </sec>
              <sec id="sec004">
                <title>Apparatus, Task and Stimuli</title>
                <p>Two adjacent force plates (Balance Plate 6501, Bertec, USA) recorded the ground reaction forces at 100 Hz during experimental task performance. The resultant vertical ground reaction force normalized to the participant’s Body Weight (BW) was displayed as a yellow dot in real-time via an overhead projector (View Sonic, PJ510) on a large projection screen (2.2m horizontal x 1.6m vertical) located in front of the standing participant at a distance of 1.5 m, at eyelevel (<xref rid="pone.0119828.g001" ref-type="fig">Fig. 1</xref>). The force feedback signal was superimposed on the computer simulated target signal displayed as a red dot (<xref rid="pone.0119828.g001" ref-type="fig">Fig. 1</xref>). An eye tracking system (Dikablis, Ergoneers) tracked the gaze of the standing subject at 50 Hz during task performance. Force, gaze and target motions were synchronously sampled (100 Hz) and digitized through a Vicon system’s (Vicon Motion Systems, Oxford, UK) data acquisition board (MX Giganet).</p>
                <fig id="pone.0119828.g001" orientation="portrait" position="float">
                  <object-id pub-id-type="doi">10.1371/journal.pone.0119828.g001</object-id>
                  <label>Fig 1</label>
                  <caption>
                    <title>Set up.</title>
                    <p>Experimental setup and visual stimuli presentation a: Medio_Lateral direction (ML), b: Anterior-Posterior (AP) direction</p>
                  </caption>
                  <graphic xlink:href="pone.0119828.g001"/>
                </fig>
                <p>Posture and gaze data were collected in a single experimental session at the Motor Control and Learning laboratory of Aristotle University of Thessaloniki, Greece. At the starting position (<xref rid="pone.0119828.g001" ref-type="fig">Fig. 1</xref>), the participant stood over the midline of the two force platforms distributing his BW evenly between the platforms while maintaining a normal stance position (inter-malleolar distance was set at 10 cm). The experimental task required tracking of the moving target (i.e. red dot) by shifting BW (displayed by the yellow dot) between the two platforms in the Antero-Posterior (AP) or Medio-Lateral (ML) direction. The instruction was to use the yellow dot in order to follow the movement of the red dot as closely as possible. The red target moved either in the up-down (<xref rid="pone.0119828.g001" ref-type="fig">Fig. 1A</xref>) direction resulting in Anterior-Posterior (AP) body sway or sideways (<xref rid="pone.0119828.g001" ref-type="fig">Fig. 1B</xref>) resulting in Medio-Lateral (ML) sway. Target tracking in the AP direction required an additional visuo-motor transformation of the target’s screen (up-down) into the body’s spatial (forward-backward) coordinate system. A perceptual bias for up-far and down-close is reported for vertical saccadic eye movements [<xref rid="pone.0119828.ref017" ref-type="bibr">17</xref>] as well as depth perception of visual surfaces [<xref rid="pone.0119828.ref018" ref-type="bibr">18</xref>]. In our experiment, participants were free to select their intuitive sway-target direction matching in the AP tracking task. In accordance with the perceptual bias hypothesis, all participants intuitively swayed forward in order to track the upward target motion (perceived as moving away) and swayed backward when tracking the downward target motion (perceived as an approaching motion). Feet position on the platforms was adjusted based on sway direction (<xref rid="pone.0119828.g001" ref-type="fig">Fig. 1A</xref>). Participants were required to track three different target motions (periodic, chaotic, brown noise) in the AP and ML direction which resulted in 6 experimental trials that were fully counterbalanced to account for order effects. Each trial lasted 120 s.</p>
                <p>Target signals were constructed using custom Matlab (Version 7.9, MathWorks Inc, USA) algorithms while the data series were accessed and displayed through the main Labview (version 8.6, National Instruments Corporation, 2008) application onto the monitor. The maximum peak-to-peak amplitude of the target signals was scaled to 90% of BW in both directions. Each signal comprised 6000 data points. The position of the stimulus on the monitor was updated at a rate of 50 Hz providing 120 seconds of continuous target stimulus motion. All target signals had the same median frequency (0.25 Hz) that corresponds to the dominant frequency of self paced sway as this was estimated by pilot tests and prior experiments [<xref rid="pone.0119828.ref019" ref-type="bibr">19</xref>]. This resulted in 30 full sway cycles performed in 120 s.</p>
                <p>Three signals of different degree of complexity (<xref rid="pone.0119828.g002" ref-type="fig">Fig. 2</xref>) were used to construct the frequency structure of the motion of the visual target signal (red dot): a sine wave, a chaotic signal generated using a Lorenz attractor and a brown noise signal. These specific signals were chosen, as they span the spectrum of signal properties related to the aims of the current investigation. The sine wave signal was created using the sin function [sine = sin (2*pi*f/fs*t)] in Matlab. This signal represents simple periodic redundancy, similar to what would be seen from a frictionless clock pendulum. The Lorenz signal was generated by fixing the following parameters at: σ = 10, β = 8/3 and r = 28 and the initial conditions: x0 = 0.1, y0 = 0.1 and z0 = 0.1. The signal characteristics were: h (time resolution) = 0.0040, steps (number of points) = 10000 (we choose 6000 data points from y axis [y (4000:10000)], noise flag = 0. The Lorenz signal as a model closely resembles a double-pendulum, which has previously been shown to emulate the dynamics of human posture [<xref rid="pone.0119828.ref020" ref-type="bibr">20</xref>]. The brown noise signal was created using readily available software (<ext-link ext-link-type="uri" xlink:href="http://people.sc.fsu.edu/~jburkardt/m_src/brownian_motion_simulation/brownian_motion_simulation.m">http://people.sc.fsu.edu/~jburkardt/m_src/brownian_motion_simulation/brownian_motion_simulation.m</ext-link>) with input, integers M (the spatial dimension) = 2, N (the number of time steps) = 10000 [we choose 6000 data points (4000:10000)], the d (diffusion coefficient) = 10.0 and the real T (the total time) = 1.0.This signal was selected as it provides an non-periodic motion structure, but also affords continuous smooth pursuit eye movement responses. Furthermore, work by Collins and Deluca [<xref rid="pone.0119828.ref021" ref-type="bibr">21</xref>], have suggested that human posture can be modeled as Brownian motion.</p>
                <fig id="pone.0119828.g002" orientation="portrait" position="float">
                  <object-id pub-id-type="doi">10.1371/journal.pone.0119828.g002</object-id>
                  <label>Fig 2</label>
                  <caption>
                    <title>Stimulus signals.</title>
                    <p>Signals used for constructing stimuli motion: Lorenz attractor (a), brown noise (b) and sine (c)</p>
                  </caption>
                  <graphic xlink:href="pone.0119828.g002"/>
                </fig>
              </sec>
              <sec id="sec005">
                <title>Data Analysis</title>
                <p>In order to compare how well one’s postural sway and gaze was coupled to the visual target motions two different metrics of coupling were calculated in Matlab (Matlab7.9, MathworksInc, USA): the spectral coherence (Coh) and Cross Approximate Entropy (CrossApEn). These two measures estimate the magnitude and the temporal structure of the association respectively between a) the resultant force vector and the target stimulus motion b) the gaze (eye coordinate in the respective target’s direction) and the target stimulus motion in the AP and ML directions.</p>
                <p>Spectral coherence measures the degree of correlation between two signals in the frequency domain. The magnitude-squared coherence is estimated as a function of sway frequency with values between 0 and 1 that indicate how well force and gaze couple to the target stimulus motion at the dominant sway frequency of 0.25 Hz [<xref rid="pone.0119828.ref019" ref-type="bibr">19</xref>]. Cross-ApEn quantifies the regularity of patterns in a pair of related time series [<xref rid="pone.0119828.ref022" ref-type="bibr">22</xref>] and is indicative of the dimensionality of control of the two signals [<xref rid="pone.0119828.ref023" ref-type="bibr">23</xref>]. Cross-ApEn has the advantage of being independent of the variance of the signals under comparison. The calculation of Cross-ApEn is similar to approximate entropy (ApEn) with the exception that successive two-point vectors of one signal are compared with current and previous two-point vectors of another signal [<xref rid="pone.0119828.ref022" ref-type="bibr">22</xref>]. Larger Cross-ApEn values indicate greater joint signal asynchrony while lower Cross-ApEn values indicate greater joint signal synchrony.</p>
                <p>The effect of direction and target stimulus motion on the performance-target coupling was evaluated employing a 2 (direction) x 3 (stimulus complexity) repeated measures ANOVA. Significant interactions between factor levels were further analyzed by performing pairwise (t-tests) comparisons between the respective factor levels after adjusting p values for multiple comparisons.</p>
              </sec>
            </sec>
            <sec sec-type="results" id="sec006">
              <title>Results</title>
              <p><xref rid="pone.0119828.g003" ref-type="fig">Fig. 3</xref> shows exemplar performance (force and gaze) curves superimposed on the target waveforms for a representative trial of one participant. With the exception of the brown noise stimulus motion, participants could entrain their postural sway and gaze to the motion of the visual stimulus reasonably well when sway and gaze were guided by the sinusoidal and Lorenz attractor stimulus motion.</p>
              <fig id="pone.0119828.g003" orientation="portrait" position="float">
                <object-id pub-id-type="doi">10.1371/journal.pone.0119828.g003</object-id>
                <label>Fig 3</label>
                <caption>
                  <title>Performance-target curves.</title>
                  <p>Performance (red line)–target (blue line) curves plotted for the three stimuli motions of a representative trial</p>
                </caption>
                <graphic xlink:href="pone.0119828.g003"/>
              </fig>
              <sec id="sec007">
                <title>Coherence</title>
                <sec id="sec008">
                  <title>Posture</title>
                  <p>Group results for the force-target coherence are plotted in <xref rid="pone.0119828.g004" ref-type="fig">Fig. 4A</xref>. Analysis revealed a significant main effect of stimulus motion complexity on the magnitude of the coherence between the resultant force vector and the visual target signal (F (2, 18) = 46.769 p = .001). Post hoc pair wise comparisons between the three signals revealed that the magnitude of force-target coherence was significantly higher when postural sway was guided by the Lorenz attractor target motion than when was guided by the sinusoidal (AP, t(9) = 4.284, p = .002, ML, t(9) = 11,986, p = .001) and brown noise target motion (AP, t(9) = −7.860, p = .001, ML, t(9) = −8.369, p = .001). Moreover a significant stimulus complexity x direction interaction (F (2, 18) = 4.074, p = .035) revealed that differences between the two directions were dependent on the stimulus complexity. Specifically, post hoc pair wise comparisons between the two directions revealed that the magnitude of force-target coherence was significantly higher in the ML than the AP direction but only when sway was guided by the Lorenz attractor stimulus motion (t(9) = −3,159, p = .012).</p>
                  <fig id="pone.0119828.g004" orientation="portrait" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pone.0119828.g004</object-id>
                    <label>Fig 4</label>
                    <caption>
                      <title>Coherence results.</title>
                      <p>Force-target (a) and gaze-target (b) coherence for different stimuli motions and sway directions.</p>
                    </caption>
                    <graphic xlink:href="pone.0119828.g004"/>
                  </fig>
                </sec>
                <sec id="sec009">
                  <title>Gaze</title>
                  <p>Group results for the gaze-target coherence are plotted in <xref rid="pone.0119828.g004" ref-type="fig">Fig. 4B</xref>. Analysis revealed that the magnitude of gaze-target coherence was depended on the complexity of the stimulus motion (F(2,18) = 23.147, p = .001). Specifically, both the sinusoidal and Lorenz attractor visual motions produced significantly higher gaze-target coherence than the brown noise motion in both directions (AP: (t(9) = −2.741, p = .023, (t(9) = −4.088, p = .003); ML: (t(9) = −4.056, p = .003),(t(9) = −4.840, p = .001)). However, in contrast to the force-target coupling, the magnitude of gaze-target coherence was higher when postural sway was guided by the sinusoidal than the Lorenz attractor visual motion (t(9) = −2.354, p = .043). This difference was significant only in AP and not in ML direction.</p>
                </sec>
              </sec>
              <sec id="sec010">
                <title>Cross Approximate Entropy</title>
                <sec id="sec011">
                  <title>Posture</title>
                  <p>Group results on the Cross ApEn metric are shown in <xref rid="pone.0119828.g005" ref-type="fig">Fig. 5</xref>. The Cross ApEn between force and target (<xref rid="pone.0119828.g005" ref-type="fig">Fig. 5A</xref>) was particularly sensitive to the complexity of the visual stimulus motion (F(2,18) = 210.713, p = .001). This was significantly higher when sway was guided by the brown noise visual motion than the other two target motions suggesting a greater degree of asynchrony between posture and target movements (AP: (t(9) = 12.570, p = .001, (t(9) = 18.316, p = .001); ML: (t(9) = 12.762, p = .001),(t(9) = 17.075, p = .001)). In addition, the Cross ApEn between the force and target signals was significantly lower when sway was guided by the sinusoidal than the Lorenz attractor visual motion revealing a more synchronous force-target coupling (AP, (t(9) = 5.369, p = .001); ML (t(9) = 5.692, p = .001). No significant direction effect on the force–target coupling was noted suggesting that the effect of target motion complexity was similar in both sway directions.</p>
                  <fig id="pone.0119828.g005" orientation="portrait" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pone.0119828.g005</object-id>
                    <label>Fig 5</label>
                    <caption>
                      <title>Cross Approximate Entropy results.</title>
                      <p>Force-target (a) and gaze-target (b) Cross Approximate Entropy for different stimuli motions and sway directions.</p>
                    </caption>
                    <graphic xlink:href="pone.0119828.g005"/>
                  </fig>
                </sec>
              </sec>
              <sec id="sec012">
                <title>Gaze</title>
                <p>A significant main effect of visual motion complexity on the gaze-target Cross ApEn (F(2,18) = 95.031, p = .001)suggests that gaze was also sensitive to the visual stimuli motion complexity (<xref rid="pone.0119828.g005" ref-type="fig">Fig. 5B</xref>). Similarly to the force-target coupling, the Cross ApEn value was significantly higher when gaze was guided by the random (brown noise) than the sinusoidal and the Lorenz attractor stimulus motion ((AP: (t(9) = −7.236, p = .001, (t(9) = 3.628, p = .006); ML: (t(9) = 28.721, p = .001),(t(9) = 11.889, p = .001))). Interestingly however, the gaze-target Cross ApEn was significantly lower when gaze was guided by the Lorenz attractor than the sinusoidal visual stimulus motion (AP(t(9) = −2.659, p = .026); ML (t(9) = −3.722, p = .005) revealing a more synchronous eye tracking of the complex than the periodic visual target motion.</p>
              </sec>
            </sec>
            <sec sec-type="conclusions" id="sec013">
              <title>Discussion</title>
              <p>The novel finding of this study is that humans can track, with their gaze and posture, the complex motion of a visual target equally well or even better than the motion of a target moving periodically, regardless of whether tracking is performed in the AP or ML direction. This finding was confirmed by both metrics of performance-target coupling used in this study.</p>
              <sec id="sec014">
                <title>Gaze performance</title>
                <p>As expected, gaze showed a higher degree of coherence and lower Cross ApEn with the sinusoidal than the brown noise motion suggesting tighter coupling to the predictable target motion. Moreover, gaze synchronized better to the complex target motion as revealed by the lower Cross ApEn between gaze and the Lorenz attractor than the sinusoidal signal. Gaze in our task was defined by the direction of the visual axis (the line connecting the centre of the fovea and the point of fixation) in the two-dimensional coordinates of the projection screen. This reflected the eye and head movement in smoothly pursuing the target since the stimulus motion was sufficiently slow to eliminate the recruitment of eye saccades. The more synchronous gaze-target coupling when tracking the Lorenz attractor signal suggests that the complex target motion imposes a higher demand on attending to the visual target as opposed to the sinusoidal stimulus motion which is more predictable. Our findings complement previous evidence showing that the complexity of the visual stimulus elicits reciprocal complexity in the response of the smooth pursuit gaze behavior [<xref rid="pone.0119828.ref014" ref-type="bibr">14</xref>]. Eye-tracking literature connecting stimulus motion qualities to properties of smooth pursuit eye movements [<xref rid="pone.0119828.ref024" ref-type="bibr">24</xref>,<xref rid="pone.0119828.ref025" ref-type="bibr">25</xref>] confirms that humans tend to demonstrate complex gaze behavior, aligning with the idea that a search state with chaotic properties provides the visual system access to an optimal amount and quality of information. For this reason, studies investigating the relationship between environmental statistics and neural responses suggest that neural representation in the visual cortex is more efficient when visual scenes are natural, i.e. fractal [<xref rid="pone.0119828.ref026" ref-type="bibr">26</xref>]. The more efficient encoding of natural images or sounds assumes non-linear response properties of typical neurons in the primary visual cortex or auditory nerve [<xref rid="pone.0119828.ref027" ref-type="bibr">27</xref>].</p>
                <p>Gaze-target coherence was still higher for the sinusoidal than the Lorenz attractor signal when the target was moving in the AP direction, whereas in the ML direction there was no difference between the two target motions. This difference in the AP direction could be due to the additional visuo-motor transformation required for tracking the vertically moving target and converting this information into forward-backward sway. The fact that gaze demonstrated a greater coupling to the sinusoidal than the Lorenz stimulus motion in the frequency domain may be attributed to the smaller amplitude of the gaze signal. As it is evident from <xref rid="pone.0119828.g003" ref-type="fig">Fig. 3</xref>, gaze is responding with significantly smaller amplitude against the sine stimulus signal in comparison to the Lorenz stimulus signal. Even though gaze was more synchronous (i.e. lower Cross ApEn) with the Lorenz stimulus motion it is possible that the organized complexity of the Lorenz attractor evoked a faster eye pursuing movement which resulted in a deviation of the gaze signal from the dominant sway frequency (0.25Hz) and therefore a lower gaze-target coupling to the Lorenz signal in the frequency domain.</p>
              </sec>
              <sec id="sec015">
                <title>Postural performance</title>
                <p>Force-target coupling was greater when the target was moving periodically than randomly (simulated by the brown noise signal). This finding complements previous evidence showing that a predictable target moving in the ML direction is tracked with a shorter time delay and higher accuracy than an unpredictable one [<xref rid="pone.0119828.ref001" ref-type="bibr">1</xref>]. Moreover, our results suggest that humans can entrain their posture to a complex visual motion, simulated by a Lorenz attractor signal, equally well or even better than to a periodic visual target motion. Tracking of a moving target with the whole body requires the coordination of the body’s multiple degrees of freedom in order to convert joint to spatial coordinates through a single point of force application. An additional transformation of the projector screen coordinates (up-down) to the body’s spatial coordinates (forward-backward) was required for AP tracking. The complexity of the sensory-motor transformations underlying this task may explain why entrainment was greater to the complex than the periodic target motion. This is because tracking of a complex stimulus motion allows for more flexibility and better resembles the inherent variability characterizing healthy human postural behavior.</p>
                <p>Postural sway synchronized better with the periodic than the more complex target motion as indicated by the lower force-target Cross ApEn for the sinusoidal than the Lorenz attractor visual motion. The fact that posture showed a more synchronous coupling with the sinusoidal stimulus motion suggests that participants were able to predict the target motion and adjust their posture employing an open loop type of control without necessarily attending to the stimulus when tracking the sine wave. Our results are in agreement with experimental evidence from the tapping literature suggesting that synchronizing with biologically variable auditory rhythms involves similar internal processes as with other variable rhythms (whether totally random or comprising lawful regularities), but different from those involved with a regular metronome [<xref rid="pone.0119828.ref028" ref-type="bibr">28</xref>,<xref rid="pone.0119828.ref029" ref-type="bibr">29</xref>]. Specifically, synchronizing to a regular (periodic) metronome is assumed to involve an internal timekeeper prescribing time intervals in an open-loop manner and being completed by an error-correction process to achieve synchronization [<xref rid="pone.0119828.ref030" ref-type="bibr">30</xref>,<xref rid="pone.0119828.ref031" ref-type="bibr">31</xref>]. On the other hand, synchronizing to a biological rhythm is assumed to involve strong anticipatory processes [<xref rid="pone.0119828.ref013" ref-type="bibr">13</xref>] for short-term prediction and correction of periods and/or asynchronies. Instead of prediction on a local time scale however, strong anticipation assumes coordination on a non-local time scale. Therefore, based on the strong anticipation principle, entraining to a Lorenz attractor derived signal would require the coordination of posture to the global temporal structure of the stimulus signal and not on the local temporal changes. In other words, the anticipatory control of posture during tracking of the Lorenz attractor would depend not only on the past and current states of the system but also on future states. [<xref rid="pone.0119828.ref015" ref-type="bibr">15</xref>,<xref rid="pone.0119828.ref016" ref-type="bibr">16</xref>]. Indeed, the complex stimulus motion required the continuous pursuing/attendance of the visual target motion, which explains the greater temporal gaze-target coupling. Although, manual tracking literature suggests a common drive (or motor plan) to both eye and hand tracking systems [<xref rid="pone.0119828.ref032" ref-type="bibr">32</xref>], this may not be true for posture because of the more abstract cortical representation and multiple degrees of freedom involved in postural control.</p>
              </sec>
              <sec id="sec016">
                <title>Effect of direction</title>
                <p>Entrainment of posture and gaze to the target motions of varying complexity was similar regardless of whether tracking was performed in the AP or ML direction. Of note here is the fact that during the experiment, special attention was given to maintain a consistent stance width across all trials performed in both directions. AP tracking was expected to result in greater entrainment than tracking in the ML direction because visual information about self-motion and orientation is available predominantly in the AP [<xref rid="pone.0119828.ref033" ref-type="bibr">33</xref>,<xref rid="pone.0119828.ref034" ref-type="bibr">34</xref>]and to a lesser extent in the ML direction[<xref rid="pone.0119828.ref035" ref-type="bibr">35</xref>]. Nevertheless, tracking of a target moving in the vertical direction by voluntarily swaying in the sagittal plane required an additional coordinate transformation between the target’s screen (up-down) and the body’s spatial (forward-backward) coordinates which increased the computational load of the tracking task. For ML target tracking on the other hand, the direction of the visual stimulus motion was congruent with the postural sway direction and therefore did not require any additional transformation. The absence of differences in performance-target coupling between AP and ML postural tracking suggests that the two effects, the greater AP entrainment on one hand and the additional computational load of transforming body coordinates to screen coordinates on the other were canceled out. Several issues however are prone to further investigation. First, the greater entrainment to visual stimuli motion in the AP compared to the ML direction has been reported for unintentional looking and standing and not for voluntary intentional postural tracking. It is possible that visual stimuli motions are differently perceived and processed in quiet standing and voluntary postural tracking because the two tasks involve different visuo-motor transformations [<xref rid="pone.0119828.ref015" ref-type="bibr">15</xref>]. Second, for both AP and ML tracking the target motion was congruent to the body and gaze motion and intuitively selected. Whether similar results could be obtained for incongruent target-performance directions (e.g. visual stimulus moving in the AP direction while tracking is performed in the ML direction) remains to be seen in future studies.</p>
              </sec>
              <sec id="sec017">
                <title>Conclusions and practical considerations</title>
                <p>The results of the present study revealed that humans can track, with their gaze and posture, the complex motion of the visual stimulus equally well or even better than the motion of a target moving predictably. This novel finding complements recent multidisciplinary research proposing that information exchange is improved between complex long-range correlated systems [<xref rid="pone.0119828.ref036" ref-type="bibr">36</xref>]. Healthy physiological movement and posture in particular exhibits a natural organized complexity (chaos) whereas loss of complexity is indicative of aging, disease and pathology [<xref rid="pone.0119828.ref010" ref-type="bibr">10</xref>,<xref rid="pone.0119828.ref037" ref-type="bibr">37</xref>,<xref rid="pone.0119828.ref038" ref-type="bibr">38</xref>]. The optimization of information exchange by complexity matching between the human body and environmental stimuli reveals the importance of cooperative interactions over many possible perturbation timescales: a multiscale complexity that enhances system adaptability and learning [<xref rid="pone.0119828.ref007" ref-type="bibr">7</xref>]. Practically, the newly acquired visuo-motor transformation that goes together with previously learned responses is changed by the introduction of new critical stimuli without the presence of invariance in memory. Such a pattern is the result of effective dynamic neural interactions in sensory cortex and not of “purifying” stimuli. Thus, the process is dynamic and not just noisy involving active nonlinear cooperation between components and not just information processing.</p>
                <p>In sum, based on our findings we propose that tracking of visual cues of a higher degree of complexity could be ecologically more sound and a better type of stimulus for optimizing visuo-motor learning while maintaining functional variability in the motor output. This type of practice may enable the human system maintain and use its functional degrees of freedom and adaptability. In this context, further studies should be designed to assess the sensitivity of the human perceptual-motor systems to the (long-range correlated) structure of fluctuations in environmental stimuli. This investigation may contribute to optimize human/environment interactions in several contexts, as the use of rhythmic auditory stimulation for gait rehabilitation in Parkinson’s patients [<xref rid="pone.0119828.ref039" ref-type="bibr">39</xref>]. Despite the potential that this emerging field presents for a) improving our understanding of dysfunction, b) providing sensitive biomarkers for evaluating interventions, and c) designing novel interventions based on restoration of complexity, its actual impact in the field of rehabilitative medicine has been minimal. The present study is an effort towards addressing this knowledge gap.</p>
              </sec>
            </sec>
            <sec sec-type="supplementary-material" id="sec018">
              <title>Supporting Information</title>
              <supplementary-material content-type="local-data" id="pone.0119828.s001">
                <label>S1 Dataset</label>
                <caption>
                  <title>Data file of all subjects.</title>
                  <p>Coherence and Cross Approximate Entropy data for all subjects.</p>
                  <p>(XLSX)</p>
                </caption>
                <media xlink:href="pone.0119828.s001.xlsx">
                  <caption>
                    <p>Click here for additional data file.</p>
                  </caption>
                </media>
              </supplementary-material>
            </sec>
          </body>
          <back>
            <ref-list>
              <title>References</title>
              <ref id="pone.0119828.ref001">
                <label>1</label>
                <mixed-citation publication-type="journal"><name><surname>Cofre</surname><given-names>Lizama LE</given-names></name>, <name><surname>Pijnappels</surname><given-names>M</given-names></name>, <name><surname>Reeves</surname><given-names>NP</given-names></name>, <name><surname>Verschueren</surname><given-names>SM</given-names></name>, <name><surname>van Dieen</surname><given-names>JH</given-names></name>. <article-title>Frequency domain mediolateral balance assessment using a center of pressure tracking task</article-title>. <source>J Biomech</source>. <year>2013</year>;<volume>46</volume>: <fpage>2831</fpage>–<lpage>2836</lpage>. <pub-id pub-id-type="doi">10.1016/j.jbiomech.2013.08.018</pub-id>
<?supplied-pmid 24103778?><pub-id pub-id-type="pmid">24103778</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref002">
                <label>2</label>
                <mixed-citation publication-type="journal"><name><surname>Hatzitaki</surname><given-names>V</given-names></name>, <name><surname>Voudouris</surname><given-names>D</given-names></name>, <name><surname>Nikodelis</surname><given-names>T</given-names></name>, <name><surname>Amiridis</surname><given-names>IG</given-names></name>. <article-title>Visual feedback training improves postural adjustments associated with moving obstacle avoidance in elderly women</article-title>. <source>Gait Posture</source>. <year>2009</year>;<volume>29</volume>: <fpage>296</fpage>–<lpage>299</lpage>. <pub-id pub-id-type="doi">10.1016/j.gaitpost.2008.09.011</pub-id>
<?supplied-pmid 18996012?><pub-id pub-id-type="pmid">18996012</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref003">
                <label>3</label>
                <mixed-citation publication-type="journal"><name><surname>Hu</surname><given-names>MH</given-names></name>, <name><surname>Woollacott</surname><given-names>MH</given-names></name>. <article-title>Multisensory training of standing balance in older adults: I. Postural stability and one-leg stance balance</article-title>. <source>J Gerontol</source>. <year>1994</year>;<volume>49</volume>: <fpage>M52</fpage>–<lpage>61</lpage>.
<?supplied-pmid 8126353?><pub-id pub-id-type="pmid">8126353</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref004">
                <label>4</label>
                <mixed-citation publication-type="journal"><name><surname>Radhakrishnan</surname><given-names>SM</given-names></name>, <name><surname>Hatzitaki</surname><given-names>V</given-names></name>, <name><surname>Vogiannou</surname><given-names>A</given-names></name>, <name><surname>Tzovaras</surname><given-names>D</given-names></name>. <article-title>The role of visual cues in the acquisition and transfer of a voluntary postural sway task</article-title>. <source>Gait Posture</source>. <year>2010</year>;<volume>32</volume>: <fpage>650</fpage>–<lpage>655</lpage>. <pub-id pub-id-type="doi">10.1016/j.gaitpost.2010.09.010</pub-id>
<?supplied-pmid 20934876?><pub-id pub-id-type="pmid">20934876</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref005">
                <label>5</label>
                <mixed-citation publication-type="journal"><name><surname>Miall</surname><given-names>RC</given-names></name>, <name><surname>Haggard</surname><given-names>PN</given-names></name>, <name><surname>Cole</surname><given-names>JD</given-names></name>. <article-title>Evidence of a limited visuo-motor memory used in programming wrist movements</article-title>. <source>Exp Brain Res</source>. <year>1995</year>;<volume>107</volume>: <fpage>267</fpage>–<lpage>280</lpage>.
<?supplied-pmid 8773245?><pub-id pub-id-type="pmid">8773245</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref006">
                <label>6</label>
                <mixed-citation publication-type="journal"><name><surname>Hatzitaki</surname><given-names>V</given-names></name>, <name><surname>Konstadakos</surname><given-names>S</given-names></name>. <article-title>Visuo-postural adaptation during the acquisition of a visually guided weight-shifting task: age-related differences in global and local dynamics</article-title>. <source>Exp Brain Res</source>. <year>2007</year>;<volume>182</volume>: <fpage>525</fpage>–<lpage>535</lpage>.
<?supplied-pmid 17576545?><pub-id pub-id-type="pmid">17576545</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref007">
                <label>7</label>
                <mixed-citation publication-type="journal"><name><surname>Stergiou</surname><given-names>N</given-names></name>, <name><surname>Decker</surname><given-names>LM</given-names></name>. <article-title>Human movement variability, nonlinear dynamics, and pathology: is there a connection?</article-title><source>Hum Mov Sci</source>. <year>2011</year>;<volume>30</volume>: <fpage>869</fpage>–<lpage>888</lpage>. <pub-id pub-id-type="doi">10.1016/j.humov.2011.06.002</pub-id>
<?supplied-pmid 21802756?><pub-id pub-id-type="pmid">21802756</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref008">
                <label>8</label>
                <mixed-citation publication-type="journal"><name><surname>Stergiou</surname><given-names>N</given-names></name>, <name><surname>Harbourne</surname><given-names>R</given-names></name>, <name><surname>Cavanaugh</surname><given-names>J</given-names></name>. <article-title>Optimal movement variability: a new theoretical perspective for neurologic physical therapy</article-title>. <source>J Neurol Phys Ther</source>. <year>2006</year>;<volume>30</volume>: <fpage>120</fpage>–<lpage>129</lpage>.
<?supplied-pmid 17029655?><pub-id pub-id-type="pmid">17029655</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref009">
                <label>9</label>
                <mixed-citation publication-type="journal"><name><surname>Goldberger</surname><given-names>AL</given-names></name>, <name><surname>Rigney</surname><given-names>DR</given-names></name>, <name><surname>West</surname><given-names>BJ</given-names></name>. <article-title>Chaos and fractals in human physiology</article-title>. <source>Sci Am</source>. <year>1990</year>;<volume>262</volume>: <fpage>42</fpage>–<lpage>49</lpage>.
<?supplied-pmid 2343294?><pub-id pub-id-type="pmid">2343294</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref010">
                <label>10</label>
                <mixed-citation publication-type="journal"><name><surname>Buzzi</surname><given-names>UH</given-names></name>, <name><surname>Stergiou</surname><given-names>N</given-names></name>, <name><surname>Kurz</surname><given-names>MJ</given-names></name>, <name><surname>Hageman</surname><given-names>PA</given-names></name>, <name><surname>Heidel</surname><given-names>J</given-names></name>. <article-title>Nonlinear dynamics indicates aging affects variability during gait</article-title>. <source>Clin Biomech</source>. <year>2003</year>;<volume>18</volume>: <fpage>435</fpage>–<lpage>443</lpage>.
<?supplied-pmid 12763440?><pub-id pub-id-type="pmid">12763440</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref011">
                <label>11</label>
                <mixed-citation publication-type="journal"><name><surname>Goldberger</surname><given-names>AL</given-names></name>, <name><surname>Amaral</surname><given-names>LAN</given-names></name>, <name><surname>Hausdorff</surname><given-names>JM</given-names></name>, <name><surname>Ivanov</surname><given-names>PC</given-names></name>, <name><surname>Peng</surname><given-names>CK</given-names></name>, <name><surname>Stanley</surname><given-names>HE</given-names></name>. <article-title>Fractal dynamics in physiology: Alterations with disease and aging</article-title>. <source>Proc Natl Acad Sci USA</source>. <year>2002</year>;<volume>99</volume>: <fpage>2466</fpage>–<lpage>2472</lpage>.
<?supplied-pmid 11875196?><pub-id pub-id-type="pmid">11875196</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref012">
                <label>12</label>
                <mixed-citation publication-type="journal"><name><surname>Stepp</surname><given-names>N</given-names></name>, <name><surname>Turvey</surname><given-names>MT</given-names></name>. <article-title>On Strong Anticipation</article-title>. <source>Cogn Syst Res</source>. <year>2010</year>;<volume>11</volume>: <fpage>148</fpage>–<lpage>164</lpage>.
<?supplied-pmid 20191086?><pub-id pub-id-type="pmid">20191086</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref013">
                <label>13</label>
                <mixed-citation publication-type="journal"><name><surname>Stephen</surname><given-names>DG</given-names></name>, <name><surname>Stepp</surname><given-names>N</given-names></name>, <name><surname>Dixon</surname><given-names>JA</given-names></name>, <name><surname>Turvey</surname><given-names>MT</given-names></name>. <article-title>Strong anticipation: Sensitivity to long-range correlations in synchronization behavior</article-title>. <source>Physica A</source>. <year>2008</year>;<volume>387</volume>: <fpage>5271</fpage>–<lpage>5278</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0119828.ref014">
                <label>14</label>
                <mixed-citation publication-type="journal"><name><surname>Haworth</surname><given-names>JL</given-names></name>, <name><surname>Vallabhajosula</surname><given-names>S</given-names></name>, <name><surname>Stergiou</surname><given-names>N</given-names></name>. <article-title>Gaze and posture coordinate differently with the complexity of visual stimulus motion</article-title>. <source>Exp Brain Res</source>. <year>2014</year>; <volume>232</volume>: <fpage>2797</fpage>–<lpage>2806</lpage>. <pub-id pub-id-type="doi">10.1007/s00221-014-3962-5</pub-id>
<?supplied-pmid 24792502?><pub-id pub-id-type="pmid">24792502</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref015">
                <label>15</label>
                <mixed-citation publication-type="journal"><name><surname>Oullier</surname><given-names>O</given-names></name>, <name><surname>Bardy</surname><given-names>BG</given-names></name>, <name><surname>Stoffregen</surname><given-names>TA</given-names></name>, <name><surname>Bootsma</surname><given-names>RJ</given-names></name>. <article-title>Postural coordination in looking and tracking tasks</article-title>. <source>Hum Mov Sci</source>. <year>2002</year>;<volume>21</volume>: <fpage>147</fpage>–<lpage>167</lpage>.
<?supplied-pmid 12167296?><pub-id pub-id-type="pmid">12167296</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref016">
                <label>16</label>
                <mixed-citation publication-type="journal"><name><surname>Duarte</surname><given-names>M</given-names></name>, <name><surname>Zatsiorsky</surname><given-names>VM</given-names></name>. <article-title>Effects of body lean and visual information on the equilibrium maintenance during stance</article-title>. <source>Exp Brain Res</source>. <year>2002</year>;<volume>146</volume>: <fpage>60</fpage>–<lpage>69</lpage>.
<?supplied-pmid 12192579?><pub-id pub-id-type="pmid">12192579</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref017">
                <label>17</label>
                <mixed-citation publication-type="journal"><name><surname>Collewijn</surname><given-names>H</given-names></name>, <name><surname>Ferman</surname><given-names>L</given-names></name>, <name><surname>Van den Berg</surname><given-names>AV</given-names></name>. <article-title>The behavior of human gaze in three dimensions</article-title>. <source>Ann N Y Acad Sci</source>. <year>1988</year>;<volume>545</volume>: <fpage>105</fpage>–<lpage>127</lpage>.
<?supplied-pmid 3071205?><pub-id pub-id-type="pmid">3071205</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref018">
                <label>18</label>
                <mixed-citation publication-type="journal"><name><surname>Gibson</surname><given-names>JJ</given-names></name>. <article-title>The perception of visual surfaces</article-title>. <source>Am J Psychol</source>. <year>1950</year>;<volume>63</volume>: <fpage>367</fpage>–<lpage>384</lpage>.
<?supplied-pmid 15432778?><pub-id pub-id-type="pmid">15432778</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref019">
                <label>19</label>
                <mixed-citation publication-type="journal"><name><surname>Sofianidis</surname><given-names>G</given-names></name>, <name><surname>Hatzitaki</surname><given-names>V</given-names></name>, <name><surname>Grouios</surname><given-names>G</given-names></name>, <name><surname>Johannsen</surname><given-names>L</given-names></name>, <name><surname>Wing</surname><given-names>A</given-names></name>. <article-title>Somatosensory driven interpersonal synchrony during rhythmic sway</article-title>. <source>Hum Mov Sci</source>. <year>2012</year>;<volume>31</volume>: <fpage>553</fpage>–<lpage>566</lpage>. <pub-id pub-id-type="doi">10.1016/j.humov.2011.07.007</pub-id>
<?supplied-pmid 22742723?><pub-id pub-id-type="pmid">22742723</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref020">
                <label>20</label>
                <mixed-citation publication-type="journal"><name><surname>Suzuki</surname><given-names>Y</given-names></name>, <name><surname>Nomura</surname><given-names>T</given-names></name>, <name><surname>Casadio</surname><given-names>M</given-names></name>, <name><surname>Morasso</surname><given-names>P</given-names></name>. <article-title>Intermittent control with ankle, hip, and mixed strategies during quiet standing: a theoretical proposal based on a double inverted pendulum model</article-title>. <source>J Theor Biol</source>. <year>2012</year>; <volume>310</volume>: <fpage>55</fpage>–<lpage>79</lpage>. <pub-id pub-id-type="doi">10.1016/j.jtbi.2012.06.019</pub-id>
<?supplied-pmid 22732276?><pub-id pub-id-type="pmid">22732276</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref021">
                <label>21</label>
                <mixed-citation publication-type="journal"><name><surname>Collins</surname><given-names>JJ</given-names></name>, <name><surname>De Luca</surname><given-names>CJ</given-names></name>. <article-title>Random Walking during Quiet Standing</article-title>. <source>Phys Rev Lett</source>. <year>1994</year>;<volume>73</volume>: <fpage>764</fpage>–<lpage>767</lpage>.
<?supplied-pmid 10057531?><pub-id pub-id-type="pmid">10057531</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref022">
                <label>22</label>
                <mixed-citation publication-type="journal"><name><surname>Pincus</surname><given-names>S</given-names></name>, <name><surname>Singer</surname><given-names>BH</given-names></name>. <article-title>Randomness and degrees of irregularity</article-title>. <source>Proc Natl Acad Sci USA</source>. <year>1996</year>;<volume>93</volume>: <fpage>2083</fpage>–<lpage>2088</lpage>.
<?supplied-pmid 11607637?><pub-id pub-id-type="pmid">11607637</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref023">
                <label>23</label>
                <mixed-citation publication-type="journal"><name><surname>Hong</surname><given-names>SL</given-names></name>, <name><surname>Newell</surname><given-names>KM</given-names></name>. <article-title>Change in the organization of degrees of freedom with learning</article-title>. <source>J Mot Behav</source>. <year>2006</year>;<volume>38</volume>: <fpage>88</fpage>–<lpage>100</lpage>.
<?supplied-pmid 16531392?><pub-id pub-id-type="pmid">16531392</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref024">
                <label>24</label>
                <mixed-citation publication-type="journal"><name><surname>Born</surname><given-names>RT</given-names></name>, <name><surname>Pack</surname><given-names>CC</given-names></name>. <article-title>Integration of motion signals for smooth pursuit eye movements</article-title>. <source>Ann N Y Acad Sci</source>. <year>2002</year>;<volume>956</volume>: <fpage>453</fpage>–<lpage>455</lpage>.
<?supplied-pmid 11960838?><pub-id pub-id-type="pmid">11960838</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref025">
                <label>25</label>
                <mixed-citation publication-type="journal"><name><surname>Kowler</surname><given-names>E</given-names></name>. <article-title>Eye movements: the past 25 years</article-title>. <source>Vision Res</source>. <year>2011</year>;<volume>51</volume>: <fpage>1457</fpage>–<lpage>1483</lpage>. <pub-id pub-id-type="doi">10.1016/j.visres.2010.12.014</pub-id>
<?supplied-pmid 21237189?><pub-id pub-id-type="pmid">21237189</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref026">
                <label>26</label>
                <mixed-citation publication-type="journal"><name><surname>Simoncelli</surname><given-names>EP</given-names></name>, <name><surname>Olshausen</surname><given-names>BA</given-names></name>. <article-title>Natural image statistics and neural representation</article-title>. <source>Annu Rev Neurosci</source>. <year>2001</year>;<volume>24</volume>: <fpage>1193</fpage>–<lpage>1216</lpage>.
<?supplied-pmid 11520932?><pub-id pub-id-type="pmid">11520932</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref027">
                <label>27</label>
                <mixed-citation publication-type="journal"><name><surname>Schwartz</surname><given-names>O</given-names></name>, <name><surname>Simoncelli</surname><given-names>EP</given-names></name>. <article-title>Natural signal statistics and sensory gain control</article-title>. <source>Nat Neurosci</source>. <year>2001</year>;<volume>4</volume>: <fpage>819</fpage>–<lpage>825</lpage>.
<?supplied-pmid 11477428?><pub-id pub-id-type="pmid">11477428</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref028">
                <label>28</label>
                <mixed-citation publication-type="journal"><name><surname>Kaipust</surname><given-names>JP</given-names></name>, <name><surname>McGrath</surname><given-names>D</given-names></name>, <name><surname>Mukherjee</surname><given-names>M</given-names></name>, <name><surname>Stergiou</surname><given-names>N</given-names></name>. <article-title>Gait variability is altered in older adults when listening to auditory stimuli with differing temporal structures</article-title>. <source>Ann Biomed Eng</source>. <year>2013</year>;<volume>41</volume>: <fpage>1595</fpage>–<lpage>1603</lpage>. <pub-id pub-id-type="doi">10.1007/s10439-012-0654-9</pub-id>
<?supplied-pmid 22956164?><pub-id pub-id-type="pmid">22956164</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref029">
                <label>29</label>
                <mixed-citation publication-type="journal"><name><surname>Torre</surname><given-names>K</given-names></name>, <name><surname>Varlet</surname><given-names>M</given-names></name>, <name><surname>Marmelat</surname><given-names>V</given-names></name>. <article-title>Predicting the biological variability of environmental rhythms: Weak or strong anticipation for sensorimotor synchronization?</article-title><source>Brain Cogn</source>. <year>2013</year>;<volume>83</volume>: <fpage>342</fpage>–<lpage>350</lpage>. <pub-id pub-id-type="doi">10.1016/j.bandc.2013.10.002</pub-id>
<?supplied-pmid 24212115?><pub-id pub-id-type="pmid">24212115</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref030">
                <label>30</label>
                <mixed-citation publication-type="journal"><name><surname>Vorberg</surname><given-names>D</given-names></name>, <name><surname>Schulze</surname><given-names>HH</given-names></name>. <article-title>Linear phase-correction in synchronization: Predictions, parameter estimation, and simulations</article-title>. <source>J Math Psychol</source>. <year>2002</year>;<volume>46</volume>: <fpage>56</fpage>–<lpage>87</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0119828.ref031">
                <label>31</label>
                <mixed-citation publication-type="book"><name><surname>Vorberg</surname><given-names>D</given-names></name>, <name><surname>Wing</surname><given-names>A</given-names></name>. <chapter-title>Modeling variability and dependence in timing</chapter-title> In: <name><surname>Keele</surname><given-names>IHHSW</given-names></name>, editor. <source>Handbook of Perception and Action</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Academic Press</publisher-name>; <year>1996</year> pp. <fpage>181</fpage>–<lpage>262</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0119828.ref032">
                <label>32</label>
                <mixed-citation publication-type="journal"><name><surname>Maioli</surname><given-names>C</given-names></name>, <name><surname>Falciati</surname><given-names>L</given-names></name>, <name><surname>Gianesini</surname><given-names>T</given-names></name>. <article-title>Pursuit eye movements involve a covert motor plan for manual tracking</article-title>. <source>J Neurosci</source>. <year>2007</year>;<volume>27</volume>: <fpage>7168</fpage>–<lpage>7173</lpage>.
<?supplied-pmid 17611270?><pub-id pub-id-type="pmid">17611270</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref033">
                <label>33</label>
                <mixed-citation publication-type="journal"><name><surname>Stoffregen</surname><given-names>TA</given-names></name>, <name><surname>Hove</surname><given-names>P</given-names></name>, <name><surname>Schmit</surname><given-names>J</given-names></name>, <name><surname>Bardy</surname><given-names>BG</given-names></name>. <article-title>Voluntary and involuntary postural responses to imposed optic flow</article-title>. <source>Motor Control</source>. <year>2006</year>;<volume>10</volume>: <fpage>24</fpage>–<lpage>33</lpage>.
<?supplied-pmid 16571906?><pub-id pub-id-type="pmid">16571906</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref034">
                <label>34</label>
                <mixed-citation publication-type="journal"><name><surname>Giveans</surname><given-names>MR</given-names></name>, <name><surname>Yoshida</surname><given-names>K</given-names></name>, <name><surname>Bardy</surname><given-names>B</given-names></name>, <name><surname>Riley</surname><given-names>M</given-names></name>, <name><surname>Stoffregen</surname><given-names>TA</given-names></name>. <article-title>Postural Sway and the Amplitude of Horizontal Eye Movements</article-title>. <source>Ecological Psychology</source>. <year>2011</year>; <volume>23</volume>: <fpage>247</fpage>–<lpage>266</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0119828.ref035">
                <label>35</label>
                <mixed-citation publication-type="journal"><name><surname>Jeka</surname><given-names>J</given-names></name>, <name><surname>Allison</surname><given-names>L</given-names></name>, <name><surname>Saffer</surname><given-names>M</given-names></name>, <name><surname>Zhang</surname><given-names>YF</given-names></name>, <name><surname>Carver</surname><given-names>S</given-names></name>, <name><surname>Kiemel</surname><given-names>T</given-names></name>. <article-title>Sensory reweighting with translational visual stimuli in young and elderly adults: the role of state-dependent noise</article-title>. <source>Exp Brain Res</source>. <year>2006</year>;<volume>174</volume>: <fpage>517</fpage>–<lpage>527</lpage>.
<?supplied-pmid 16724180?><pub-id pub-id-type="pmid">16724180</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref036">
                <label>36</label>
                <mixed-citation publication-type="journal"><name><surname>West</surname><given-names>BJ</given-names></name>, <name><surname>Grigolini</surname><given-names>P</given-names></name>. <article-title>The living matter way to exchange information</article-title>. <source>Med Hypotheses</source>. <year>2010</year>;<volume>75</volume>: <fpage>475</fpage>–<lpage>478</lpage>. <pub-id pub-id-type="doi">10.1016/j.mehy.2010.04.028</pub-id>
<?supplied-pmid 20493639?><pub-id pub-id-type="pmid">20493639</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref037">
                <label>37</label>
                <mixed-citation publication-type="journal"><name><surname>Cavanaugh</surname><given-names>JT</given-names></name>, <name><surname>Kochi</surname><given-names>N</given-names></name>, <name><surname>Stergiou</surname><given-names>N</given-names></name>. <article-title>Nonlinear Analysis of Ambulatory Activity Patterns in Community-Dwelling Older Adults</article-title>. <source>Gerontol A Biol Sci Med Sci</source>. <year>2010</year>;<volume>65</volume>: <fpage>197</fpage>–<lpage>203</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0119828.ref038">
                <label>38</label>
                <mixed-citation publication-type="journal"><name><surname>Hausdorff</surname><given-names>JM</given-names></name>, <name><surname>Mitchell</surname><given-names>SL</given-names></name>, <name><surname>Firtion</surname><given-names>R</given-names></name>, <name><surname>Peng</surname><given-names>CK</given-names></name>, <name><surname>Cudkowicz</surname><given-names>ME</given-names></name>, <name><surname>Wei</surname><given-names>JY</given-names></name>, <etal>et al</etal><article-title>Altered fractal dynamics of gait: Reduced stride-interval correlations with aging and Huntington's disease</article-title>. <source>J Appl Physiol</source>. <year>1997</year>;<volume>82</volume>: <fpage>262</fpage>–<lpage>269</lpage>.
<?supplied-pmid 9029225?><pub-id pub-id-type="pmid">9029225</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0119828.ref039">
                <label>39</label>
                <mixed-citation publication-type="journal"><name><surname>Hove</surname><given-names>MJ</given-names></name>, <name><surname>Suzuki</surname><given-names>K</given-names></name>, <name><surname>Uchitomi</surname><given-names>H</given-names></name>, <name><surname>Orimo</surname><given-names>S</given-names></name>, <name><surname>Miyake</surname><given-names>Y</given-names></name>. <article-title>Interactive rhythmic auditory stimulation reinstates natural 1/f timing in gait of Parkinson's patients</article-title>. <source>PLoS One</source>. <year>2012</year>;<volume>7</volume>: <fpage>e32600</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0032600</pub-id><?supplied-pmid 22396783?><pub-id pub-id-type="pmid">22396783</pub-id></mixed-citation>
              </ref>
            </ref-list>
          </back>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
